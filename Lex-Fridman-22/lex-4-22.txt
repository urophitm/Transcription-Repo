The following is a conversation with Yosha Bach, VP of Research at the AI Foundation with the history of research positions at MIT and Harvard. Yosha is one of the most unique and brilliant people in the artificial intelligence community, exploring the workings of the human mind, intelligence, consciousness, life on earth, and the possibly simulated fabric of our universe. I can see myself talking to Yosha many times in the future. Quick summary of the ads. Two sponsors. ExpressVPN and CashApp. Please consider supporting the podcast by signing up at expressvpn.com slash Lex Pod and the online and cashapp and using code Lex Podcast. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, review it with five stars and half a podcast, support it on Patreon, or simply connect with me on Twitter at Lex Friedman. Since this comes up more often than I ever would have imagined, I challenge you to try to figure out how to spell my last name without using the letter E. And it'll probably be the correct way. As usual, I'll do a few minutes of ads now and never in the middle that can break the flow of the conversation. This shows sponsored by ExpressVPN. Get it at expressvpn.com slash Lex Pod to support this podcast and to get an extra three months free on a one-year package. I've been using ExpressVPN for many years. I love it. I think ExpressVPN is the best VPN out there. They told me to say it, but I think it actually happens to be true. It doesn't log your data. It's crazy fast and it's easy to use literally just one big power on button. Again, for obvious reasons, it's really important that they don't log your data. It works on Linux and everywhere else too. Shout out to my favorite flavor of Linux of Bantu Mate 204. Once again, get it at expressvpn.com slash Lex Pod to support this podcast and to get an extra three months free on a one-year package. This show is presented by CashApp, the number one finance app in the app store. When you get it, use code LexPodcast. CashApp lets you send money to friends by Bitcoin and invest in the stock market with as little as $1. Since CashApp does fractional share trading, let me mention that the order execution algorithm that works behind the scenes to create the abstraction of the fractional orders is an algorithmic marvel. So big props to the CashApp engineers for taking a step up to the next layer of abstraction over the stock market, making trading more accessible for new investors and diversification much easier. So again, if you get CashApp from the app store Google Play and use the code LexPodcast, you get $10. And CashApp will also donate $10. First, an organization that is helping advance robotics and STEM education for young people around the world. And now, here's my conversation with Yosha Bach. As you've said, you grew up in a forest in East Germany, just as we were talking about off my two parents who were artists. And now I think, at least to me, you've become one of the most unique thinkers in the AI world. So can we try to reverse engineer your mind a little bit? What were the key philosophers, scientists, ideas, maybe even movies or just realizations that impact on you when you're growing up that kind of led to the trajectory or were the key sort of crossroads in the trajectory of your intellectual development? My father came from a long tradition of architects, distant branch of the Bach family. And so basically he was technically a nerd. And nerds need to interface in society with non-standard ways. Sometimes I define a nerd as somebody who thinks that the purpose of communication is to submit your ideas to peer review. And normal people understand that the primary purpose of communication is to negotiate alignment. And these purposes tend to conflict, which means that nerds have to learn how to interact with society at large. Who is the reviewer in the nerd's view of communication? Everybody who will consider to be a peer. So whatever hapless individual is around, well you would try to make him or her the gift of information. Okay. So you're not by the way my research will malenformed me. So you're architect artist. So he did study architecture. But basically my grandfather made the wrong decision. He married an aristocrat and was drawn into the war. And he came back after 15 years. So basically my father was not parented by a nerd, by somebody who tried to tell him what to do and expected him to do what he was told. And he was unable to. He's unable to do things if he's not intrinsically motivated. So in some sense, my grandmother broke her son and her son responded by when he became an architect to become an artist. So he built 100 vassar architecture. He built houses without right angles. He built lots of things that didn't work in the more brutalist traditions of Eastern Germany. And so he bought an old water mill moved out to the countryside and did only what he wanted to do, which was art. Eastern Germany was perfect for Bohem because you had complete material safety. Put was heavily subsidized. Haska was free. You didn't have to worry about rent or pensions or anything. So socialized communist side of memory. And the other thing is it was almost impossible not to be in political disagreement with your government, which is very productive for artists. So everything that you do is intrinsically meaningful because it will always touch on the deeper currents of society, of culture and being conflict with it and tension with it. And you will always have to define yourself with respect to this. So what impact did your father this outside the outside of the box thinker against the government against the world artists have actually not a thinker. He was somebody who only got self-aware to the degree that he needed to make himself functional. So in some sense, he was also late 1960s and he was in some sense a hippie. So he became a one person cult. He lived out there in his kingdom. He built big sculpture gardens and started many avenues of art and so on and convinced a woman to live with him. She was also an architect and she adored him and decided to share her life with him. And I basically grew up in a big cave full of books. I'm almost feral and I was bored out there. It was very, very beautiful, very quiet and quite lonely. So I started to read and by the time I came to school, I read everything until fourth grade and then some and there was not a real way for me to relate to the outside world. And I couldn't quite put my finger on why and today I know it was because I was a nerd obviously and it was the only nerd around. So there was no other kids like me and there was nobody interested in physics or computing or mathematics and so on. And this village school that I went to was basically a nice school. Kids were nice to me. I was not beaten up but I also didn't make many friends or built deep relationships. They only happened in starting from ninth grade when I went to a school for mathematics and physics. Do you remember any key books from the small myself? Basically read everything. So I went to the library and I worked my way through the children's and young adult sections and then I read a lot of science fiction. For instance, Dani's left lamb basically the great author of cybernetics has influenced me back then I didn't see him as a big influence because everything that he wrote seemed to be so natural to me. And so only later that I contrasted it with what other people wrote. Another thing that was very influential on me were the classical philosophers and also the literature of romanticism. So German poetry and art trust the hills off and Hainer and up to Heisse and so on. I love Heisse. So at which point do the classical philosophers end at this point when the 21st century what's the latest classical philosopher? Does this stretch through even as far as Nietzsche or is this I were talking about Plato and Nerothalyn? I think that Nietzsche is the classical equivalent of a shit poster. So he's a classical troll. He's easy to read. But he's not so much trolling others. He's trolling himself because he was at Orts, Westerville, largely his romantic relationships didn't work out. He got angry and he basically became an analyst. And it's not a beautiful way to be as an intellectual is to constantly be trolling yourself to be in that conflict in that no. I think it's like of self-evidence. At some point you have to understand the comedy of your own situation. If you take yourself seriously and you are not functional it ends in tragedy as it did for Nietzsche. I think you think he took himself to seriously in that tension. And it's like the same thing in Hesse and so on this steppenwolf syndrome is classic, a dollar sense where you basically feel misunderstood by the world and you don't understand that all the misunderstandings are the result of your own lack of self-evidence because you think that you are a prototypical human and the others around you should behave the same way as you expect them based on your innate instincts and it doesn't work out. And you become a transcendentalist to deal with that. So it's very, very understandable and have great sympathies for this to the degree that I can have sympathy for my own intellectual history. But you have to grow out of it. So as an intellectual life well lived a journey while travel is one where you don't take yourself seriously. No, I think that you need a serious or not serious yourself because you need to become unimportant as a subject that is if you are a philosopher belief is not a verb. You don't do this what the audience you don't do it for yourself. You have to submit to the things that are possibly true and you have to follow wherever your inquiry relates but it's not about you. It has nothing to do with you. So do you think then people like I and Rand believe it's sort of an idea of there's objective truth. So what's your sense in the philosophical if you remove yourself that's objective from the picture you think it's possible to actually discover ideas that are true or we just in a measure relative concepts that are either true nor false it's just a giant mess. You cannot define objective truth without understanding the nature of truth in the first place. So what does the brain mean by saying that discovers something is true. So for instance a model can be predictive or not predictive. Then there can be a sense in which a mathematical statement can be true because it's defined as true under certain conditions. So it's basically a particular state that a variable can have in a simple game and then you can have a correspondence between systems and talk about truth which is again a type of model correspondence and that also seems to be a particular kind of ground truth. So for instance you're confronted with the enormity of something existing at all right that's stunning when you realize something exists rather than nothing and this seems to be true right there's an absolute truth and in the fact that something seems to be happening. Yeah that's that that teammates are showstopper I could just think about that idea be amazed by that for the rest of my life and not going you further because I don't even know the answer to that. Why does anything exist at all? Well the easiest answer is existence is the default right so this is the lowest number of pits that you would need to encode this whose answer who brought the simplest answer to this is that existence is the default. What about non-existence I mean that seems non-existence might not be a meaningful notion in this sense. So in some sense if everything that can exist exists for something to exist it probably needs to be implementable. The only thing that can be implemented is finite automata so maybe the whole of existence is the superposition of all finite automata and we are in some region of the fractal that has the properties that it can contain us. What does it mean to be a superposition of finite so I wish superposition of all like all possible rules. Imagine that every automaton is basically an operator that acts on some substrate and as a result you get emergent patterns. What's the substrate? I have no idea to know so it's based on some substrate. It's something that can store information. Something like a store information there's a automaton of all. Something that can hold state. Still doesn't make sense to me the why that exists at all. I could just sit there with the with a beer or a vodka and just enjoy the fact pondering the why. It may not have a why. This might be the wrong direction to ask into this so there could be no relation in the wide direction without asking for a purpose or for a cause. It doesn't mean that everything has to have a purpose or a cause. We mentioned some philosophers in that early just taking a brief step back into into that. We asked ourselves when the classical philosophy end. I think for Germany it largely ended with the first revolution. That's basically when we ended the monarchy. And started a democracy. At this point we basically came up with a new form of government that didn't have a good sense of this new organism that society wanted to be and in a way it decapitated the universities. So the universities went on so modernism like a headless chicken. At the same time democracy failed in Germany and we got fascism as a result. It burned down things in the similar way as Stalinism burned down intellectual traditions in Russia. Germany, both Germany's have not recovered from this. Eastern Germany had this vulgar dialectic materialism and West and Germany didn't get much more edgy than Habermass. So in some sense both countries lost their intellectual traditions and killing off and driving out the Jews didn't have. Yeah so that was the end. That was the end of really rigorous all you would say is classical classical philosophy. There's also this thing that in some sense the low hanging foods in philosophy were mostly wrapped. And the last big things that we discovered was the constructives turned in mathematics. So to understand that the parts of mathematics that work are computation there was very significant discovery in the first half of the 20th century and it hasn't fully permeated philosophy and even physics yet. Physicists checked out the code libraries from mathematics before constructivism became universal. What's constructivism? What are your friends of girls and completeness there and those kinds of ideas? So basically Gurdel himself I think didn't get it yet. Hilbert could get it. Hilbert saw that for instance a country's sets theoretic experiments and mathematics led into contradictions and he noticed that with the current semantics we cannot build a computer and mathematics that runs mathematics without crashing. And Gurdel could prove this. And so what Gurdel could show is using classical mathematical semantics you run into contradictions and because Gurdel strongly believed in these semantics and more than in what he could observe and so on he was shocked. It basically shook his world to the core because in some sense he felt that the world has to be implemented in classical mathematics. And for Turing it wasn't quite so bad. I think that Turing could see that the solution is to understand the question mathematics was computation all along which means your for instance pi and classical mathematics is a value. It's also a function but it's the same thing and in computation a function is only a value when you can compute it. And if you cannot compute the last digit of pi you only have a function. You can plug this function into your local sign. You let the dryn and all the sun burns out. This is it. This is the last digit of pi you will know. But it also means that there can be no process in the physical universe or any physically realized computer that depends on having known the last digit of pi. Yes. Which means there are parts of physics that are defined and such a way that cannot strictly be true because assuming that this could be true leads into contradictions. So I think putting in computation at the center of the the world view is actually the right way to think about it. Yes. And Wittgenstein could see it and Wittgenstein basically preempted the logitous program of AI that Minsk started later like 30 years later. Turing was actually a pupil of Wittgenstein. Really? I didn't know there's any connection. Yeah. Wittgenstein even cancelled some classes when Turing was not present because he thought was not worth spending the time on the process. Interesting. And if you read the Tractatus it's a very beautiful book. Like a piece of one sort on 75 pages. It's very non-typical for philosophy because it doesn't have arguments in it and it doesn't have references in it. It's just one thought that is not intending to convince anybody. He says it's mostly for people that had the same insight as me. Just spell it out. And this insight is there is a way in which mathematics and philosophy ought to meet. Mathematics tries to understand the domain of all languages by starting with those that are so formalizable that you can prove all the properties of the statements that you make. But the price that you pay is that your language is very very simple. So it's very hard to say something meaningful in mathematics. Yes. And it looks complicated to people but it's far less complicated than what our brain is casually doing all the time. It makes sense of reality. That's right. And philosophy is coming from the top. So it's mostly starting from natural languages which vaguely define concepts. And the hope is that mathematics and philosophy can meet at some point. And Wittgenstein was trying to make them meet and he already understood that for instance you could express everything with the non-calculus that you could reduce the entire logic to non-gates as we do on our modern computers. So in some sense you already understood Turing's universality before Turing spelled it out. I think when he wrote the track titles he didn't understand yet that the idea was so important and significant. And as a suspect then when Turing wrote it out nobody cared that much. Turing was not that famous when he lived it was mostly his work in decrypting the German codes that made him famous or gave him some notoriety but the same status that he has to computer science right now. And yeah I something that I think he got acquired later. That's kind of interesting. Do you think of computation and computer science? And you kind of represent that to me is maybe that's the modern day you in a sense are the new philosopher by sort of the computer scientist who dares to ask the bigger questions that philosophy originally started is the new philosopher. Certainly not me I think I'm mostly still this child that grows up in a very beautiful valley and looks at the world from the outside and tries to understand what's going on. And my teachers tell me things and they largely don't make sense. So I have to make my own models. I have to discover the foundations of what the others are saying. I have to try to fix them to be charitable. I try to understand what they must have thought originally or what their teachers or their teachers teachers must have thought until everything got lost in translation and how to make sense of the reality that we are in. And whenever I have an original idea I'm usually late to the party by say 400 years. And the only thing that's good is that the parties get smaller and smaller the older I get in the more explore. The party the parties get smaller and more exclusive and more exclusive. So it seems like one of the key qualities of your upbringing was that you were not tethered whether it's because of your parents or in general maybe you're something within your within your mind some genetic material. They were not tethered to the ideas of the general populace which is actually a unique property. We're kind of throughout the education system and whatever from that education system just existing in this world forces a certain sets of ideas on to you. Can you disentangle that? Why were you why are you not so tethered even in your work today? You seem to not care about perhaps a best paper in Europe's right being tethered to particular things that current today in this year people seem to value as a thing you put on your CV and resume. You're a little bit more outside of that world outside of the world of ideas that people are especially focusing the benchmarks of today the things what's can you disentangle that? Because I think that's inspiring and if there were more people like that we might be able to solve some of the bigger problems that sort of AI dreams to solve. And that's a big danger in this because in a way you are expected to marry into an intellectual tradition and visit this tradition into a particular school. If everybody comes up with their own paradigms the whole thing is not cumulative as an enterprise. So in some sense you need a healthy balance you need paradigmatic thinkers and you need people that work within given paradigms. Basically scientists today define themselves largely by methods and it's almost a disease that we think is the scientist that somebody who was convinced by their guidance counselor that they should join a particular discipline and then they find a good mentor to learn the right methods and then they're lucky enough and privileged enough to join the right team and then their name will show up on influential papers. But we also see that there are diminishing returns with this approach. And when our field computer science and AI started most of the people that joined this field had interesting opinions. And today's thinkers and AI either don't have interesting opinions at all or these opinions are inconsequential for what they're actually doing because what they're doing is they apply the state of the art methods with a small epsilon. And this is often a good idea if you think that this is the best way to make progress. And for me it's first of all very boring if somebody else can do it why should I do it? If the current methods of machine learning lead to a strong AI why should I be doing it? Well just wait until they're done and wait until they do this on the beach or read interesting books or write some and have fun. But if you don't think that we are currently doing the right thing if we are missing some perspectives then it's required to think outside of the box. It's also required to understand the boxes. But it's necessary to understand what worked and what didn't work and for what reasons. So you have to be willing to ask new questions and design new methods whenever you want to answer them. And you have to be willing to dismiss the existing methods if you think that they're not going to yield the right answers. It's very bad career advice to do that. So maybe to briefly stay for one more time in the early days. When would you say for you was the dream before we dive into the discussions that we just almost started? When was the dream to understand or maybe to create human level intelligence born for you? I think that you can see AI largely today as advanced information processing. If you would change the acronym of AI into that most people in the field would be happy. It would not change anything what they're doing. We are automating statistics and when you of the statistical models are more advanced than what statisticians had in the past and it's pretty good work. It's very productive. The other aspect of AI is philosophical project. This philosophical project is very risky very few people work on it and it's not clear if it succeeds. Keep throwing a lot of interesting ideas and I have to pick which ones we go with. First of all, you use the term information processing just information processing as if it's the mere mock of existence as if it's the pitemy of the entire universe, maybe information processing that consciousness and intelligence might be information processing. So maybe you can comment on if the advanced information processing is a limiting kind of round of ideas and then the other one is what do you mean by the philosophical project? So I suspect that general intelligence is the result of trying to solve general problems. Intelligence I think is the ability to model. It's not necessarily gold-directed rationality or something. Many intelligent people are bad at this but it's the ability to be presented with a number of patterns and see a structure in those patterns and be able to predict the next set of patterns to make sense of things. And some problems are very general. Usually intelligence serves control so you make these models for a particular purpose of interacting as an agent with the world and getting certain results but the intelligence itself is in the sense instrumental to something but by itself it's just the ability to make models and some of the problems are so general that the system that makes them needs to understand what itself is and how it relates to the environment. So as a child for instance you notice you do certain things despite you perceiving yourself as wanting different things. So you become aware of your own psychology. You become aware of the fact that you have complex structure in yourself and you need to model yourself to reverse engineer yourself to be able to predict how you will react to certain situations and how you deal with yourself in relationship to your environment. And this process, if this project, if you reverse engineer yourself in your relationship to reality in the nature of a universe that can continue, if you go all the way, this is basically the project of AI or you could say the project of AI is a very important component in it. The tutoring test in a way is you ask a system what is intelligence. If that system is able to explain what it is how it works then you would assign it the property of being intelligent in this general sense. So the test that you were was administering in a way. I don't think that he couldn't see it but he didn't express it yet in the original 1950 paper is that he was trying to find out whether he was generally intelligent because in order to take this test the rap is of course you need to be able to understand what that system is saying. And we don't yet know if we can build an AI, we don't yet know if we are generally intelligent. Basically you win the tutoring test by building an AI. Yes. So in a sense hidden within the tutoring test is a kind of recursive test. Yes, it's a test on us. The tutoring test is basically a test of the conjecture where the people are intelligent enough to understand themselves. Okay, but you also mentioned a little bit of a self-awareness and the project of AI, do you think this kind of emergent self-awareness is one of the fundamental aspects of intelligence? As opposed to goal oriented, you said kind of puzzle solving is coming to grips with the idea that you're an agent in the world. And like, find that many highly intelligent people are not very self-aware. Right? So self-awareness and intelligence are not the same thing. And you can also be self-aware if you have what priors especially without being especially intelligent. So you don't need to be very good at solving puzzles if the system that you are already implement the solution. But I do find intelligence. So you kind of mentioned children, right? Is that the fundamental project of AI is to create the learning system that's able to exist in the world? So you kind of drew a difference in self-awareness and intelligence. And yet you said that the self-awareness seems to be important for children. So I call this ability to make sense of the world and your own place. And so to make you able to understand what you're doing in this world, sentience. And I would distinguish sentience from intelligence because sentience is processing certain classes of models. And intelligence is a way to get to these models if you don't already have them. I say so. Can you maybe pause a bit and try to answer the question that we just said we may not be able to answer. And it might be a recursive meta question of what is intelligence. And I think that intelligence is the ability to make models. So models. I think it's useful as examples, very popular now neural networks, form representations of large scale data sets. They form models of those data sets. When you say models and look at today's neural networks, what are the difference of how you're thinking about what is intelligent in saying that intelligence is the process of making models? Two aspects to this question. One is the representation as the representation adequate for the domain that we want to represent. And the other one is the type of the model that you arrive at adequate. So basically, are you modeling the correct domain? And I think in both of these cases, modern AI is lacking still. And I think that I'm not saying anything new here. I'm not criticizing the field. Most of the people that design our paradigms are aware of that. And so one aspect that we're missing is unified learning. When we learn, we at some point discover that everything that we sense is part of the same object, which means we learn it all into one model. And we call this model the universe. So our experience of the world that we are embedded on is not a secret direct via to physical reality. Physical reality is a view at quantum graph that we can never experience or get access to. But it has this properties that it can create certain patterns that our systemic interface to the world. And we make sense of these patterns and the relationship between the patterns that we discover is what we call the physical universe. So at some point in our development is a nervous system. We discover that everything that we relate to in the world can be mapped to a region in the same three dimensional space by and large. We now know in physics that is not quite true. Well, it's not actually three dimensional. But the world that we are entangled with at the level which we are entangled with is largely a flat three dimensional space. And so this is the model that our brain is intuitively making. And this is I think what gave rise to this intuition of rest extensor of this material world, this material domain. It's one of the mental domains. But it's just the class of all models that relate to this environment, this three dimensional physics engine in which we are embedded. Physics engine was embedded. I love that. Right. It's just slowly paused. So the quantum graph, I think you called which is the real world which you can never get access to. There's a bunch of questions that I want to sort of disentangle that. But maybe one useful one of your recent talks I looked at, can you just describe the basics? Can you talk about what is dualism? What is idealism? What is materialism? What is functionalism? And what connects with you most in terms of because you just mentioned there's a reality we don't have access to. Okay. What does that even mean? And why don't we get access to it? And we part of that reality? Why can't we access it? So the particular trajectory that mostly exists in the West is the result of our indoctrination by a cut for two thousand years. A cut which point? Yes, yes. And for better overs, right? It has created or defined many of the modes of interaction that we have that have created this society. But it has also in some sense scarred our rationality. And the intuition that exists if you would translate the mythology of the Catholic Church into the modern world is that the world in which you and me interact is something like a multiplayer role-playing adventure. And the money and the objects that we have in this world is all not real. Or Eastern philosophers would say it's my eye. It's just stuff that is it appears to be meaningful and this embedding in this meaning and people leaving it is samsara. It's basically the identification with the needs of the mundane secular everyday existence. And the Catholics also introduced a notion of higher meaning, the sacred. And this existed before, but eventually the natural shape of God is the platonic form of the civilization that you're part of. It's basically the super organism that is formed by the individuals as an intentional agent. And basically the Catholics used a relatively crude mythology to implement software on the minds of people and get the software synchronized to make them walk on lockstep to basically get this got online and to make it efficient and effective. And I think God technically is just a self that spends multiple brains as opposed to your and myself which mostly exists just on one brain. And so in some sense you can construct a self functionally as a function that is implemented by brains that exists across brains. And this is a God with a small G. That's one of the if you look you've all heard kind of talking about this is one of the nice features of our brains. It seems to that we can all download the same piece of software like God in this case and kind of share it. Yeah so man you give everybody a spec and the mathematical constraints that are intrinsic to information processing make sure that given the same spec you come up with a compatible structure. Okay so that's there's the space of ideas that we'll share and we think that's kind of the mind. But that's separate from the idea is from from Christianity for from religion is that there's a separate thing between the mind. There is a real world and this real world is the world in which God exists. God is the quarter of the multi player adventure so to speak and we are all players in this game. And that's dualism you would say. But the dualism aspect is because the mental realm is exists in a different implementation than a physical realm. And the mental realm is real. And a lot of people have this intuition that there is this real room in which you meet talk and speak right now. Then comes a layer of physics and abstract rules and so on. And then comes another real room where our souls are and our tool form is and the thing that gives us phenomenal experience. And this of course a very confused notion that you would get. And it's basically it's the result of connecting materialism and idealism in the wrong way. So okay I apologize but I think it's really helpful if we just try to define tried to define terms like what is dualism what is idealism what is materialism for people don't know. So the idea of dualism in our cultural tradition is that there are two substance as a mental substance and a physical substance and they interact by different rules. And the physical world is basically causally closed and is built on a low level causal structure. So they're basically a bottom level that is causally closed that's entirely mechanical and mechanical in the widest sense. So it's computational. There's basically a physical world in which information flows around and physics describes the laws of how information flows around in the child. Would you compare it to like a computer or you have a hardware and software? The computer is a generalization of information flowing around basically but you weren't discovered that there is the universal principle you can define this universal machine that is able to perform all the computations. So all these machines have the same power. This means that you can always define a translation between them as long as they have unlimited memory to be able to perform each other's computations. So would you then say that materialism is this whole world is just the hardware and idealism is this whole world is just a software? Not quite. I think that most idealists don't have a notion of software yet because software also comes down to information processing. So what you notice is the only thing that is real to you and me is this experiential world in which things matter, in which things have taste, in which things have color, phenomenal content and so on. And you are bringing up consciousness. And this is distinct from the physical world in which things have values only in an abstract sense and you only look at cold patterns moving around. So how does anything feel like something and this connection between the two things is very puzzling to a lot of people of course, too many philosophers. So idealism starts out with the notion that mind is primary, materialism, things that matter as primary. And so for the idealist, the material patterns that we say playing out are part of the dream that a mind is dreaming and we exist in a mind on a higher plane of existence if you want. And for the materialist, there is only this material thing and that generates some models and we are the result of these models. And in some sense, I don't think that we should understand, if you understand it properly, materialism and idealism is a dichotomy but there's two different aspects of the same thing. So the weird thing is we don't exist in the physical world. We do exist inside of a story that the brain tells itself. Okay, let me, let me, let me, my, my information processing take that in. We don't exist in the physical world. We exist in the narrative. Basically, a brain cannot feel anything. New York cannot feel anything. Their physical things, physical systems are unable to experience anything. But it would be very useful for the brain or for the organism to know what it would be like to be a person and to feel something. The brain creates a similar lack of such a person that it uses to model the interactions of the person. It's the best model of what that brain, this organism thinks it is in relationship to its environment. So it creates that model. It's a story, a multimedia novel that the brain is continuously writing and updating. But you also kind of said that you said that we kind of exist in that story. That story. What is real in any of this? So like there's a, again, these terms are, you kind of said there's a quantum graph. I mean, what is, what is this whole thing running on then? Is the story and is completely fundamentally impossible to get access to it? Isn't the story supposed to, isn't the brain in something in existing in some kind of context? So what we can identify as computer scientists, we can engineer systems and test our theories this way that might have the necessary insufficient properties to produce the phenomena that we are observing, which is the self in a virtual world that is generated in some bodies in your cortex that is contained in the skull of this primate here. And when I point at this, this indexicality is of course wrong. But I do create something that is likely to give rise to patterns on your retina that allow you to interpret what I'm saying, right? But we both know that the world that you and me are seeing is not the real physical world. What we are seeing is a virtual reality generated in your brain to explain the patterns on your retina. How close is it to the real world? That's kind of the question. Is it when you have people like Donald Hoffman, let's say that you're really far away. The thing we're seeing you and I now that interface we have is very far away from anything. We don't even have anything close to the sense of what the real world is. Or is it a very surface piece of architecture? Imagine you look at a mental board right? This famous thing that Bernabéin Mandebrot discovered. If you see an overall shape in there right, but you know, if you truly understand it, you know it's two lines of code. It's basically in a series that is being tested for complex numbers and in the complex number plane for every point. And for those where this series is diverging, you paint this black. And where it's converging, you don't. And you get the intermediate colors by taking how far it diverges. Yes. This gives you this shape of this fractal. But imagine you live inside of this fractal and you don't have access to where you are in the fractal or you have not discovered the generator function even. So what you see is all I can see right now is this viral. And this viral moves a little bit to the right. Is this an accurate model of reality? Yes, it is. It is an adequate description. You know that there is actually no spiral in the mental board fractal. It only appears like this to an observer that is interpreting things as a two dimensional space and then defines certain irregularities in there at a certain scale that it currently observes. Because if you zoom in, this viral might disappear and turn out to be something different at the different resolution, right? Yes. So at this level, you have this viral. And then you discover this viral moves to the right and some point it disappears. So you have a singularity. At this point, your model is no longer valid. You cannot predict what happens beyond the singularity. But you can observe again and you will see it hit another spiral. And at this point, it disappeared. So maybe now have a second order law. And if you make 30 layers of these laws, then you have a description of the world that is similar to the one that we come up with when we describe the reality around us. It's reasonably predictive. It does not cut to the core of it. It's not explained how it's being generated. How it actually works. But it's relatively good to explain the universe that you're entangled with. But you don't think the tools of computer science that the tools of physics could get could step outside, see the whole drawing and get at the basic mechanism of how the pattern, the spirals, the generated. Imagine you would find yourself embedded into a model bot fragile and you try to figure out what works and you have some however, throwing machine. There's enough memory to think. And as a result, you come to this idea. It must be some kind of automaton. And maybe you just enumerate all the possible automata until you get to the one that produces your reality. So you can identify necessary and sufficient condition. For instance, we discover that mathematics itself is the domain of all languages. And then we see that most of the domains of mathematics that we have discovered are in some sense describing the same fractals. This is what category theory is obsessed about that you can map these different domains to each other. So they're not that many fractals. And some of these have interesting structure and symmetry breaks. And so you can discover what region of this global fractal you might be embedded in from first principles. But the only way you can get there is from first principles. So basically, you are understanding of the universe has to start with automata and then number theory and then spaces and so on. Yeah, I think Steven Wolf from still dreams that he's that he'll be able to arrive at the fundamental rules of the cellular automata or the generalization of which is behind our universe. Yeah, it's you've said on this topic you said in a recent conversation that quote, some people think that a simulation can't be conscious and only a physical system can. But they got it completely backward. A physical system cannot be conscious. Only a simulation can be conscious. Yeah, consciousness is a simulated property that simulate itself. Just like you said, the mind is kind of the called story narrative. There's a simulation or so our mind is essentially simulation. Usually, I try to use the terminology so that the mind is basically a principles that produce the simulation. It's the software that is implemented by your brain. Yeah. And the mind is creating both the universe that we are in and the self. The idea of a person that is on the other side of attention and is embedded in this world. Why is that important? That idea of a self. Why is that important feature in the simulation? It's basically a result of the purpose that the mind has. It's a tool for modeling, right? We are not actually monkeys. We are side effects of the regulation needs of monkeys. And what the monkey has to regulate is the relationship of an organism to an outside world that is a large part also consisting of other organisms. And as a result, it basically has regulation targets that it tries to get to. These regulation targets start with priors. They're basically like unconditional reflexes that we are more less born with. And then we can reverse engineer them to make them more consistent. And then we get more detailed models about how the world works and how to interact with it. And so these priors that you commit to are largely target values that our needs should approach. Set points. And this deviation to the set point creates some urge, some tension. And we find ourselves living inside of feedback loops, right? Consciousness emerges over dimensions of disagreements with the universe. Things where you care, things are not the way there should be, where you need to regulate. And so in some sense, the sense itself is the result of all the identifications that you're having. And that identification is a regulation target that you're committing to. It's a dimension that you care about. Do you think is important? And this is also what locks you in. If you let go of these commitments of these identifications, you get free. There's nothing that you have to do anymore. And if you let go of all of them, you're completely free and you can enter Navana because you're done. And actually, this is a good time to pause and say thank you to sort of friend of mine, Gustav Sorastrom, who introduced me to your work. I went to give him a shout out. He's a brilliant guy. And I think the AI community is actually quite amazing. And Gustav is a good representative of that you are as well. So I'm glad, first of all, I'm glad the internet exists. YouTube exists where I can watch your talks and then get to your book and study your writing and think about, you know, that's amazing. Okay. But you've kind of described in sort of this emergent phenomenon of consciousness from the simulation. So what about the hard problem of consciousness? Can you just linger on it? Like, why does it still feel like I understand you're kind of the self as an important part of the simulation? But why does the simulation feel like something? So if you look at the book, I say, watch our Martin with the characters of plausible psychology. And they stand on a hill because they want to conquer the city below the hill and they're done in it and they look at the color of the sky and they are apprehensive and feel empowered and all these things. Why do they have these emotions? It's because it's written into the story, right? And it's written to the story because it's an adequate model of the person that predicts what they're going to do next. And the same thing is happened to us. So it's basically a story that our brain is writing. It's not written in words. It's written in perceptual content, basically multimedia content. And it's a model of what the person would feel if it existed. So it's a virtual person. And you and me happen to be this virtual person. So this virtual person gets access to the language center and talks about the sky being blue. And this is us. But hold on a second. Do I exist in your simulation? You do exist in almost similar way as me. So there are internal states that are less accessible for me that you have and so on. And my model might not be completely adequate. There are also things that I might perceive about you that you don't perceive. But in some sense both you and me are some puppets, two puppets that enact a play in my mind. And I identify with one of them because I can control one of the puppet directly. And with the other one, I can create things in between. So for instance, we can go in an interaction that even leads to a coupling to a feedback loop. So we can think things together in a certain way or feel things together. But this coupling is itself not a physical phenomenon. It's entirely a software phenomenon. It's the result of two different implementations interacting with each other. So there's a thing. So I used to just think, like the way you think about it is the entirety of existence, the simulation. And we're kind of each mind is a little sub simulation that like why don't you why doesn't your mind have access to my mind's full state? For the same reason that my mind hasn't have access to its own full state. So what I mean there is no trick involved. So basically when I know something about myself, it's because I made a model. So part of your brain is tasked with modeling what other parts of your brain are doing. Yes. But there seems to be an incredible consistency about this world in the physical sense that does repeatable experiments and so on. How does that fit into our silly the center of the apes simulation of the world? So why is it so repeat why is everything so repeatable? And not everything. There's a lot of fundamental physics experiments that are repeatable for a long time all over the place and so on. The laws of physics. How does that fit in it seems that the parts of the world that are not deterministic are not long left. So if you build a system any kind of automaton. So if you build simulations of something you'll notice that the phenomena that endure are those that give rise to stable dynamics. So basically if you see anything that is complex in the world, it's the result of usually of some control of some feedback that keeps it stable around certain attractors. And the things that are not stable that don't give rise to certain harmonic patterns and so on, they tend to get vided out over time. So if we are in a region of the universe that sustains complexity which is required to implement minds like ours. This is going to be a region of the universe that is very tightly controlled and controllable. So it's going to have lots of interesting symmetries and also symmetry breaks that allow to the creation of structure. But they exist where. So the decision-interesting idea that our mind accumulation that's constructing the narrative. My question is just to try to understand how that fits with this with the entirety of the universe. You're saying that there's a region of this universe that allows enough complexity to create creatures like us. But what's the connection between the brain, the mind and the broader universe which comes first which is more fundamental is the mind the starting point the universe is emergent is the universe the starting point the minds are emergent. I think quite clearly the letter at least a much easier explanation because it allows us to make causal models and I don't see any way to construct an inverse causality. So what happens when you die to your mind simulation? My implementation ceases. So basically the thing that implements myself will no longer be present. Which means if I am not implemented on the minds of other people the thing that I identify with. The weird thing is I don't actually have an identity beyond the identity that I construct. If I was the Dalai Lama he identifies as a form of government. So basically the Dalai Lama gets reborn not because he is confused but because he is not identifying as a human being. He runs on a human being. He's basically a governmental software that is instantiated in every new generation and you. So his advice is for pick someone who does this in the next generation. So if you identify with this you are no longer a human and you don't die in the sense that what dies is only the body of the human that you run on. Yeah. To kill the Dalai Lama you have to kill his tradition. And if we look at ourselves we realize that we are to a small part like this. Most of us so if you have children you realize something lives on in them or if you spark an idea in the world something lives on or if you identify with a society around you because you are a part that you're not just a human being. Yeah so in a sense you are kind of like a Dalai Lama in the sense that you Joshua Bach is just a collection of ideas. So like you have this operating system on which a bunch of ideas live and interact and then once you die they kind of part some of them jump off the ship. You put it put it the other way identity is a software state it's a construction it's not physically real you have identity is not a physical concept it's basically a representation of different objects on the same world line. But identity lives and dies. Are you attached this is what's the fundamental thing is it the ideas that come together to form identity or is each individual identity actually a fundamental thing. It's a representation that you can get agency over if you care. So basically you can choose what you identify best if you want to. No but it just seems if the mind is not real that's not that the birth and death is not a crucial part of it. Well maybe I'm silly maybe I'm attached to this whole biological organism but it seems that the physical being a physical object in this world is an important aspect of birth and death. It feels like it has to be physical to die. It feels like simulations don't have to die. The physics that we experience is not the real physics. There is one it's no color and sound in the real world. Color and sound are types of representations that you get if you want to model reality with oscillators right so colors and sound in some sense have octaves yes and it's because they are represented probably with oscillators right so that's why colors form a circle of use. And colors have harmonics sounds have harmonics is a result of synchronizing oscillators in the brain right so the world that we subjectively interact with is fundamentally the result of the representation mechanisms in our brain. They are mathematically to some degree universal. There are certain regularities that you can discover in the patterns and not others but the patterns that we get this is not the real world. The world that we interact with is always made of too many parts to count right so when you look at this table and so on it's consisting of so many molecules and atoms that you cannot count them so you only look at the aggregate dynamics at limit dynamics. If you had almost infinitely many patterns of particles what would be the dynamics of the table. And this is roughly what you get so geometry that we are interacting with is the result of discovering those operators that work in the limit that you get by building an infinite series that converges. For those parts where it converges is geometry for those parts where it doesn't converge its chaos. Right and then so all that is filtered through the consciousness that's emerging in our narrative. The consciousness gives it color gives it feeling gives it flavor. So I think the feeling flavor and so on is given by the relationship that a feature has to all the other features. It's basically a giant relational graph that is our subjective universe. The color is given by those aspects of the representation or this experiential color where you care about where you have identifications. There's something mean something where you are the inside of a feedback loop and the dimensions of of caring are basically dimensions of this motivational system that we emerge over. The the meaning of the relations, the graph. Can you elaborate that a little bit like where does the maybe we can even step back and ask the question of what is consciousness to be more systematically? What do you how do you think about consciousness? As to that consciousness is largely a model of the contents of your attention. It's a mechanism that has evolved for a certain type of learning. At the moment our machine learning systems largely work by building chains of weighted sums of real numbers with some non-linearity and you will learn by piping an error signal through these different chain layers and adjusting the weights in these weighted sums and you can approximate most polynomials with this if you have enough training data. But the prices you need to change a lot of these weights. Basically the error is piped backwards into the system until it accumulates at certain junctures in the network and everything else evens out statistically. And only at these junctures this is where you had the actual error in the network. You make the change there. This is a very slow process and our brains don't have enough time for that because we don't get all enough to play go the way that our machines learn to play go. So instead what we do is an attention based learning. We pinpoint the probable region in the network where we can make an improvement and then we store the the binding state together with the expected outcome in a protocol. There's ability to make index memories for the purpose of learning to revisit these commitments later. This requires a memory of the contents of our attention. Another aspect is when I construct my reality and make mistakes. So I see things that turn out to be reflections or shadows and so on which means I have to be able to point out which features of my perception gave rise to a present construction of reality. So the system needs to pay attention to the features that are currently in its focus and it also needs to pay attention to whether it pays attention itself. In part because the attention system gets trained with the same mechanism so it's reflexive but also in part because your attention lapses if you don't pay attention to the attention itself. So it's the thing that I'm currently seeing just a dream that my brain has spun off into some kind of daydream or am I still paying attention to my perception. So you have to periodically go back and see whether you're still paying attention and if you have this loop and you make it tight enough between the system becoming aware of the contents of its attention and the fact that it's paying attention itself and makes attention the object of its attention. I think this is the loop over which we make up. So there's this so there's this attention mechanism that somehow self referential that's fundamental to what consciousness is. So just ask you a question. I don't know how much you're familiar with the recent breakthroughs in natural language processing. They use attentional mechanisms. We use something called transformers to learn patterns and sentences by allowing them to focus its attention to particular parts of the sentence that each individual. So like parametrize and make it learnable the dynamics of a sentence by having like a little window into the into the sentence. Do you think that's like a little step towards the adventure will take us to the intentional mechanisms from which consciousness can emerge? Not quite. I think it models only one aspect of attention. In the early days of automated language translation there was an example that I found particularly funny where somebody tried to translate a text from English into German and it was a bad broke the window. And the translation in German was a Nifle der Maus. It's a brach does fence them with an embassable schläger. So to translate back into English a bad this flying mammal broke the window with a baseball bat. Yes. And it seemed to be the most similar to this program because it somehow maximized the possibility of translating the concept bad into German in the same sentence. And this is a mistake that the transformer model is not doing because it's tracking identity. And the attention mechanism in the transformer model is basically putting its finger on individual concepts and make sure that these concepts pop up later in the text. Yeah. And tracks basically the individuals through the text. And this is why the system can learn things that other systems couldn't before it which makes the for instance possible to write a text where it talks about the scientist then the scientist is a name and has a pronoun and it gets a consistent story about that thing. What it does not do it doesn't fully integrate this. So this meaningfuls apart at some point it loses track of this context. It does not yet understand that everything that it says has to refer to the same universe. And this is where this thing falls apart. But the attention in the transformer model does not go beyond tracking identity. And tracking identity is an important part of attention. But it's a different, very specific attention mechanism. And it's not the one that gives rise to the type of consciousness that we have. It's just a link on what what do you mean by identity in the context of language. So when you talk about language, we have different words that can refer to the same concept. Got it. And in the sense that the space of concepts. So yes. And it can also be in a nominal sense or in an ethical sense that you say this word does not only refer to this class of objects, but it refers to a definite object to some kind of agent that waves their way through the story. And it's only referred by different ways in the language. So the language is basically a projection from a conceptual representation from a scene that is evolving into a discrete string of symbols. And what the transformer is able to learn aspects of this projection mechanism that other models couldn't learn. So have you ever seen artificial intelligence or any kind of construction idea that allows for unlike neural networks or perhaps within neural networks that's able to form something where the space of concepts continues to be integrated. So what you're describing, building a knowledge base, building this consistent larger and larger sense of ideas that would then allow for a deeper understanding. Vidkins, Diane's thought that we can build everything from language, from basically a logical grammatical construct. And I think to some degree there's also what Minskie believed. So that's why he focused so much on common sense reasoning and so on. And project that was inspired by him was psych. That was basically going on. Yes. Of course ideas don't die. Only people die. And that's true. But in outside is a productive project. It's just probably not one that is going to converge to general intelligence. The thing that Vidkins, Diane, couldn't solve. And he looked at this in his book at the end of his life, philosophical investigations was the notion of images. So images play an important role in track titles that track titles and attempt to basically turn philosophy into logical programming language to design a logical language in which you can do actual philosophy that's rich enough for doing this. And the difficulty was to deal with perceptual content. And eventually I think he decided that he was not able to solve it. And I think this preemtered the failure of the logitist program in AI. And the solution as we see it today is we need more general function approximation. There are functions, geometric functions that we learn to approximate that cannot be efficiently expressed and computed in a grammatical language. We can of course build automata that go via number theory and so on to learn in algebra and then compute an approximation of this geometry. But to equate language and geometry.
