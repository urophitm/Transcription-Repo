 Hello everyone and welcome to the Mindscape Podcast. I'm your host, Sean Carroll. Before jumping into today's episode, let me just talk about some meta commentary, the State of the Podcast. As we all know, this is a new project for me. We're all learning what's going on. I'm having fun. I hope that you're having fun. But we're still propagating the podcast out there in different ways. I certainly appreciate any efforts that you folks make to get the word out through Twitter or recommending it to your friends. iTunes reviews or make me just as happy as any other podcaster. Some of you might know that Libsyn, the host that I use for the actual podcast episodes, has an automatic thing, well they will put the podcast on YouTube. It's just a still image. It's not really a video. It's just the Mindscape banner logo there, but the audio is the same on YouTube as you would get on the podcast. So for those of you listening to it, if for whatever reason you would like to watch it on YouTube, go ahead. There's no video there. There probably never will be any video. I know people say video would be better. You know, Joe Rogan does video. Joe Rogan also makes millions of dollars off of his podcast and so far I am putting money into it and not getting any out. Maybe someday I would get some out. I would like to at least pay for the microphones and so forth. I don't know what that would eventually mean. Maybe just some kind of Patreon page or something like that. That would be ideal. If it comes to ads, then that's fine because you can get money and I like money. But we'll have to see. Well, it's not going to be something that happens right away. For those of you who are watching on YouTube already, just so you know, it's also available on audio in the usual ways. On iTunes, Stitcher, it finally got onto Google Play. Google Play was having a problem with Libs and Feeds. So you don't need to have your YouTube open there. You can just click on the links that are in the description of each video on YouTube. It will take you to the podcast website where you can just listen to the audio or download it on your apps on your phone, whatever you want. There is even a subreddit, a Sean Carroll subreddit that you can check out if you want to discuss further. The YouTube comments have been awesome, but a more centralized place to go is on Reddit where people are talking about these things. So I think that's all that I wanted to say for the commentary stuff. So let's get into today's episode. The theme of which is that we don't know everything as we go through life, but we still have to make choices. We still have to act in the world somehow, but we live in a situation of incomplete information. We don't know what's going to happen in the future. We also don't even know everything about the world right now. So what we do is we attach probabilities to things. We say there's a certain chance that something's going to happen. Accredence is how much weight we put on one possibility versus another, and then we act accordingly. Formalizing this idea of placing probabilities on things and then acting accordingly is called betting. And nowhere is the idea of betting made more explicit and formalized than in the game of poker. Poker's one of my favorite games. It's a game of skill that has luck involved because you don't know what the other players have, but you can make choices. And some of those choices you can win. There are people who make money over the long term, very regularly playing poker. Those are called professional poker players. They really exist. There's no professional slot machine players because they are just losing money overall. But poker is a game of skill. And today's guest, Liv Borey, is a perfect person to talk to about this stuff. Liv was a physics major as an undergraduate at the University of Manchester. And she was quite good at that, but she decided instead to add a little spice of excitement to her life by becoming a professional poker player. And she's done pretty well. I can't say it was a bad choice. She's made almost $4 million in winnings at the poker table. And so we're going to talk about what you learn from being a poker player. What that helps you do in terms of your everyday life, making choices about one thing to do or another in conditions of incomplete information where probabilities are central. Liv is also still remains interested in science and is developing TV projects to help popularize science. She also has become interested in altruism and charitable giving within the umbrella of effective altruism, trying to use empirical data to maximize our impact as charitable givers. She's the co-founder of an organization called Raising for Effective Giving, which funnels money to organizations that have shown that they really have gotten good bang for their buck in terms of the charitable dollars. So we're going to talk about poker, we're going to talk about altruism. We're also going to talk about how to think about the existence of aliens. Whether or not aliens exist out there in the world turns out to be something that's at the intersection of science and also probability. How do you reason about something like that when you have so little data? So let's go. Did you know Fast Growing Trees is the biggest online nursery in the US, with thousands of different plants and over 2 million happy customers. They have all the plants your yard needs, like fruit trees, privacy trees, flowering trees, shrubs and so much more. Whatever plants you're interested in, Fast Growing Trees has you covered, find the perfect fit for your climate and space. Fast Growing Trees makes it easy to get your dream yard. After online and get your plants delivered directly to your door in just a few days, without ever leaving home. Their alive and thrive guarantee ensures your plants arrive happy and healthy. This spring they have the best deals for your yard up to half off on select plants and other deals. And listeners to our show get 15% off their first purchase, while using the code Mindscape at checkout. That's an additional 15% off at Fast Growing Trees.com using the code Mindscape at checkout. Fast Growing Trees.com code Mindscape. Now it's the perfect time to plant. Use Mindscape to save today. Offers valid for limited time, Terms and Conditions may apply. Liberi, welcome to the Mindscape Podcast. Thank you very much. So now you are trained at least undergraduate, education wise as a physicist, astrophysicist. Now you are a professional poker player. So just to set the stage, I think for a lot of people, if you say professional poker player, they know exactly what that means. I bet a lot of people in the audience are unclear that there are such a thing as professional poker players. Is that even legal? Are you like in downstairs? Is it like rounders? Are you getting in trouble? What is the situation? How does your lifestyle like how does this work being a professional poker player? So it depends obviously from person to person. There are different types of professional poker players. But I, for the most part, play a type of poker called tournament poker, where everyone puts up an equal amount of money and in exchange for that, you all get a certain amount of chips and basically everyone keeps playing until everyone else is knocked out and one person has all the chips and wins either all the money or certain sort of distribution of the prize pool. Capitalism. Exactly. Yes. A very aggressive, zero sum form of capitalism. And yeah, so I got into it in a very random way. As you said, I studied physics. I fully intended to carry on in physics. I loved it. But at the same time, I had been in education. I was 21. I also had ambitions of being a rock star. I was very into heavy metal and disturbing my neighbours late at night playing guitar. And so I was like, you know what? I'm going to take the summer off after my graduation and start. I need to make some money somehow. So I'm going to apply for TV game shows. Because I felt like that made a- As a contestant. As a contestant. I always like playing games. Long story short, I learned how I learned to play poker on one of these game shows and I loved the game. And I was like, you know what? I think I want to take a few years and throw myself into this game. I think I have an aptitude for it. It seems like a lot of fun. I want to travel the world and get some life experience. Still in the back of my mind saying, I'll come back to physics. Right. Once we've made our pile. Yeah, once we've made some money, pay back my student debt, etc. And now 10 years later, still here. The debt has long since been reviewed. Yeah, exactly. Well, things just turned out pretty well in the focus sense. And yeah, so like in terms of sort of lifestyle, it's a lot of... For me, it leaves traveling to different tournaments. So like there's a big stop in Barcelona every August. Or there's a big stop in Vegas, which I've just come from the World Series. And you're sort of traveling around to these... You know, it's not the pro tour because anyone can play them. Right. But the professionals tend to like that lifestyle going from event to event and playing in these tours. So literally anyone listening right now, as long as they have the right amount of money, can show up. They have the tournament, say, here I am. And want to play. I don't like a golf tournament or basketball. Anyone is welcome. And it's a meritocracy once you're there. Exactly. Yeah, so anyone can play. It doesn't mean you necessarily should play. But if you want to and you have the money and the desire, then you absolutely can. And I mean, I think that's what sort of separates poker a little bit from something like golf. Because golf is, you know, the results of a golfer is very closely correlated to their skill level. Whereas with poker, particularly over like a small sample size of maybe 10, even 100 tournaments, the worst players could be vastly outperforming the best players. And so to say, oh, well, we're only going to let in the people who've had the best results over the last six months. Right. That's stupid. And people would just get very annoyed with it. Because A, first of all, everyone thinks they're the best. And that's why poker exists. But B, it wouldn't actually be correlated to necessarily being the best players getting in. And C, the ones who are good would like the money from the people who are not good to be in the tournament. Exactly. Yeah, it's a constant battle between, well, I want to be playing against the best. I'm going to say I'm the best. But at the same time, I don't want to scare people off. And so, yeah, you need the weaker players. You want to be playing against it in an ideal world. But it is a game of, it's a combination of luck and skill, right? I mean, like everything in life. But it's not just luck. There's a certain element of randomness. You're dealt the cards. But then you play them in a certain way. So it's not like playing Blackjack or Crap's where there's really no way to win without some kind of cheating. Yeah, exactly. I mean, with those games, yeah, the casino, it's built its big golden halls and amazing rooms and spaces because they have this small edge that over time they make money from. And the longer you play, unless you know how to count cards, which again, the casinos will kick you out for for doing, you can't make money playing Blackjack and roulette. Whereas poker, because you're playing against other people, and the casino hosted it basically, because I think casinos don't really want to host poker. They're not really making great money from it, basically, just like a small percentage of each pot. But yeah, with poker, you're playing against other people. And so if you are consistently making better decisions than your opponents, then you are going to be making a profit in the long run. I do get the feeling though that the casinos enjoy having poker players around. Some of them are very good at playing poker, but then are perfectly willing to go blow it at the Becker-Aut table. That's a very, very correct observation. Yeah, I've known many, many poker players who were some of the best in the world and yet had no money to their name because they were the worst in the world at walking past the roulette table. It's just another game, just walking past it. Yeah. You just who's the best at what they've been to? And they know that they should lose on average. Yeah, but they just love it. Like that's, you know, it's, yeah, I mean, there's, I think to be a good poker player, you have to obviously have a willingness to, or you cannot be a risk of a human. Like you have to be willing to gamble, to take risks, to have those like, heart and the throat moments. But at the same time, you need to be able to do that in an intelligent, moderated way. And some, certainly not the best players you see around now, but most of them actually don't have what we call sort of the degenerate gambler speaking as much. But there are still some who do struggle with it. And it's quite a tragedy to see someone who's like worked so hard at being so good at one particular game, but then have this sort of life, we call it a life leak, a leak in the bottom of their pocket, which is some other form of gambling. But I mean, it makes for great stories though. It does. And it's, it also contributes to this aura that the game has of being slightly disreputable, right? No matter how much money and TV exposure and everything, and you still, to this day, do as you alluded to, hear stories of some of the world's best players just disappearing. Like they're hiding. Right. They come back, oh, they just lost $5 million over the weekend. And it, it, it therefore must be a very different kind of lifestyle than maybe you thought you were signing up for when you went to university as a physics major. Yeah, I mean, like, I've seen it sort of, I had some insights, I mean, like, you know, to have some insights into the world of, you know, the top chess players, for example. And it is for the most part a very different sort of social dynamic because the best chess players, like they really have to, I mean, they just study and study and study and study. And I mean, they're brilliant, obviously, at what they do. But I don't know, like many, I think, but I think poker players have a little bit more of the wild, the sort of, not free spirit, but you know what I mean? Like this, this wildness to them. Right. They, you know, there's this, these urges, I guess, they want to fulfill, they get thrills from many other things as well as well as chess players tend to, you know, they have to be so laser focused on what they do. Sorry. But also, but sorry, but just to continue exactly in that line, the thing that you're doing when you're playing poker is fundamentally different than the thing that you're doing when you're playing chess. When you're playing chess, both players see the board. Right. 100%. When you're playing poker, you don't know what the other person's cards are. And so they put out a big bet. They go, all right, here it is. This is all your stack. This is for your tournament life. You have a pretty good hand, but not the metaphysically perfect hand. And you need to, I mean, ideally say, well, there's a certain chance that they're bluffing. There's a certain chance that they're not and I'm just going to risk it. Yeah, exactly. I mean, with chess, you have all the information out there. There is no hidden information. I mean, sure, you can't directly see into the other person's brain to see what specific strategies. But you usually have a pretty good idea and there's not like a very definite bits of information that you don't have. Whereas poker, yeah, it's incomplete. And so that's why you have to think probabilistically. And yeah, so then it becomes sort of this, I mean, largely a science of being able to quantify these uncertainties that you have. Like, OK, well, what is the range of hands that they can conceive of? They'll be playing here. OK, it's from pocket twos to eighth king, also, and like that. And also what is the, but then I have the piece of information that they bet this particular card, but not this one. And they bet this size. And then on top of that, there's the even harder to quantify things like, oh, the pulse in there next seems to be going really, really strongly here when I wouldn't expect it to. This is inconsistent with the story they're telling with their chips. So how, what do I do with that? Like, and so it's this, there's all these, like, little bits of variables of information of some of which are extremely confident about and others you're really not. And you've got to sort of evaluate all of these somehow and put them together to come out to one answer that is most likely to be the correct decision that you make. This episode of Mindscape is sponsored by BetterHelp. When it comes to relationships, we often hear about the red flags we should avoid. But what if we focus more on looking for the green flags in friends and partners? If you're not sure what green flags look like, therapy could help you identify them. Actively practice them in your relationships and embody the green flag energy yourself. Whether you're dating, married, building a friendship or just working on yourself, it's time to form relationships that love you back. One of the great things about therapy is by looking inside yourself, you can both learn to take those warning signs seriously, but also learn to be open to new experiences and new things to know when something might be worth pursuing. BetterHelp is a fully online service that makes therapy affordable and convenient, serving over 5 million people worldwide. You can easily switch therapists any time at no extra cost. So discover your relationship green flags with BetterHelp. Visit betterhelp.com slash Mindscape today to get 10% off your first month. That's BetterHelpHELP.com slash Mindscape. A lot of us start the new year saying that we will learn a new language, but it's hard to actually commit to it. Babble makes it easy to learn one in less time than you think. Bappbles quick, 10 minute lessons handcrafted by over 200 language experts, get you to begin speaking your new language in three weeks or whatever pace you choose. And because conversing is the key to really understanding each other in new languages, Babble is designed using practical, real world conversations. What I love about Babble is you can either dive in deeply and truly get fluent, or you can just master some of the basics before going on a trip. So let's get more of you talking in a new language. Babble is gifting our listeners 60% off subscriptions at babble.com slash Mindscape. Get up to 60% off at babble.com slash Mindscape. Spelled B-A-B-B-E-L.com slash Mindscape. That's babble.com slash Mindscape rules and restrictions may apply. I don't know, you know Ed Witten, the physicist? Ed Witten, the famous string theorist? Of her, yes. Yeah, he is, you know, he would probably win the poll if you asked most theoretical physicists in the world today, who's the smartest theoretical physicist. Oh, ready? Yeah. He doesn't like poker, because he says, I don't know what the other person has. In chess, I could outthink everybody, but in poker, you have to make up these humor. Like, he works. He works basically. He works. He works models, right? Yes. Because of the opponent. And of course, the counter to that would be the John Funnoiman helped invent game theory, because he wanted to become a better poker player, literally, right? He was playing poker. That's a damn surprised Ed Witten, then it doesn't like it so much, because it, I mean, is still ultimately a mathematical game. It is. But there's also psychology. So I'm sure one of the classic questions you're asked is what is the balance of doing math versus doing psychology when you're literally at the table? So the answer to that is it entirely depends. But to throw a hate throwing, like, probabilities that when it really does wildly depend, I would say like 90%. In fact, say for example, I wanted to make you into the very best poker player in the world, I would want to sit with you and make sure that you have put 90% of our effort into making sure that you understand the game theory. The math, right? Yeah. The actual, like, the building blocks of the game so that your strategies are built upon that, because it's ultimately a mathematical game. Then on top of that, if I can teach you some of the psychology and the harder to quantify parts, these, like, sort of, I guess, build your intuitions up so that you are able to sort of intuit from people's behaviors what they're thinking. But that's just more really just a matter of experience, I think, ultimately. Some people are more inclined, you know, are just better at reading people than others naturally. But I still think it's ultimately a learnable skill. And again, some of the best poker players still find ways to almost quantify their uncertainty about these, like, very psychological human characteristics. Yeah, so you know, you'll have it. You'll know what the correct, you know, I should be calling 40% of the time, according to game theory. And then I have a piece of evidence that suggests that actually the opponent's bluffing very far, well, rarely, then that will how confident am I in that? And then I might waver the needle to say, so I'm at down to 35% or cool instead. But it's still something that you can quantify. Yeah, I once went to a movie premiere with a bunch of people and one of the people was Phil Locke, the poker player, famous poker player. He goes himself a time scientist. A time scientist? I did not know that. We didn't talk about that. But we're, like, chitchatting a whole bunch of us in the lobby before the movie starts. And Phil suddenly says, there's an 83% chance that I'm going to have to pee before the movie ends. So I should go to the bathroom right now. And I didn't know whether or not that sort of silly precision of 83% was a joke or whether he's just that good at estimating things. Knowing Phil, he is pretty good. He does like to think in terms of probabilities, but that degree of granularity over the estimate. He's just having fun. Yeah. So obviously, there's math in the sense of, OK, I need a heart to come down. Only of one card. There's some elementary math. What is the percentage chance a heart will come down? But there's also higher level math. In particular, the game theory situation with sort of optimal strategies and dominant strategies and exploitative strategies. Do you study that as part of your education trading as a professional poker player? Yeah. Ideally, you want to sort of familiarize yourself with, so I mean, well, you're lucky in this day and age, there are these solvers out there that you can basically run Monte Carlo simulations in different. You can go, OK, what should I do with Jack 9 suited on a 10, 7, 4, 1 suit board of the same suit? And similar scenarios like that. Put them into the solver, let it run for a few hours, and it'll show you what the game theory optimal strategies with the range of hands that you can see be have in that situation would be. So there would usually be a percentage of those hands that you would want to check rays because they're really good, for example, because they have a lot of equity. But there's a percentage that you would want to check cool because they're kind of in the middle of the road. And then there's a percentage that you would then want to bluff because you need to balance out your range. You can't just check rays with the strongest hands. You need to have some bluffs in there so that you can get called. You need to have the appearance of having a balanced range of hands, bluffs and weekends, when you make an aggressive action. And so anyway, you can literally find out what is as mathematically close to the perfect game theory optimal solution is now in these different scenarios. And so the very best players will sit and work with these solvers. You can't use them in real time, but you can go away and just study for hours and sort of try to basically build a mental model that emulates these game theory optimal solutions. And then once you have this mental model of game theory optimal, then you can go out there and play using this style as a sort of base. But then you would then deviate it from it as and when you come across an opponent who is playing not in a game theory optimal style. Because a good way to think about it is like if you're an eye for to play rock paper scissors and you don't know anything about me, what would you be the strategy, the best strategy that you would employ? I believe the best strategy is randomly do one third, one third, one third, one third rock play. Exactly, you want to perfectly randomize, because you don't have any information about me. So in response to that, the best case that I can do is to also randomize perfectly. Because if I don't do anything on that, you're going to be exploiting, you'll be taking advantage of me. So that's like a Nash equilibrium basically. Sorry, explain what that is for the people out there in podcast land. So a Nash equilibrium is basically a state strategy where it's unprofitable for either competitor or any competitor, it can be multiple competitors as well, like more than two, to deviate from that strategy. If you deviate from it, you're only going to be losing on average in the long run. So it's the equilibrium where everyone is doing as best they can. As best they can and breaking even. In this situation, you're breaking even against each other. Like if we both play. Zero something. Exactly, yes. However, if you then notice that I start throwing rock every time. Yeah. Should you continue playing this three? I could have had a better strategy. Exactly. You wouldn't want it. You'd be stupid to carry on just playing this perfect 33% randomised thing. No, you'd want to start playing paper far more often or like 100%. And so that is what you'd call then an exploit. You exploit my bad play by deviating from the previous game theory optimal. And so that same kind of thing applies in poker. You'll be playing your start off maybe ideally playing this game theory optimal strategy. And if your opponent's equally good, they'll hopefully try and match that. And you'll be in the long run breaking even against each other. But because basically no human in the world can play perfectly game theory optimal, there are these rooms you want to see over the course of time you'll observe what these mistakes are people are playing. And so you'll deviate and start exploiting those. I was highly amused to learn that there were competitive rock paper scissors leagues. I did not know that they exist. They do because people are not good at randomizing, right? Right. And in fact, this is a very educational moment for me also. The New York Times had an app where you could go and play rock paper scissors against the app. And basically it had trained as a AI sort of thing on millions of real life human being rock paper scissors players and realized what the tendencies were, what the deviations from randomness were. And it would beat you. And I, you know, went in there. Well, kind of edge of a. It was small, you know, it was not large, but noticeable like, you know, over 20 hands, you could definitely tell you you were losing. Yeah, yeah, that was my experience. But then what I realized, like, so I went in there, cocky, I'm like, I know that how this is working, I'm going to beat it. And it destroyed me. But so then I realized I, there was something that I felt I should be doing. Like I played rock two times in a row, I should play scissors or something like that, right? And I would tend to do that and I was losing. You don't do these like same thing in the row at many times. Yeah, that's right. That's hard to do because you don't realize how many times those sequences come up randomly, right? Right. But what I realized was if I figured out what my impulse was and real and and had the strategy that the New York Times app would probably play a dominant strategy against my tendency. Yeah. Then I should play the one that would beat that. And suddenly I kicked it's ass. I really did. Wow. So it's just a matter of how many, how many impressions you know. It's not the most exciting game in the world, right? So you know, dozens but not hundreds of iterations. Let's put it that way. I want to do that. Yeah, we can find that. But and another thing that I along these lines, I remember the first time I learned about in the realm of Nash equilibrium and game theory, the fact that in games like this mixed strategies will generally be the dominant or the equilibrium optimal strategies. In other words, there's no one action you should ever take every time in that situation. And it's perfectly obvious in rock paper scissors. It's also true in poker. If you have pocket aces, you know, in some position, the best possible strategy is not to do the same thing every time, no matter what you have. It's almost always true there. And then so you have to, if the strategy is to do one thing, 90% of the time and something else 10% of the time, it's really hard to ever do that 10% thing. You know you're not doing the best thing. Right. Well, so what some of the, again, the top players have started doing now because like everyone knows that you need to be able to basically be a perfect randomizer machine to have these, not only sort of to remember what the, these ratios you need to have, you know, in certain situations where you want to be bluffing with say 10% of your hands and and and betting for value with 90%. How do you randomize that? Well, people have started looking like watches like yours, you've taken it off, but with the second hand, old analog watches have become popular again. Why? Because it's a really good randomizer. If you're, if you go, okay, you just use where the second hand is on the clock face. Okay, if it's between zero and if you want, if you know you want to check, raise 25% the time, is it between zero and 15? Oh, yes it is. Okay, this is a check, raise situation. If it's not, okay, I check, cool. Do you do that? Um, not as much as I should. I've done it, I've done it a few times, um, but A, I always forget my watch. Um, other players do it by actually just like shuffling their chips all the time because usually the chip will have, you know, the word, word written on it and just wear it lands, you know, again, yeah, that's, that's a way. And even if you're, this is a thing, people think, oh, you need to then keep the secret that you're doing this. No, even if you're opponent, no, they just go, oh, shit. The optimal strategy, yeah. They're playing GTO against me, okay? Yeah, I need to, it's just, it's just an unsettling thing to know basically, yeah. But part of me thinks that it's less important to actually play the game theoretical optimal strategy than to make your opponent think you're playing it, right? Because they're not perfect optimizers or randomizers either. So if you're supposed to do something two thirds of the time and something else one third of the time, and your randomizer makes you do the one third of the time thing three times in a row, then I would definitely do the other thing no matter what they randomize as it told me the next time because I'm not actually, my opponent is not building the correct model of me. That is true to an extent, yes. But at the same time, if your opponent is also then playing this perfectly sort of, you know, randomize in the right way style, their style will not be losing out to the, because they're playing this, this unexploidable style, then arguably you're going to still be playing less, less perfectly than they are. And so in the long run, again, it's always down at, you know, in the long run, you'll still be playing less, a less profitable style than them, or sorry, a more exploitable style than them. But when it comes to poker at a table with six or ten people, we don't know the game theoretical optimal. No. No, poker has not been solved. In fact, as far as like no artificial intelligence cannot win at a ten hand, ten player table against help players. So there's been the AI that successfully beat humans heads up one on one. But I don't even know if anyone's trying to do the three person in a higher game, because I mean, the game treat us gets ridiculous. Yeah. The decision tree. And yet, before humans do it. Exactly. Yeah, we're really, really good at building these sort of heuristics, these, these, I don't know why we're so good at it, but it's, we're able to sort of condense this down into these rules of thumb that work out really well. I mean, I think it kind of makes sense that that's, that is what we're good at, right? The thinking fast and slow, Daniel Cahneman would explain, you know, we don't think in terms of rational logical choices generally, we think in terms of heuristics, we think in terms of rules of thumb, and we're really good at coming up with models of the world that are pretty good. Yes, good approximations that get us by. Yeah, yeah, yeah. I mean, do you use Bayesian analysis or something like that very much? Why don't we explain what Bayesian analysis is? Sure. So Bayesian analysis, Bayesian analysis is basically updating our model of the world based upon new information, incorporating new evidence based on sort of the weight, the strength of this evidence, whether it's proving or disproving our beliefs, and then, you know, when we see, when we see that thing happen, we'll go, okay, well, this means I should change my mind by this amount. I should shift the needle, you know, if you think, all trees are green, all leaves are green, you'll go around, but then if you see, you'll go around assuming that, but then if you see a tree with purple leaves, well, now that's evidence to suggest that's not so true, so you now shift towards, okay, maybe not all trees are green, etc. And there's a way you can actually model that mathematically using Bayes' theorem. Do I do it mathematically in game? Absolutely not. I don't have likelihood ratios and so on in my head, but no, I mean, ultimately our brains are Bayesian machines, right? That's what we're doing naturally without really realizing it. And I mean, at least to me, it seems like it's a sort of fundamental law of, not a physical law, but it is, you know, it's, what do you call it, a psychological law? It is some kind of law of the world we live in, right? Basis theorem? I mean, it's a math theorem. It's, you know, it's the correct way to update your model of the world, I think. Yeah, it seems like it. It's a rational way to behave. Yeah. And so my impression is, this is my amateur poker players way of thinking about it. You can tell me what that makes sense. You know, you sit down at the table and you more or less assume everyone is the same in some way. And then as you see how they play, your model of each individual player becomes more sophisticated. Yes. So we have ways in poker of sort of describing that, right? There are type players and loose players and aggressive players and so forth. And maybe then you say, well, oh, this person is tight before the flop and then they become loose afterward. And is that more or less what's going to your mind? Yeah, I mean, not that I would ever advocate stereotyping people at all, but when you sit down at a poker table, like I just played the World Series a Pok√©mon event, for example, where it's generally against a lot of amateur players who, you know, pony up their $10,000 once a year and it's, you know, it's the best tournament in the year. It's really good. It was profitable for you, right? Yeah, it worked out pretty well this time. And so when you first sit down, I will immediately look around the table and create, basically, up off first impressions of how someone looks, you know, literally their gender, their age, the way they're sitting in their chair, the clothes they're wearing, the way they look at me, you know, their appearance of confidence or not confident. And so I'll immediately create a sort of some kind of stereotype. A prior. A prior. Exactly. A prior. But then in an ideal world, I'll still just try and, you know, not let that influence my play too much. Just a little bit. But as soon as you start getting real information, after like 20, 30 hands, more now I've seen, okay, this person hasn't played a single hand over 30 hands. Did I think they were type of a hand? Actually, yes. And does the evidence continue to confirm that? Yes, it does. Okay, so I can shift the needle a little bit more to strengthen that belief. And if I notice actually the person who, you know, like the old guy who seemed kind of conservative and timid has played every single hand and is raising and re-raising everyone, okay? Better update. Better. It's time to update. This is a very strong evidence. Let's shift the needle more towards it. He's an aggressive player. And so, yeah, you'll sort of start building these models of people, and then by the end of the day, if you've been at the same table, now you've got probably multiple hundreds of hands of where you've seen a lot of information of people's tendencies, increasing degrees of nuance, and so you'll build up a very accurate mental model of players over a given period of time. With a Sport Cash Plus card from Capital One, you earn unlimited 2% cash back on every purchase. Plus, no preset spinning limit helps your purchasing power adapt to meet your business needs. Jorge Gavirio, founder of Massienda, reinvests his 2% cash back to help grow the business with new products. What could the Sport Cash Plus card from Capital One do for your business? Capital One. What's in your wallet? Find out more at capitalone.com slash Sport Cash Plus, terms and conditions apply. So do you take this way of thinking? Mixed strategies, game theory, optimal, etc. Basis, theorem, and updating your priors. Do you extend it from poker to the rest of your life? Has being a professional poker player changed how you go about buying a house or getting a boyfriend or using where to go for dinner? Yeah, I would say so. In terms of just thinking about things in terms of probabilities and uncertainties, beforehand I was very black and white in my thinking. It would either happen or it won't or I certainly wasn't comfortable with any granularity. And now I'll look at something and be like, okay, do I think, am I going to make it in time for this podcast, judging by the LA traffic? Doesn't seem, doesn't seem. The probability has gone down and I'll estimate at least mentally and hopefully I'll try and communicate it to people as well. What I think the likelihood is in terms of a percentage. I'm 30% to be there on time. That kind of thing. And in terms of picking boyfriends, well, yeah, I mean, Igor. You picked a poker player. It's hard when you're playing on the poker circuit not to also, you know, you're not to have a significant other who's sharing the same lifestyle. But yeah, funny story. Igor and I actually, what Igor asked me now about half a year ago, randomly, he said, what do you think the likelihood is that we'll still be together in three years' time? Because we were like talking about moving cities and should be by a house. And he said, well, what do you think the likelihood is we'll actually be together in three years' time? I was like, ah, good question. Sorry, that's a question that would only be asked by number one, a poker player and number two, someone who is pretty secure in the relationship already. Yeah, well, yes. Well, yeah, that's a reasonable thing to assume. And luckily, our numbers came out fairly similarly. I think it was like 92 and 94% or something like that. Excellent. Yeah. Because there's a non-linearity there, like getting the wrong answer could change the problem. That'll absolutely. Yeah, there can be. But at the same time, it's really useful to know, even if you don't end up being honest with each other, the fact that it asks you to reflect on that. Right. And you come away and think, oh, actually, the number's 60%. But I found myself the word 90% coming out my mouth. Well, if nothing else, that's information for yourself. That's right. Right? Oh, there's something not quite right here. Fortunately, I did genuinely. I was like, no, I think it's definitely over 90%. It's definitely under 100%. You know, stuff can still happen. And luckily, we were pretty much lined. But yeah, so it definitely, I found it has bled into my thinking in all sorts of ways. And in general, you just, you just become more strategic. I don't know. I mean, I don't think that's a bad thing. I know people, sometimes when people ask, well, what do you do? And I particularly, if I'm in some kind of negotiation, they're like, oh, you're a poker player. Well, I don't believe anything you say. Right. And I was like, oh, come on. Does anything poker is all about massive crazy bluffs, right? Not about strategic thinking. Exactly. Yeah. And I was like, I'm about choosing when to bluff, to actually minimizing your risk when you bluff. Like, I've found that like bluffing is stressful. Like it can be very fun when you get away with it, but it's really not fun when you get caught. Oh, yeah. And having, you know, when you poke a player, it's not what it's like to get your bluffs caught, be caught in a lie. It's a, it's embarrassing and be it actually just financially hurts and it can knock your confidence and so on. And so away from the table, I don't like lying isn't really very fun. Like I get to scratch that at the table and it just creates complications and, you know, unless there's really, really, really good reason for it. It's a tend to try and avoid it. And it is embarrassing even at the poker table, but it shouldn't be, right? I mean, you're just playing the game theoretical optimal strategy, right? Yes. And what's I be sad about my bluff called? Yeah, no, that's definitely a thing. I try to, you know, anyone I'm teaching poker, I say, like the first time you get caught in a bluff, turn those cards over and slam them down and have a big smile on your face and be proud of yourself. That's pretty good to face. It's a big part of the game and you have to get used to that sort of getting your fingers caught in the cookie jock. Because if you don't ever get caught, then you're not probably not doing it often enough. So yeah, there's like, there's so many, like, different facets of the game that sort of bleed over into life. I mean, just the emotional control part of it. You know, poker, you learn to get used to bad luck very fast because I mean, you play 10,000 hands in a week. You're going to have one percent as, you know, where you should win the hand, 99% of the time, but you don't, you'll have multiple of those happen. And they really sting. Yeah. But, you know, probabilities they compound over time. And if there's many, many instances of bad luck things that can happen, then eventually one of those will happen to you. And so if you sort of remember that, I find you get less emotionally attached. And it says a shock. Yeah, I mean, what you said about the granularity of probabilities, I think, is very true. I mean, I have this idea that almost everyone thinks there are only three probabilities for anything. It's either 0%, 100%, or 50%. 50, 50, yeah. Yeah, yeah. You know, nothing. The idea of something being 70, 30 is just really hard for human beings to latch on to. And maybe this is those heuristics that we grew up with in the, you know, in the wild, in the vault of Africa. Like, you better make a decision right away under conditions of stress and you don't get to do things over and over again. But so you would really say that your experience as a poker player has given you a better ability to correctly handle those 70, 30 situations. Yeah, I think so. I think you, you know, I mean, you're familiar with the term scope and sensitivity in terms of you, humans, we evolved in sort of tribes, probably up to 150 or so people. And so beyond that, numbers weren't that useful in terms of we didn't have to count too much beyond that. Yeah. And, you know, the classic example of, oh, there's a thousand birds dying in oil, dying from an oil spill somewhere. You'll feel some degree of sadness about that. And if I say there's a million birds dying from oil, you don't feel a thousand times sad or you feel probably a little bit sadder, but not a thousand times. And so we have this like our brains aren't intuitively equipped to think accurately around really large numbers or really, really small numbers. We just work on this sort of a little macroscopic level that's in our everyday lives. And so that, I would say that's very in realms of probability that sorts us out between the sort of 30% and the 70% but beyond that, things just, it feel really, oh, it happens 10% of the time. Oh, that's a never. Yeah, that's a never. Oh, 85% time. I pretty much always. And I don't know, like I think on the most part, you don't have an intuitive understanding of what actually like a 5% feels like or a 7% or a 10%. But poker, you play enough. You will, like I find my emotions genuinely correlate with like, when I turn the cards up on the flop, you know, we get a big all in. And I'm a 12% underdog. So I'm, yeah, I only got a 12% chance to win. Well, I'm just not going to get excited. I'm like, okay, I've lost. Yeah, I've got to win. Yeah, and, and, or if I have a 1% chance of winning, then my emotions are even less, you know, I just don't feel anything. I mean, I'm just annoyed that I got it in so bad. And, but if it's a coin flip, my heart will genuinely be racing because I'm like, wow, I will win this 50% of the time. And who knows what's going to happen. And so, yeah, you sort of become well calibrated to what these actually, these, these probabilities mean because we've just seen, we've seen these situations so many times over. Does that therefore apply to the everyday world? I mean, yeah, like if I'm, someone says, oh, you're, I don't know, 10% to, to make a flight. I think, well, if I can figure out that I'm roughly 10% to make a flight, then I will be, I, you know, I would be extremely pleasantly surprised if I did make it. Whereas I think, but at the same time, I don't think I'm that well calibrated as I am in poker. It's hard. Yeah, it's hard. So just to change gears a little bit, I was pleased to see that you had an article in Vox recently. You went back to your sort of astrophysics training and it, you know, is a story about the application of probabilities to interesting questions about the nature of the universe. So why don't you fill us in on what that was? Yeah. So recently, some of this, the researchers at the Future of Humanity Institute and in Oxford published a paper on, called Disolving the Fermi Paradox. I just, I imagine most viewers know what the Fermi Paradox is. Let's not imagine that. Let's tell them what it is. Okay. Fermi Paradox is basically, well, Enrico Fermi back in, when was it, 1963? 50s. Yeah, he didn't live into the, he didn't. He was very radioactive, yeah. Bad. But yeah, basically, he, you know, he looked up, he was like, wait, there seem to be billions, if not trillions of stars out there. We know that the universe is somewhere around 14 billion years old. If there's so many possible sites for life, why are we not at least, you know, we've been releasing radio waves now for, you know, a few decades, like relatively easily. Surely we should be at least hearing or picking up trace signals from other worlds or seeing aliens all the time. Like, the universe is so old, there should, there must be at least a few other thousand civilizations out there that have got a big head start on us. So where, where is everybody? And so that's the like famous Fermi Paradox, like the, the contradiction between the size and age of the universe and the lack of observed alien life. And so this paradox is seemingly only gotten stronger with time as, you know, we've become more space-faring. And we've discovered more and more exoplanets and, you know, it seems like there are, you know, universes even sort of more, more capable of hosting life than we imagined. There are so many places out there where it could be. Right. And yet, and yet we've still seen nothing and we've been, you know, really looking hard. And anyway, so this paper that they published uses the Drake equation, which was sort of this equation that sort of is the best way we could try and estimate the number of intelligent civilizations within the Milky Way. And it does a sort of novel form of analysis on it that hadn't been really done before. And the answers that sort of came out the back of that is that we are somewhere around 75% to be the only intelligent civilization within the galaxy and somewhere around a coin flip, about 5050, to be the only intelligent civilization in the entire observable universe, which is pretty, pretty astonishing stuff. Right. Counterintuitive to many people. Extremely counterintuitive, agreed. Also quite disappointing, because I'd love there to be some aliens out there. I mean, at least from Curiosity standpoint. But yeah, nonetheless, pretty groundbreaking claim. And so the article was sort of discussing how they came to that claim, what the actual processes that they did, the methods of analysis. But then I wanted to make a sort of larger point from that, which is, okay, well, we don't know for certain that this is actually the case. But let's assume that it is based upon our current best state of knowledge. It seems like if nothing else, life is extremely intelligent life is extremely rare in the universe. What does that mean philosophically speaking? For us, if we really are the only intelligent civilization out there, I mean, may well be for the rest of the universe's future. What does that mean? Should we do anything with that information? Should we change any of the behaviors that we're currently exhibiting and the trajectories that we seem to be putting ourselves onto? And I think, yes, I think it speaks that we have a greater responsibility to not blow ourselves up. I do want to get into that, but first I want to dig into this probability stuff. Yeah. Because the Drake equation is something that has been, you know, battered around nausea, right? And so for the two of you out there in podcast land who have not heard about it, the Drake equation is the way of estimating the number of intelligent civilizations by saying, well, how many planets are there, times what's the fraction of planets on which life develops, times what's the fraction on which the life becomes intelligent? It's different ways of breaking it down. But as far as I can tell, there's quite a two things in the new paper that are kind of interesting. One is they take seriously the idea of rather than finding just our best fit number for the fraction of time's life comes into existence and then becomes multicellular. They say, what's the uncertainty or what is the probability distribution? Right. So, taking those probabilities a bit more seriously. And secondly, it is a matter of being good basians and updating our priors, right? I mean, they're not saying just based on the laws of physics were probably the only intelligent civilization of the galaxy. They're saying, based on the fact that we haven't seen it yet, right? That in some sense, Fermi was right. It would have been very, very easy to run into another civilization if they were out there. We haven't seen them. They don't seem to be out there. And therefore, from that, we draw the conclusion that probably the simplest explanations are just not there. Maybe it's just way more unlikely that intelligence civilizations exist and continue to exist than we thought it might have been. Right. Exactly. The fact that we haven't found any evidence of aliens is evidence unto itself and should be incorporated into sort of the Bayesian model that we have of the situation. Were they able to pinpoint one of the factors and say, this is probably the tiny one? In terms of which one has the... The smallest probability is that light doesn't usually form or tell us about that. Yeah. So, the one that has the biggest number of range of uncertainty on it is a fraction of planets that develop life. Okay. Which makes perfect sense. What do we know about that? We still haven't really figured out how life started on Earth the process of A by Genesis is just really not well understood yet. And so, the difficulty that we've had with the Drake equation is that, for example, we're sort of plugging in numbers like the rate of stellar genesis within the number of stars that develop per year, that's an astronomical number. We have a reasonably accurate number. We have data on that. Exactly. But then something like the fraction of planets that develop life, it could literally be the uncertainties. They have like 200 orders of magnitude of uncertainty. Oh my goodness. Yeah. It's that much. Yeah. And the thing is, is that because like that's... Any number between that is actually completely plausible by saying, oh well, yeah, but let's ignore the fringe parts of it. That's making a statement, that's making a claim of knowledge that we can't make. You know, say, oh well, it's probably somewhere in the middle. No, like it's as can see, you know, the probability distribution is like fat tailed all the way down. And so to cut these off is just doing bad math basically. Yeah, I'm glad the paper came out because I've run into great resistance. I've always felt basically this, like we don't know how likely it is that life's going to exist. The other obvious bottleneck is multicellular life, which again we don't know how that exists. I tend to think that once we get multicellular life intelligence is probably not far behind. Yes. But both the existence of life itself and multicellularity seem like very mysterious. Maybe the chances are just 10 to the minus 100, right? And people say there are so many planets out there and like, there's no number N such that I cannot find another number that multiplies it and gives us a small number. Tiny, tiny, tiny number, exactly. Yeah. I mean, there's sort of the idea of like this great filter where there's some kind of insurmountable barrier that exists somewhere in the chain of evolution that for whatever reason most planets can't get past. Right. And for some reason, Earth managed to get past it. Like I hate to even like hazard a guess at where it is, but like intuitively, no, the intuition's really applied to this. It feels to me that it's somewhere in the step from singular, oh, prokaryotic to eukaryotic life, somewhere around there. But again, that's just not just multicellularity, but just the idea of having a nucleus. Exactly. Having a nucleus within a cell. That seems to be. That's probably more important. Yeah. Something somewhere around that. And there's some other work that Future Humanity Institute are doing right now on the similar analysis, but looking at the transitionary time, the rates it takes to go from each step to each step. And it just seems quite likely that the reason why the reason why life isn't everywhere is because it just takes such a long time for it to actually get to the stage where intelligent civilizations are actually spring up. Right. The plan, you know, we made it on Earth five, six of the way through. Yeah. Earth's lifespan in about 750 million years. This came into being relatively quickly, right? But then it sat around in this boring, nothing state for eight-in-aages. And then suddenly, there was this explosion where evolution got, you know, kick started faster and things, interesting things started appearing. But that wasn't basically until five, six of the way through Earth's lifespan. Had it just been a little bit longer, we would not have existed because Earth would have been gone world up by the sun. And so that's a reasonably plausible explanation as to why life is incredibly rare. I suspect that's the right explanation. My other favorite one is that there are plenty of civilizations. They all become highly advanced. They upload their consciousness into computers and then they become bored and they don't go space traveling anymore. Yes. That's a good one. Also, the activation hypothesis. You know that one? I don't know that one. You'll be better to explain the exact reason why. Because computation is expensive in higher temperatures. In, and you would expect a rational civilization that would want to maximize the number of computations it can do over time. So it makes sense for them to hibernate or activate until the general temperature of the universe, you know, until far, far in the future and the ambient temperature of the universe is much lower and therefore it's much cheaper. And you can, I think it's something like 10 to the 30 more computations a second you could achieve or something like that. I can't remember because it's, and a sample has a very fun paper on it. I've never heard of that one. I like the audacity of it. I don't believe it. No, I don't. I don't. I don't. I'll tell you why I don't believe it because the temperature of the universe goes down. Right. That's fair. But also the free energy of the universe goes down. Right. The energy we have available to run our computation goes down. So I presume someone smarter than me has actually done the calculation and said it's still better to wait, but there's clearly a. Yeah, I'm pretty sure he fights us that in, but I, I'm not first enough to explain why. Nonetheless, again, it was one that felt into it. It was very fun, but intuitively I'm like nah. It only takes one, you know, plucky counter example, right? Only one civilization has to not buy into that. Yeah. But it does remind me of John Wheeler used to say when he mixed cream into coffee, he always felt sad because he was increasing the entropy of the universe irretrievably. But you do bring up this question of what does it mean? What do you, what, what implication? So what if we are the only civilization, only intelligent life forms, it makes you think, you know, for better or for worse, but making you think is good. Why are we here? What is the point? So and you actually been thinking about things like this, right? Yeah, I mean, I, I mean, I was just having a, having a conversation with my partner, Igor about sort of moral, moral realism. I know that you're very much a non moral, moral realist in terms of. That's the humane constructivist, yes. Yes. And I'm of the same, same mindset. But that said, it, if you want to sort of, if nothing else, maintain optionality, us going extinct is definitely going against that. Like now the options have disappeared to zero and that seems, it definitely appears like there is a very real risk that we can go extinct by even 2100 and by real risk, estimate somewhere between, anywhere between like two and 20%. I'm a moral constructivist, but the morals I construct do say that human extinct can be bad. We'll be bad, yes. That's okay. I don't need an objective story to tell myself about it. Right. Exactly. And, and yeah, it just seems like it would be a terribly big shame if, you know, all this and these little pockets of low entropy have managed to appear, us, you know, basically going against the second law of thermodynamics to a degree, are we actually going against the second law of thermodynamics? No. No thing goes against the second law of thermodynamics. So how, this is what I've never wrapped my head around, how do pockets of low entropy so successfully exist then? Well, it's, it's actually an outgrowth of the second law of thermodynamics because if we think about it, if it weren't, what would it mean to not have the second law of thermodynamics? Right. What it means is that we were already in thermolegal equilibrium, right? We were already at our maximal entropy state, right? Once you say that early universe started with low entropy, that's all you need to say, then entropy increases and that's the second law. The only way out of that is to say you were already in high entropy and then there would never be any life, there would never be any complex structure, there would never be anything like that. I see. We are not creating pockets of low entropy, we are leaching off of the fact that the early universe had an extraordinarily low entropy, we're increasing the entropy of the universe willy-nilly, right? Yes. So, a separate question, related but separate, which is why are we complicated? Why are there complex structures in the universe? And that's something that it makes sense that complexity develops along the way from low entropy to high entropy, but the details of how it actually happens is an ongoing, fun research problem. And life is certainly just an example of exactly that. Right. And, and so yeah, I think it would be arguably a tragedy on a universal scale in terms of just lost utility and lost potential and lost optionality if, you know, even from just the, looking from an expected value standpoint, if we were to go extinct, even if it's a 0.001 percent chance, there's still going to be 10 to the, I don't know how many possible lives, you know, and possibly very happy lives in the future. I have met people who argue that the human race should go extinct, that it would be a moral good, that the rest of the planet would be better off with it. Right. Oh, they're, I assume they're extreme negative utilitarians in terms of their nature. No, no, no. It says that the utility goes to the plants and the animals, not to us. We're in that negative, they claim. I don't believe them. I'm just saying, yeah, what's their main argument as to why we are in that negative, just because we create suffering upon... Yeah, we're highly distorting the ecosystem and, you know, the, so much of the biomass is devoted to keeping us happy and it's not a natural state of life. Right. But define natural. That's the thing. I don't want to defend this. I'm just laying it out there. No, I mean, it's definitely an interesting viewpoint to discuss and I have to say, intuit my intuitions are very, you know, I grew up in nature. I, like, I love nature more than anything and nothing upsets me more than seeing, like, images of the rainforest, you know, this millions and millions of years old, beautiful, unbelievably complex rainforest, you know, a tree being cut down into planks of wood, coming that's so unbelievably complex and sustains this intricate framework of an ecosystem around it, all the insects and animals and fungi and everything that grows off it and relies upon it is reduced to more planks of wood that people then put, you know, we put our coffee mug on. Coffee table, yeah. You know, that's put down into this complicated ecological, sorry, economic system out of this complex and I think there are two very different things, complex ecological systems. So like intuitively, it seems like a huge tragedy that we are doing that. Nonetheless, I also think intuitively is a huge tragedy that this, you know, human consciousness that does seem, so I don't know inherently special, but there's definitely something inherently unique that is not, we're not seeing elsewhere in the natural world as much and for that to go out. And the thing is, is if we go extinct, well chances are probably all the other, most the other big animals will go extinct too as well. I just wanted on the record that we are having this conversation at a concrete table, not a rainforest wood table. With metal legs, yes, very good. So we're very morally correct in our living room here. But it doesn't, we probably don't really think that it affects that calculation, whether or not we're the only civilization. I mean, maybe it makes it more poignant, right? Right. But we still don't want human beings to go extinct even if there's 100 million others, out there. I mean, there are plenty of people who think that there are 100 million others out there, and they're waiting for us to grow up a little bit, right? Right. I have my suspicions that that's crazy also, but it is at least one of the options on the table. Yeah, it's definitely, I mean, you can't, you can't rule anything out. That's the thing when we're dealing with something of such uncertainty like this. And certainly humanity has a lot of growing up to do. But that said, there's a lot of beauty and goodness in the things that we are doing. And it would be nice if we were given the opportunity to try and grow up. And you have put your money where your mouth is quite literally, becoming interested not only in these philosophical questions, but the applied questions of how to be better people, how to make the world a better place in the effective altruism movement in particular. And you don't just talk it, but you've like started an organization, is that it? So... So help people with effective altruism even is? Yeah. So effective altruism is basically the combining the head and the heart when it comes to philanthropy and doing good. We all, well, vast majority of us, we want to do good in the world. If we see someone suffering, we'll try and help them. You see someone passed out in the street, natural human instinct is to usually go and check on them or a doggy alping or whatever it is, someone's screaming fire. They're all, for the most part, naturally altruistic. And that's a great thing. But at the same time, there will also be different ways. There will be some ways which are more effective at getting a certain problem alleviated. And so effective altruism is basically applying science to philanthropy, to altruism, doing good as effectively and efficiently as possible. And so, I remember hearing about this, that I wanted to give money to, for example, environmental charities, but I often just felt lost. I was like, well, where do I start? What's, I'm concerned about climate change, I'm concerned about biodiversity loss, etc., etc., all these different things. Which, how do I weigh these off against each other? When I give my money to one charity, that means I'm actively not giving my money to another. We only have limited resources ever to give. And so it's imperative that we do as much research we can, or at least consult people who've done the research, to figure out where we can get, have the biggest positive impact with whatever we give, whether it's not just money, as well time, if you choose to work for a charity, you want to make sure that it's the actions that you are taking in new line of work are achieving the most good, because you won't get those hours back. Time is also a scarce resource. And so after hearing all these arguments, I was like, oh, this makes a lot of sense. And a team of full-time effective altruists, they suggested, well, look, we think poker players will get this. They're very used to thinking in numbers about uncomfortable things. They're comfortable with the idea of sort of thinking about expected value and uncertainty, quarry and variance, quantifying things. And they're also, you know, poker players, I think, are willing to, despite sort of the impression that we're all like dark, degenerate money-grabbing. General gamblers, actually, you know, like, I think a lot of poker players are aware of sort of a unique position that they have in terms of we have sort of time and we can make good money and it'd be nice to contribute to society in some way. And so we decided to start this organization called Raising for Effective Giving, rake hyphen charity.org. Raising is a part. Exactly, fun on the old chips thing. Igor and I have many arguments about who came up with the name. But yeah. That's what it is. But anyway. That's not going to happen. Yeah. Well, you know, one more I've already known. And yeah, so four of us poker players started it alongside these Swiss effective altruists. And we, yeah, we were encouraging, originally we were encouraging poker players to give 2% of their profits. Sorry, 2% of their net, no, gross winnings every quarter. And some people sort of continue on that model. Others just sort of, because poker's a very all on nothing kind of game often, you'll have a big win followed by months of losing. One six months, yes. And so generally people just tend to donate when they have a big win as a percentage. And yeah, it's been extraordinarily well received. I had no idea that poker players would like get it as much as they did and it's raised over $6 million now. And so the charities are specifically, we either use GiveWell, who you might know, GiveWell.org, which is a very... GiveWell is usually where I go when I... Yeah, they're fantastic in terms of... In terms of like human suffering reduction, they are the go-to in terms of you want to find out how you can help human lives right now as best as possible. So we use their top three recommended charities, which are almost always against Malaria Foundation and sort of something deworming and direct poverty alleviation with like GiveDirectly. And that's because like the cost to save a human life, like your or hate it, unfortunately, is just many hundreds of times cheaper, around a hundred times cheaper in the developing world than it is here, say, in the US or in the UK. In the US, the government will up to... It's to spend up to around a million dollars to save a life on if you look across healthcare and that kind of thing. And yet you can demonstratively save a life in some parts of South Africa for around $7,000. So that's a huge, huge difference. And even if you think that an American life is worth more than someone save from Malawi, do you really think that they're worth a hundred X? Like would you press that button to say I will kill a hundred Malawians to save one random American? And it's not about an American you know, like someone random from America, in a part you'd never been to. Would you really say they're worth a hundred, you know, a hundred mothers or a worth one mother here? No. And so, yeah, it's about this sort of idea. Unfortunately, you do. You have to like put a price effect. It's not putting a price on a human life, but it's about saying, my actions, I can help someone with the money that I give. And so I want to help as many people as possible with that. And so, yeah, so we've got some, we've got the best charities in human suffering alleviation. The best ones in animal suffering alleviation. By best, I mean most cost effective. And the animal ones almost always are to do with anti-factory farming. Just because it's pretty tragic what's going on out there. And it's very, very cheap just to save very sentient animals from the life of misery. And then we also have an elected research areas, specifically ones looking into things like global catastrophic risk. That's quite cool. So, yeah, like people looking into risk from bioterrorism. Because even if it's a tiny chance. Exactly. Yes, even as it's a 0.1% chance. If you factor that over the 100 billion or so lives that are going to exist over the next century, and there's roughly what the number is, even over the next century, that's a lot of people. I mean, it seems kind of obvious that we should try to be efficient and spend our charitable givings as effectively as possible. But there has been pushback, right? I mean, some people don't like it. I mean, personally, I'll confess I'm not a utilitarian. I think it's hard to be a consistent utilitarian. But still, I take the effective, effective altruism to be a good nudge in the right direction, right? I mean, we certainly do value the things we see right in front of our eyes more than the things we know are going on out there in the world. And this is an excellent reminder that there's ways to make a huge impact elsewhere in the world that might not be quite as obvious to us. Exactly. It's not just, it's taking, you know, it's not saying that if you, you know, react, you know, to something immediately happening in front of you that that's not a good way of doing good. Of course, it's good. Like, it's there. And a big part of when you do good, you're trying to do something altruistic and help, it's fine to also feel good about it. You know, I think people go, oh, you know, you shouldn't have any positive emotions that come out of it or you shouldn't be doing it that way. I think that's silly. Like, no, like, you want to do whatever continues to motivate you. Yeah, that doesn't mean from giving you the answer. Absolutely. And, you know, and so it's about, like, like I said, it's about balancing not just the head, but also the heart. The heart is a big part of any kind of charity giving and so on. And I think it's a mistake to try and remove that out of it. But at the same time, we have to be aware that just purely acting emotionally, when we know that we have these big biases in terms of like, we randomly will sort of value people who happen to live in the same town as from someone who lives in a town a hundred miles away, even though we don't know either of them, just because that's just the way human intuitions are sort of built. And that can then be a mistake in terms of our sort of narrow resources that we have to allocate. I mean, maybe from what we said earlier, there would be a good charity that could give everyone free poker lessons, because it would help them think in probabilistic ways about the world. I wouldn't specifically say that, but yeah, I mean, like, there is a charity who, I mean, there are at least a sort of 5013C, but who train young people in applied rationality. So quantifying things, which is basically applied poker, doesn't at all talk about poker, but they training promising young people who are looking to get into sort of research, politics, you name it. The art of rationality, which is incredibly important because these are going to be the future leaders. And I think we want leaders who are aware of human biases and aren't afraid to think in sort of scientific terms, to give them the tools to understand their own emotions and so on, and therefore be better equipped decision makers. And I think that's an incredibly valuable thing, and that's one of these kind of organizations that are looking into teaching rationality classes in schools. I think these are incredibly promising areas to donate to, because they can create a... There's definitely a huge lack in our current education system. And how many kids are taught to think through their feelings, for example, or, yeah, like, oh, it's okay to be uncertain. Let's see if we can estimate our probabilities. These basic rationality tools that you and I take for granted. We only know them because we learnt them as adults, either through poker or through another means. But imagine if you were just taught these basic things, or learning to think through the counterfactuals. Something like that. I wish I'd learnt that when I was ten. It would save me so much time. Or, yeah, just like looking up the probabilities of, I used to be a huge hyperchondriarch. The amount of worrying time I've spent, you know, always my headache and brain tumour. If I just learnt to do a bit of Bayesian updating, I would have saved me a lot of misery over my late teens. And so, yeah, I think it's a big shame that these areas are neglected. Well, I think it's a perfect place to end, because you've basically encapsulated the mission statement of this podcast, trying to get people to think a little bit more rationally, a little bit more cognizant of their biases, and a little bit thinking in different ways than they usually do. So, live worry. Thanks so much for coming on the podcast. Thank you, Sean.