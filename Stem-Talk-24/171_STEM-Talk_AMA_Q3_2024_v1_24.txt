 Welcome to STEM Talk, where we introduce you to fascinating people who passionately inhabit the scientific and technical frontiers of our society. Hi, I'm your host, Dawn Cornegas, and joining me to introduce today's podcast is the man behind the curtain, Dr. Ken Ford, HMC's director and chairman of the Double Secret Selection Committee that selects all the guests who appear on STEM Talk. Hi, Dawn. Great to be here. Well, it's time for another Ask Me Anything episode. So today, Ken and I will be answering questions that touch on a pretty wide range of topics, from the quest for artificial general intelligence to the glymphatic system to whether one's APOE status will cause that person to develop Alzheimer's disease and many other things. Before we start answering our listeners' questions, we have some housekeeping to take care of. First, we really appreciate all of you who have subscribed to STEM Talk, and we are especially appreciative of all the wonderful five-star reviews. As always, the Double Secret Selection Committee has been continually and carefully reviewing iTunes, Google, Stitcher, and other podcast apps for the wittiest, most lavishly praised-filled reviews to read on STEM Talk. If you hear your review read on STEM Talk, just contact us at stemtalk at ihmc.us to claim your official STEM Talk t-shirt. Today, our winning review was posted by someone who goes by the moniker I Heart Science Saturdays. It reads, As a very long-time listener of STEM Talk, today's podcast episode with Vivian Lowe has raised my standards when it comes to informational content as well as production quality. I've heard her on various other podcasts, and this interview was by far the best. Thank you, Ken and Dawn, for asking the most informed questions on the internet. And thank you to the Double Secret Selection Committee for keeping their fingers on the pulse of today's most important research topics. So, Ken, this must be an alumnus of our Science Saturdays program at IHMC. How cool is that? It's really cool. I hope it is an alumnus. Our Science Saturday program for children is something we are quite proud and passionate about at IHMC. Yeah, absolutely. So, thank you, I Love Science Saturdays, and thanks to all of our other STEM Talk listeners who helped STEM Talk become such a great success. Okay, and now on to answering our listeners' questions. STEM Talk. STEM Talk. STEM Talk. STEM Talk. STEM Talk. Hi, welcome to STEM Talk. I'm your host, Dawn Kornagas, and joining me today is Ken Ford. Hello, Dawn. So, today is an Ask Me Anything episode, so we're going to start off with some questions for Ken. So, a listener writes, The FDA recently issued approval for a human trial of a neural implant device that is touted as a device that could give patients with degenerative neuromuscular disease or spinal cord injuries to control external technology with neural signals. I'm not asking for your comment on the device specifically, but rather, I love your insight into what is being called the brain-computer interface technologies. What is the true status of this emerging discipline, or is it still the realm of science fiction? Well, we'll talk a little bit about science fiction in a minute, but with respect to this listener's question, since its start, really in the 1970s, that's when brain-computer interface work started. The primary aim of research and development in this area has been to provide communication between a brain's electrical activity and external devices, such as robotic limbs or computers. And these interfaces, these brain-computer interfaces, have permitted patients to control things like a cursor on a computer screen, to open email, or to operate a device, or control a prosthetic arm or a robotic arm. And in recent times, really in the last year or so, in particular, this area of work has garnered substantial media attention. And this is largely attributable to Neuralink, a company founded by Elon Musk and others in 2016, which is developing implantable brain-computer interfaces. There are many and various approaches to the development of brain-computer interfaces. Neuralink's approach requires patients to undergo invasive brain surgery to implant a small circular device that processes neural signals, which is itself connected to a collection of thin, flexible, really like threads, that are inserted directly into brain tissue and thereby detect neural signals. The goal is, as I mentioned earlier, for patients to be able to control external devices, such as a mouse or a keyboard, via a Bluetooth connection. In January of this year, Neuralink implanted a brain-computer interface in a human and later reported that this first trial participant had been able to control a cursor on the computer screen. However, in May, the Wall Street Journal reported that 85% of the implant threads from the device had already detached. Neuralink has said that it will address the detachment issue in a second patient by implanting the threads more deeply in the brain. Although it remains early days for sure for brain-computer interfaces, they have demonstrated a significant clinical potential across a range of disorders. However, this rapidly growing field of research and development faces numerous challenges, which really point to the need of further research and innovation, particularly in enhancing non-invasive brain-computer interface techniques and in integrating AI for improved signal interpretation and application. That said, brain-computer interfaces are the product of exciting intersections of advanced technology and neuroscience, which, if successful, might significantly enrich the lives of many patients. I absolutely agree with you on that, Ken. So the same listener continues and says, Speaking of science fiction, the genre is in the throes of a cultural resurgence, with small and big screens alike awash in stories of space exploration, settlement, and survival. Some are like For All Mankind, presenting an alternate history of the space race with the Soviets beating the U.S. to the moon, and others, like Foundation, mind classics like Isaac Asimov with some added twists. And Frank Herbert's Dune is in the middle of an epic retelling. So, Ken, I'm curious, do you have a favorite science fiction writer or sci-fi story or series that really moves you? Well, as I have mentioned previously, I occasionally do read fiction. My work requires me to read many government reports, and some of those are clearly fiction. I also read lots of nutrition research, and as many of our listeners are aware, most or much of that is fiction. But, if you mean actual science fiction in the traditional sense, no, I don't read much of it these days. But if I had to pick a favorite science fiction author, it would be the late Robert Heinlein. He was born in 1907, and he died in 1988. In addition to his primary work as a science fiction writer, Heinlein was an aeronautical engineer and a naval officer. Perhaps as a consequence of this background, he always tried to include accurate or at least plausible science and technology in his fiction stories. I particularly appreciated his ability to weave certain social societal themes, such as the importance of individual liberty and self-reliance, into the framework of his science fiction stories. And Heinlein produced really many of the best quotes of the 20th century. And here are but a few I'll share with you. There are lots more available online. Many of you will recognize some of these quotes, but might not recall that they were in fact due to Heinlein. I will start with perhaps my longtime favorite Heinlein quote. He says, What a great quote. And here are a few more that I'm sure our listeners will have heard versions of, but perhaps did not know the source. You cannot conquer a free man. The most you can do is kill him. Never attribute to malice that which can be adequately explained by stupidity. Never underestimate the power of human stupidity. And as a side note, unfortunately, I've noticed some folks exhibit both traits. Here's my last Heinlein quote of the day. The United States has become a place where entertainers and professional athletes are mistaking for people of importance. And that trend he identified a long time ago has only accelerated. All fantastic quotes, Ken. So we're going to move on to another listener. So actually several very concerned listeners have asked about a paper titled, APOE4, Homozygosity, Represents a Distinct Genetic Form of Alzheimer's Disease. And the listeners want to know if, as the paper claimed, they were essentially certain to develop the disease. And was there really nothing that could be done to improve their outcomes? Wow. Yes. This paper lit up the old email inbox. And it's a recent paper, a really frustrating paper for me to review. And frankly, I'm quite surprised it was published in its current form in Nature Medicine. This is a well-respected journal. Peter Attia has also done a nice analysis of this paper that I could point our listeners to. And he did identify some of his shortcomings. And this discussion will take a more in-depth look at this paper. And we also consulted with our colleague on this, Dr. Tommy Wood. The study asserted, as reflected in the title, that there is a special, distinct, and genetically driven form of Alzheimer's disease, which is essentially unavoidable for folks having two copies of the APOE4 allele. That is, rather than considering genetics as a risk factor, which we have long known, This paper makes the claim that this allegedly special form of Alzheimer's disease is actually caused by having two copies of the APOE4 allele. Now, this is pretty crushing news for many. And of course, the media only made matters worse with exaggerated headlines and superficial reporting in general. To back up a bit, the apolipoprotein E, that is, APOE, is a protein involved in the metabolism of fats and lipids in the body of mammals. There are three major human alleles of the APOE gene, E4, E3, and E2. Today, we'll only discuss E4 in the context of Alzheimer's disease and this particular paper. The APOE4 allele has long been recognized as the largest genetic risk for Alzheimer's disease. We each inherit one copy of the APOE gene, one from each parent. So, having one APOE4 allele is thought to roughly double the risk of Alzheimer's. Having two copies of the APOE4 allele has been thought to increase the risk of getting Alzheimer's perhaps about 8 to 12-fold, depending on sex, race, and other variables. Now, turning to the paper in question and its methods, something that stands out from the start is the lack of clinical equipoise. They seem to want APOE4-4 to be its own classification from the outset and really set up their study to find that outcome, including the ways they stratified and substratified the data. For example, like ignoring the APOE4-4 is not having Alzheimer's because they don't fit the pattern. The apparent bias of the authors is despite decades of research that suggests that APOE4-4 does not act as a genetically determined single cause of Alzheimer's disease. As early as 1998, a paper published in JAMA Neurology titled Risk Estimates of Dementia by APOE Lipoprotein E Genotypes from a Population-Based Incident Study, the Rotterdam Study, reported that the proportion of patients with dementia that is attributable to the E4 allele was estimated to be about 20%. The APOE genotypes explained about 10% of the variants in age at the onset of dementia. The association between the E4 allele and dementia was strongest in the young age category and in those with a family history of dementia. Our colleague, Tommy Wood, has run some simulation studies previously with data from high-quality, relevant published research. And when you look at APOE4-4-4s, only about a third seem to be at risk of developing Alzheimer's disease at an age that is outside the distribution for non-APOE4-4s. That leaves roughly two-thirds of the APOE4-4s with approximately the same risk as everyone else. Now, when I say the same risk is for everyone else, we're talking in this case about the risk of developing Alzheimer's earlier than the normal population. This fact alone should tell you that it's clearly not acting like an autosomal dominant form of Alzheimer's disease. Perhaps the greatest weakness in this paper, which was partly highlighted by Peter Atiyah, is that the sample provided by the National Alzheimer's Coordinating Center is hugely enriched for people with mild cognitive impairment and dementia. Therefore, you really can't use it to tell you anything about the natural course of APOE4-4s. Even the clinical cohorts they included tend to focus on those at elevated risk, recruiting those that have a family history of Alzheimer's disease. So automatically, any APOE4-4s included are probably from an environment that is already going to be associated with higher Alzheimer's disease risk. It does seem reasonable, from their data though, to believe that at a given age, somebody with two copies of the APOE4 allele will likely have more of the Alzheimer's disease-related biomarker changes compared to a non-APOE4-4. However, we know that these biomarkers are very poorly correlated with both cognitive function and dementia risk and status. They also didn't measure Ptau-217, which is perhaps the best, though still not perfect, current biomarker for Alzheimer's disease. One can observe from their supplementary figures that the biomarkers do a very poor job of differentiating who does and doesn't have dementia, yet they use these same biomarkers as the primary outcome of Alzheimer's disease diagnosis. The authors justify this by citing a 2018 paper titled Toward a Biological Definition of Alzheimer's Disease, which they use to suggest that you can diagnose Alzheimer's disease from biomarkers alone and in the absence of any observable cognitive changes. Now, this does not align with clinical or patient experience. Few people would care about certain protein levels in their blood if they never experienced cognitive decline or dementia. In some places, the authors seem quite inconsistent with their primary claim. In the discussion section, it seems that perhaps the reviewers may have forced a little balance on the authors because suddenly they acknowledge in the discussion section that lifestyle and environment can still alter risk in APOE4-4s and that Ancestry alters the penetrance of APOE4-4 on Alzheimer's risk. If their hypothesis was correct that this is entirely genetically driven, then this obviously wouldn't be the case. These ancestry, lifestyle, environmental factors would make no difference. But they do. Other than a 2023 paper in JAMA Neurology titled APOE4 Genotype and Alzheimer's Disease Risk Across Age, Sex, and Population Ancestry, there have been multiple studies in populations where APOE4 has no relationship with dementia risk. This includes Indigenous Americans, Indigenous people found in the Bolivian lowlands, and Nigerian Yoruba. Even the idea that APOE4 is particularly harmful to those of European ancestry is not borne out by previous research. A very interesting paper published in 2019 titled The Varying Effects of APOE Alleles on Extreme Longevity in European Ethnicities found that E4 was associated with a higher mortality and higher dementia in southern Italians when they lived in the United States, but not when they lived in Italy, implying there may be a lifestyle and or environmental factors, and thereby cannot be entirely genetically determined. In conclusion, it seems that the literature suggests that APOE4 excaborates responses to dementia, Alzheimer's disease risk factors. So, in a sense, it's a moderator of the environment rather than necessarily being a highly penetrant genetic risk factor on its own. As such, that means that you should be able to dramatically reduce excess risk associated with being an APOE4 by modifying well-known environmental and lifestyle-related risk factors for Alzheimer's disease. Several papers have explored modifiable risk factors for Alzheimer's disease, including how they might be amplified by APOE4. The Lancet Commission in 2020, led by Professor Gil Livingston, identified hearing loss, high blood pressure, excessive alcohol intake, obesity, smoking, social isolation, and physical inactivity as the primary modifiable contributors to dementia risk. A meta-analysis of modifiable risk factors from 396 studies conducted by Professor Jin Taiyu, also in 2020, identified sleep disturbances, diabetes, elevated homocysteine as the largest risk factors for Alzheimer's disease, with cognitive activity being the most important protective factor. A meta-analysis conducted by Bedun et al. in 2014 suggested that smoking, physical inactivity, high homocysteine, and low omega-3 intake were the most important modifiable contributors to Alzheimer's disease risk at the population level. Since then, multiple randomized controlled trials have also shown that the combination of increasing omega-3 intake while lowering homocysteine synergistically slows brain atrophy and cognitive decline. Related to this, a 2018 paper titled Apolipoprotein E4 Magnifies Lifestyle Risks for Dementia, a population-based study found that those with ApoE4 in particular had amplified risk for dementia related to excess alcohol consumption, low physical activity, and low omega-3 or polyunsaturated acid intake. Therefore, improving sleep, physical activity, and nutrient status, addressing sensory losses, such as hearing aids or cataract surgery if needed, as well as increasing cognitive stimulus and social engagement will likely dramatically reduce dementia risk regardless of genotype. As ApoE4 is a risk factor for cardiovascular disease as well, and cardiovascular disease is itself a risk factor for dementia, it may be particularly pertinent for those individuals to monitor and address cardiovascular risk factors, such as lipid profile and blood pressure. Finally, there's still much to learn, but it seems clear that the paper's primary claims are false, and those with ApoE4-4 are not genetically determined to experience Alzheimer's disease. We will include links to all the papers I have mentioned in the show notes. That's a fantastic answer, Ken, and so important for so many of our listeners. So we're going to move on to another question for you, Ken. So a listener writes, Back in 2019, Ken, you were part of the National Security Commission on Artificial Intelligence. It's been five years since that commission issued its report, which included very specific recommendations for our government to take to prepare for and defend against the national security implications of AI. Eric Schmidt, the commission's chairman in January 2024, spoke at the Nuclear Threat Initiative on Global Security in the Age of AI. He noted the government acquisition system as a hindrance to properly preparing the needed resources to guard against cyberattacks and the continuing risks. So what grade do you give the implementation of the commission's recommendations? And are there recommendations that haven't been fulfilled that you think should be fast-tracked at this time? Well, let me start by saying I strongly agree with Eric Schmidt that the procurement system in DOD and the government in general is broken. And worse, it seems highly resistant to repair. The commission issued our final report in March of 2021. Nearly all of the recommendations of the National Security Commission on Artificial Intelligence were acted on by Congress, not always in ways consistent with our intent, but that is to be expected in D.C. To provide a sense of the scale of this effort and its impact, approximately 111 of the recommendations have been passed into law. Additionally, 44 of the recommendations from the National Security Commission on AI are currently pending in ongoing legislation. Additionally, the Senate has integrated various recommendations into their AI roadmap they're building. In general, I give the commission and Congress a good grade on this matter. We will provide a link to the commission's final report in our show notes. A listener asks Dawn to follow up on her collaboration with Jeff Iliff that the two of them discussed during his interview on STEM Talk. I am curious about their project that looked at the potential approach that would optimize glymphic clearance for individuals with acute or chronic sleep deprivation. I suspect that some of the nurses I worked with struggle with sleep deprivation. So I'm trying to learn as much as I can about the subject. Yeah, thanks, Ken, for the question. And thanks to the listener for the question. So probably some of the nurses that you worked with struggle with sleep deprivation, as many people in the medical industry, many people in military, many athletes, pretty much a lot of the population, to be fair, struggles with sleep deprivation. So this is really important research that's happening with respect to the glymphatic system. And so that was a really fun interview with Jeff, really informative, and just an update on the projects that we had talked about that we've been working on together. So at the moment, we have two ongoing studies with Dr. Jeff Iliff, who we interviewed on STEM Talk. And we have a collaborative team at the University of Washington, Montana State University, and Oregon Health and Science University. So the first study involves that team working with another research organization called Brain Electrophysiology Lab. And they're investigating a device that's been developed that has been shown to stimulate slow-wave sleep in humans. And since glymphatic clearance has been shown to amplify during slow-wave sleep, the specific study is investigating whether this device has an effect on glymphatic function in humans. And that's starting up at the University of Washington. So I would say stay tuned for results. Maybe that'd be a great chance for us to get Jeff back onto STEM Talk to give us results of those studies. There's a second study being run by Dr. Iliff and team, same team, University of Washington, Montana State University, and Oregon Health and Science University, that's investigating the effect of a pharmacological agent, dexmedetomidine, on glymphatic function in several different models, including humans. And so just a little bit of background on dex. So this is kind of interesting. I'm going to start calling dexmedetomidine dex just for simplicity's sake. This is an alpha-2 adrenergic agonist that suppresses central noradrenergic signaling. And it's widely used and well-studied as a sedative agent that promotes delta-band activity and also non-REM sleep in humans. And there have been several studies in rodents that have demonstrated that dex administration enhanced glymphatic function. So in rodents, dex has been shown to attenuate neuroinflammatory response to sleep deprivation. While in human clinical populations, use of dex improves post-operative sleep and also reduces the risk of post-operative delirium. So pretty exciting results in that context. So based on its safety, mechanisms of action, and established non-invasive administration, we're looking at self-administration of low-dose dex as a proposed pharmacological approach for enhancing glymphatic function in the setting of sleep deprivation. So that second study is going to look at that in humans. So really exciting. And again, we should bring Jeff on again to talk about the results of that study. That study is spinning up at the University of Washington as I speak. Through both of these studies, I will also note that that collaborative team that I was talking about has also been optimizing glymphatic imaging strategies. So it's really important for us to be able to measure glymphatic function to see if these different approaches actually work and get the glymphatic system to either amplify or restore glymphatic function in the setting where it may not be working efficiently. So the glymphatic system is a functional system, meaning we can't image a structure per se. We have to actually image it working. So the gold standard in the past for imaging the glymphatic system when we started working together was intrathecal contrast MRI, where contrast agent is administered in the spine, and then we measure uptake and elimination of that fluid in the brain through imaging. Now, not ideal for a number of reasons, for the participant or the patient or for the researchers. So we really wanted to move away from that approach. So we collaborated with Dr. Rachel Seiler and her team at the University of Florida. And just to note, this is research that was funded by the Office of Naval Research at IHMC. And that work demonstrated that intravenous contrast MRI worked just as well as intrathecal contrast. So that was a step in the right direction, right? So a little bit less invasive, a little bit simpler administration for our participants and patients. Also during this time, one of our collaborators, Dr. Swati Rane, has been developing non-contrast-based imaging approaches that are currently being validated in humans as part of the ongoing studies that I already talked about and also other parallel studies. And a non-contrast-based approach using MRI would really open up the field of glymphatics as something that could really amplify the ability to measure glymphatics in a variety of settings. Just to note, there's also a device that has been developed by a collaborating company who's working with us on that second project that I mentioned. That company is called Applied Cognition. And the device that they've developed allows us to measure glymphatic function without MRI. So it's actually a head-worn device. And that device is being tested in that second study, as I mentioned. So one other shout out in both of those studies, we are being funded by MTECH. MTECH. So it's a funding mechanism through Department of Defense because there's a lot of interest in being able to amplify glymphatic function, improve cognition in the setting of sleep deprivation for military personnel. So there's a lot of exciting work underway. And again, I guess that means a revisit by Jeff on STEM Talk would be necessary down the line as we get to share those results. Really good answer. Thank you, Dawn. You're welcome. STEM Talk is an educational service of the Florida Institute for Human and Machine Cognition, a not-for-profit research organization investigating a broad range of topics aimed at understanding and extending human cognition, locomotion, healthspan, resilience, and performance. All right. So, Ken, back to you. After listening to this Sten Stray Gunderson interview, a listener wonders why more gyms and physical therapy facilities don't make blood flow restriction devices available for their clientele. As you point out, studies have shown that blood flow restriction improves strength and muscle mass, not just in younger people, but also seniors. So it seems like a no-brainer that gyms and physical therapists should be promoting blood flow restriction, but they're not. So what am I missing? Ken, do you have any thoughts? Yes, I do. As noted by the listener, blood flow restriction training, and from here on I'll just call it BFR for short, is indeed effective and perhaps especially useful in the context of seniors. It would seem the primary reason that physical therapy facilities often do not offer BFR is that the trainers and therapists lack education regarding BFR and thereby lack expertise in its application. The existing scientific literature around BFR is confusing in some respects. There are important technical differences between the various BFR products and also a wide range and a wide variety of exercise protocols that make comparison difficult. Together, these two factors have strongly contributed to the aforementioned confusion. That said, BFR is steadily becoming more widely adopted. On a personal note, I'll use two BFR systems, BeStrong and Katsu. Those are my two favorites, and I find them both to be safe and practical. So, Ken, another listener asks, please do another episode on AI. Much has transpired in the past few years, especially in generative AI, so much so that chat GPT has now become a household name. I have a friend who says that AI is about to peak, but another friend says AI is just warming up and that new capabilities are on the horizon. I'm curious about Ken's thoughts. Well, this could be the question of the day, and both of your friends could be right. Lots of confusion on this topic, in my view. While very impressive, it's important to realize that large language models, such as chat GPT, are only one part of AI. They aren't AI, they're part of AI, which is itself a very large and broad field. So, in that sense, AI writ large, taken as a whole, is not about to peak as any other science it will continue to advance. However, large language models, as part of AI, may peak or at least slow their advance for a variety of reasons, and this may lead to a degree of disillusionment. Some potential challenges for large language models include, among others, large language models often produce erroneous outputs. In keeping with the unfortunate propensity to anthropomorphize AI systems, these failures are often called hallucinations. But they're not hallucinations, they're just errors that large language models make, and then these errors render large language models not suitable for some and perhaps many application domains. The next challenge is that large language models have a limited ability to respond effectively to novel events or problems not found in the model. This is partly due to an inability to effectively generalize. The third limitation that I'll mention is that large language models have not demonstrated strong causal reasoning capabilities. And then finally, the power requirements for the training phase of large language models are immense as these models scale up. We have discussed large language models' so-called hallucination problem before on STEM Talk, but a particularly compelling example involved a rather naive attorney representing a passenger who had brought a lawsuit against an airline and he cited six legal precedents as part of the evidence for his case. Surprisingly, the judge was unable to verify any of the precedents the attorney offered. When the judge naturally demanded an explanation of this, the attorney admitted to using ChatGPT-3 to identify the legal precedents relevant to the case. He went on to explain to the judge that he even asked ChatGPT to verify that the cases were indeed real. And ChatGPT assured him that they were real cases. Poor guy. Large language models, as currently developed, in a sense can be thought of as essentially memorization machines. Given that you can think of them in this way, scale is everything from this perspective. I would argue that intelligence is, of course, more than only memory and recall. For many large language model enthusiasts, however, including the premier builders of large language models such as OpenAI, Google, Microsoft, Anthropic, among others, the goal is what is sometimes referred to as AGI, or Artificial General Intelligence. This is typically taken to mean that the machine would have the ability to learn and understand anything a human can. Many pundits have made strong and confident predictions that large language models will certainly achieve AGI by the end of this decade, and perhaps much sooner. In recent years, we have seen a great performance improvement, largely through, and as a consequence of, massive increases in compute power and model size, as well as some algorithmic advances. In addition to the aforementioned limitations of large language models, I would argue that this rather brute force approach is probably not sustainable in the long run, and its power requirements are a primary reason why that's the case. It is important to understand the practical consequences of massive scaling. As described by Leopold Aschenbrenner, formerly of OpenAI, in his recent report that is available online called Situational Awareness, The Decade Ahead, Aschenbrenner writes that future advances using large language models will require massive new data centers, which in turn will require massive availability of electrical power. And when he says massive, he's not kidding. He is emboldened in his prediction of AGI in the very near future by the observation that over the past decade, compute efficiency has improved by roughly half an order of magnitude per year. And he anticipates this rate of improvement will continue. But he also anticipates that the growth in compute resources needed for training such systems will also continue to grow by, roughly, half an order of magnitude per year. By this method, Aschenbrenner extrapolates a half order of magnitude growth in computer cluster size each year. So, to quote Aschenbrenner, AI is a massive industrial process. Each new model requires a giant new cluster, soon giant new power plants, and eventually giant new chip fabs. The investments involved are staggering. Aschenbrenner projects that by 2026, a single large gigawatt AI data center will be built, which will require the power of a mid-sized nuclear reactor and cost tens of billions of dollars. Again, this is his strong prediction for 2026. Continuing, he foresees by 2028, again, he's using the same method, the half order of magnitude growth per year. He foresees in 2028, a 10 gigawatt cluster, which, according to his calculations, will require more power than is currently consumed by many entire U.S. states. The cost of such a cluster would be on the order of hundreds of billions of dollars. Continuing to extrapolate forward, and assuming the same annual half order of magnitude increase in cluster size per year, by 2030, a 100 gigawatt cluster will require roughly 20% of the total U.S. energy consumption for that single cluster and cost about $1 trillion. As Aschenbrenner notes, U.S. power production has hardly changed over many decades. It takes roughly three years to build a natural gas-fueled power plant and at least 10 years to construct a nuclear power plant in the United States. The power requirements for his 2030 vision seem entirely unfeasible in today's political context and are in direct conflict with today's government-mandated direction toward even less reliable power sources than those available today. The AI megaclusters he envisions will not be driven by sunshine and wind. Of course, our current power grid is barely adequate now. One can indeed imagine a new generation of small reactors powering data centers, but nothing on the scale or timeline he contemplates. TerraPower, a company founded by Bill Gates, has just begun construction of a small next-generation nuclear power plant in Kemmerer, Wyoming. The demonstration plant will house a natrium reactor, which is water-cooled with liquid sodium as opposed to water, and features a molten sea salt energy storage system. These reactors are thought to cost roughly half the cost of a traditional reactor, and also the expectation is these new small reactors will be safer and more energy-efficient than existing reactors. The reactor in Wyoming will produce about 345 megawatts on a steady-state basis. The reactor should be operational in 2030. Open AI's Sam Altman is chairman of a nuclear power company called Oklo, whose goal is to build micro-reactors, far smaller than the reactor TerraPower is building in Wyoming. The first Oklo reactor is expected to have a capacity of about 1.5 megawatts of electrical energy. There are other companies planning to operate micro-reactors as well. These micro-reactors come with many challenges, such as a lack of scale, and perhaps the biggest challenge is the need for security at all times. Neither of these reactors will produce anything close to the power required for the mega-compute clusters needed for training the huge, large language models envisioned by Askenbrenner and many others. So, Ken, another question for you. A listener writes, I was amazed by the range of health issues that a ketogenic diet is being used to treat. I knew about epilepsy and type 2 diabetes, but not Alzheimer's and migraines and psoriasis and dozens of more diseases and disorders. The Dom DiAgostino episode blew my mind, but I have a hard time with a ketogenic diet. I am more low-carb. Are the benefits of a low-carb diet similar to a ketogenic diet? Yes, the short answer is yes. Most of the health benefits, such as improved metabolic biomarkers, can be achieved with a very low-carb, less than 100 grams a day diet. Now, a true ketogenic diet is at least less than 40 grams a day and can be stricter than that. Now, this diet would be considerably more effective for neurologic disorders, cancer, type 1 diabetes, those kinds of specific situations. But in general, a low-carb diet, and by that I mean a true low-carb diet, less than 100 grams, provides many of the benefits of a ketogenic diet. And many, including myself, often cycle between low-carb and true ketogenic. But sometimes I also use exogenous ketone supplements as well. In fact, as I sit here just by happenstance, I am drinking one called Kinetic. And so there you go. So, Ken, another question for you. A listener asked about episode 166 with Dr. Vivian Lowe, where we talked about heart disease. And the listener says, I have a friend who has a family history of heart disease. She has been on hormone therapy because of menopause, and recently her blood work showed a slightly elevated level of LDL cholesterol, the bad cholesterol, which my friend says isn't unusual for people on hormone therapy. On the plus side, my friend also has high HDL, the good cholesterol. Her doctor wanted to put her on statins, but my friend didn't want to go that route. So the doctor recommended a carotid scan, which showed that my friend had no blockage in her arteries. As a result, my friend isn't on statins. I had not heard of a carotid scan. What can you tell me about carotid scans? And is this something that women or anybody with elevated LDL cholesterol should consider before going on statins? Well, of course we cannot give medical advice on STEM talk. So we're speaking here theoretically and scientifically. I believe the test our listener's friend experienced is called CIMT, carotid intimal media thickness. This is a non-invasive test to assess arterial aging and the extent of arthroscorotic disease. The assumption is that a positive CIMT in the carotid arteries is a proxy for arthroscorotic plaques elsewhere, including the coronary arteries. It's an ultrasound test and therefore quite cheap and a good place to start to evaluate vascular health. If I were her, I would also discuss with her physician the possibility of having a coronary calcium scan, which is a specialized computerized tomography scan of the heart, which identifies calcium deposits in the heart arteries. Also, her physician could order a more complete lipid panel, such as the Quest CardioIQ or equivalent panels at LabCorp and other places. Boston Heart offers a really complete panel called CVMAP. And finally, she could book a consultation with Dr. Lowe on her website if she chose to do so. So Ken, this is a pretty detailed question for you that was received sometime back from one of our favorite listeners. And Ken answered the question directly with him via email, but we thought others might benefit from it as well. So we're going to bring it up here on the podcast. The question goes like this. So I'm a 72-year-old and have exercised daily my entire life. My current program entails roughly two hours per day of exercise, broken up as follows. 60% to 70% zone 1 and zone 2 endurance focus. I currently use a weighted ruck pack, aerosol bike, and a ski erg. Also, some hybrid kettlebells, weights, et cetera, with little or no rest. 20% to 30% resistance training and 5% to 10% VO2 max slash sprint. My impression is that you focus on resistance training and high-intensity cardiovascular work and do not focus so much on zone 1 and zone 2. How do you structure your training in terms of zone 1 and zone 2 resistance training and VO2 max slash sprint work? Do I need to focus more on high-intensity training? As I get older, that can lead to injuries if I'm not careful, but I'm beginning to lose strength and speed. I listen to every one of your podcasts. They are instructive, fascinating, and entertaining. Thank you. Clearly, part of the question is around the listener's own training, and so it's hard to give very specific suggestions without knowing more details. I'm going to assume that the listener is optimizing for cardiovascular fitness and strength as two of the best predictors of longevity. Here are a few thoughts based on the literature, my own experience, and the thoughts of trusted colleagues. Your current training balance looks really good to me, frankly. You should be complimented on doing more and better training than 99.9% of the population. In terms of VO2 max, fitness improves proportionally, though not linearly, to the intensity of the exercise. There's nothing that seems to be magical about the zone 2, despite what some say. The fitter you are, the higher intensity aerobic workouts need to be to improve VO2 max. Longer high-intensity intervals, like 2-4 minute efforts with similar periods of recovery, may be best for VO2 max improvements. My view is that getting low-intensity movement by hiking, walking, cycling, etc. is very important, especially when combined with strength training and high-intensity interval training. Walking or hiking in steep terrain, perhaps at altitude even, is a strenuous and wonderful relaxing exercise. Also, although often ignored, avoid sitting for long periods. And if you must sit for extended periods, such as on a long flight or when stuck in a seemingly endless meeting, perhaps do some soleus push-ups, as discussed with Mark Hamilton on episode 162. Specific to the question about doing more high-intensity, the 10% that you mentioned is consistent with what is typically recommended in polarized training models, which generally suggest 10-20% at high intensity. The listener says, I'm beginning to lose strength and speed. This is inevitable, I'm afraid, at some point. As we age, we lose power much more quickly than strength, and we lose strength more quickly than mass. In our youth, in our middle years, we should build muscle just as we save for retirement. And then later in life, we should do what we can through nutrition and exercise to hold off or slow the rate of decline. Eventually, if we live long enough, we will all need to make some withdrawals from our reservoir of muscle. So let's do our best to keep it topped up. For strength improvements, the time you spend does seem reasonable to me, but your mention of injury makes me think that it's possible that the intensity of your weight training workouts may be dropping as you naturally wish to avoid injury. The most important thing to maintain strength will be to maintain the intensity of resistance training workouts. Ideally, regularly nearing voluntary muscular failure with cycling of intensity as you need to recover. To maintain intensity while minimizing injury risk, there are multiple options, and I'll mention a few here for you. Swapping free weights at some point for machines does reduce the rate of injury. Pyramid sets, drop sets, super slow sets like Doug McGuff discussed way back in episode 24, and blood flow restriction training, which we mentioned earlier, are all good approaches. For avoiding injury and still having a strong benefit, I sometimes use, or often use actually, hierarchical sets, where my first set may employ a weight that I can handle for 15 reps, but probably not 17. The next set is a weight I can handle for 8 reps, but maybe not 10. And the last set is much heavier, permitting only 4 or 5 reps. I do not like to go to complete failure. It's a bad habit, which normally involves breaking form as well. When you see people go to absolute failure, the form is often affected in a bad way. An injury can follow. I like to get close to failure, but leave 1 or 2 reps in the tank. Now, as I mentioned earlier, I am a huge fan of blood flow restriction training and think that it is ideal for many older trainers. As we age, many of us experience arthritis and other joint issues. Blood flow restriction training permits effective resistance training with light weights and a low risk of injury. I like this question, and I hope many other listeners have pondered these issues and may benefit from it as well. That was a great answer, Ken. So this is the last question. So Ken, one more question for you. A listener asks, does Dr. Ford have any current annoyance that he is willing to share with us? Back in 2022, he mentioned the use of the term new normal and cell phone addiction. So Ken, to wrap up our episode, I wonder if you have another annoyance to share with our listeners. Where do these annoyance questions come from? So my new annoyance is annoyance questions. Oh, yes. I do have an annoyance, though, that I am willing to share. And it is the continual and often misused use of the word existential. Everything is now somehow an existential threat. And things labeled as such rarely are. And things that are actually existential threats are hardly ever mentioned. As I mentioned, in 2022, the world provides sufficient annoying stimulus for one to live in a constant state of annoyance. It's important to remember that how we react to such stimuli is up to each of us. And we should work to avoid living in a state of frustration regarding things not in our control. So I ignore existential everything. This is, of course, easier to say than to do. Well, Ken, that was a great answer. And it's been really fun and interesting discussion across a wide range of topics and great questions from our listeners. Well, thank you, Don. And to our listeners, please keep sending your wonderful questions. And if we didn't get to some of them this time, we will endeavor to do so in future AMAs. STEM Talk. STEM Talk. STEM Talk. STEM Talk. STEM Talk. STEM Talk. So, Ken, that was fun as always. And we had lots of great questions and also a great five-star review from our Science Saturdays alumnus. Very cool. Yes, indeed. Those were some really good questions. So, listeners, please keep them coming. Just email your questions to our producer, Randy Hammer, at rhammer, that's hammer, H-A-M-M-E-R, at I-H-M-C dot org. So this is Don Cornegas signing off for now. And this is Ken Ford saying goodbye until we meet again on STEM Talk. Thank you for listening to STEM Talk. We want this podcast to be discovered by others. So please take a minute to go to iTunes to rate the podcast and perhaps even write a review. More information about this and other episodes can be found at our website, STEMtalk.us. There, you can also find more information about the guests we interview. Thank you. I'm sure험. That's where we interview.