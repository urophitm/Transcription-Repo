 Hello everyone and welcome to the Mindscape podcast. I'm your host, Sean Carroll, and let's start with a very quick meta note about what's going on with the podcast. In particular, I wanted to mention that we now have transcripts of every episode that are going to appear on the webpage with the individual posts for the episodes. We'll have the entire transcript as soon as it appears. This of course costs money. I'm not doing it myself, so a huge thank you to those who are supporting the podcast on Patreon, you're the ones who made that possible. So I think this is going to be very good both for accessibility and also for searchability. You can go in and you can see what's the podcast is about even before you listen to it, search for terms throughout the whole archives, that's going to be really good. Moving on to today's show, I want you to think about what is happening in your brain at this very moment. You're listening to my words or you're reading the words if you're reading the transcripts. One way or another, there's a signal coming in. Let's just say that you're listening, so you're hearing sounds. So there's a vibration going on in your ear drums, words, sentences and so forth. And you can recognize these words, just like you can recognize nonverbal sounds. But there's something else going on that by the set of words coming in, we create meaning. We attach to these words to these sounds that we're hearing, some picture of what I'm trying to say, some relationship between these sounds and something out there in the world or some abstract concept or something like that. So how does that happen? How is it that a bunch of sounds hitting our ear drums get turned into meaning inside the brain? That's what we're talking about on today's episode with Professor David Purple, who is a professor at NYU and also the director of a Mox Plunk Institute in Frankfurt, Germany. I love this. His Max Plunk Institute is called the Institute for Empirical Esthetics. I have no idea what that means, but I know that what David does is actually study what's going on inside your brain. He studies it not primarily with the standard FMRI picture, which is when you put someone's brain inside someone's head, you don't take the brain out. You put someone's head inside a machine and look at where the blood is flowing to to the end point where things are happening in the brain, which is very precise in terms of where things are happening, but it's slow. You can't see when things are happening. So mostly David uses MEG machines, Magneto and Sepulograph machines, to see exactly when a thought is happening inside your brain. In fact, if you have my book, The Big Picture, you can see an image of my brain, not the conventional wrinkly crinkly thing that you're used from pictures of the brain, but just a very crude image of the quadrants of my brain in which different magnetic fields are appearing as charged particles race around from neuron to neuron, perfect evidence that I really do have a brain inside my head. So it turns out that this question we're asking about how sounds get turned into language and meaning. People have thought about this for a long time. There's a standard model, if you like, but that standard model appeared in the 1800s and has not been updated as much as you would like since then. So with his collaborator Greg Hickock, David Purple has suggested a updated model, something called the dual stream model, which isolates not just one part of the brain, but different parts of the brain that are responsible for different aspects of language processing. We'll talk about that exactly how it works, and also just because David is an opinionated guy, we'll talk about all sorts of other issues in neuroscience, including the role of big data, how we're coming along in understanding memory, and so forth. So let's go. Did you know Fast Growing Trees is the biggest online nursery in the US with thousands of different plants and over 2 million happy customers. They have all the plants your yard needs, like fruit trees, privacy trees, flowering trees, shrubs, and so much more. Whatever plants you're interested in, Fast Growing Trees has you covered. Find the perfect fit for your climate and space. Fast Growing Trees makes it easy to get your dream yard. Enter online and get your plants delivered directly to your door in just a few days, without ever leaving home. Their live and thrive guarantee ensures your plants arrive happy and healthy. This spring they have the best deals for your yard up to half off on select plants and other deals, and listeners to our show get 15% off their first purchase while using the code Mindscape at checkout. That's an additional 15% off at Fast Growing Trees.com using the code Mindscape at checkout. Fast Growing Trees.com code Mindscape. As the perfect time to plant, use Mindscape to save today. Offers valid for limited time, terms and conditions may apply. David Purple welcome to the Mindscape Podcast. Hi there. Nice to be here. Yeah, this is completely by accident that we met each other. We've known each other for a while. You were a famous participant at the moving naturalism forward meeting back in 2012. Now it happened to be in the area where you lived. Of course, I'm going to podcast you and that's great. Let's start by laying the groundwork. I'm trying to think of a way for the audience to describe what you do for a living. You're like a professor in half of the departments of the various universities that you're a member of. Is it okay to say thought and language? Well, it's fair enough. I mean, the one liner that I try to remind myself of is a study how you go from vibrations in the ear to abstractions in the head. So as we're having this conversation, the only signal you're actually getting is your drum vibrating because I'm sending sound your way. And amazingly, that turns into abstract ideas, words ideas in your head. So the fact that that works at all is already amazing and weird. And all the subprocesses are things that I study in my labs. Yeah, I mean, that's a great way of putting it because really the position of the ear drum it only vibrates in one dimension, right? It's only in and out. So we get one number time stream into our brain and from that we create everything we think about. The fact that it works at all is astonishing. And the fact that it works at the speed at which we're doing it is even more astonishing. You have a bunch of, you have tens of thousands of words stored in your head and we're sitting in this, you know, my lovely backyard in Connecticut and it's a little bit noisy. We might see a bear walk by and it's, and yet you can extract complicated information in, you know, segments of tens of milliseconds. How does that work at all? And so those are the kinds of problems I worry about and that includes obviously listening to music, listening to sounds that are not speech, but the major emphasis in my lab is on speech perception and language comprehension. Just a note for podcast listeners, if a bear does walk by, I will let you know, but we are inside. We're relatively safe, right? Ish. I'm thinking the bear could probably get through these flimsy walls that are surrounding us. Well, we're looking pretty, we're looking pretty tasty, so we've got to be careful. All right, we'll be careful. So good. So how do you go about doing this? Well, actually, let me back up even before we get to how you go about it. What got you here? Like did you, when you were 10 years old, start thinking I want to understand how audio signals in my ear turn into abstract thoughts? Exactly. Exactly what I wanted to know when I was 10, 12, even 16, yes, as a, as a pubescent boy, those were my main thoughts. No, I got there completely by accident or partial accident. And after college, I really wanted to be an actor or rather a director. I really wanted to be a director. Really wanted to direct. Everybody wants to be a director. I really wanted to be a director partially because my wife is an actress and she was a successful actress. And then we thought, well, one of us should have a job. So I thought I should perhaps go to graduate school. And I ended up accidentally in a neuroscience lab working for a distinguished neurologist at MIT learning how to do neurophysiology and all the different, using the different tools. But in the back of my head, I liked language. I grew up in a very multilingual environment. And it was sort of, you know, something I had a gut level intuition about. And people at that point said, you know, there's a famous language researcher here. You should probably go listen to some of the lectures. His name is Noam Chomsky. And I said, oh, oh, that's interesting. I'll go to some of those lectures. And I did. And that was sort of like somebody opens the curtains for you. You go to some of those lectures. Of course. And you suddenly have a completely different view of how language can be looked at, studied, investigated. And it really, that's a game-changing experience. And at that point, I decided to go to graduate school to study language works, house beach works, and then began to connect it to sort of my interest in biology. So it's accidental that I really did want to be a director. I'm not kidding. I still want to be a director. Now, like, you're young. You could do it. So that sort of counts. No, but it doesn't quite have the same vibe. So put Noam Chomsky in perspective for us, since you mentioned him. I mean, obviously he's a huge name. He's a huge name, not only in the academic field of linguistics and psychology, but outside. So forget about the outside and the politics. My impression is that, and my impression is completely untrustworthy here, so I'm hoping you'll correct it, that Chomsky was extremely influential, but there's a sense of moving beyond him, or have we simply improved upon what he, I mean, tell us a little bit what he had to say and how we think of it today. Yeah, so he remains an incredibly influential and very polarizing figure. So his influence derives from the fact that he really changed how we do psychology and language sciences and philosophy of mind in the mid-50s. So based on the series of his early books and papers, he, first of all, effectively got rid of behaviorism. One can even pinpoint that into the most important behavior. So behaviorism was the dominant view in psychology for decades before that. And it's a very sort of pleasing and simplistic view, and effectively it boils down to there's one principle of the mind, which is the principle of association. So it's the basis for all of the theories of conditioning, conditioning underlies learning, conditioning underlies effectively all of behavior. So the term behaviorism became used as a sort of catch-all phrase for all of psychology and psychology was based on the principle of association. Now, that's a very nice and have-love and is dull. Have-love and conditioning, and then of course the most, let's say, egregious direction, which has went as Skinner's work. So Skinner's notion of the BF Skinner had famously, and Professor at Harvard worked on this Skinner box with the presupposition that you could put your, even your own children. And I don't begrudge him. This idea has a father of three sons, nice idea, put them into a box and train them explicitly to respond in selective ways to certain stimuli. And so the stimulus response, stimulus response paradigm was the dominant paradigm for learning memory for everything in psychology and neuroscience. Does some of this, I know this is a tangent, but that's okay, we have time. Does some of this reflect the influence of positivism in the sense that rather than looking for some underlying mechanisms, we should just look at what happens in the world and describe it as fully as possible? Yeah, I mean, I think the more sophisticated behavior is certainly where, you know, average readers of, you know, V&E's positivism, I would think. But the-so I think that the most disturbing part of the story of behaviorism is that it's still around. Of course, deeply and certainly true in my field and the neurosciences, I think it's actually the default position. Now the influence of Chomsky was to argue, in my view, successfully, that you really wanted to have a kind of mentalist stance about psychology. And he had a lot of very interesting arguments. He also made a number of very important contributions to computational theory, to computational linguistics, and obviously to the philosophy of mind. And we're bracketing his political work. Yeah. Which is interesting, but it's separate. It's completely separate, although I think he doesn't see it as completely separate in a principled sense. But it is separate. And, you know, he's very well known in Europe as a political dissident in some sense. And he's basically not invited on most US channels because he's too obnoxious. Never. Of course, you just don't hear him. You see him on TV shows in the Netherlands, but in the US, you know, he's on some kind of fringe radios show and Cambridge messages or something. Yeah. But he's difficult. I actually just finished a chapter, a couple of, you know, last year or so called the influence of Chomsky on the neuroscience of language. And because, you know, many of us are deeply influenced. But the fact of the matter is his role has been both deeply important and moving and terrible. And it's partly because he's so relentlessly undidactic. If you've ever picked up any of his writings, he's just, it's all about the work. Okay. He's not there to make it bite size and fun. He assumes a lot, a lot of technical knowledge and a lot of hard work. And so if you're not into that, you're never going to get past page one because it is technical. But that's made it very difficult because it's, you know, it sort of seems obscure and just to many people. I mean, it's always very interesting. There's so many fields where certain people manage to have huge outside influences, despite being really hard to understand. That's, is it partly the cache of the reward you feel when you finally do understand something? I mean, I wish that were true. That would mean that a lot of people would read, let's say, my boring papers. But the, I think in the case of Chomsky, it's true because there are superficial misinterpretations and misreadings that are very catchy and that people take. So the, you know, the most famous concept is, you know, language is innate. Right. Now, such a claim was never made, never said. It's much more nuanced, it's highly technical. It's about what's the structure of the learning apparatus, what's the nature of the evidence that the learner gets. So obviously this is a very sophisticated and nuanced notion. But what comes out is, oh, that guy's claim is language is innate. But I can remember that and repeat it at cocktail parties. Exactly. But that's a little bit unfortunate because, you know, that's true for all fields. I mean, if they're sort of nugget size one liners, they're fun to remember, they're fun to talk about, but they're probably almost always wrong. That's right. Stuff's complicated. Yeah, stuff is complicated. But so, generative grammar is the other phrase that I associate with Chomsky. All of my Chomsky becomes from reading the language instinct by Stephen Sanger. By Stephen? Yeah. No, I mean, so Steve, one of my professors in graduate school did a, you know, remarkable job popularizing the language sciences and linguistics, although he's himself actually not a linguist. He's a psychologist, right? But of course, lots of the interpretation of what people think by Chomsky comes through the lens of how Pinker wrote about it. And of course, that has its own interesting flavors, right? Right. So, I mean, Steve's a remarkable writer and fabulously interesting thinker. But, you know, he has his own lens. Yes. So, you probably go to the source and read the actual material to understand. No, I'm writing a book about quantum mechanics right now and everyone should read it and everything I say in it is correct. But it's not necessarily what anyone else thought in the past, even though I try my best to represent. No, no, I think in your books, of course, every word is true. Yeah. That goes with it, saying. That's it. It's good to know that there's some people out there like that. This episode of Mindscape is sponsored by Better Health. When it comes to relationships, we often hear about the red flags we should avoid. But what if we focus more on looking for the green flags in friends and partners? If you're not sure what green flags look like, therapy could help you identify them. Actively practice them in your relationships and embody the green flag energy yourself. Whether you're dating, married, building a friendship or just working on yourself, it's time to form relationships that love you back. One of the great things about therapy is by looking inside yourself, you can both learn to take those warning signs seriously, but also learn to be open to new experiences and new things to know when something might be worth pursuing. Better Health is a fully online service that makes therapy affordable and convenient, serving over 5 million people worldwide. You can easily switch therapists any time at no extra cost. So discover your relationship green flags with Better Health. Visit betterhelp.com slash Mindscape today to get 10% off your first month. That's BetterHelpHELP.com slash Mindscape. A lot of us start the new year saying that we will learn a new language, but it's hard to actually commit to it. Bappel makes it easy to learn one in less time than you think. Bappel's quick 10 minute lessons handcrafted by over 200 language experts, get you to begin speaking your new language in three weeks or whatever pace you choose. And because conversing is the key to really understanding each other in new languages, Bappel is designed using practical, real world conversations. What I love about Bappel is you can either dive in deeply and truly get fluent or you can just master some of the basics before going on a trip. So let's get more of you talking in a new language. Bappel is gifting our listeners 60% off subscriptions at bappel.com slash Mindscape. Get up to 60% off at bappel.com slash Mindscape spelled B-A-B-B-E-L dot com slash Mindscape. And Bappel dot com slash Mindscape rules and restrictions may apply. But I mean, yeah, sometimes I mean, especially in the, let's say, technical disciplines, you have to do the hard work and you can't cut any corners, right? So you have to actually get into the technical notions and why they were, what are the presuppositions? What are the, let's say, hypothesized primitives of a system? How do they work together to generate the phenomena we're interested in, so on? So yeah, the concept of generative grammar, very interesting. It's a notion of grammar that's trying to go away from simply a description or list of factoids about languages and trying to say, well, how is it that you have a finite set of things in your head, finite vocabulary and ostensibly finite number of possible rules, maybe just one rule who knows, but you can generate and understand an infinite number of possible things. It's the concept that's typically called discrete infinity. And that's a, that's a cool idea. And the idea was to work it out. Well, if, you know, if those are the, if that's the parts list, how can you have a system? How can you learn that system? Acquire the system. How can that system grow in you and you become a competent user of it? That's actually subtle and that's, you can't just, right? So it requires thinking deeply about, well, what is, what is actually the parts that's the, the architecturally given to you as a human being, having a human brain? So in which sense do we have to be parochial, a human brain has its own properties? In which things are sort of, let's say, general properties of the vertebrate. Right. So, and those are, how do they interact? What do you need? Is there extra special sauce? Do you need God? God forbid? And things like that. So these are, of course, this has had a tremendous influence on how we think about the system and how we study it, what kind of methods we can use and what are the bigger questions. But it's safe to say the mind is not a blank slate, right? The brain does have function in there. Pretty much a good bet. Right. I think you can put that one in the back. And when it comes to language, there is something, what I remember from Pinker is that there's in some sense a set of switches in the brain hypothetically, which sort of by learning different languages, we flip one way or another. I think that's a pretty fair way to think about it in a non-technical, so you can think about as parameters or something like that. I mean, there's, and people think about it in many different ways, but I mean, we can certainly assume that we have a system. So look, let's back up for a second. Because we were talking about the visual system and not the language system. We wouldn't be having this discussion because people say, obviously, you have a visual system, you have it because you're a vertebrate brain. And obviously it changes in some specifics as a function of what's around you. This is not newsworthy. But as soon as we talk language, everyone's an expert. Everyone speaks the language. Everyone has a powerful intuition. And the amount of nonsense promulgated is a, you know, there's a kind of, it's astonishing. There's a level of silliness, it's kind of, no, I'm very sympathetic. I've written three popular books so far, one on the nature of time, one on the Higgs boson, and one on, you know, the big picture in the meaning of life. By far, the best Amazon reviews are for the Higgs boson book. Because no one has pre-existing view of the Higgs boson, right? They're willing to take what you have to say about it, but they think they know the meaning of life and they think they know how time works. And if you don't agree with what they have to say, they're not going to be receptive. Yeah, no, it's just, it's, it's, again, there's something about well, in the arts, I guess it would be called connoisseurship, right? Do we still appreciate the pain and the neck of having to do the hard work to become a connoisseur or have technical knowledge and something? And well, whatever, it takes a long time, it's hard and you might not get very good at it, but it turns out to be required, right? I mean, so if you want to become really good at knowing the old masters, you know, the Netherlands, you can become a connoisseur only if you actually study it. Likewise, with language or the brain or physics, well damn, sit down, do the work. Yeah. So having said that, let's proceed to drastically oversimplify how the brain works. Yes, let's do it. Let's drastically do it. So where did you go after being inspired by Chomsky and started studying how the brain processes what we hear? Yeah, I mean, I'd be relatively, so I studied a lot of sort of the technical aspects of language for a while and I became relatively quickly, like everyone else of my generation, I guess, seduced by the possibilities that we now have of recording from the human brain. So when I was a graduate student, about halfway, early on in graduate school, was the time when the modern brain imaging machines were actually first developed and first rolled out. So for many years, we had things like X-rays and CAT scans, but in the late 80s, there was a lot of research using PET scanning. It's positron emission tomography, a very onerous and, you know, in some sense, invasive technique to take pictures of the brain while it was processing something in a complicated way with a lot of analytic steps. And then the early 90s, there was really a kind of game-changing event, the development of functional magnetic resonance imaging, FMRI, we call it, and everybody's probably seen an MRI machine. It's in every hospital. If you've blown out your knee or your shoulder, or God forbid, you've had your head scanned, and those are ubiquitous. And there were a lot of interesting developments both in the physics of magnetic resonance and in engineering and signal processing that allowed us to begin to use these machines to measure and quantify the human brain while something is happening. So you're lying in this, it looks like, you know, a giant hair dryer or something. Tube, you're lying in this sausage, and it's taking, it's really taking pictures. It's called a tomographic technique, where it's an imaging technique. And it was able to take pictures of which parts of your head were, you know, informally speaking active when you were doing something like listening to words or listening to a piece of music or moving your right finger or looking at a checkerboard, those are the usual experiments. And blood flow is the proxy for that technique. And their other proxy is blood flow or actually blood oxygenation. Okay. And so that was an interesting technique because you could take not completely non-basively, like it's kind of cool. Imagine you can take a picture inside someone's head from a meter away. Who knew? I mean, that's, you know, with a resolution by the way of about a millimeter these days. I was going to ask about the resolution. So the spatial resolution now with the machines that we use is on the order of a millimeter sometimes even better. So, you know, there are high resolution scanners for instance, it's seven Tesla, which is, you know, a really pretty substantial magnetic field. And you can scan things with the resolution better than one millimeter, which is pretty good. But what do you give up for that wonderful picture? You give up temporal resolution, right? So now you take a really, really great picture of someone's head, but the dynamics that you're able to capture are very, very slow. So what have you given up there? Well, cool picture, but nothing about the change or the actual online processing. And by the way, a cubic millimeter of brains still has a butt load of neurons in it, right? It's not, I was a butt loader or a shitton. I mean, it depends on what your units are, but the, you want to be the, if you take a square millimeter of, of tissue in the brain and the cortex and the cerebral cortex and you look in the cortical column above, right? So the cell, the tissue that's directly above a square millimeter, it's, it goes up about three millimeters or so depending on where you are, estimates are that's on the order of a hundred thousand neurons. And that's just a neurons. There's other junk. So the, so the, the parts list of the brain is very complicated. There's lots of little stuff in there. So we vastly underestimate what's going on in even, you know, certainly a cubic millimeter of cortex. We have no idea. Right. Okay. I mean, it's shameful. But anyway, you were mentioning that we also don't have pinpoint timing of what's going on. So now, so yeah, so here things get interesting because we have to, so let's say we want to, you know, we're committed to studying the human brain and there's stuff you can learn from, from animal research, very important stuff and you can do other kinds of experiments that we can't and should not do with people, right? So they are, you can use techniques that have even higher spatial resolution, even higher temper resolution, but, you know, except for very extreme medical cases, those are not appropriate. So we have to use non invasive techniques. So you're talking about things where animals are sacrificing themselves to the cause of science. Yes. And then in, in, very important ways and, and, you know, if you've ever gone to the dentist, then you should be very grateful for their research. If you've taken now, there are, you know, this is a very politically sensitive and complicated topic. To what extent do we support animal research? I'm 100% enthusiastically in favor of careful, responsible, ethically executed, well-managed animal research. There is no alternative for it and there are currently wild and scary debates about this in Europe in particular, more active than the United States. And they're quite terrible and they're, they're, you know, the debates are irrational, vitriolic, and dangerous. And they are leading to a sharp reduction in, you know, careful animal research. So we, of course, it's not necessary for, you know, as far as I'm concerned for, let's say, cosmetics or shampoos. Shampoos, forget that, right? But they're, you know, to understand basic principles of physiology. I mean, we have no alternative. And I think it would be, you know, a very peculiar stance not to advance that. So, at this point, we do not take human subjects and pry open their brains. We do not, and we should not. Yeah. And so we have, so there are wonderful new techniques that are used and, you know, everyone talks about them. Optogenetics is a particularly exciting one. You can treat cells. You can inject cells with particular light activated molecules such that you can then control their activity, but you can't do that with people. You can record single cells for, in animals, but you can only do it under rare conditions in humans. For example, during epilepsy surgery. But, so look, we have non-invasive techniques that are amazing. I mean, there are, so we can take MRI pictures of your brain, but then we're sacrificing time. And if you don't believe time matters, you, how fast do you think our conversation is going? Right. And so our conversation, if you measured it, the mean rate of speech across languages, by the way, it's independent of languages between four and five hertz. Right? So the amplitude modulation of the signal, so the signal is a wave. You have to imagine that any signal, the speech signal in particular is a wave that just goes up and down in amplitude, or informally speaking in loudness, right? So the signal goes up and down, and the speech signal goes up and down four to five times a second. What is the speech signal mean? This is what you're bringing. So the speech signal is the stuff that comes out of your mouth. Okay. Okay. Right. So I'm saying your computer is gray. That is a, let's say that was two and a half seconds of speech. It came out of my mouth as a wave form. And that's the wave form that vibrates your ear, your ear drum, which is cool. But if you look at the amplitude of that wave form, right? It's a signal amplitude going up and down. It's actually now, you know, this is not debated. It's four to five times per second. This is a fact about the world, which is pretty interesting. So the speech rate is, or the so-called modulation spectrum of speeches is four to five hertz. Is it very different for different mammals? It's a good question. We don't know so much about that because nobody vocalizes as much as we do. It's probably a little different because it has to do with sort of the cortical processing rate, and of course the biomechanics of the articulators. So it's likely to be a little different. Music incidentally has a modulation spectrum that's a little bit slower. It's about two hertz. So that's equivalent to roughly 120 beats per minute, which is pretty cool. Favorite number. So a favorite number really comes out when you do the physics of signals. If you take dozens and dozens of hours of music and you calculate what does the mean, you know, across different genres, what does the mean rate that the signal goes up and down? It's two hertz. Cool. Cool fact. You should remember it. That's science. We science say it. So speech happens very fast. And in that rate, so if our mouth opens four to five times per second, that's not fast enough yet because of course inside those, that's roughly the rate of syllables, but syllables have internal structure. So that means it must be going even faster than a hundred milliseconds. So if you really want to understand what's going on, as stuff comes into your head, whether it's hearing or vision or touch, you need devices that can measure things at the rate of milliseconds, you know, or tens of milliseconds, or thousands of a second. That's absolutely necessary because that's the speed at which our mind and our perceptual apparatus works. So there are other tools that we use. And if MRI was an FMRI's time resolution is on the order of at best a second. Okay. But more likely, you know, seconds, five seconds, eight, a hundred times improvement. So now we need different machines. So we have one kind of machine like MRI that takes really detailed pictures in space, but has miserable temper resolution. On the other hand, there are other tools. The most well-known one is electroencephalography. It's been around since the 1920s. That has those are electrical techniques. So they have very good temper resolution. So you can measure things at the outside of the head using electrodes. And now you have very, very high temper resolution as high as you want. It depends on your processor. Let's say 1000 samples per second. Right. So really, so every millisecond you measure the data, that's still very low for some processes in physics. That would be ultra slow. Oh, we're zepto seconds. Yeah. But that's okay. Yeah. We're, but you know, we're not between friends. What's the big deal? What's a few orders of magnitude? And so you want to pair, you want to have those machines too, right? Because you want to, since processing is fast, you want to be able to understand, well, how does, you know, what's actually happening at those timescales? And for that, my own favorite technique is one called magnetoencephalography. And that measures the magnetic fields generated by current flow in your brain. And it's the most sensitive technique we have to measure the human brain non-invasively. It looks like a giant hair dryer. And that giant hair dryer has little, and detectors in it, typically then they, you don't see them. Obviously, they're inside the hair dryer. And they're swimming in liquid helium to keep them at superconducting temperature. And they're little coils. And let's say there's about, you know, 150 above them inside, in surrounding your head. And then you can measure the brain activity at, let's say, a millisecond resolution. And reconstruct as best you can, how fast and where things happen. So you really want to pair these different techniques if you want to have an increasingly comprehensive thing. And I remember not that long ago, I stuck you into one of those machines. I was in the, in fact, I got a lot of mileage out of that. You stuck, I stuck your head into an MEG machine. And we measured your brain response to different tones and a few visuals to a million. And it turns out your brain worked. You confirmed the existence of my brain. So the news was good all as well. The internet has mixed reviews on the existence of my brain. So I was glad you could confirm. We found all the parts and no extra parts. So it's all good. And I like it especially because there's physics, right? The reason why you could get the signal is because a thought is manifested by charged particles being accelerators. That's right. And that's where the magnetic field comes from. It's amazing. Again, amazing that it works. So I mean, the, the fact that we can have a conversation is a mechanical wave vibrating your ear, which turns into electricity in your auditory periphery, which sends a signal using a code we don't yet understand into different parts of your brain, where it's decoded or represents information using some code that we also don't understand using electricity, which flows around generating magnetic fields. I mean, it's wild out there. You have a lot to do. A lot of science let it be done here. But it's pretty cool that it were that we can do it at all suggests that, using the insights and tools of physics and the sort of the toolbox of physiology is the best way to go. And so if you have a theory, that's my, I know. Well, that's the other tool. That's the next step. You need some ideas. We have learned something by doing all these things, right? We've changed how we think about how language is processed. It's not just, maybe we can do this. We've made progress. We've made, I think, good progress. And I'd say, it's very hard to measure in this area of research. What would constitute compelling progress, right? What's, and what universe would be say, holy cow, we have a true explanation. We got it once and for all. And partly that has to do with what do we think is an explanation. And that's a very complicated concept in its own right, whether you're thinking about from the point of view of philosophy, the sciences, you know, sort of an epistemological idea. But we do have, let's say, what we have for sure is better descriptions, if not better explanations. And the descriptions have changed quite a bit. And that being said, and I don't know what the timescale is that would count as success. But I think it's we can sort of say that we've had the same paradigm for, we've had the same neurobiological paradigm for about 150 years since Broca and Velnica, since the 1860s, actually. A very straightforward idea, you know, so that's older than electromagnetism. Yes, that's the same age. And then that should were you. It's older than statistical mechanics. And so what you worry about that is that that model is still so what is that model? Let me tell you, I mean, the idea was, well, language is a some faculty of the mind. It lives, whatever that means, in the left hemisphere, typically. So the model says so the model says. And there's a blob on the front part of your brain and the frontal lobe on the left side. And there's another blob of tissue in the posterior part of your brain and the temporal lobe. They're connected by a wire, which has the charming name Archaeot Physiculus. And that's what you get. You've got an area for production, an area for comprehension, and a wire that connects the two. And if you go and there's a couple extra wires, but they're not, you know, they're not talked about much, if you go to classic neurology textbooks now, and if you have a stroke, the chances are probably better than, you know, 10 to 1 that the neurologist examining will refer to that figure and that model. And that really should worry you. With a Spark Cash Plus card from Capital One, you earn unlimited 2% cash back on every purchase. Plus, no preset spinning limit helps your purchasing power adapt to meet your business needs. Jorge Gavirio, founder of Massienda, reinvest his 2% cash back to help grow the business with new products. What could the Spark Cash Plus card from Capital One do for your business? Capital One, what's in your wallet? Find out more at capitalone.com slash Spark Cash Plus terms and conditions apply. And was that model based on people dissecting human brain? It was that model was based on, well, really in some sense, the oldest model in neuroscience. It was based on patient data, famously the patient guy named LeBorne or known in the literature as Tau, and Broca, who was a neurologist in Paris. Right. And the examined him, tested him behaviorally, came and noticed that the guy couldn't say much. Remarkably, a few days after he gave him a thorough examination, the man died and was able to do, you know, huh? Who knew? Why did I never work out that way? Yeah. Well, let's say I've been seeing your machines, laughing, I'm happy it doesn't work out. So, you know, they found correlations. So it's what's called, you know, deficit lesion correlations. So they found a lesion in this patient's brain and or Broca in this case and was able to correlate it with the particular behavioral deficits. And look, it's interesting. If this part of the brain is broken and this behavior is broken, there must be a some kind of causal relationship between a particular brain area and the function it executes. Now, that's a very reasonable hypothesis. I mean, you know, subject to subtle things when could change about it, but it's very, but it seems like a good start. That's a good. Some years later, the German neurologist Vanikke made a similar discovery for a different part of the brain. He found patients that had a lesion or, you know, a brain injury through, due to stroke in the posterior part of the brain in the temporal lobe. And that patient or those patients had trouble understanding they were, they could talk, they were very fluent, but didn't make any sense. So the assumption was, ah, okay. So the comprehension part is broken. So we have a production part and a comprehension part. And so now we have a kind of understanding. Now, what's the problem with that? Well, first of all, that's not a theory of language. For that, we had to wait another hundred years until language, the language sciences were more mature. And there, the work of Chomsky and the 18, in the 1950s played an enormous role. But for those hundred years, from 1861 to, let's say, 1961, the theory of language was at the basis of how we think about brain and language was pretty naive. I mean, it was something we could come up with right now with a piece of paper, you know, and that's, of course, it's amazing how powerful that model was and how hard it was to get, to get beyond it. But now we've known for, you remind me what are the two blobs connected to the wire. So there's an area called Broca's region, right? So Broca's area named after the neurologist Paul Broca, an area called Vatamik's region after the neurologist's calvernica, and then a wire, a set of wires really in between called the arqueud vesiculus. So that's basically tissue connect, you know, those are literally the wires connecting the one blob to the other and the idea is, well, yeah, the role of the two areas, the role of the two areas is one is for production and one's for comprehension. Okay, got it. Very simple idea and very elegant, very elegant. It's only the world. If only the world were also aligned to, you know, so models are doomed to be true for a while. So in this case, this is very powerful because it has the elegance of simplicity, but it also is empirically wrong. Right. So it's wrong for many reasons. Patients with the different lesions turned out not to have those syndromes. The brain organization is much more complicated. The wiring diagram is, you know, gazillions of times more complicated. So we've known for certainly 40 years that it's incorrect. And now in the last 10 years, I'm happy to say, and there are, you know, a handful of models that really go well beyond that and that show us actually how long the parts list is and how much more complicated the structure is partly that's because these contemporary models are much more in tune with what we know about the biology of the human brain. And likewise, what we know about the psychology of human language. So they try to link the, you know, let's say models of linguistics and cycle linguistics to models of neurobiology. And surely they're as inadequate, but hopefully they're wrong in an interesting way. And they are, you know, de facto the state of the art right now. One hopes for progress, not for definitiveness, in especially the brain. That's a nice way to say it. Yes. I mean, I think, you know, so look, the brains are complicated plays. You work on big things, really, really, really big places. And so the place I work on is small by comparison, just a size of two fists really squished together. That being said, my small place is pretty complicated. Way more complicated. No, it has a hundred billion parts, right? And it has about a, so the current estimate for the human brain is that it has 86 billion cells. And each cell has, you know, if you think about it, serve in the Facebook sense, each cell has between 1,000 and 10,000 friends. So are they really friends though? Are they friends? There's likes, there's acquaintances, you know, how should we really cash this out? But then if you imagine that they're course, you know, communicating with each other electrically and chemically, the computational complexity of the problem gets out of hand in a hurry. This is one of the reasons we don't really have, you know, the kinds of theories that are successful and adequate at the moment. Right. But we do. So you are part of the originator of something called the dual stream model. So you complicated the simple model a little bit by imagining that there were, there's more than one thing going on. Is it possible to simplify that enough to podcast my? Sure. I mean, so that's of course the correct model. Of course. Now we know. So that was an attempt by a colleague of mine, Greg Hickark. And we've worked together on this kind of thing for many years trying to bring together data from patients, right? Patients with stroke and imaging and biology and linguistics to come up with a much more, let's say, biologically realistic, computationally explicit and theoretically well motivated idea. And what we really did is, we borrowed or let's say we adopted and adapted the standard model of vision actually. So in the standard model. So what do you have to do when you see something? The most straightforward way to think about vision is you have to locate things and then you want to know what they are. Right. So there's a where system and a what system. And that's, you know, actually not that much of a simplification as it turns out. So there's a whole chunk of brain tissue, you know, the human brain, the vertebrate brain has enormous amounts dedicated to the visual system. And so there's an enormous amount dedicated to processes that identify objects, the so-called what system. And they go along as it turns out the temporal lobe and their job. So this is sort of the side of the brain under your ears. And these series of regions of which there are dozens actually are, their job is to extract the information that lets you actually identify things. So how do I know this is a glass of water? That's a glass of wine. This is a chair. That's a hawk flying by where you have to identify the object. That's super useful. You kind of want that. However, you also want another thing. You need to know where is it relative to where you are. So you need a system that allows you, for instance, to regulate your eye movements, figure out where you're reaching to grab something, see that a saber tooth tiger is coming from the left and not the right. So vision has really worked us out in wonderful detail, you know, very, very elegant. And we so we have one stream principally responsible for localization information and other things as well. But in the sort of a good summary statement and another stream of another anatomic stream with sub areas responsible for identifying objects. Very cool idea. So you've sub by the way, you've now bought yourself an interesting problem. How do you put them together? Well, I was going to say that it could have been that there was really only one system that did both functions, but it's two different systems, both sort of operationally, but also literally where they are in the brain. There's literally a different stream of information. Yeah. And so this has discovered a long time ago in the 60s and the hamster actually. So this notion of multiple sensory areas and multiple different streams responsible for in some sense it's an engineering idea that you then see replicated in the brain. So you want sort of subspecialization because the circuitry in those areas really does things optimized for that thing. So you want to, let's say you want to really identify an object, you want to have very high spatial resolution. You really want to be able to see the details, analyze its surface, make guesses about a heavy it isn't so on, whereas you don't care so much when you just need to move your eyes to the right to run away or something. So that's special. So we basically stole that idea. In the best scientific. In the sense of adopting and adapting and said, well, what if the speech and language system actually that's something that's not that similar capitalizing on similar computations, right? So the visual system is pretty old, but it's pretty useful. So one of the things you have to do in the language case is what do you want from the information that you have? Well, one of the things you want is the content. The what? So I need to recognize words. I need to string words together to recognize meaning. So I need to be able to tell the difference between a dog bites Sean and Sean bites dog, which would be uncool. So those are the same same set of words, but they mean something completely different. So you need to actually, so you know, in this case, the particular ordering has a clear consequence for the interpretation. And so we reasoned that maybe the brain is organized or capitalized on the same computational principles is you have one stream of information and says, look, what I really need to do is figure out what am I actually hearing? What are the words? How do I put them together and how do I extract meaning from that? And you have another stream that really needs to be able to deal with, well, how do I translate that into an output stream? So let's say let's call it a how stream or an articulatory interface. So why would you do such a thing? Well, let's take a simplest case of a word. And so what's a word? Well, you know, word is not a technical concept, by the way. Word is an informal concept. As you remember from your reading of Steve Pinkers book. So the technical term here would be morpheme, the smallest meaning bearing unit, but we'll call them words, words roughly correspond to ideas. So what is a word? So you have a word that comes in. So my word that comes in into your head now is let's say computer. And as it comes in, you have to link that sound file to the concept in your head. Right. So it comes in, you translate into a code we don't know. Let's say, you know, Microsoft brain. And you then translate that code then gets linked somehow to the file that is the storage of the word computer in your head. Now in your head somewhere, there's a file in address that says the word computer, what it means for you like, I owe it, you know, I'm on deadline, you know, oh, this file got down my email crashed. But there's many other things. So you know what it means, you know how to pronounce it, you know, a lot about computers, but you also know how to say it. Right. So it also has to have an articulatory code. Now here comes the rub that articulatory code is in a different coordinate system than all the other ones because it's in the motor system. So it's in basically time and what in motor people call joint space because you move articulators or you move your jaw, your tongue, your lips. So the coordinate system that you use as a controller is quite different than the other ones. So you have to have areas of the brain that go back and forth seamlessly and very quickly because speech is fast between an articulatory coordinate system for speaking and an auditory coordinate system for hearing and some coordinate systems yet unspecified, which we would understand at all for meaning. So you're screwed. So even something but now like, you know, knowing the word computer or glass or milk or that is already a deeply complicated theoretical problem. So in the visual case, the dual streams, if we call that in the visual case, yeah, the simply called the what and where, but the dual stream is simply that you subdivide problems in the multiple streams. Right. Like an engineer would. But those particular streams are what things are and where they are. And then in the audio case, the hearing case, it's what they mean. Well, let's say we call an interface to the meaning system, let's say, structure and meaning and an interface to the motor system. So we call it a word. Yeah, for example, I mean, so we called it a sound to the meaning interface and a sound to articulation interface. It does sound like it's a slightly different problem in the sense that language is where these meanings come from, or at least often, you know, sometimes we just yelper scream or whatever. But in the vision problem seems much more straightforward, right? Like any vertebrae is going to want to know where things are and what they are. We humans have a special problem when it comes to sound, which is that we want to interpret these in much more abstract ways. Yeah, I mean, the it's quite true that you don't want to over-analogize here. I mean, the and there are aspects of this, which we which to me seem quite different. Right. So one of the main things you do in the language case is what's technically called compositionality. Right. So it's just to take things and put them together. And that's not so obvious how that's true. In the vision case, although it may be, I don't want to over, you know, state my case here. But the kinds of things you have to do in language and vision are different, and certainly the output systems are different. Right. So, you know, the i-movement system is not like this beach system or something like that. But what you could imagine is that certain of the subroutines that are executed in the way they're are shared. Or that so, for instance, that's a very common evolutionary strategy, right? That's right. The brain is always borrowing, the body's always borrowing. That's exactly right. So you want to basically recycle stuff, right? So one reason that Greg Hickark and I argued for this particular dual stream physician, ours is now one of a few. I mean, there's a handful of these that I think there are, you know, we, of course, things are still the best though. That's not 10 years old, but now it's actually, but it's the fact that one of this, I'll tell you a fun sociological story about that in a second. But the, so one of the things that might be shared is this notion of, let's say, a coordinate transformation. So the reason I'm very attached to this is because the same part of the brain that we argue does this for the language speech case, for speech perception to production, sensory motor cases, that you have to do a similar thing in the i-movement case. So if you take the problem, I mean, here's a simple problem that everybody can do for themselves right now. You're sitting while you're listening to this magnificent podcast, you have a glass of wine in front of you. And we do, by the way, gentle listeners, which we do. Which we do. And I now really want to reach for this glass of wine, terrific red wine, by the way. And so what do I have to do to execute that, you know, ostensibly simple thing? So the first thing is the glass falls onto my eye, ball, into my retina in particular, right? So the surface, the back of my eye, that does the initial encoding. And so the coordinates of that are retina-centric, right? So that is a particular two-dimensional sheet. And the glass is now falling somewhere on that sheet. And the information now goes into my head. But now note that I can move my eyes. So now it's no longer in the coordinates of the retina, but in the accordance of the eyeball. Now I can move my head. I can also move my trunk. But in the end, what I'm trying to do is reach for the damn glass of wine. So it has to be in coordinates that are relative to my trunk and to my arm, right? So because I'm going to reach my arm out and it needs to be, I need to have knowledge of where is my current position of my hand? Where does my hand need to be? How hard does my hand need to grasp? So the simple act of reaching for a glass of wine or a pencil or anything ever requires a series of transformations conceptually, right? So it doesn't mean you're doing a series of equations right there, but you maybe. But you need to transform the information into a suitable format. And so if it comes in an eye-centered coordinates and has to go out in hand-centered or muscle-centered coordinates, what gives? How do you do that? That's a come for free. So the regions of the brain that do that in the posterior part of the parietal lobe, but different are more on the top of your head, likely are optimized for that kind of computation. And we reasoned, well, look, I mean, if that's the same kind of mathematical problem, maybe that's really well implemented there. And maybe the speech problem is similar in kind. Now obviously the inputs and outputs are quite different. You're going to get, let's say, you know, informally speaking, a sound file in and some kind of motor command out, but the kind of problem is the same kind of problem. I mean, you have to have some kind of basis function, you have to transform it into a different thing. So that's why we borrowed the thing from vision and tried to say, well, this is computationally similar. And that's why we think this sort of constitutes a form of progress because we try to be explicit about the set of operations that you really do have to do in order to achieve what's ostensibly almost idiotically simple. But, you know, the bottom line is we do not know how we recognize a single word or a single object. You just realized that your business needed to hire someone yesterday. How can you find amazing candidates fast? Easy, just use indeed because when it comes to hiring, indeed is all you need. Indeed's sponsored jobs will help you stand out and hire fast. With sponsored jobs, your post jumps to the top of the page for your relevant candidates so you can reach the people you want faster. And it makes a huge difference. According to indeed data, sponsored jobs posted directly on indeed have 45% more applications than non sponsored jobs. There's no need to wait any longer. Speed up your hiring right now with indeed. And listeners of mindscape will get a $75 sponsored job credit to get your jobs more visibility at indeed.com slash mindscape. Just go to indeed.com slash mindscape right now and support our show by saying you heard about indeed on this podcast indeed.com slash mindscape terms and conditions apply hiring indeed is all you need. I do have a question but first I'm using sociological story. You promise me. Okay, fair. So I this is this is kind of how science sometimes works and you know it has funny parts and slightly less amusing parts but when so about 10 or maybe by now 15 years ago when Greg Hickark and I started working this out one of the things we argued for was this dual stream concept. Another thing we argued for was that things really are much more bilaterally organized and at that point we were still extremely young. Well, ish and younger than now. Now you're only mostly young. No, I'm just you know a little more mature. The so Greg and I wrote this stuff up and we sent it and our the initial reaction to our work was that we were basically crazy because there was a model from the 19th century it worked. It was clinically useful and we were accused of being you know charlatans and the most naive bunch of Yahoo's who didn't know the first thing about any of the relevant disciplines which you know kind of bummed us out. Yeah, we were lucky to hear that right. We were like okay, you know we were just reading literature and doing our work and I mean it's true that we departed pretty drastically from the standard model at that point but we thought we were being very you know motivated by vision thinking about linguistics, thinking about the biology of the brain. People basically dismissed as a complete nut jobs. The problem is that people who sound like complete nut jobs. If you do have a tremendously important breakthrough the changes of the world you will be told you are a complete nut job. But most people who sound like complete nut jobs do not have tremendously important breakthroughs that will change. Yeah, there's a yeah I mean we were so we thought we were being pretty careful in our reasoning. No, so of course our feelings were because we were young we were both I think assistant professors at that point in our feelings were heard understandably. But then ironically so you know people started saying well maybe that's maybe they're not so stupid. The day that started a massing and you know the people started really thinking about it and reading it and pay a lot of attention to this thing. And now 10 years or 15 years later it's become more or less a standard thing and it's now it is the textbook model. But now ironically all the young people stand up and basically take shots at us about how naive and how stupid are we. So we never had the good years right. We never were initially we were the cranks who were just didn't know and now we're just like the old guard you know who just really isn't on the cutting edge. You were outdated even before you were excited. So sometimes we saw a little wistfully think like when we ever get a break here do we know people get the answer is no you do not get a break you do not get a break so that was I mean we're obviously happy that people are interested in this but it would have been nice to have like two years where you say good for you you know nice idea it's probably wrong it's good for you. I know it well but I'm thinking you know is it is there an obstacle to understanding both vision and auditory signals that we kind of in the back of our minds know a little bit too much about how computers work like when we take a picture with a camera we have pixels and we imagine there's just data of where things are and what color they are and the brain is much more based on extrapolations from incomplete data both in speech and in vision is that is that getting in the way of solving this important problem of how we go from the basic input stream to the meaning inside. Well I think you I think that's not quite right that is to say the pixel or camera metaphor for vision is also wrong right so just as hearing and language comprehension is entirely constructive process so is vision. No for in the brain it is yeah I'm saying for a camera for camera it's not yeah so we're taking the camera analogy we so we don't want to take that too far. I mean what we do know and we've known effectively since I want to say hemolts but probably earlier. Yes hemolts always write about most things. Most there's a there's a good line but I want to say David Hubel the noble laureate and winning neuroscientists who discovered fundamental principles of the early visual cortex he and Thorsten Weasel won the Nobel Prize in 1981 and I think it's I vaguely remember hearing this in the lecture that and David Hubel gave many years ago thing most of what we do are footnotes to hemolts very nice which I thought was sort of you know cribbing normalizing but pretty cool right you know Emerson's lying he that philosophy is just footnotes to playdoh yes that's where he gets it so I mean I think that the the notion that it's entirely constructed right so this is that you need a kind of computational theory using the word computational but loosely I think is now completely convincing right so that it's that the way we do things are predictive for instance that most of what we do is a prediction that the data that you get are you know vastly under-determined the the percepts and experience that you and that you extract from the initial data and so that it's a it's a filling in process right so you take under-specified data and that are probably noisy anyway and then you build a internal representation that you use for inference and you use for action those are the two things you presumably want to do most I mean you want to not run into things and you want to think about stuff and so there I think story of my life not wanting to think about stuff that's yeah I mean we all have the same issue there I often succeed it's better than I do I mean I make both mistakes I think poorly and do but the so I think that the there's now I'm for many years the start I mean this actually brings us back what we're talking about earlier the influence of Chomsky and mentalism was the embracing of what was and still is called the computational theory of mind and very influential I mean I think people like voter played an enormous role in this and subsequent you know so Jerry voter the philosophy Jerry the philosopher Jerry voter and then subsequently people like Dan Dennett picked it I mean it's you know de facto as far as I can tell the most reasonable way to think about the mind bar I mean there are no alternatives I find even vaguely credible not that they're not all over the interwebs you're right I don't know the brain yeah but these are I mean so these are extremely and what has made these helpful is the the requirement to make things explicit and sort of proceed right to think a little bit like a program I mean really spell out what are the I mean in some sense it's taking work on the mind and brain which I don't take to be particularly different just like any other discipline biology or physics that is to say your first job is to identify the parts list right I mean what is the ontological structure of your domain what are actually the primitives is Michael or I just like to go at the parts lists it's less complicated sounding what are the smallest elements that you need to use to generate the phenomena and then you need to identify the forces or the interactions between the primitives that generate the phenomenon under study and that's the computational theory of mind has been very good about that now the question they're obviously one can do better because we don't what the primitives are is a research program just like in physics takes decades and decades we don't know what the smallest pieces are right because it turns out to be really difficult every time we look it's a little bit smaller it's changed a little bit or it's you know for example now if you ask someone well what do you think is the relevant part of the brain they're going to say it's a neuron I'm like well that's a nice idea that's but maybe it's a sub part of a sub part of a neuron or it could turn out that it's going to be five neurons wired up a certain way namely two or a capacitor and ones are written uh who the hell knows we simply don't know what the encoding of information is well even for the neurons it's progress right in the sense that I get the impression that in at some point in the history of psychology it was thought that their you know the brain was a bunch of blobs interacting with each other and just the progress that has been made by thinking of it as a network right of neurons and they're not all connected to each other equally there's some hierarchical structure there I mean yeah that look I mean that's that breaks a very interesting and slightly dodgy point right so the and now nobody would argue that the network metaphor isn't necessary and important research agenda uh that being said isn't that just kicking the can down the road and before you said well it's this part of tissue and we don't understand now you say well it's five pieces of tissue with a bunch of wires interacting and we don't understand those so I'm so simply saying well it's a network is kind of punting on the problem for me it's a tiny little thing I so it is very so that we look I mean we're all on board with obviously everybody agrees look it's a super complicated dynamic system with many interacting parts we're trying to figure out how this you know the extremely high dimensional dynamics of the things work but it's a bit it's to me not a mechanistic answer sure it's a metaphoric extension not it's a metaphor or not a mechanism to say it's in that well how far does so there has been progress made how far does that get us to the stated goal of understanding what happens when we hear words like freedom or love you know words that are not referring to objects out there that we can point at abstract questions very difficult question I mean the vast majority of standard work should we say refers to let's say with the so-called open class items or you know nouns and verbs you know chairs and dogs and bears and things like that and no bears yet by the way no bears although some deer are often over there and maybe brought them to New York the so the the issue of abstraction is particularly difficult because you no longer want to deal with things like oh this concept has a bunch of features that make them and you know these necessary and sufficient features make you a member of the category honesty right the now there are such ideas namely the concept of embodied cognition very very popular these days in psychology neuroscience I can't say that I find it coherent but it's certainly you know be my guest and work it out and then I'll watch the movie you know it's all good but the it gets even more gnarly when you think not just about abstract concepts so so how does the let's you know back up for one thing how does thought partition roughly you might say well there are concrete things that we think about like dogs cats and tables and you know the untruthed intuitions as well those are the easy ones yeah not easy either then there are abstracts that they're not easier or just not easy they're not easy and they're not easier there's no reason to believe that the way we understand cat is easier than the way we understand honesty okay I have no reason to believe that all right right so we have intuitions that because I can understand honesty at all I know that but I don't know that your cat also doesn't understand cat cat actually no but I mean there so there are of course in our world concrete things that we that we reason about there are abstract things that we make inferences about but then there are the real juicy bits which is the small list of words in all our languages so called close class items that make you know make it all worthwhile namely things like and or right under through not yeah and that's where the fun begins so how are the and those are the ones you really want to understand because that's actually the glue that holds the stuff together right so you don't say cat dog or I mean that's the near if unless you're a phasic actually but I mean what you really say is you know no I don't want that quinoa right you know pass the gluten-rich pasta so but you're sounding pessimistic you're sounding like well at least well no I'm realistic about so I'm trying to say look you know I'm not I'm not pessimistic about where I think we've made wonderful progress and I think that sort of we're piecing the stuff slowly together but I'm a little and and actually okay so here's what I'm optimistic and pessimistic about I'm optimistic about that we can get a grip on let's say in the next 10 years the let's call them rules or operations or computations that put items together to yield larger items so the fact that red can for instance is a can and not a red right how'd you know that yeah that doesn't follow from first principle you have to actually figure that out right so that's actually you know that that's not a gimmick right and the so but my my hunch is that these sort of elementary operations of composition or combinatorics that yields larger units that then become the input to the next steps I'm actually pretty optimistic about that we're going to get a grip on that believe it or not okay what I'm much more we're not pessimistic but just kind of bewildered about and then stuff that I think that's giving me more you know sort of stuff that I think about a lot is well how do you store anything to begin with so if I say red can that's great but where is red where is can and how to put red can together so that literally literally located in the brain such that so the the remarkable thing is as we talked about earlier you have let's say you have 50,000 or you're uber educated so you probably have a hundred thousand things in your head right now in the mercily and useless many of them useless but but even the useless ones you pull it so at the rate that our conversation is happening we said you know four to five hertz is a typical syllable rate that means we speak you know something between three to five words per second super fast so it means at that time scale you have to translate the information coming into the periphery into the correct code go into your bag of words pull out the correct item not the wrong item we're pretty good right compared to machines are unbelievably robust resilient to noise and all kinds of stuff pull out the right item and keep doing that sequentially put them together with the next one and also with ones that are distant and get the correct interpretation out at a scale at a sub-second scale all the time right i mean that is so the operations that happen i'm pretty optimistic about that we get a grip on because we're i think there's wonderful research happening of that in many different labs but the process of the identification of how we actually store not just words but anything at all is to me deeply puzzling and i think is one of the deepest mysteries of neuroscience and i always well i would have thought at the most naive level again perhaps being misled by the analogy with computers that information is stored in individual neurons as some bits somewhere like there's a computer memory my understanding is that that is wrong and neuroscientists will tell me that it's closer to being stored in the connections between the neurons but maybe you're going to tell me that we don't even know that um so that's your your absolute right so i much prefer your first story that you say uh another that maybe things are stored inside cells or the structures of cells or even possibly the genome but the uh that would be the really interesting case how do you color red i can learn the color red and it will be stored in my well i mean what do you have all the introns for you know i mean they who know we don't know but look the standard story is the one you just said right so our standard story in memory right now is it's the connections between cells there's the synaptic structure and the synaptic connectivity is what uh reflects memory of something and the modification of that connection between cells is effectively what learning means so learning means a modification a cellular molecular level modification and ultimately a genetic level modification right and Nobel prizes have been giving out the given out numerous discoveries right so this is yes i mean so the you know the first one perhaps kind of candle most famously for you know for this synaptic so the synaptic pattern of things is the basis of this and this is you know this is the standard story but when you start to dig in a little bit and i think the most most um let's say harsh critic is is Randy Galistel from the from Rutgers who's a very distinguished psychologist and cognitive scientist who's worked most of his life on learning actually and from a computational point of view and has written a very very fascinating word called memory and the computational brain okay and a bunch of papers in which he basically pulls the rug out from under neuroscience of memory and says look you know show me at least how you store the number 17 or something or anything for that matter any bit of information yeah where and where is it how is it done and then how is it actually implemented when you use it how do you so we have sort of intuitions that yes the pattern of connectivity maybe you know activated or deactivated but you really need some kind of digital storage device right so i mean the issue that's very tricky in memory is you on the one hand so the way human memory works is certainly content addressable we know that for words for instance right so it's content addressable in sense of essay doctor you think nurse or toothache or you know whatever the appropriate semantic field is that that associates with you so that that's what content addressability is right so there's a content based sort of cloud of ideas but you also want what a computer has which is address addressability right you go to a location and you pull something out and so how do we so is that possible can we put things there how would we store in a sort of digital format the digital information we have how do we actually compute let's say with variables i mean take that might you know my what the wonderful examples from you know the animal world the Tunisian desert and cut that glufus okay it lives in desert Tunisia flat not much to see right no visual cues the ant walk comes out of its you know burrows and comes out and what has to walk around to finance a leaf right so the ant has to these answers small and it's not huge brains the ant walks around walks around meandering you know maybe a meter two meters finds a bit of leaf how does the ant walk back straight back to its hole how okay how does it know how to do that okay so how would you do that right so you don't have to figure out a bit of math you have to figure out okay wait wait a minute so here's a simple one it does it like hensel and gruddle so it leaves a little bit of chemical trail but if it did that it would wander back the same path it doesn't do that it actually takes a kind of straight vector back and then looks for its hold so it must have first of all figured out how far it so that's the count the steps or something yeah which turns out it does it has to keep track of time because at that point the sun has of course changed position so it needs a solar and thermal function yeah so you need to actually have an equation in your head in which you plug in the value of variables that you then calculate in order to say I have to go back you know south by south west and you know yay much you know whatever four feet now that's a kind of simple example well it tested in beautiful experiments by the way but that's a kind of compelling you know and very clear case where a small nervous system has to take you know it does a very simple behavior namely finding your home after walking out but in order to do that it has to plug a value into a variable so how do you abstract right now things get a little bit more than your high school students struggle not enjoy this concept and so how does the little tiny brain have represented a variable that then is able to take a specific value then do its little calculation and say I'm going that way is this the experiment where they put the little ants on still that is exactly one of them yeah there's a whole bunch of experiments but these are mostly by Rudiga Vina from Zurich and beautiful beautiful experiments and when they were on stills they got the wrong answer because they took a number of steps but they didn't understand how far they were going exactly right so that was the evidence that they you have a counter because if you're too high and you take the number you go too far so so very so but that makes us such a compelling case for a simple kind of computation so if they ant does that it can't be impossible yeah so there is circuitry and a small brain that allows you to have variable based computation right now if you attribute it to the ant do you not attribute it to the vertebrate right that seems weird to me and you're hinting at this might be part of the origin of abstraction well I mean that's already too far and I think I would like to you know to me it's a sort of reminder that one of the things we have to have an answer for is computation it let's say algebraic computation yeah so I mean it's actually good to have a tractable goal right so okay so if we can understand that which in some primitive sense even ants can do it that'll be nice yeah I mean it gives a very specific and so it's the kind of problem that the you know that language faces too so for instance look I mean one of the interesting things about language processing is that it's the so-called property of structure dependence right so one of the things that makes computers different from you know human brains is for the most part I mean that so is that the way the language language works across all languages it's not a string of pearls but it's more like an Alexander Calder mobile right so it has relationships that are dependent on where in a structure things are not just in a sequence so it's not just you know I have a sentence that has seven words one two three five six seven in a row and it matters what is your neighbor your nearest but it matters what their structural relation is and there's you know there's sort of incontrovertible evidence for this is not debated right so this notion of that means you have to have some kind of yeah some people give it a kind of tree structure because that's a good way to visualize it other people are deeply offended by trees and they say well you can't have trees living in the brain but that's just a notational variant of you can express that many different ways you know where people will love it come that was or it can be bracketing like a borrower whatever I mean you could call whatever you want it's just that their relations are not non-local right and that's a really deep property right so you have to be able to deal with non-local relationships the most obvious example is how you deal with let's say and pronouns and the thing that they refer to the so-called antecedents I say like you know and Sean was finished with his recording and he asked me to give him another glass of wine what is it him yeah is that that could be Sean but that could be someone else could be some other him could not be me but how do you know that often fly knows because there's actually a structural relationship between the pronoun or and the antecedent if you use himself that can only refer so these are kind of trivial examples but they highlight a very special property namely the property of and sort of what's commonly called that there are constituents or constituents are just equivalents classes right so constituents when I say you know horse greenings yeah the red can was on the table then the red can is a constituent it's because I could say the transparent glass was on so I can substitute for something else and the fact that you have such things and that they have of course causal force and how we say stuff suggests that they make you know they must be in your head somehow and unless you are a dualist and that's fine too no it's not but we don't be dualists here I'm not well I'm not okay with that but I mean it doesn't work for me some of my best friends are dualists I mean if you have a brain with 85 billion neurons in it and as you said each neuron has thousands of friends right so there's lots of connections it's a gigantic computational problem as you said even if the most functional level forgetting about meaning and abstraction and poetry and music if physicists were in charge of this they'd just be throwing gigantic computer power at it and treating as a big data problem and I do get the impression this is happening also in neuroscience no that's that's absolutely right I mean I think that there were you know many of us maybe all of us are seduced by the power of by the computational power now available right everybody and their brother has you know some wicked GPU in their laptop and the and but it is changing ways in interesting ways maybe it's good maybe it's bad the fact of the matter is that the the data sizes that we now collect the data amounts are extremely large that's true so when I stick someone in so like I put you in a magneto and cephalography scanner right so we recorded for let's say 10 minutes that was about two gigabytes of data immense a lot of data and it's very and so obviously you need to automatize the analysis you need to figure something out the but now comes a very important epistemological choice that you have to make does do you approach these data with let's let's caught well it's almost old school with a hypothesis you know like you learned do you actually have an idea where were you looking for something I mean is did you design what you did with a particular thing in mind so do you have a hypothesis a model a theory yeah and which is a very baconian and boring and you know but has done pretty well last few hundred years I'm not going to lie yeah or do you and throw do you pursue a kind of data driven or you know big data approach at the thing and that's very popular because we can right we have machines that do well and you can certain problems are and let's say at least descriptively reasonably well addressed by simply classifying things and if you're if you have a classification problem then big data is a cool approach you just throw you know you train your network on gazillions of trials and then you throw some new data on it maybe you have even an unsupervised learning situation and you get a beautiful clusters of things at them and I think that's very powerful and I I'm not going to lie we use that in my lab and looking for a legal data for you basically look so let's be clear I mean if you if you take this approach you're looking at an orgy of data that's almost treated hypothesis for it's purely correlation approach you use for a job so it's basically the mother of all regressions right and that's so what might happen so in one universe you might get lucky it might turn out that the the regression you build the giant correlation matrix which is you know obscenely large turns out to give you an interesting fractionation or you know factorization of the problem but what are the chances I mean I mean it could happen but I mean there's a lot of a data are weird and messy and noisy a lot of weird things could happen and so my here I tell you my as I'm not against this at all I mean we're nobody's against having more data I mean that's kind of silly but the question is how do you approach this data you've collected and I mean I guess I'm very sympathetic and you know in my own lab we have vitriolic energetic debate I love everybody in my lab wonderful people but we don't all agree and I have you know lab members that are strongly pushing me on this and I'm strongly pushing back and I believe it's a really good idea to design the experiment with a question in mind right there's if I stick you in a machine and I'm going to spend a lot of money energy and time on recording these really quite sophisticated complicated data I kind of want to know what I'm looking for and look I mean a very very big version of this is the large Hadron collider you don't build that thing you know just because you say oh shit let's just correlate a bunch of stuff oh no but exactly the same debate is going on between targeted searches and sort of blank searches for some some anomaly in something somewhere yeah that's interesting how you might interpret it I I'm sympathetic to finding things by serendipity but my own feeling is still that are from you know my own hunches that actually a very well articulated model that can then be shown to be wrong reduces the nature of the problem and I'm simply not satisfied by some giant correlation matrix or you know the answer there are regression those are engineering solutions in my own you know as I don't even worry my sort of gut feeling is that in the neurosciences in the summer of 2018 engineering approaches and big data approaches are actually replacing the standard approach of the sciences I mean that's a little weird that engineering is superseding a science but is it a temporary enthusiasm that well it's where we're all enthusiastic because it's cool to be able to look at gigantic amounts of things but here's the danger the danger is that we end up maybe it's not a danger maybe I'm just an old guy maybe an old angry guy and I think the potential danger is that we become theoretically myopic those to say the kinds of answers that are yielded by this approach are of a certain form and we will only be getting that form of answer right the form of answer that comes out of giant regressions right and that may be theoretically misleading that is we might have a generation of science in which the answers that are provided us come from that from that kind of epistemological stance and prevent us from seeing theoretical alternatives that are not you know fully aligned with that approach which I think would be a huge bummer so ironically by not having a theoretical framework with which to analyze and construct the experiment you're locking yourself in to certain possible things you could discover that's right refusing to look for other ones I mean my own so I'm working on this problem with one of my colleagues right now so the way we're trying to I mean so our diagnosis of this is we're not at all against using huge amounts of data that's exciting but here's our diagnosis suppose you run a big data approach on a neuroscience problem so let's say you know I want to study you know spoken word recognition something I actually know something a little bit about rent and what I'm going to do is I'm going to record I'm just going to have you know a thousand people listen to 10,000 words some giant data I mean I'm going to crank this thing through my you know convolutional neural network and then I'm going to get some interesting classifications came out of it and I can probably record in different layers and so you're looking at what happens in the brain when they're listening to these words yeah so just look for correlation and I'm just going to record this and then just going to take this data and I'm going to correlate everything with everything right so and of course some correlations will come out that's great now let's say I end up with a very good model terrific model fits and that model will be characterized by a series of parameters and it's going to be great and let's say it has you know 14 different things that I had to tweak awesome now I have a fantastic model and I have these 14 these 14 values I've got a capa because you got to have a capa okay maybe a towel always good lambda lamb does nice get a couple of lamb does good okay so now I have these parameters that I fixed and they yield the optimal thing what do I have what's my next step my next step presumably is to do quote-unquote normal science on what these parameters are right so I now I've just bit myself in the button I was say well I have these 14 things now I have to actually figure out what they are because they're the ones that are ostensibly the causal they have the force of being explanatory over the model so what gives I mean I think that's fine but my so my you know we our argument is that this is a lovely approach but in the end you're going to actually reinvent what you have to do to begin with to give a full comprehensive explanatory account of the parameters of your machine learned models so you think that there's still room for human thought and language in trying to understand human thought and language I think you need human thought you need just common sense yeah good solid common sense no bullshit have a good bullshit detector uh-huh and read all the details and and don't worry about it and it turns out you have to actually do the you have to do the homework you have to do the homework all right good advice we'd like to leave leave on a good advice and I can't do better than do the homework so David purple thank you very much for being on the plus thank you