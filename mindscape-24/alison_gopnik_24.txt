 You just realized that your business needed to hire someone yesterday. How can you find amazing candidates fast? Easy. Just use Indeed. Because when it comes to hiring, Indeed is all you need. Indeed's Sponsored Jobs will help you stand out and hire fast. With Sponsored Jobs, your post jumps to the top of the page for your relevant candidates so you can reach the people you want faster. And it makes a huge difference. According to Indeed data, Sponsored Jobs posted directly on Indeed have 45% more applications than non-sponsored jobs. There's no need to wait any longer. Speed up your hiring right now with Indeed. And listeners of Mindscape will get a $75 sponsored job credit to get your jobs more visibility at Indeed.com slash Mindscape. Just go to Indeed.com slash Mindscape right now and support our show by saying you heard about Indeed on this podcast. Indeed.com slash Mindscape. Terms and conditions apply. Hiring, Indeed, is all you need. With a Spark Cash Plus card from Capital One, you earn unlimited 2% cash back on every purchase. Plus, no preset spending limit helps your purchasing power adapt to meet your business needs. Jorge Gaviria, founder of Masienda, reinvests his 2% cash back to help grow the business with new products. What could the Spark Cash Plus card from Capital One do for your business? Capital One. What's in your wallet? Find out more at CapitalOne.com slash Spark Cash Plus. Terms and conditions apply. Did you know Fast Growing Trees is the biggest online nursery in the U.S. with thousands of different plants and over 2 million happy customers? They have all the plants your yard needs, like fruit trees, privacy trees, flowering trees, shrubs, and so much more. Whatever plants you're interested in, Fast Growing Trees has you covered. Find the perfect fit for your climate and space. Fast Growing Trees makes it easy to get your dream yard. Order online and get your plants delivered directly to your door in just a few days without ever leaving home. We've just received a white dogwood tree. We've not had a chance to plant it yet, but are very excited to do so. This spring, they have the best deals for your yard, up to half off on select plants and other deals. And listeners to our show get 15% off their first purchase while using the code MINDSCAPE at checkout. That's an additional 15% off at FastGrowingTrees.com using the code MINDSCAPE at checkout. FastGrowingTrees.com code MINDSCAPE. Now's the perfect time to plant. Use MINDSCAPE to save today. Offers valid for a limited time. Terms and conditions may apply. Hello, everyone, and welcome to the MINDSCAPE podcast. I'm your host, Sean Carroll. So here's a question. Given a problem, how do you find the solution to that problem? This is one of those questions that sounds deep or profound or something like that, but in fact, you might worry it is a little bit too abstract. How can we hope to understand how in perfect generality to find the answer to a problem if you haven't given me a bit more information about what kind of problem it is you're talking about? But it's not so abstract that we can't make some progress. You know, in general, how do we, in fact, go about solving problems? Sometimes, hopefully indeed, you'll find a problem that resembles another problem, a problem that you've seen before, so you can either use or maybe adapt the kind of solution that you already knew about. Other times, you know nothing about the context of a problem, so maybe you'll just try some things randomly, sort of flail about, just get some information. These kinds of questions, as abstract as they are, turn out to be frighteningly relevant to things like building artificial intelligence, right? When you turn on the computer and there's no software on it yet, the computer doesn't have any pre-existing strategies for solving problems. You have to choose how to build them in. So how should we go about figuring out the best way in different contexts to solve problems? Well, one thing to do is to look at what actual human beings actually do. The lesson of today's conversation with Alison Gopnik is that human beings use different ways to solve problems in different life stages. There's a way that we do it when we're adults, when we're flourishing, in the prime of life, and there's a different thing that we do when we're children or babies. Very roughly speaking, babies are a little bit more creative, a little bit more free-flowing. They just try a whole bunch of things. Their attention is hard to pin down. You might have noticed that if you've ever dealt with babies. And that's a feature, not a bug. The fact that babies have trouble focusing their attention on something is a reflection of the fact they're trying to learn about the world by interacting with it in many different ways. Whereas adults are optimized for something different. Hopefully, by the time you're an adult, by the time you're in your 30s, you've learned a lot about problem-solving strategies, and you're more about perfecting the methods that you already know rather than flailing around randomly and learning new ones. Not that you can't do it, not that it's impossible, but you're better at some techniques than others. And maybe, who knows, we sort of brush upon the possibility in the conversation that later in life, once you're past your prime reproductive cycle, for example, you can go back to being less hidebound. I mean, maybe that would be ideal. We all know people who don't quite live up to that. But you serve different purposes. I guess the overarching lesson here is that there's a division of labor, not only between different human beings working in groups, but even between different life stages of single human beings. And as we'll talk about, we do, in fact, learn some lessons that might be very, very relevant to AI and programming computers and thinking about how we should best approach understanding the world. That's what we're here to do here at Mindscape. So let's go. Alison Gopnik, welcome to the Mindscape podcast. Happy to be here. So one of the things I guess we could start with from your work that I've derived is the idea that little children, kids, babies, whatever, maybe shouldn't just be thought of as unformed adults, right? That they actually think in a different way. Is that an okay way to put it? Yeah, that's exactly the right way to put it. So I think a lot of people have always thought about the 35-year-old psychologist or philosopher as sort of the height of all of intelligence. And then we just build up to that amazing person as we get older, and then we fall off as we get older. But of course, that doesn't make very much sense from an evolutionary perspective. And in fact, I think what's become clearer and clearer is that children are really fundamentally a different kind of intelligence than typical adults are. And there's also some interesting questions about elders having a different kind of intelligence as well. So it's more like a kind of trade-off between different kinds of intelligences than it is having one magic thing, which is called intelligence that we have more of or less of, and that we have less of to begin with and more of later on. And an idea that I've been working on a lot is an idea that actually comes from computer science, which is the idea of a trade-off between different kinds of intelligences. And in particular, a trade-off between what's called exploit intelligence and explore intelligence. And what I've argued is that childhood is really about this kind of exploration intelligence, which is not just different from, but even intention with exploit intelligence. And now I have to say, when I first started making these sets of arguments, I was, as you could tell from that last comment, I was a little snarky about those, you know, 35-year-old philosophers and psychologists sitting and thinking that they were the apex of intelligence. But since my own children have gotten older and I have more grandchildren, now I sort of reverse that. My main feeling now is, oh my God, those poor 35-year-olds, the children and the grandmoms are getting to do all the really fun human stuff. One of my other slogans is that we're basically human up till puberty and after menopause. And in between, we're sort of glorified primates. We're doing the things that all the primates do. We're finding our way in the dominance hierarchy. And we're mating. And we're getting resources. Yep. And all that stuff. And it's only when we're little and we're old that we get to do things like theory of mind and discovery about the world and causal inference and cultural transmission and large scale storytelling, all the things that really make us human. So now I feel like, okay, we grant moms and kids to just keep quiet the fact that we're having all the fun and then the 35-year-olds are having to do all the work. And so this is going to be a preview for what's to come in the conversation. But that's basically because we're in that exploratory phase early on. And in what is nominally thought of as the prime of our adult lives, we're more focused, right? We have tasks and we're very good at doing those tasks, but we're less good at being flexible and creative about things. So there's this idea that comes from computer science about what happens when you're trying to solve what's called a high dimensional task. That means that a problem that has lots of different possible solutions that vary along a lot of different dimensions. And one thing you can do is you can just kind of tweak what you're already doing a little bit and see if that makes things a bit better. And that's a very efficient, effective way of trying to solve the problem. So just change where you are a little bit, see if that makes it better. If it does, then try something else. And that's the essential exploit strategy. That's the grownup strategy. Here's the thing that I need to do. I'm going to focus on trying to do it. But of course, the problem with that is that there might be another solution that's much further out in this space that's, as it were, you know, in the far reaches of the box, at least, if not actually out of the box. And if you just keep making these little tweaks, you're never going to get there. But what you could do is you could bounce around, try lots of things sort of independent of whether you think they're going to be useful or not. Just try things. Just see how the world works. And in computer science, they talk about this is the difference between a low temperature search. Think about it. Your audience will get this analogy, right? Think about it as if it was like a molecule of air that's just either going very slowly or bouncing randomly around in this space. And the interesting solution that comes out of computer science is that the best strategy... So these two things trade off against each other, right? Like you can't do both at the same time. So which should you do? And it turns out the best strategy is start out with a big, bouncy, random, wild search, even though, of course, that's going to take a lot longer and you're going to spend a lot of time thinking about things that actually aren't going to help you. And then gradually cool off to the more focused search. And people in computer science talk about this as simulated annealing. It's like what happens when you heat up... Again, your audience should know this. So what happens when you heat up metal and cool it to make it more robust? And what I think is that childhood is essentially evolution's way of doing simulated annealing. So if you think about those two descriptions, there's one way that's focused and oriented towards outputs. And then there's this noisy, bouncy, random kind of way of behaving. You can sort of pretty immediately think which one fits your four-year-old better. Yeah. And the thought is that even though that might look from some perspectives as if it's a deficit because the kids are saying weird, crazy things, they're often strange pretend land, they do things that don't seem to make sense at first. If you're in explore mode, then that's really the thing that you want to do more than anything else. So of course, in some ways, what this means, and we've actually shown this empirically, is that children are more creative than grownups, at least sometimes. So for instance, we've done a bunch of studies where we give children and grownups a problem that either has a pretty obvious, there's an obvious solution you could try, or a much less obvious hypothesis, one that to start out with is less likely. And what we've discovered is that when the solution is the more likely, the more obvious one, as you might expect, the grownups are better at getting to the solution. But when it's the unlikely hypothesis, four-year-olds are actually better than, say, college undergraduates at getting to the right solution. So in some ways, the four-year-olds are more creative than adults. But the trouble is, if you look at what we think of when we think about creativity in adults, it's really got two pieces. So it's not really easy to compare. So if you look at what a creative solution for an adult, the first part is generate lots of possibilities. And then the second part is pick out the one that's good, right? Pay attention to the ones that are good and not the ones that aren't. And that first part, generate lots of solutions, think of lots of possibilities. That's where the kids really excel. But for adults, you also have to have the part about choosing the right solution in the end. And that's the part where those executive exploit capacities seem to be more useful. So the great philosopher John Locke, Sean, I know you have the chair of natural philosophy, who was a great natural philosopher, said that there were two faculties for human intelligence. One was the faculty of wit, and one was the faculty of judgment. So the faculty of wit was generate lots of new ideas. And the faculty of judgment was pick out which ones were actually good ones. And kids seem to have a tremendous amount of the faculty of wit, not quite so much of the faculty of judgment. Fair enough. But OK, if we're giving evolution credit for coming up with this nice division of temporal labor over our lifetimes, let's face up to the fact that kids are pretty helpless. Like human babies, they take a long time to be able to fend for themselves. Could you talk a little bit about how that fits in with what we know about other species and whether or not it's like an accident or actually optimizing something? Yeah, it's interesting because if you look across an incredibly wide range of species, even including insects, and there's some arguments that this is true even for plants, but certainly true for all the primates and for mammals in general, you see this really striking correlation between how smart, perhaps from a human perspective, but how good an animal is it learning, how large its brain is, how much it uses its brain, and how long a childhood it has. So you see it, the first context in which people noticed this was with birds. So if you look at birds like corvids or crows, very, very smart birds, they spend as long as a year or two being fledglings, needing to be taken care of. Whereas if you think about like the domestic chicken, chickens are mature within a couple of weeks. And although this gets me in trouble with chicken lovers, everywhere they're not very bright there. Or a better way of putting it is they're extremely good at doing the things that they do well, like pecking for grain. And they're very good at doing those from the time they're born. They're not so good at learning. And if you think about it from this sort of explore-exploit perspective, that kind of makes sense. So if you're going to be a creature that lives in a changing, unpredictable environment that has to do lots of new things, you're going to need a period to be able to do that exploration before you can exploit. And that means that in that period, you're going to be really bad at doing things. You're going to be helpless. And you're going to need the other adult members of the species to look after you, make sure you stay alive, make sure you have enough calories to fuel all of this ferocious learning that's going on. And that seems to be sort of the evolutionary strategy. The calories are kind of a nice part of this, because it turns out that if you look at how many, what percentage of your calories your brain uses up, even as an adult, 20% of your calories are going to your brain, which means that your brain is an expensive computing gadget. But when you were four, 60%, in fact, almost 70% of your calories were going to your brain. So basically, your average four-year-old is like something out of Doctor Who or science fiction. It's basically this giant hungry brain that's going around the world, hypnotizing us into feeding it both a bunch of peanut butter sandwiches so its brain can work and a bunch of data so its brain can work. A lot of us start the new year saying that we will learn a new language, but it's hard to actually commit to it. Vaple makes it easy to learn one in less time than you think. Vaple's quick 10-minute lessons, handcrafted by over 200 language experts, get you to begin speaking your new language in three weeks or whatever pace you choose. And because conversing is the key to really understanding each other in new languages, Vaple is designed using practical, real-world conversations. What I love about Vaple is you can either dive in deeply and truly get fluent, or you can just master some of the basics before going on a trip. So let's get more of you talking in a new language. Vaple is gifting our listeners 60% off subscriptions at Vaple.com slash Mindscape. Get up to 60% off at Vaple.com slash Mindscape, spelled B-A-B-B-E-L dot com slash Mindscape. That's Vaple.com slash Mindscape. Rules and restrictions may apply. So that's interesting because you're pointing to an explanation that is not purely physical or even mostly physical. It's not about brain size or anything like that, but that if we allow ourselves to poetically attribute forces of natural design to intelligent design, rather, to evolution, this sort of planned difficulty in taking care of oneself is actually serving the purpose of letting the kids explore, be creative, and that's supposed to pay off later in life. That's right. So the thought is, and you know, of course, as always in biology and evolution, it's complicated and it's connected to other kinds of aspects of animals. And there are smart animals who don't have a long childhood like cephalopods, octopuses, for example. Different kinds of animals seem to solve this explore-exploit problem in different ways. Sometimes insects, for instance, seem to do it by a kind of division of labor among some ants are, some ants and bees are explorers or scouts, and some of them are workers who are actually doing things. So there's different ways of solving it. But it does seem like this is a strikingly general and common solution among a very, very wide range of species. And that suggests that it's got this adaptive value. Is this division of labor thing a general feature? I think I remember it was Michael Muthukrishna, who I had on the podcast and who mentioned this experiment, which I guess is famous among psychologists, where human children and chimpanzees were asked to poke sticks into a box and get a reward. And then when it's revealed that one of the sticks isn't doing anything, the children didn't learn. I'm sorry. The, yeah, the children didn't learn and the chimpanzees did because the children were trusting the grownups. Right. Yeah. And of course, that's another dimension of having this long, having this long childhood and having this particular kind of intelligence, which is that we are also social and cultural learners. So we pass on information from one generation to another in a way that no other, other animals do it more simply, but they, we do more of it than any other animal does. And again, a lot of that social transmission is taking place in the context of, you know, caregivers, people who are, who are moms and dads who are helping the kids. But it's interesting because that is a famous experiment, but it's worth pointing out that, again, there's this trade-off. So if you just imitate what the other people around you are doing, then there's kind of no point because you're not going to make any progress. So somebody along the line has to actually innovate as well as imitating. And there's a bunch of work we've done some of it and other people have as well that shows that children are, when they're imitating, they're kind of balancing. Well, what do I think about how this actually works? And what do I think about the person who's actually demonstrating it to me? So for example, there's a lovely experiment where if you have the experimenter says, I'm going to show you how this works. The children are much more likely to do the kind of over imitation that you've described. So they'll just do what the experimenter did. But if the experimenter says, gee, look at this. I don't know how this works. Do you know how this works? Then the children are much more likely to explore, including exploring in these kind of unlikely ways. And vice versa. We did some experiments that showed that if you actually show, let children discover something about a machine, for instance, a lot of our experiments depend on this wonderfully simple, inexpensive machine, the Blicket Detector. It's a little box that lights up and plays music when you put some things on it and not others. And it costs like, I don't know, $29.99 or something. It's nice, nice, nice from the grant perspective. And it's been extremely productive. So if you do something like present the child with a little box, let them play with it. And they see that, say, red blocks make it go. And then you have an adult who says, oh, blue blocks make the detector go. The children, it's interesting. They'll just exactly split the difference between what they see themselves and what the adult says. So they won't just rely on what they do see themselves. They won't just rely on the adult, but they'll produce one solution or another kind of in proportion to the probability of those two solutions. So I do think the fact that we're social beings, but that in the course of cultural and social evolution, Michael might have talked about this, we have to balance imitation and innovation. And it's quite complicated to do that. I think that also plays a role in the special intelligence of children. Well, it makes me think very much of being an advisor to students, right? Especially graduate students where you want to say, look, please do be creative and come up with new ideas. But please also read some of the literature. And there's a balance there. You don't want to just slavishly follow what other people have already done. Yeah. Yeah. I mean, I think that one of the interesting things that we're working on now is thinking about caregiving, thinking about what happens as you take care of someone else. And that's been very, and particularly thinking about the intelligence of caregiving, thinking about how hard it is to figure out what you should do as a teacher or a therapist or a parent that will allow the person you're caring for to become autonomous, right? You don't want them to just imitate what you do. You don't want them to just do the same thing. But you also don't want them to get into trouble. You don't want them to do stupid or dangerous things. And I think it's really interesting about how caregivers manage to walk that line, no matter what kind of context they're in. Whether you're thinking about being a grandmother of a two-year-old or you're thinking about being a supervisor or postdocs, it's fundamentally the same problem. And it's having those caregivers that enables a lot of that cultural transmission to take place. One of the interesting things that has come out that I've been writing and thinking about recently is that actually grandmothers seem to be playing up, grandmothers and grandfathers, I always talk about grandmothers egocentrically, seem to be playing a particularly important role in that kind of cultural transmission. So there's quite a bit of anthropological evidence that when you look at who gives the songs, who gives the stories, who tells you the big aspects of the culture, it's more likely to be older people than parents. So the parents are kind of trying to deal with the everyday, keep the kids alive, keep them fed. And it's actually the grandparents who are, you know, in my case, telling, reading Narnia books and singing old Broadway show tunes and doing things that are especially designed to serve this function of cultural transmission. And of course, just as we have this exceptionally long childhood, we also have this long postmenopausal grandmotherhood, elderhood, which is not characteristic of other animals. Except, interestingly, for orcas. So orcas are one of the few examples of a mammal that also continues to live for some substantial period of time after menopause and has grandmothers that live with the pod. And what the grandmothers do is pass on information about what to eat and how to function. So especially when things get short, the grandmothers are the ones who lead the pod out to, oh, okay, I remember, you know, 20 years ago, there was krill in this site and helped to help the grandchildren, the children and grandchildren to survive. And I think that's another really nice sense of a kind of intelligence that's different from what we think of as the standard grown-up intelligence. That sounds almost too adorable to be true. How sure are we that the killer whales really put so much responsibility in the grandmother's hands? Well, what I like about this is what it shows is the really important thing to pass on is recipes, right? That's the thing that the grandmothers, that's the thing that the grandmothers are designed by evolution to do. And I just, again, with the advisor thing, just as it's on my mind, we can be egocentric a little bit. That's okay. I do think a very, very common mistake in dealing with students is that the older wise folks are sometimes too good at saying why a new idea won't work. Right. Right. And I mean, are you hinting that maybe I'll get better at that as I get older? I'll be more open to the exploration? Well, I think that's definitely one of the features of elders that seems to be important. And, you know, again, to use the analogy of the students, I think part of the reason for that is that the 35-year-old caregiver also has their own agenda, right? So they want to make sure that they get the results that they need for the grant. And the more the older person can sort of say, okay, I've gotten what I need. I can be more open to the possibility that this younger generation is actually going to do well. Now, of course, there's big individual differences among grownups about how much, how likely they are to do that or not. But it's interesting that even if you there's a little bit of evidence that even if you look at adult scientists and, you know, one of my one of my other slogans is that it's not that children are little scientists. It's that scientists are big children. And I almost always get a round of applause. You know, if I if I say this at Fermi lab or, you know, Lawrence Berkeley lab, everybody sort of agrees with that. Um, uh, and one of the the there's a little bit of empirical evidence that shows, for instance, that the labs that get the Nobel prizes are the ones where something unexpected happens. So what happens when you do your you do your experiment and what comes out is like totally weird, not what you expected at all. And you could say, okay, something strange happened. Let's go back to the grant. Or you could say, huh, like, why did that happen? Um, and it turns out that the labs where when something unexpected happens, they follow up and try and figure it out, do better in the long run than the labs where you're doing the thing that you were supposed to do. Okay, we'll try to let go of graduate students as an example here and think more about the actual human babies. Uh, tell us more about how they get their picture of the world. I know that one crucial step is when they figure out that other people have opinions or beliefs that are different than their own. Yeah. So the, the big idea about child development, which now I and other developmentalists have been arguing for, for the last, I don't know, 20, 25 years is that you should think about, um, development as being like theory formation in science. And at first that idea seems sort of unlikely. I mean, little kids, are they not like really smart scientists, but when you look carefully at the way they understand the world, it looks a lot like the kinds of theories and the changes in theories that adults, uh, that scientists have. And what that suggests is that from a, a kind of computational perspective, that's a, just a really good way of getting information about the world. So what we've shown is that from the time they're very, very little children are looking for causal relationships, for example, which is one of the things that really, it's really important in a theory. Right. And we can show again, with our little Blika detector, these little machines that have, where they have unexpected causal properties. We can show that even, you know, toddlers are doing the right kinds of inferences about how those kinds of systems work. So they seem to develop these causal models, these kind of what are sometimes called intuitive theories. Um, and then they get new data and they change the theories depending on the data. And we can show that really systematically. So we can, we can, for instance, show them information data about how that little, little, um, uh, about how that little, uh, machine works, the little Blika detector works. And then we can see what kinds of inferences do they make into a remarkable degree. They make the inferences that you should make if you're trying to, if you were being a good scientist, but of course, you know, figuring out how machines work is fine. But the thing that's most important in all of our lives, arguably is figuring out how the people around us are working. Um, so way back in the eighties, I and others, um, did developed what's come to be called, um, theory of mind, which is figuring out what is it in baby's minds that enables them to understand your mind. And what we found out, which is sort of typical of what we found out is that babies both know more to begin with than we would have thought, but they also learn more. Um, so between say one and two, for instance, they seem to start learning that people could want different things. I want one thing. You can watch another between, uh, four and six. They seem to start understand between three and six. They start to understand that I could think something different than you do. And those are really, really deep, important things to understand. But more recently, one of the things that I think has been very interesting is the development of work on children's intuitive sociology. So they're also figuring things out like, oh, when people are allies, they'll behave this way. Ah, the next level. Good. Yeah. Right. When they're enemies, then they'll behave this other way. And if one, uh, creature is dominant, is larger than the other, then they can get their way. And what we're just trying to do now, again, to go back to this caregiving point is figure out what do they actually think about caregiving? And there's a little bit of evidence that even babies already are identifying, okay, this is what it looks like for someone to take care of someone else. This is a good potential, this is a good potential caregiver for me. So there's this lovely kind of back and forth between that helplessness that I talked about. And then the fact that if you are that kind of helpless creature, learning about other people, learning about love, learning about what other people are like is going to be really important for your, your survival. And of course, as adults, that's still the most important thing that we're learning about. I want to get the, in the audience's mind, the idea of those blicket detector, because clearly it's playing a big role in your psychology experiments. Is this something you buy off the shelf or do you make them? Yeah, it's funny. We, we started out, uh, when we started doing this 20 years ago, um, we actually made them. So we had, in those days in the psychology department, you had a shop, which we don't tend to have anymore, but we had a shop and we went to the folks in the shop and said, okay, well, look, here's what we want. We want this little, it's just, it's very simple. It's a little box. You put different things on top and sometimes it lights up and plays music and sometimes it doesn't. And then we had various other kinds of variants of this. So we had one with gears where you flick a switch and then the gears go and then that makes something else happen. So they're kind of like a little Rube Goldberg machines that we'd, we'd, uh, we'd put together. Now at the time that we, this is a kind of interesting, um, anecdotal observation at the time that we first did this, we thought, gee, this would be so much easier to do if we just had screens and a computer and do it that way. The kids didn't want to have anything to do with it when it was a screen. They really needed to have the real thing. But now what we're finding is that even like three and four year olds, um, and I think the big difference is now screens are interactive. So three and four year olds have the idea. And in fact, again, if you have a baby, you know, really love the idea that they can act on, uh, uh, they can touch something, they can talk to it, they can swipe it and then figure out what the outcome, uh, is supposed to be. Although it still looks like we need the real things for the, for the younger kids, but for the older kids, the older kids now sort of have the idea. Oh, okay. Uh, uh, a screen is something that has causal powers as well as a, a little machine. This episode of Mindscape is sponsored by BetterHelp. When it comes to relationships, we often hear about the red flags we should avoid. But what if we focus more on looking for the green flags in friends and partners? If you're not sure what green flags look like, therapy can help you identify them, actively practice them in your relationships and embody the green flag energy yourself. Whether you're dating, married, building a friendship, or just working on yourself, it's time to form relationships that love you back. One of the great things about therapy is by looking inside yourself, you can both learn to take those warning signs seriously, but also learn to be open to new experiences and new things, to know when something might be worth pursuing. BetterHelp is a fully online service that makes therapy affordable and convenient, serving over 5 million people worldwide. You can easily switch therapists anytime at no extra cost. So discover your relationship green flags with BetterHelp. Visit BetterHelp.com slash Mindscape today to get 10% off your first month. That's BetterHelp, H-E-L-P dot com slash Mindscape. But still, you have these little, are you still doing the little boxes? I just like the idea that it's a rite of passage in the Gopnik lab for graduate students to build a little box that lights up under different circumstances. Well, that's exactly right. And we have a lab culture about where we get the doorbells that go in it. And one of the funny, a funny story about this when we first started doing it, when we first started doing it, we actually had the folks in the shop who were putting these things together. And at one point, one of the machines that we had broke. And my brilliant graduate student and I went in and asked, said, look, it's not working. The, you know, the gear is not making the other gear go. And they said, oh, no, that's not how it works. We just programmed it. So it does this specific thing when you, so there's no, there's actually no physics behind it at all. It's just, it's like a, you know, it's like a Tesla car. It's just a computer masquerading as a, a real physical artifact. And we were, I have to say, we were a bit crushed about this. The way that it actually works most of the time in the lab is that there's a graduate student who's sitting and pressing a button underneath the table that's determining what it does. So from the kids' perspective too, it's not, they have the illusion of actually doing physics, but what they're actually doing is doing experiments. It feels like the Wizard of Oz here. I feel like I've been fooled about all this, all this stuff going on. Okay. So if you say things like, you know, a child under one year old doesn't have this theory of mind and a two year old does. So do we know of certain benchmarks or phase transitions in the growth of a child where their, you know, cognitive view of the world expands a bit? Yeah. So as I say, from the very beginning, I mean, literally from the time they're born, babies are doing things like paying special attention to faces and interpreting them from very early on. They're imitating other people in a way that other primates don't seem to, which suggests that there's something about understanding other people. That's really important. By the time they're nine months old, they're doing things like pointing to communicate and a nine month old will point. And if you don't follow the point, they'll get antsy and go, you know, dare, dare, dare. So that suggests that they know something about what the fact that other people are, are looking at the same thing that they are. So sometimes what happens is that people say, oh, you don't get theory of mind until you're four or five, but that's not right. You just get different theories the same way you would if you thought about, you know, physics. There's different kinds of theories about different parts of the mind. But very characteristically, you see these changes coming at, you know, round about a particular age. So about nine months, you see this big revolution and, you know, some of it may just be maturation, but I think the something that is increasingly important and that we haven't thought about enough is just how active learners, even these very young children are, just how much what they're doing is not just observing statistics. Although of course they, they do that, but, but also actively experimenting on the world. And, you know, if you think about even a newborn, they're looking at you, they're smiling, they're seeing what the effects of their actions are. And by the time, by the time you're talking about, um, uh, toddler, that's like their whole lives, right? They're just constantly, constantly doing experiments, except when they do it, we call it getting into everything. When physicists do it, we call it being a good experimental physicist. Um, uh, and I think it's really under, so one of the things that we've been doing a lot recently is trying to think about how the children's learning compares to the learning of, uh, machines, for example, something like the large models that have had so much, uh, uh, play. So what's the relationship between what AI is doing and what these very little kids are doing. And I think one of the really big dimensions that makes the kids different from the AI systems is that they are going out and actively trying to get information about the world and then changing what they think based on the information they get, as opposed to the large models. For example, that are basically. They're basically just, it's, it's interesting to think about this in terms of cultural transmission, the large models I've argued really what they do is just pick out patterns and all the things that other people have already have already figured out. So they're just doing the imitation part of, of cultural transmission. Um, but the kids are actually going out there and finding out things that are new and experimenting and seeing new outcomes. And we think that may be really the crucial thing that lets them learn as much as they do, as quickly as they do. And with as few calories as they do compared to the compared to the AI systems. So it is a little bit like the distinction in causal reasoning between simply finding correlations versus being interventionist about things, right? Going outside the dataset and saying, if I did this, what would happen next? Yeah, that's exactly right. And, uh, uh, and we've for 20 years, we've been collaborating with actually philosophers of science and computer scientists who've been trying to figure out how do we do causal inference in, in science. And one of the really, you know, basic ideas is that you can't, or it's very difficult to do it just by looking at patterns of statistics or correlation that you want to make causal inferences. Well, what makes a causal inference different from just a correlation? This is a, an old philosophical problem back to Hume. And I think the idea that's become most prominent in philosophy of science and seems intuitively and in science itself is well, okay. If you want to really make the causal inference, you have to do an experiment. You have to actually intervene, do something in the world, see what the outcome is. That's what makes something, uh, causal. And I think we've been doing some work on this, but I think if you look at, uh, even quite young babies, um, you know, if you think about something like a busy box, a busy box is a toy that you use for little babies. They're called busy boxes. A busy box is a, is a thing that has lots of causal possibilities where you can do lots of experiments. It's, it's cheaper than your, you know, standard cyclotron, but it has the same kind of character for babies. It, it's a way of, um, it's a way of actually being able to, to do the kinds of experiments that you need to figure out how the world works. And of course, as I point out the, since, um, theory of mind and intuitive psychology is so important, they have a great experimental subject there all the time, which is the caregiver. So if you think about them as being little science, little psychologists, we're the lab rats. So a lot of what babies do in the terrible twos, for example, is, um, doing something and then looking to see how we, uh, react to it. You know, we had, uh, Judea Pearl on the podcast at one point. Yeah. And at one point he said, literally like, haven't you ever seen a baby? All a baby is doing is like touching things and making a causal map of the world. And I, I understood what he was saying and agreed with it, but I guess I didn't realize it was quite as literal as, uh, apparently it is. No, absolutely. So what we've done is taken some of the formalisms that Pearl developed, like causal basenets, and then show how the children are, uh, how the, the ways that children are solving these causal problems are just like, uh, what you'd expect from causal graphical models. So essentially what the children, I mean, I think we can say that we've demonstrated this, what the children are doing is constructing. Pausal, uh, graphical models from data and then using them to determine their interventions. Now, the thing is that both for Judea and for the whole world of causal inference and for us, it's still a kind of unsolved problem about, and for scientists, right? How do you decide which experiment is really the right experiment to do? Sure. So what something like, uh, um, Judea's, uh, uh, framework lets you do is say, okay, if you get this result, here's the causal graph you should have. But how do you decide what you should test in the first place? Um, and I think one interesting thing that's coming out is that a lot of the, um, the sort of old shibboleths about how you do experiments, you have to keep everything constant. You can only vary one thing at a time. That main, that's not true for babies that it may not be the best way of doing science either. It, and, and I think this is like a wonderful, um, open, uh, a wonderful open question about how do you decide what kind of, uh, experiments to do? How do you decide how to explore? And we've started doing this with kids in, um, kids and AI agents. What we've done is put them in the same kind of general environment. Um, uh, Minecraft is one of the ones that we use. If you know mine, I imagine your audience will know Minecraft. Although there's a bit of a funny story about this, which is that, um, I originally started doing this work about how you explore the Minecraft environment because my grandson was mad about Minecraft. I figured, well, at least this will make me cool. Right. If I can tell him that grandma's doing stuff about Minecraft. Um, then I gave a big talk about this. I got something called the Rummelhart prize. It's a big deal. And my grandchildren were in the audience. And I said, well, I did this because I wanted to impress Augie. And he came up to me very sweetly after the talk and said, grandma, this is a little, that was a little embarrassing because like nobody cool plays Minecraft anymore. We all play, we all play Fortnite. Um, so like, it isn't really cool to be involved in, in Minecraft if you're a 13 year old. So I, I wasn't keeping up with the changes, but in any case, Minecraft is a great game. It continues to be a great game for, for grownups and for 11 year olds. And, um, and it's, uh, uh, what we've done is put kids in that environment and then put AI agents in that environment. And just said, figure out what's going on, explore. And even relatively young kids will explore that environment in a rational way. They're not just randomly trying things. They're doing things in a way that lets them figure out how the environment, uh, how the environment works. And they're much, much, much better at it than AI agents. Interesting. Well, the thing you said about traditional scientific methodology, asking us to keep all but one thing constant and changing that one thing and seeing what the effective. I mean, that makes it, that sounds sensible to me. Uh, but is it just because it's simpler to keep track of what's going on, but maybe it's ultimately less effective than kind of poking things in concert? Yeah. Yeah. So that's a really interesting, technical, formal question about when, you know, that it is true that if you did that, that's a simple formative rule about what to do. But sometimes actually doing, trying to vary different things at once can be more informative than, than, because as you can imagine, it's really hard to keep everything else constant than just change one. Um, and that, that I think thinking about what the kids are doing can be very, because the kids, some, the kids are, are, are. Often trying lots of different things in different, in different ways. If you think about, you know, the two year old with the busy box, um, and yet they seem to be such good learners. So it's a really interesting question, I think for AI, for science, for developmental psychology about how that's possible. And how literally true is it to describe these very young children as good Bayesians? Yeah, I think it is literally true. Um, uh, we've, what we've done is take various kinds of ideas from Bayesian inference. And what we can do is give kids information, for instance, about the baseline probability of a hypothesis. And then we can give them information that will let them update that hypothesis. And they'll do the right kind of updating in the right kind of way there. Another kind of discovery that was in my lab, but also even more in labs like, uh, Richard Aslan's and Jenny Safran's back in the nineties, was that children are quite good at doing statistics. Mm-hmm . Which you might be really surprised at because after all, grownups are notoriously bad at doing probabilities. But if you do something like, um, show the children that one blicket works, um, eight out of 10 times and the other one works four out of 10 times, um, they'll pick the one that has a higher probability of activate. And then this is with 18 month olds. And then you say, okay, which one will you use here? Make the machine go. They'll pick the one that has the higher statistical probability. In fact, they'll do it even if it's like two thirds versus eight tenths. So they seem to be able to kind of do the math implicitly, obviously, and unconsciously to figure out what, how probabilities work. So, you know, there there's, and, but again, this has led to this puzzle, which is they really seem to be doing something like Bayesian inference. And yet we know that Bayesian inference ideally is sort of impossible computationally. So if you have a, if you have a big set of hypotheses, then it's going to take you, you know, if you, the, the Bayesian idea is you take a hypothesis, you generate a pattern of evidence, you check it against the data that you've got. You figure out which hypothesis would have been most likely to generate that pattern of data. And the problem is if you have a big space of hypotheses, that's just going to take forever because you're going to have to try each one of the hypotheses separately. It's called the search problem. And nobody's really quite solved that problem either in statistics or in AI or in childhood. And the children do seem to be able to solve that problem because they end up, you know, finding out about the world. And it's a really interesting question about how they solve it. And my guess at the moment is that something about this active inference might be part of the solution, that it isn't just that you're sort of sitting back, having data float over you and then trying to update your hypotheses. You're actually out there being an experimenter and figuring things out, which should make at least the, I know that in physics, there's always a bit of a tension between the theoreticians and the experimentalists. So I think from the developmental perspective, we're, we're team experimentalists. That's the, the, the. Fair enough. That's, that's, that looks like that's really the secret. And how much do we know about the neuroscience of this kind of thing? I mean, are these ideas that babies sort of get better at different kinds of reasoning as they grow older mirrored in ways that the brain is wiring itself? Yeah, it's quite neat because one of the oldest developmental neuroscience findings, which is consistent with what we've, we've seen to this day, is that early in development, what you see is lots of new synapses, lots of new connections being formed. And then there's a point, a kind of tipping point where the ones connections that have been formed are strengthened, they're myelinated, they become more effective. The ones that haven't been formed are pruned. So the weaker ones just kind of disappear. So you have this early brain that is very, very flexible, very good at changing in the light of new experience, very plastic as neuroscientists say. And then, but not very effective, right? Not very good at actually doing anything. And then you have this later brain that's very good at doing things, but much less good at changing, much less with much less plasticity. And again, this is like another version of this explore exploit trade-off. And empirically, if you look at brain development, you can see that depending on the domain that you're in, you see this pattern of very early proliferation and then later pruning. So if you look at the visual system, for instance, you see this tipping point at around 18 months. So the visual system is getting set in that early period and then it kind of settles in, which is why if you have vision problems, it's really important to correct them in a baby. It's really important to correct them early. If you look at the language areas, it's like five or six where you start seeing this, you start seeing this transition. So it's when you've developed a language that then it becomes harder for you to learn another, learn a new language. And if you look at what's sometimes called the executive function, the prefrontal part of the brain, that's the latest one. And that's not completely getting set until adolescence, for example. Okay. So you see this, but you do see this general pattern of start out with lots and lots of connections and then at some point start strengthening and pruning. Thumbtack presents the ins and outs of caring for your home. Out. Uncertainty, self-doubt. Out. Stressing about not knowing where to start. In. Plans and guides that make it easy to get home projects done. Out. Word art. Sorry, live, laugh lovers. In. Knowing what to do, when to do it, and who to hire. Start caring for your home with confidence. Download Thumbtack today. And I just hate to bring it back to academia once again, but this comports with the idea that, you know, like the energetic young idea creators are the young faculty and postdocs, right? Not the older senior faculty who've been successful for many decades. Yeah. I mean, I think it's an obvious question that lots of people have asked is, well, are there things that grownups could do that would make them as creative as the children? Yeah. And the first thing to say is, even if you're thinking about a lab, if you want to get grant money, it's really good to have people who are really, really practiced and know how that system works and are really good at it. And even if you forget about grant money, just, you know, actually doing the experiments, if you're a physicist, for example, is a giant, you know, enterprise. It really takes a lot of focus and executive energy to be able to get the experiments to run. So I don't think you'd want, you know, like you don't want your, your department chair to be this wild, wildly creative person who's thinking up strange ideas all the time, right? You want them to be, to be focused. Nevertheless, I think it's interesting that, and, and relevant to this explore and exploit trade-off that when adults want to, adults often will kind of have social institutions that allow them to switch back and forth between this explore and exploit. So sabbaticals, I think are a great example in the academic context, right? So we don't sort of expect scientists to be able to just do this on their own. And what we think is going off to a retreat, going off to a sabbatical, going off to a workshop, those are all ways that you can kind of pull yourself out of the context that you're already in and, and allow yourself to, to do greater exploration. So, you know, it's a pain that we all spend so much time traveling as scientists. But I do think there's a bit of an argument that being in a different place, being in a different context, often doing interdisciplinary work where you're, you're, you're forced to think about things in really different ways because now you're looking at biologists instead of physicists. All those seem to be ways that grownups set themselves up to be more creative. And does it, you've mentioned already several times the connection between these ideas and AI, large language models, et cetera. How operationalizable are these insights? Can we imagine building better AI models using this, the lessons we've learned from development? Well, that's kind of what we've been doing. So I'm part of the Berkeley AI research group. And, and what we're trying to do is take some of these ideas, ideas about active learning, ideas about social learning, ideas about causal model building, building, and actually implement them in, in the, in, in AI systems. And, you know, to a certain extent, what's happened is that because the large models have been so effective in lots of ways, they've, there's a tendency to sort of say, okay, well, they worked before. We'll just keep making, we'll just, you know, pour more compute into them and they'll get bigger and they'll use up more energy. And then we'll, they'll get better and better. And we'll have this mythical thing called AGI. And one of the things when I talk to AI groups, which I do a lot now, I have a, I have a, a slide where I say, there's no such thing as general intelligence, artificial or natural, which always leads to sharp intake of breath from, from the audience. Because it just isn't the, the, the theory, the, the ideology, the model. And, oh, okay. There's this one, this gets back to our very first conversation, the model that there's this one thing called intelligence. Some people have more of it. Some people have less of it. If you have more and more of it, then you're going to be more and more effective. That's not the model that comes out of cognitive science at all. What comes out of cognitive science is that we have these trade-offs between different kinds of, of cognitive capacities. So if we could design, sorry, so LLMs don't rather strikingly have any of these capacities. They're not going out in the world and doing experiments. They're not creating abstract causal models that then they can use to generalize. And you can see the difference between the amount of data that the children have and how good they are at generalizing it to new situations and, and the large models. The large models need enormous amounts of data and they're not very good at generalizing. Especially to what's called out of distribution cases, cases that weren't there in their training. The kids are with much less data are very good at doing that. So the question is what, what are the kids doing and could that make more effective AI? And I think the thing to say at the moment is we're very, very, if you start thinking about the comparison to kids, we're very, very far away. So they're, they're, they're, the kids are, you know, orders and orders of magnitude better than any of the current AI systems that we have. But I think that's the direction that we might want to go in. Well, it's a difficult conversation to have sometimes because the AI, the people who worry that we're close to super intelligence any moment now will say, look, the, you know, we can beat the best human beings at playing chess or playing Go or whatever. And, and you try to make the point as, as you just did, that there are other aspects of intelligence that they're not good at, but it's, they seem a little bit fuzzier, right? It's, it's quite, it's a little bit harder to put a benchmark on it. Is that something that we're trying to make progress on? Well, I mean, one thing is that, for example, if you look at robotics, the, you know, notoriously the, the, the AIs are better at playing chess, but they're terrible at actually picking up the pieces. If you, if you made part of the game B that you had to pick up, find the pieces in a, you know, that have spilled on the floor and put them back in exactly the right places. They're really quite bad at doing that. Especially if you had say a new chess set that was, you know, like a, an Alice in Wonderland chess set or something where, where it wasn't, you couldn't, you couldn't just identify them from your previous training. And this is the famous Moravich's paradox. This goes back to the beginnings of AI that things that look really hard for human chess and Go turn out to be relatively easy for AI and things that look really easy, like perception and action. And movement and movement and the kinds of things that kids do when they figure out how the little Blikid detector works turn out to be really hard for, for AI. I, I think the whole conversation about intelligence and AI is fundamentally misguided because really the reason why the systems are as effective as they are is because they're taking advantage of, you know, hundreds of thousands of humans who've done things like put text on the web. And, and in some ways, like with reinforcement learning from human feedback have trained up the systems. My, my, my latest metaphor about this is, do you know, the story of stone soup, the old children's story of stone soup? No. This is a wonderful children's story. This is another advantage of being a developmental psychologist. Yeah. You have wisdom of the stories that grandmothers have told in the past. So this turns out to be a very, very widespread bit of folklore. And here's the story. There's these visitors who come to a village and they say, we want some food. And the villagers say, oh, sorry, we don't have any. We can't share any with you. And the visitors say, that's okay. We're going to make stone soup. We have magic stones. So they get a big cauldron. They put a couple of stones in the cauldron. It starts boiling. They say, see, we're just going to make stone soup. It's so good. You know, it would be even better if we had an onion and a carrot that we could put in it. But I guess if we don't have it, we don't have it. So one of the villagers says, I think I have an onion and a carrot somewhere. They go and put it in. They say, oh, that's great. Like, oh, see how well this soup is working. When we made it for the king, we put a chicken in and that was really great. So could you go and, and of course you can guess what happens. The villagers all contribute their bit of, of their bit of food. And then at the end, the villagers say, this is amazing. This is magic. We got all this soup just from a stone. And I think if you think about a version of that, where you said there were the computer people, the tech guys who went to the universe of computer users and said, oh, we have AGI. We can do it just with, you know, three algorithms, gradient descent and transformers. And we'll have AGI any minute now. But, you know, we really need a lot of data to make this AGI work. And the user said, oh, okay. We have all of our text and pictures that we put on the internet, all of our books, all of our newspapers. We could give you that to make the intelligence. And then the villagers, the tech guys say, oh, that's really great. But like, if we could do reinforcement, our AGI is still saying stupid things. So if we could get reinforcement learning from human feedback and get people to give us feedback about whether our AGI is doing well or not, that would make it even better. And the people said, oh, okay. Like there's whole villages in Kenya who could do this. And finally, the tech guy said, oh, that's really, we're getting really good intelligence. But if we could do prompt engineering, so we could figure out what exactly what prompt to use, that would make it even more intelligent. Could you do that? And the user say, oh, yeah, we could think a lot about that. And then, of course, in the end, what happens is that the tech guys say, see, we told you we made AGI just from a couple of algorithms. And it's ignoring the fact that the reason why it works is not because of the algorithms, but because of the data. And that data comes from a bunch of humans who are doing the kind of exploratory creative intelligence that four-year-olds do. I do presume that there are other angles on building AI systems that are more oriented towards making causal models of the world, even intervening, putting them in robots. I really don't know. Yeah, that's one of the things that people have thought about. But as I say, it's hard. So, you know, trying to do the Bayesian inference is hard because the search problem is hard. There's what's called reinforcement learning. And reinforcement learning, an old idea in psychology, is the idea and actually take actions and then see if the actions make you better off or not. So, you know, the mouse who runs through the maze and gets cheese sometimes, but gets a shock other times, right? And learns to go towards the cheese and away from the shock. So that's a technique that, for example, in the Go solution, reinforcement learning played a really important role in trying to solve that problem. So the chess agent is playing against itself over many, many trials to try and figure out what the best reinforcement learning is. But the problem with reinforcement learning is that it's too narrow. Like if you just end up on, you could, since all you're thinking about is am I better off or not, you're not going to be able to do the kind of exploration that you need to really figure out how the world works. And so the idea that I think is most promising and we've been working on is an idea that should be very familiar from science, which is an idea that you could do learning. But instead of trying to calculate whether you've got, you know, higher usefulness or utility or not, or whether you've got more cheese, what you're calculating is, did I get more information? Did I find out more about the world? Or did I find out more about the system when I did this action versus this other action? And the result is that you are going to do, again, to go back to the point we made before, you're going to do the things that will tell you something about how the world works, even if they don't make you any better off in the, in the short run. And there are ideas in an idea I really like and that we've been working on is the idea of a kind of intrinsic reward, like the kind of reward you get as a scientist when you, when you just are doing it because it's so cool when things work out the way that you want. So I think the solution to the problem means having a kind of reinforcement learning agent, but one where the reward isn't cheese or utility or winning the game. It's finding out something new, figuring out more about how the world works. And there's been a lot of interesting attempts, both in development and in AI to figure out how you could make that happen. What kind of signal would tell you that as a result of this action, you'd learn more. And one that we're working on now that I think is really interesting is something called empowerment. And the idea behind empowerment is that you get rewarded when you do something and it has a predictable effect on the world. So what you do is try to do as many things as you can, where varying the action that you take will vary what happens out there in the world. And when you do that, that's really exciting. That's really cool. That is something you're going to be likely to try again. But you also want as many different kinds of actions, as many different relationships like that as you can. So if you find one, after a while, you'll get bored and you'll try and find another one. And I think that's very closely related to the causal learning that I talked about before. So if you think about what you mentioned this, Sean, that causation is all about intervention, right? So really what you're learning with this empowerment reward is, I'm going to learn how to intervene. I'm going to learn how doing things out there in the world ends up having, ends up having effects. And we have a little bit of evidence that even tiny babies, you know, if you take literally a two or three month old, and you put a ribbon between their foot and a mobile, so that they can actually control what happens to the mobile, they'll sit there and try all sorts of different patterns of kicking to try and see what the consequences are going to be for the mobile. So they really are like little, and they'll smile and they'll giggle and they'll go back to doing it. It just seems to be an incredibly satisfying, an incredibly satisfying enterprise for them. And of course, they're doing the same thing with mom when they're, you know, doing all sorts of funny faces and seeing if mom gives funny faces back again. So I think that might be a really, really important part of the solution. And again, it speaks to science, because going back to what we were saying before about how systematic do your experiments have to be. One of the things that I've noticed is that the powers that be always say, well, you don't want to just have a fishing expedition, right? This grant is just a fishing expedition. But a lot of times what you actually end up doing is doing a fishing expedition. You, you try something and then kind of unexpectedly, it has this particular systematic result. And that's the, that's where the gold is rather than the causation that you already, that you already know about. And empowerment is kind of a way of saying, yeah, get, keep that fishing expedition going. Well, and there are better and worse ways to go fishing. Right, exactly. You know, we did have Carl Friston also on the podcast, and he has these ideas of the free energy principle and the Bayesian brain. And, and part of it, part of the sort of aspect that gives people pause is he seems to be saying that our brains try to minimize being surprised. And you might think that therefore you should just sit in a dark room and never do anything. But if I understand correctly, he was saying, no, actually we want to minimize the net surprise over our lives. And therefore we better explore around and do weird things now so we can anticipate what's coming. Yeah, that's exactly like the exploration exploitation trade-off that I was talking about. So it's, it's interesting if you think about something like empowerment or all of these kinds of intrinsic rewards, the failure cases are, you just sit there and do the same thing over and over again. And maybe those are human failure cases too. So what you need to do is to be able to want to have a coherent story about what's going on around you. You don't want to just be, you don't want to just be paying attention to random stuff that's happening. Yeah. Even though that might give you something that's new and surprising. But you also don't want to just do the same thing over and over again. And, and we've been looking at, you know, comparing for instance, what do children think when you give them a machine that just randomly does different things like our, our blinking detector, but a kind of random blinking detector versus one where there's a systematic relationship between what you do and what comes out, even if what comes out is surprising versus one that just does something obvious that you know about beforehand. And they really seem to like to play with the machine that, that is surprising, but surprising in a systematic way. And I think that's true about scientists too. The world has some structure and we do take advantage of that. And I think this is something that we haven't quite as philosophers, physicists, AI researchers, whatever, learned how to systematize perfectly. Yeah. I mean, one of the things that, that always strikes me, I mean, the reason why I started doing this work in the first place, back when I was a philosophy student, completely a philosophy student is if you think about, you know, going back to Plato and Aristotle, one of the deep philosophical questions is this question of knowledge. It's how we know that there's a world out there. It has structure. Not only does it have, it has, you know, forks and minds and all sorts of things that we can't immediately observe in it. And yet all that reaches us from that world is a bunch of disturbances of air at our eardrums and photons at our eyes. How do we ever at any point manage to reconstruct that world from that data? And I think going back to Plato and Aristotle, the two ways of trying to answer that question have been to say, well, okay, it just looks as if we're understanding that world from data. It's really there all along. So it's really some kind of innate, there's some kind of innate evolved structure that's responsible for this. And that's been one, that's Plato's approach. That's, that's one of the approaches. The other approach going back to Aristotle, which is the approach of the most recent version of AI, like the LLMs is, it just looks as if we're really understanding the structure. All we're doing is pulling out correlations between those photons and those disturbances of air. So all we're doing is just taking the data and pulling out correlations. And we think that that's telling us something about structure, but, but we have no particular reason to think that. And the great thing about development is that if you look at actual babies and children actually learning, they don't seem to fit either of those pictures. They seem to be able to learn really. And I think also, if you look at science, we seem to be able to learn really radically new things about the world, whether it's learning that I might like broccoli and you don't, or whether it's learning about, you know, quarks and, and leptons. And, and yet it doesn't look as if all we're doing is just pulling together the finding statistical correlations in the data. It looks as if we're genuinely developing theories that go beyond just the correlations in the data. And I don't think we have a good, you know, even though we've been doing this for a thousand years, we still don't have a good formal model, computational model, good understanding of how that's possible. And I think looking at the kids who are clearly doing it is, is a really good route to answering that philosophical question. And that's what I've spent my whole career doing. You know, sometimes looking at what actually happens in the world does help us understand it better. Alison Gopnik, thanks so much for being on the Mindscape podcast. Well, thanks so much for having me, Sean. A great conversation.