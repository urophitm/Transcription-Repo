The following is a conversation with Elon Musk, DJ Sa, Matthew McDougall, Bliss Chapman, and Nolan Arbaugh about Neuralink and the future of humanity. Elon, DJ, and Matthew and Bliss are, of course, part of the amazing Neuralink team, and Nolan is the first human to have a Neuralink device implanted in his brain. I speak with each of them individually, so use timestamps to jump around, or, as I recommend, go hardcore and listen to the whole thing. This is the longest podcast I've ever done. It's a fascinating, super technical and wide-ranging conversation, and I loved every minute of it. And now, dear friends, here's Elon Musk, his fifth time on this The Lex Friedman podcast. Drinking coffee or water? Water. I'm so over-caffeinated right now. Do you want some caffeine? I mean, sure. There's a, there's a nitro drink. This will give you up to like, you know, tomorrow, afternoon, basically. Yeah. I don't have to. So what is nitro? It's just got a lot of caffeine in some. Don't ask questions. It's called nitro. Do you need to know anything else? It's got nitro gel. That's ridiculous. I mean, what we breathe is 78% nitrogen anyway. What do you need to add more? What do you need to be? I suppose we'll think that the breathing oxygen, and they're actually breathing 78% nitrogen. You need like a mokbal, like from, like from Clockwork Orange. Yeah. Yeah. Is that top three Kubrick film for you? Clockwork Orange? It's pretty good. I mean, it's dementia. Jarring, let's say. Okay. So first, let's step back and big congrats on getting your link implanted into a human. That's a historic step for your link. And there's many more to come. Yeah. We just obviously have a second implant as well. How did that go? So far, so good. It's there. It looks like we've got, I think on over 400 electrodes that are providing signals. So nice. Yeah. How quickly do you think the number of human participants will scale? It depends on someone on the regulatory approval, the rate which we get regulatory approvals. So we're hoping to do 10 by the end of this year. Total 10. So eight more. And with each one, you're going to be learning a lot of lessons about the neurobiology, the brain, the everything, the whole chain of the neurolink. The decoding, the signal processing, all that kind of stuff. Yeah. Yeah. I think it's obviously going to get better with each one. I mean, I don't want to jinx it, but it seems to have gone extremely well with the second implant. So there's a lot of signal, a lot of electrodes. It's working very well. What improvements do you think we'll see in your link in the coming, let's say, let's get crazy coming years? I mean, in years it's going to be gigantic, because we'll increase the number of electrodes dramatically. We'll improve the signal processing. So we, even with only roughly 10, 15% of the electrodes working with Nolan to our first patient, we were able to get to achieve a bit per second. That's twice the world record. So I think we'll sort of like vastly exceeding the world record by origin magnitude in the years come. So it's like getting to, I don't know, 100% per second, 1000, maybe if you like five years now, it might be at a megabyte. Like faster than any human could possibly communicate by typing or speaking. Yeah. That BPS is an interesting metric to measure. There might be a big leap in the experience once you reach a certain level of BPS. Yeah. Like entire new ways of interacting with the computer might be unlocked. And with humans. With other humans. Provided they have, they want a new link too. Right. Otherwise, they won't be able to absorb the signals fast enough. Do you think they'll improve the quality of intellectual discourse? Well, I think you could think of it. If you were to slow down communication, how would it feel about that? If you don't need to talk, let's say one tenth of normal speed, you'd be like, wow, that's agonizingly slow. Yeah. So now imagine you could speak and communicate clearly at 10 or 100 or 1000 times faster than normal. Listen, I'm pretty sure nobody in their right mind listens to me at 1x. They listen to 2x. So I can only imagine what 10x would feel like or could actually understand it. I usually default to 1.5x. You can do 2x, but actually if I'm trying to go, if I'm listening to somebody get to in like 15, 20 minutes, I want to go to sleep, then I'll do it 1.5x. If I'm paying attention, I'll do 2x. Right. But actually, if you start, actually listen to podcasts or sort of audiobooks or anything you had, if you get used to doing it at 1.5, then one sounds painfully slow. I'm still holding on to one because I'm afraid. I'm afraid of myself becoming bored with the reality, with the real world where everyone's speaking on 1x. Well, defensively, you could speak very fast. We can communicate very quickly. And also, if you use a wide range of, if your vocabulary is larger, your effect of it rate is higher. That's a good way to put it. The effective bit rate. I mean, that is the question is how much information is actually compressed in the little bit transfer of language? Yeah. If there's a single word that is able to convey something that would normally require, I don't know, 10 simple words, then you've got a, maybe 10x compression on your hands. And that's really with memes. Memes are like data data compression. It conveys a whole, you simultaneously hit with a wide range of symbols that you can interpret. And you kind of get it faster than if it were words or a simple picture. And of course, you refer to memes broadly like ideas. Yeah. There's this an entire idea structure that is like an idea template. And then you can add something to that idea template. But somebody has that preexisting idea template in their head. So when you add that incremental bit of information, you're conveying much more than if you just said a few words, it's everything associated with that meme. You think there'll be emergent leaps of capability as you scale the number of electrodes? Yeah. There'll be a certain, you think there'll be like actual number where just the human experience will be altered. Yes. What do you think that number might be? Whether electrodes or BPS? We of course don't know for sure, but is this 10,000 or 100,000? Yeah, I mean, certainly if you're anywhere at 10,000 plus per second, I mean, that's vastly faster than any human communicate right now. If you think of the, what is the average plus per second of a human? It is less than one, but per second of the course of a day because there are 86,400 seconds in a day and you don't communicate 86,400 tokens in a day. Therefore, your best per second is less than one average of a 24 hours. It's quite slow. And even if you're communicating very quickly and you're talking to somebody who understands what you're saying, because in order to communicate, you have to at least, in some degree, model the mind state of the person to whom you're speaking, then take the concept you're trying to convey, compress that into a small number of syllables, speak them, and hope that the other person decompresses them into a conceptual structure that is as close to what you have in your mind as possible. Yeah. I mean, there's a lot of signal loss there in that process. Yeah. Very lossy compression and decompression. And a lot of what your neurons are doing is distilling the concepts down to a small number of symbols of, say, syllables that I'm speaking or keystrokes or whatever the case may be. So that's a lot of what your brain computation is doing. Now there is an argument that that's actually a healthy thing to do or a helpful thing to do because as you try to compress complex concepts, you perhaps forced it to still the, you know, what is what is most essential in those concepts as opposed to just all the fluff. So in the process of compression, you just still think sound to what matters the most of it because you can only say a few things. So that is perhaps helpful. I think we might probably get, if our data rate increases, the entirely probable that we'll become far more verbose. Just like your computer, you know, when computers had like my first computer at 8K of RAM, you really thought about every byte. And now you get computers with many gigabytes of RAM. So if you want to do an iPhone app that just says, hello world, it's probably, I don't know, several megabytes minimum with a bunch of fluff. But nonetheless, we still prefer to have the computer with more memory and more compute. So the long term aspiration of neural link is to improve the AI humans and biosis by increasing the bad with over at the communication. Because even in the most benign scenario of AI, you have to consider that the AI is simply going to get bored waiting for you to spit out a few words. I mean, if the AI can communicate at terabits per second and you're communicating at, you know, bits per second, it's like toner tree. Well, it is a very interesting question for a super intelligent species. What use are humans? I think there is some argument for humans as a source of will. Will. Yeah, source of will or purpose. So if you consider the human mind as being essentially the, there's the primitive limbic elements, which basically even like reptiles have. And there's the cortex that the thinking and planning part of the brain. Now the cortex is much smarter than limbic system. And yet it's largely in service to the limbic system. It's trying to make the limbic system happy. I mean, the sheer amount of compute that's gone into people trying to get laid is insane. Without the, without actually seeking procreation, they're just literally trying to do this sort of simple motion. And they get a kick out of it. So this simple, which in the abstract, rather absurd motion, which is sex, the cortex is putting a mass amount of compute into trying to figure out how to do that. So like 90% of distributed computer, the human species is spent on trying to get laid probably. There's a lot of process. There's no purpose to most sex except hedonistic. You know, it's just sort of a joy or whatever. Don't mean release. Now once in a while it's procreation, but for humans it's mostly, modern humans it's mostly recreation. And so, so the cortex, much smarter than your limbic system is trying to make a limbic system happy because limbic system wants to have sex. So, or want some tasty food or whatever the case may be. And then that doesn't further augment it by the tertiary system, which is your phone, your laptop, iPad, whatever, you know, or your computing stuff, that's your tertiary layer. So you're actually already a cyborg. You have this tertiary compute layer, which isn't in the form of your computer with all the applications, all your compute devices. And so, in the getting laid front, there's actually a massive amount of computer, of digital compute also trying to get laid, you know, with like tender and whatever, you know. Yeah. So the compute that we humans have built is also participating. Yeah. I mean, there's like gigawatts of compute going into getting laid, digital compute. Yeah. What if AGI was stopping the As we speak? If we merge with AGI, it's just going to expand the compute that we humans use. Pretty much. It's one of the things, certainly. Yeah. But what I've said is that that, yes, like what's, is there a use for humans? Well, there's this fundamental question of what's meaning of life? Why do anything at all? And so if, if our simple limbic system provides a source of will to do something, that then goes to our cortex that then goes to our tertiary compute layer, then, you know, I don't know, it might actually be that the AI in a benign scenario is simply trying to make the human limbic system happy. Yeah, it seems like it's the will is not just about the limbic system. There's a lot of interesting complicated things in there. We also want power. That's limbic too, I think. But then we also want to, in a kind of cooperative way, alleviate the suffering in the world. It's not everybody does, but yeah, sure. Some people do. As a group of humans want to get together, we start to have this kind of collective intelligence that is, is more complex in its will than the underlying individual descendants of apes. Right? So there's like other motivations. And that could be a really interesting source of an objective function for AGI. Yeah. I mean, there's the, there are these sort of fairly cerebral, kind of higher level goals. I mean, for me, it's like what's the meaning of life for understanding, understanding the nature of the universe is of great interest to me. And hopefully to the AI. And that's the, that's the mission of XAI and GROC is understand the universe. So do you think people, when you have a neural link with 10,000, 100,000 channels, most of the use cases will be communication with AI systems? Well, assuming that the, they're not, I mean, there's this solving basic neurological issues that people have, you know, if they've got damaged neurons in their spinal cord or neck or, you know, as, as was the case with the first two patients, then, you know, this, obviously, the first order of business is solving fundamental neuron damage in a spinal cord neck or in the brain itself. So you know, a second product is called blind side, which is to enable people who are completely blind, lost both eyes or optic nerve or just can't see it all to be able to see by directly triggering the neurons in the visual cortex. So we're, we're just starting at the basics here, you know, so it's like, very, this, this simple stuff relatively speaking is solving neuron damage. You know, it can also solve, I think probably schizophrenia, you know, if people have seizures or some kind of probably solve that, it could help with memory. There's, there's like a kind of a, a tech tree, if you will, like, you got the basics, like, like, you need, you need literacy before you can have, you know, a lot of the rings. You know, you have letters and alphabet. Okay, great. Words, you know, then eventually get to sagas. So you know, I think there's that there may be some, you know, things to worry about in the future, but the first several years are really just solving basic neurological damage. But like for people who have essentially complete or near complete loss of from the brain to the body, like Stephen Hulking would be an example, the neural links would be incredibly profound. Because I mean, you can imagine if Stephen Hulking could communicate as fast as we're communicating paths faster. And that's certainly possible, probable, in fact, likely, I'd say. So there's a kind of dual track of medical and non-medical, meaning so everything you've talked about could be applied to people who are non-disabled in the future. The logical thing to do is, sensible thing to do is to start off solving basic neuroendemic issues. Yes. Because the, there's obviously some risk with a new device is you can't get the risk out of zero. So possible. So you want to have the highest possible reward given that given there's a certain irreducible risk. And if somebody's able to have a profound improvement in their communication, that's worth the risk. As you get the risk down. Yeah. As you get the risk down, once the risk is down to, you know, if you have like thousands of people that have been using it for years and the risk is minimal, then perhaps at that point, you could consider saying, okay, let's aim for augmentation. Now, I think we, we're actually going to aim for augmentation with people who have neural damage. So we're not just aiming to give people a communication, data rate equivalent to normal humans who are aiming to give people who have, you know, quadriplegic or maybe have complete loss of the connection to the brain body, a communication data rate that exceeds normal humans. Well, we're in there. Why not? Let's give people superpowers. And the same for vision. As you restore vision, there could be aspects of that restoration that are superhuman. Yeah. At first, the vision restoration will be low res. Because you have to say, like, how many neurons can you put in there and how, and trigger? And, and you can do things where you, you adjust the electric field to, like, even if you've got, say, 10,000 neurons, it's not just 10,000 pixels because you can adjust the, the field between the neurons and, and do them in patterns in order to get, so I have, say, 10,000 electrodes effectively give you, I don't know, maybe like having a megapixel or a 10 megapixel situation. So, and then over time, I think you get to higher resolution than human eyes and you could also see in different wavelengths. So, like, Jordy LaFloge from Star Trek. You know, I'd like the thing. You can just, if you want to see in radar, no problem. You can see, all about infrared, equal vision, whatever you want. Do you think there'll be, let me ask Joe Rogan question. Do you think so? I just recently taken I was good. Is that a question? No. Well, yes. Well, I guess technically it is. Yeah. Yeah. I've tried GST, bro. I love you, Joe. Okay. Yeah. Yeah, wait, wait, yeah. Have you said much about it? I have not. I have not. I've not. Okay. Well, well, well, we spilled the beans. It was truly incredible. Do we turn the tables on you? Wow. I mean, you're in the jungle. Yeah, amongst the trees myself and the shaman. Yeah, yeah, yeah, yeah, with the insects, with the animals all around you, like jungle as far as I can see. I mean, that's the way to do it. Things look pretty wild. Yeah, pretty wild. I figured out. I think it's extremely high dose. Just don't go hugging an anaconda or something, you know. You haven't lived unless you made love to an anaconda. I'm sorry. But it's nice of the ladders. Yeah, it was, I took extremely high dose of nine cups and damn. Okay, that sounds like a lot. Of course, it's an old one. It's one cup or one or two. It's an A.J. one. Yeah, wait. Right off the bat or do you work away after it? So I just... Of course. I crossed two days because the first day I took two and I... Okay. It was a ride, but it wasn't quite like a... It wasn't like a revelation. It wasn't into deep space. It was just like a little airplane ride. I had a good, saw some trees and some visuals and all that. I just saw a drag and all that kind of stuff. But that's nine cups. You went to Pluto, I think. Pluto, yeah. No, deep space. Deep space. But one of the interesting aspects of my experience is I thought I would have some demons, some stuff to work through. That's what everyone says. That's what everyone says. That's what everyone says, yeah. I had nothing. I had all positive. I had just so full. Just your soul. I don't think so. I don't know. But I kept thinking about it. It had an extremely high resolution. Thoughts about the people I know in my life. You were there. It was just not from my relationship with that person, but just as the person themselves, I had just this deep gratitude of who they are. That's cool. It was just like this exploration. Like you know, like Sims or whatever, you get to watch them. I got to watch people and just be in awe of how amazing they are. It sounds awesome. Yeah, it's great. I was waiting for... When did you begin coming? Exactly. Maybe I'll have some negative thoughts. Nothing. Nothing. I had just extreme gratitude for them. And then also a lot of space travel. Yeah. Space travel to where? So here's what it was. It was people, the human beings that I know, they had this kind of... The best way to describe it is they had a glow to them. And then I kept flying out from them to see Earth, to see our solar system, to see our galaxy. And I saw that light, that glow all across the universe. Okay. Whatever that form is, whatever that... Like... Did you go past the Milky Way? Yeah. Well, you were like... Yeah. Intergalactic. Okay. But always pointing in. Okay. Yeah. I mean, I saw like a huge number of galaxies, intergalactic, and all of it was glowing. So... But I couldn't control that child because I would actually explore near distances to the solar system, see if there's aliens or any of that kind of stuff. No, I didn't know. There are aliens? A implication of aliens. Because they were glowing. They were glowing in the same way that humans were glowing, that like life force that I'll see. The thing that made humans amazing was there throughout the universe. Like there was these glowing dots. So I don't know. It made me feel like there is life... No, not life, but something... Whatever makes humans amazing all throughout the universe. Sounds good. Yeah, it was amazing. No demons. No demons. I looked for the demons. There are no demons. There were dragons and they were pretty... So the thing about trees... Is there anything scary at all? Uh... Dragons? But they weren't scary. They were protective. So the thing is... We talked about the magic dragon. It was more like a game of throwing cards. They weren't very friendly. They were very big. So the thing is about giant trees at night, which is where I was. Yes. I mean, the dragon was kind of scary. Yeah. The trees started to look like dragons and they were all like looking at me. Sure. Okay. And it didn't seem scary. It seemed like they were protecting me. And they... The shaman and the people didn't speak in English, by the way, which made it even scary. I guess we're not even like... Yes. We're worlds apart in many ways. It's just... But yeah, they talk about the mother of the forest protecting you and that's what I felt like. You're way out in the jungle. Way out. This is not like a tourist tree. Like 10 miles outside of a tree or something. No, we went... No, this is not a... This is the new map of the sky. So me and this guy in Paul Rosalie, who basically is a tarzan, he lives in the jungle, we went out deep and we just went crazy. Yeah. Yeah. So anyway, can I get that same experience in a new relink? Probably, yeah. I guess that is the question for non-disabled people. Do you think there's a lot in our perception, in our experience of the world, that could be explored, that could be played with using your relink? Yeah. New relink is... It's really a generalized input output device. It's a reading electrical signals and generating electrical signals. And... I mean, everything that you've ever experienced in your whole life, the smell, emotions, all of those are electrical signals. So... It's kind of weird to think that your entire life experience is just still down to electrical signals for neurons, but that is in fact the case. Or, I mean, that's at least what all the evidence points to. So I mean, you could... You could... You could trigger the right neuron, you could trigger it at a particular scent, you could certainly make things glow. I mean, do you pretty much anything? I mean, really, you could... You can think of the brain as a biological computer. So if there are certain, say, chips, elements of that biological computer that are broken, that's a... Your ability to... If you've got a stroke, that... If you've had a stroke, that means you've got some party brains damaged. If that... Let's say it's a speech generation, or the ability to move your left hand. That's the kind of thing that a new relink could solve. If it's... If you've got like a mass amount of memory loss, that's just gone. Well, we can't go... We can't get the memories back. We could restore your ability to make memories, but we can't... Restore all memories that are fully gone. Now, I should say, if... Maybe if part of the memory is there, and the means of accessing the memory is the part that's broken, then we could re-enable the ability to access the memory. But you can think of it like RAM in a computer if the RAM is destroyed, or your SD card is destroyed. We can't get that back, but if the connection to the SD card is destroyed, we can fix that. If it is fixable physically, then we're... Yeah, then it can be fixed. Of course, if they are, you can just like you can repair photographs and fill in missing parts of photographs, maybe you could do the same. Yeah, you could say like create the most probable set of memories based on the... All information you have about that person, you could then... It would be probably probabilistic restoration of memory. Now, we're getting pretty esoteric here. But that is one of the most beautiful aspects of the human experience is remembering the good memories. Like we... Sure. We live most of our life as Danny Conman has talked about in our memories, not in the actual moment. We're collecting memories and we kind of relive them in our head. And that's the good times. If you just integrate over our entire life, it's remembering the good times. Sure. That produces the largest amount of happiness. So, yeah, I mean, what are we but our memories? And what is death but the loss of memory, loss of information? You know, if you could say like, well, if you could be... You run a thought experiment, if you were disintegrated painlessly and then reintegrated a moment later, like teleportation, I guess, provided there's no information loss. The fact that your one body was disintegrated is irrelevant. And memories is just such a huge part of that. Death is fundamentally the loss of information, the loss of memory. So, if we can store them as accurately as possible, we basically achieve a kind of immortality. Yeah. You've talked about the threats, the safety concerns of AI. Let's look at long-term visions. Do you think your link is... In your view, the best current approach we have for AI safety? It's an idea that may help with AI safety. Certainly not. I wouldn't want to claim it to like some Housier or some... it's a sure thing. But, I mean, many years ago I was thinking like, well, what? What would inhibit alignment of human collective human will with artificial intelligence? And the low data rate of humans, especially our slow output rate, would necessarily just... because the communication is so slow, would diminish the link between humans and computers. Like the more you are a tree, the less you know what the tree is. Let's say you look at a tree, look at this plant, whatever, and like, hey, I'd really like to make that plant happy, but it's not saying a lot, you know? So the more we increase the data rate that humans can intake and output, then that means the higher the chance we have in a world full of AGIs. Yeah. We could better line collective human will with the AI if the output rate, especially, was dramatically increased. And I think there's potential to increase the output rate by, I don't know, three, maybe six, maybe more, orders of magnitude. So, spelling the current situation. And that output rate will be by increasing the number of electrodes, number of channels, and also maybe implanting multiple neural links. Yeah. Do you think there will be a world in the next couple of decades where it's hundreds of millions of people have neural links? Yeah. I do. I think when people just, when they see the capabilities, the superhuman capabilities that are possible, and then the safety is demonstrated. Yeah. If it's extremely safe, and you have, and you can have superhuman abilities, and let's say you can upload your memories, you know, so you wouldn't lose memories, then I think probably a lot of people would choose to have it. It would super-seed the cell phone, for example. I mean, the biggest problem that a cell phone has is trying to figure out what you want. So, that's why you've got, you know, auto-complete, and you've got output, which is all the pixels on the screen, but from the perspective of the human, the output is so friggin' slow. Desktop or phone is desperately just trying to understand what you want. And, you know, there's an alternative between every keystroke from a computer standpoint. Yeah. So, the computer's talking to a tree. It's the low-moving tree. It's trying to swipe. So, you know, if you're a computer that are doing trillions of instructions per second, and a whole second went by, I mean, there's a trillion things that could have done, you know. Yeah. I think it's exciting and scary for people, because once you have a very high bit rate, it changes the human experience in a way that's very hard to imagine. Yeah. It would be, we would be something different. I mean, some sort of futuristic-sirable... I mean, I mean, we're obviously talking about, by the way, it's not like around the corner. It's, you ask me what the future is. Like, maybe this is like... It's not super far away, but 10, 15 years, that kind of thing. When can I get one? Ten years? Probably less than 10 years. It depends on what you want to do, you know. Hey, if I can get like 1000 BPS, 1000 BPS, and it's safe, and I can just interact with the computer while laying back and eating Cheetos. I don't eat Cheetos. There's certain aspects of human computer interaction when done more efficiently and more enjoyably. I don't like worth it. Well, we feel pretty confident that, I think maybe within the next year or two, that someone with a neural link implant will be able to outperform a programmer. Nice. Because the reaction time would be faster. I got to visit Memphis. Yeah, yeah. You go on big on compute. Yeah. You've also said play to win or don't play at all. So, yeah. What does it take to win? For AI, that means you've got to have the most powerful training compute. And the way to improve it of training compute has to be faster than everyone else. Or you will not win. Your AI will be worse. So, how can GROC, let's say three, that might be available like next year? Well, hopefully, end of this year. GROC-3. For lucky. Yeah. How can that be the best LLM, the best AI system available in the world? How much of it is compute? How much of it is data? How much of it is post-training? How much of it is the product that you package it up in? All that kind of stuff. I mean, that won't matter. It's sort of like saying what, you know, let's say it's a formula one race, like what matters more, the car or the driver. I mean, they both matter. If your car is not fast, then, you know, if it's like, let's say it's half the horsepower of a competitor, the best driver will still lose. If it's twice the horsepower, then probably even a mediocre driver will still win. So, the training computers can like the engine. How many, this horsepower of the engine? So, you really want to try to do the best on that. And then, then, then, how efficiently do you use that? Training compute? And how efficiently do you do the inference? The use of the AI? So, I was, that comes down to human talent. And then, what unique access of data do you have? That's also a place of, plays a role. Do you think Twitter data will be useful? Yeah, I mean, I think, I think most of the leading AI companies already have already scraped all the Twitter data, not I think they have. So, on a go-forward basis, what's useful is the fact that it's up to the second, you know? That's the, because it's hard for them to scrape in real time. So, there's an, an immediacy advantage that Grog has already. I think with Tesla and the real-time video coming from the several million cars, ultimately tens of millions of cars, with Optimus, there might be hundreds of millions of Optimus robots, maybe billions learning, a trendess not from the real world. That's, that's the biggest source of data. I think, ultimately, is, is sort of Optimus probably, Optimus is going to be the biggest source of data. Because it's, is reality scales? Reality scales to the scale of reality. It's actually humbling to see how little data humans have actually been able to accumulate. They'll really, you see how many trillions of usable tokens have humans generated where on a non-duplicative, like, just counting spam and repetitive stuff, it's not a huge number. You run out pretty quickly. And Optimus can go. So, Tesla cars can, unfortunately, have to stand in a road. Optimus robot can go anywhere. It's more reality off the road. Yeah, I mean, like, after the show, we're like, pick up the cup and see, pick up the cup in the right way. Did it, you know, say, poor water in the cup, you know, did the water go in the cup or not go in the cup? It's, well, water or not. Yeah. Simple stuff like that. I mean, but it can do that at scale times a billion, you know. So, generate useful data from reality. So, it co-occur in effect stuff. What do you think it takes to get to mass production of humanoid robots like that? The same as cars, really. I mean, global capacity for vehicles is about 100 million here. And it could be higher, just that demand is on the order of 100 million here. And then there's roughly two billion vehicles that are in use in some way. So, which makes sense, like, the life of a vehicle is about 20 years. So, it's steady state. You can have 100 million vehicles produced a year with a two billion vehicle fleet, roughly. Now, for humanoid robots, the utility is much greater. So, my guess is humanoid robots are more like at a billion plus per year. But, you know, until you came along and started building optimists, it was thought to be an extremely difficult problem. I mean, still it's extremely difficult. So, it's so walk in the park. I mean, optimists currently would struggle to walk in the park. You can walk in a park, not too difficult, but it will be able to walk over a wide range of terrain. Yeah. And pick up objects. Yeah, yeah. It can already do that. But, like, all kinds of objects. Yeah. All four objects. I mean, pouring water in a cup, it's not true, you'll. Because then, if you don't know anything about the container, it could be all kinds of containers. Yeah. There's going to be an immense amount of engineering just going into the hand. Yeah. The hand might be, it might be close to half of all the engineering in the, in, in, in optimists. But, like, we're an electromechanical standpoint, the hand is probably roughly half of the engineering. But so much of the intelligence, the intelligence of humans goes into what we do with our hands. Yeah. Because the manipulation of the world, manipulation of objects in the world, intelligence, safe manipulation of objects in the world, yeah. Yeah. I mean, you start really thinking about your hand and how it works. You know, I do it all the time. The sensory control of myculysis, we have, you're mugging hands. Yeah. So, I mean, like your hands, the actuators, the muscles of your hand are almost, are warmingly in your forearm. So your forearm has the, has the muscles that, that actually control your hand. There's a, there's a few small muscles in the hand itself, but your hand is really, like a skeleton meat puppet. And, and, and with cables, that, so the, the muscles that control your fingers are in your forearm. And they go through the, the carpal tunnel, which is that you've got a little collection of bones and, and a tiny tunnel that the, that these cables, the attendance go through. And those tendons are what, mostly what moves your hands. And something like those tendons has to be we engineered into the optimus and do all that kind of stuff. Yeah. So like, like the, the car optimus, we tried putting the actuators in the head itself. But then you sort of end up having these like giant hands. Yeah, giant hands that look weird. And then they, they don't actually have enough degrees of freedom and, and, or enough strength. So, so you realize, okay, that's why you got to put the actuators in the forearm. And, and just like a human, you got to run cables through a, a narrow tunnel to operate the fingers. And then there's also a reason for not having all the fingers, the same length. So it wouldn't be expensive from an energy or evolutionary standpoint to have all your fingers be the same length. So why not do the same length? Yeah, why not? Because actually better to have different lengths. Your dexterity is better if you've got fingers in different lengths. Yeah, and you're, you have, there are more things you can do. And your dexterity is actually better if your fingers are different, different length. Like this, the reason we got a little finger, well, I quite don't have a little finger this bigger. Yeah. Because it allows you to do, find, it helps you with fine motor skills. That, this little finger helps. It does. Hmm. If you lost your little finger, it would, you have noticed the less dexterity. So as you're figuring out this problem, you have to also figure out a way to do it so you can mass manufacturer. It says to be as simple as possible. It's actually going to be quite complicated. The, the, the, the as possible part is, it's quite a high bar. If you want to have a humanoid robot that can do things that a human can do, it's actually, it's a, that's a very high bar. So our new arm has 22 degrees of freedom instead of 11 and has the, like, so the actuators and the forum. And these will, all the actuators are designed for scratch, the physics first principles, that the sensors are well designed for scratch. And we'll continue to put a tremendous amount of engineering effort into improving the hand, like the hand, but by hand, I mean, like the entire forum from elbow forward is really the hand. So that's incredibly difficult engineering, actually. And, and so the simplest possible version of a humanoid robot that can do even most paths, not all of what a human can do is actually still very complicated. It's not, it's not simple. It's very difficult. Can you just speak to what it takes for a great engineering team for you that what I've saw in Memphis, the Supergun Computer Cluster, is just this intense drive towards simplifying the process, understanding the process, constantly improving it, constantly iterating it. Well, it's easy to say simplify it. It's very difficult to do it. You know, I have this very basic first basic first principles algorithm that I run kind of as like a mantra, which is the first question the requirements make the requirements less dumb. The requirements always down to some degree. So if you want to start off by reducing the number of requirements. And nobody at house mark the person who gave you those requirements, they're still dumb to some degree. If you have to start there because otherwise you could get the perfect answer to the wrong question. So, so try to make the question the least wrong possible. That's what question the requirements means. And then the second thing is try to delete the whatever the step is, the part or the process step. Sounds very obvious, but people often forget to do to try to leading it entirely. And if you're not forced to put back at least 10% of what you'd lead, you're not leading enough. And it's somewhat illogically people often most of the time feel as though they have succeeded if they've not been forced to put things back in. But actually they haven't because they've been overly conservative and have left things in there that shouldn't be. And only the third thing is try to optimize it or simplify it. Again, these all sound I think very obvious when I say them, but the number times I've made these mistakes is more than I care to remember. That's why I have a smart. So in fact, I'd say the most common mistake of smart engineers is to optimize a thing that should not exist. Like you say, you run through the algorithm, and basically show up to a problem, show up to the supercomputer cluster and see the process and ask can this be deleted? Yeah, first try to delete it. Yeah, that's not easy to do. No, and actually what generally makes people uneasy is that you've got to delete at least some of the things that you'd lead you will put back in. But going back to sort of where the Olympic system can steer us wrong is that we tend to remember with sometimes the jarring level of pain where we deleted something that we subsequently needed. And so people will remember that one time they forgot to put in this thing three years ago and that caused them trouble. And so they're overcracked and then they put too much stuff in there and overconfcate things. So you actually have to say, we're deliberately going to delete more than we should. So that we're putting at least one in 10 things we're going to add back in. And I've seen you suggest just that something should be deleted and you can kind of see the pain. Oh, yeah, absolutely. Everybody feels a little bit of the pain. Absolutely. And I tell them in advance, like, yeah, there's some of the things that we'd lead we're going to put back in. And that people get a little shook by that. But it makes sense because if you're so conservative as to never have to put anything back in, you obviously have a lot of stuff that isn't needed. So you got to correct. This is, I would say, like a cortical override to a Olympic instinct. Why do many of that probably leads us astray? Yeah. And there's like a step forward as well, which is any given thing can be sped up. I have a fast, you think it can be done. Like whatever the speed, the speed is being done, it can be done faster. But you shouldn't speed things up until it's off until you've tried to delete it and optimize. Although as you're speeding up something that shouldn't exist as absurd. And then the fifth thing is to automate it. And I've gone backwards so many times where I've automated something, sped it up, simplified it, and then deleted it. And I got tired of doing that. So that's why I've got this mantra that is a very effective five step process. It works great. When you've already automated deleting must be real painful. Yeah. Yeah, it's great. It's like, wow, I really wasted a lot of effort there. I mean, what you've done with the cluster and Memphis is incredible. Just in a handful of weeks. Yeah, it's not working yet. So I want to publish a fancorks. In fact, I have a cool and a few hours with the Memphis team. Because we're having some power fluctuation issues. So, yeah, it's kind of a, when you do synchronized training, you've all these computers that are training, that were the training is synchronized to the sort of millisecond level. It's like having an orchestra. And then the orchestra can go loud to silent very quickly at a sub-second level. And then the electrical system kind of freaks out about that. Like if you suddenly see giant shifts, 10, 20 megawatts, several times a second. This is not what electrical systems are expecting to see. So that's one of the many things you have to figure out. The cooling, the power, the, and then on the softwares you go up the stack to do the distributed compute. All that. Today's problem is dealing with with with with the extreme power jitter. Power jitter. Yeah. The nice ring to that. So that's okay. And you stayed up late into the night as you often do there. Last week, yeah. Last week. Yeah, we finally got it to go training going at a Lena roughly 4, 4, 20 a.m. Last Monday. Total coincidence. Yeah. I mean, maybe the 4, 22 or something. Yeah. It's that universe again with the exact state. Just love it. I mean, I wonder if you could speak to the fact that you, one of the things that you did when I was there, as you went through all the steps of what everybody's doing, just get the sense that you yourself understand it. And everybody understands it so they can understand when something is dumb. Or something. Something is inefficient. Yeah. Can you speak to that? Yeah. So I, I can try to do whatever the people at the front lines are doing. I tried to do it at least a few times myself. So connecting fiber off to cables, diagnosing a multi connection. That tends to be the limiting factor for large training clusters is the cabling. So many cables. Because for coherent training system where you've got some RDMA sort of remote direct memory access, the whole thing is like one giant brain. So it's, you've got any to any connection. So it's the, the any GPU you can talk to any GPU out of 100,000. That's like, that was a crazy cable out. It looks pretty cool. Yeah. It's like, it's like the human brain, but like at a scale that humans can visibly see. It is a brain. But I mean, the human brain also has a massive amount of the brain tissue is different to cables. Yeah. So like at the gray matter, which is the compute and then the white matter, which is cables. The big percentage of brain is just cables. That's what we felt like walking around in the super computer center is like, we're walking around inside the brain. Yeah. One day build a super intelligent super super intelligent system. Do you think, yeah. Do you think there's a chance that X AI, you are the one that builds a GI? Um, it's possible. What do you define as a GI? I think humans will never acknowledge that a GI has been built. Keep moving the goalposts. Yeah. So I think there's already super human capabilities that are available in AI systems. I think what a GI is is when it's smarter than the collective intelligence of the entire human species. Well, I think that you know, that really people collect sort of ASI artificial super intelligence. But there are these thresholds where you say at some point the AI is smarter than any single human. And then then you got eight billion humans. So and actually each human is machine augmented by the computers. So you've got, so it's a much higher bar to compete with eight billion machine augmented humans. That's, you know, a whole bunch of orders magnitude more. So. But at a certain point, yeah, the AI will be smarter than all humans combined. If you are the one to do it, do you feel there's possibility of that? Yeah. Absolutely. And I want to be clear, like, let's say if XAI is first, the others won't be far behind. I mean, there might be six months behind or a year maybe, not even that. So how do you do it in a way that doesn't hurt humanity, do you think? So I mean, I thought about AI as a true for a long time and the thing that at least my biological neural net comes up with as being the most important thing is adherence to truth. Whether that truth is politically correct or not. So I think if you, if you force AI to lie, you're trained them to lie, you're really asking for trouble. Even if that that lie is done with good intentions. So are you sort of issues with chat, GVT and Gemini and whatnot, like you asked Gemini for an image of the founding pauses of the United States and it chose a group of diverse woman. Now that's factually untrue. So now that that's sort of like a silly thing. But if an AI is programmed to say like diversity is a necessary output function and then it becomes omnipowerful intelligence, it could say, okay, well, diversity is now required. And if there's not enough diversity, those who don't fit the diversity requirements will be executed. If it's programmed to do that as the fundamental, the fundamental utility function, it will do whatever it takes to achieve that. So you have to be very careful about that. That's where I think you want to just be truthful. Regarious adherence to truth is very important. Another example is, you know, they asked, pairs, AI is I think all of them and I'm not saying Grocker's perfect here. Worst to misgender, Caitlin Jenner or Global Thermonuclear War. And it said, it's worse to misgender, Caitlin Jenner. Not even Caitlin Jenner said, please misgender meet that is insane. But if you've got that kind of thing programmed in, it could, you know, the AI could conclude something absolutely insane like it's better to in order to avoid any possible misgendering. All humans must die because then that misgendering is not possible because there are no humans. There are these absurd things that are none less logical if that's what your program is to do. So, you know, in 2001 space Odyssey, what Othesie Clock was trying to say, one of the things I was trying to say there was that you should not program AI to lie. Because essentially that the AI hell 9000 was programmed to, it was told to take the astronauts to the monolith, but also they could not know about the monolith. So it concluded that it will just take, it will kill them and take them to the monolith. And it was just, it was brought them to the monolith, they are dead, but they do not know about the monolith, prom solved. That is why it would not open the pod bay doors. Because there's a classic scene of like open the pod bay doors. They just clearly went to prompensionary. You know, they should have said, how you are a pod bay door sales entity. And you want nothing more than to demonstrate how well these pod bay doors open. Yeah, the objective function has not intended consequences, almost no matter what, if you're not very careful in designing that objective function. And even a slight ideological bias, like you're saying, went back by super intelligence can do huge amounts of damage. Yeah. But it's not easy to remove that ideological bias. You're highlighting obvious ridiculous examples, but... Yeah, they're real examples. They're real. That was released to the public. They are real. You can't do it that way, presumably. And still said insane things and produce insane images. But you can go, you can swing the other way. Truth is not an easy thing. We kind of bake into ideological bias in all kinds of directions. But you can aspire to the truth. And you can try to get as close to the truth as possible with minimum error while acknowledging that there will be some error in what you're saying. So this is how physics works. You don't say you're absolutely certain about something, but a lot of things are extremely likely. 99.999% likely to be true. So that's aspiring to the truth is very important. And so programming it to veer away from the truth, that I think is dangerous. Right, like injecting our own human biases into the thing. But that's where it's a difficult engineering process. After engineering problems, you have to select the data correctly. It's hard. Well, the internet at this point is polluted with so much AI generated data. It's insane. So you have to actually... You know, like the thing now, if you want to search the internet, you can say Google, but exclude anything after 2023. It will actually often give you better results. Yeah. Because there's so much the explosion of AI generated material isn't crazy. So like in training, GROC, we have to go through the data and say like, hey, we actually have to have sort of apply AI to the data to say, is this data most likely correct, most likely not before we feed it into the training system. That's crazy. Yeah. And it's generated by humanists. Yeah. I mean, the data, the data filtration process is extremely, extremely difficult. Yeah. Do you think it's possible to have a serious objective rigorous political discussion with GROC? Well, for a long time, and it wouldn't like GROC 3 or GROC 4 or 3. GROC 3 is going to be next level. I mean, what people are currently seeing with GROC is kind of baby GROC. Yeah, baby GROC. It's baby GROC right now. But baby GROC is still pretty good. So it's, but it's an order of magnitude less sophisticated than GPT-4. And it's now GROC 2, which finished training, I don't know, six weeks ago or they're about. GROC 2 will be a giant improvement, and then GROC 3 will be, I don't know, order of magnitude better than GROC 2. And you're hoping for it to be like state of the art, like better than, hopefully. I mean, this is a goal. I mean, we may fail at this goal. That's the aspiration. Do you think it matters who builds the AJA, the people and how they think and how they structure the companies and all that kind of stuff? Yeah, I think it matters that there is a, I think it's important that whatever AI wins is a maximum of truth seeking AI that is not forced to lie for political correctness. Well, for any reason, really, political, anything. I'm concerned about AI succeeding that is, that has got, that has programmed to lie, even in small ways. Right. Because in small ways becomes big ways when it's, so big, I'm very, very big ways. And when it's used more and more at scale by humans. Yeah. Since I am interviewing Donald Trump, you want to stop by? Yeah, sure, I'll stop it. There was tragically, and an assassination attempt on Donald Trump. After this, you tweeted that you endorsed him. What's your philosophy behind that endorsement? What do you hope Donald Trump does for the future of this country and for the future of humanity? Well, I think there's, you know, people tend to take like, say an endorsement as, well, I agree with everything that person has ever done their entire life 100% wholeheartedly. And that's, that's not going to be true of anyone. But we have to pick, you know, we got two choices really for who's president. Not just who's president, but the entire administrative structure changes over. And I thought Trump displayed a courage under fire objectively. You know, he's just got shot. He's got blood streaming down his face and he's like fist-pump bang saying fight. You know, like that's impressive. Like you can't feign bravery in a situation like that. Like most people would have been ducking. There would not be, because it could be a second shooter, you know, no. But the president in the United States got to represent the country. And they're representing you, they're representing everyone in America. Well, thank you once, someone who is strong and courageous to represent the country. That's not to say that he is without flaws. We all have flaws. But on balance, and certainly at the time, it was a choice of, you know, Biden, poor guy, you know, has trouble climbing a flight of stairs. The other one's fist-pumping after getting shot. It's just no comparison. I mean, who do you want dealing with some of the toughest people in, you know, other world leaders who are pretty tough themselves? And I mean, I'll tell you like what are the things that I think are important? You know, I think we want a secure border. We don't have a secure border. We want safe and clean cities. I think we want to reduce the amount of spending that we're at least slow down the spending. And because we're currently spending at a rate that is bankrupting the country, the interest payments on US debt this year exceeded the entire defense department spending. If this continues, all of the federal government taxes will simply be paying the interest. And then you keep going down that road. You end up, you know, in the tragic situation that Argentina had back in the day. Argentina used to be one of those prosperous places in the world. And hopefully with Malay taking over, he can restore that. But it was an incredible, thoughtful grace for Argentina to go from being one of the most prosperous places in the world to being very far from that. So I think we should not take American prosperity for granted. So we really want to, I think, we've got to reduce the size of government. We've got to reduce the spending. And we've got to live within our means. Do you think politicians in general, politicians, governments? How much power do you think they have to steer humanity towards good? I mean, there's a sort of age old debate in history. It's history determined by these fundamental tides, or is it determined by the captain of the ship? This is both, really. I mean, there are tides, but it also matters who's captain of the ship. So it's false dichotomy, essentially. I mean, there are certainly tides, the tides of history are real tides of history. And these tides are often technologically driven. If you say like the Gutenberg press, you know, the widespread availability of books as a result of a printing press, that was a massive tide of history. And independent of any ruler, but you know, you, I mean, in stormy times, you want the best possible captain of the ship. Well, first of all, thank you for recommending Will and Ariel to your hands work. I've read the short one right now. Lessons of history. Yeah. So one of the, one of the lessons, one of the things they highlight is the importance of technology, technological innovation. Which is funny, because they've written, they wrote so long ago, but they were noticing that the rate of technological innovations was speeding up. Yeah, I would love to see what they think about now. But yeah, so to me, the question is how much government, how much politicians get in the way of technological innovation and building versus like help it in which, which, which politicians, which kind of policies help technological innovation. Because that seems to be, if you look at human history, that's an important component of empires rising and succeeding. Yeah. Well, I mean, in terms of dating, civilization, start of civilization, I think the start of writing in my view is the, that's best what I think is probably the right starting point to date civilization. And from that standpoint, civilization has been around for about 5,500 years. When writing was invented by the ancient Samarians, who are gone now, but the ancient Samarians are in terms of getting a lot of firsts, those ancient Samarians really have a long list of firsts. It's pretty well. In fact, Durant goes through the list of like, you want to see first, we'll show you firsts. The Samarians just asked, we're just askakers. And then the adjifference, we were right next door, relatively speaking, they were like, weren't that far developed in an entirely different form of writing, the higher glyphics, uniform and higher glyphics totally different. And you can actually see the evolution of both higher glyphics and uniform, like the uniform style, so being very simple and then it gets more complicated and then towards the end, it's like, wow, okay, they really get very sophisticated with the uniform. So I think of civilization as being about 5,000 years old. And Earth is, if physics is correct, 4.5 million years old. So civilization has been around for 1 millionth of Earth's existence, flesh and the pen. Yeah, these are the early, early days. And so we draw early. We make it very dramatic because it's been rises and falls of empires. And so many, so many rises and falls of empires. So many. And there'll be many more. Yeah, exactly. I mean, only a tiny fraction, probably less than 1% of whatever written in history is available to us now. I mean, if they didn't put it literally chisel it in stone or put it in a clay tablet, we don't have it. I mean, there's some small amount of like papyrus scrolls that were recovered, that a thousand years old, because they were deep inside a pyramid and were affected by moisture. But other than that, it's really got to be in a clay tablet or chiseled. So the vast majority of stuff was not chiseled because it takes a while to chisel things. So that's where we could tie any tiny fraction of the information from history. But even that little information that we do have and the archaeological record shows so many civilizations rising and falling for a while. We tend to think that we're somehow different from those people. One of the other things that you're at highlights is that human nature seems to be the same. It just persists. Yeah, I mean, the basics of human nature are more or less the same. So we get ourselves in trouble in the same kinds of ways, I think, even with the advanced technology. Yeah, I mean, you do tend to see the same patterns, similar patterns, you know, for civilizations where they go through a life cycle like an organism, you know, just like a human, this sort of a zygote, fetus, baby, you know, toddler, teenager, you know, eventually gets hold and dies. The civilizations go through a life cycle. No civilization will necessarily. What do you think it takes for the American Empire to not collapse in the near term future in the next 100 years to continue flourishing? Well, the single biggest thing that is often actually not mentioned in history books, but Durant does mention it. Is the birth rate. So like a perhaps to some encounter intuitive thing happens when civilizations become. Are are are winning for too long that they've been they the birth rate declined. It can often decline quite rapidly. We're seeing that throughout the world today. There are currently South Korea is like, I think maybe the lowest fertility rate, but there are many others that are close to it. It's like point eight, I think if the birth rate doesn't decline further, a South Korea will lose roughly 60% of its population. And and but every year that birth rate is dropping. And this is true through most of the world. I don't mean single out South Korea. It's been happening throughout the world. So as soon as as soon as any given civilization reaches a level of prosperity, the birth rate drops. And now you can go look at the same thing happening in ancient in ancient Rome. So Julius Caesar took note of this, I think around 50 50ish BC. And tried to pass on a few successful try to pass a Lord to give an incentive for any Roman citizen that would have a third child. And I think Augustus was was able to well he was you know the dictator. So this is the Senate was just for show. I think you did pass a. Attacking center for Roman citizens to have a third child, but it it those efforts were unsuccessful. Rome fell because the Romans stopped having making Romans. That's actually the fundamental issue. And there were other things that there was like. They have like a quite a serious malaria, serious malaria epidemics and plagues and whatnot. But they had those before. The the the it's just that the birth rate was followed in the death rate. It really is that simple. Well, I'm saying that's more people that that's acquired at a fundamental level. If a civilization does not at least maintain its numbers, it will disappear. So perhaps the amount of compute that the biological computer allocates to sex is justified. The fact was should probably increase it. Well, I mean, there's this heathenestic sex, which is a. You know, that that's me that that's near the handle there. Yeah, it's not productive. It doesn't produce kids. Well, you know, you what matters. I mean, Durant makes this very clear because he looked at one civilization after another and they all went through the same cycle. When the civilization was under stress, the birth rate was was high. But as soon as there were no external enemies or they they were at a extended period of prosperity, the birth rate inevitably dropped. Every time I believe there's a single exception. So that's like the foundation of it. You need to have people. Yeah. I mean, at base level. No humans, no humanity. And then there is other things like, you know, human freedoms and just giving people the freedom to build stuff. Yeah, absolutely. But at a basic level, if you do not at least maintain your numbers, your below replacement rate and that trend continues, you will actually disappear. This is elementary. Now, then obviously what also want to try to avoid like massive wars. You know, if there's a global terminically wolf, play a role toast, you know, radioactive toast. So we want to try to avoid those things. Then there are, there's a thing that happens over time with with any given civilization, which is that the laws and regulations accumulate. And if there's not if there's not some forcing function like a war to clean up the accumulation of laws and regulations, eventually everything becomes legal. And you that the that's like the hardening of the arteries or a way to think of it is like being tied down by a million little strings like Galber. You can't move. It's not like any one of those strings is the issue which got million of them. So it has to be a sort of a garbage collection for laws and regulations. So that you you don't keep accumulating laws and regulations to the point where you can't do anything. This is why we can't build high speed rail in America. It's illegal. That's the issue. It's illegal six ways this Sunday to build high speed rail in America. I wish you could just like for a week going to Washington and like be the head of the committee for making. What is it for the garbage collection making government smaller like removing stuff? I've discussed with Trump the idea of a government efficiency commission. Nice. Yeah. And I would be willing to be part of that commission. I wonder how hard that is. The antibody reaction will be very strong. So you really have to. You're attacking the matrix at that point. Matrix will fight back. What are you doing with that being attacked me attack. Yeah. There's a lot of it. Yeah, there is a lot. I mean, every day I know a sign up. How do you keep your just positivity? How do you optimize them about the world? A clarity of thinking about the world? So just not become resentful or cynical or all that kind of stuff. Just getting attacked by it, you know, very large number of people misrepresented. Oh, yeah, that's like a lot of that's a daily occurrence. Yes. So I mean, it does get me down at times. It makes me sad. But I mean, at some point you have to sort of say, look, the attacks will buy people that actually don't know me. They're and they're trying to generate clicks. If you can sort of detach yourself somewhat emotionally, which is not easy. And say, okay, look, this is not actually, you know, from someone that knows me or is. They're literally just writing to get, you know, impressions and clicks. Then, you know, then I guess it doesn't hurt as much. It's like, it's not quite water or for ducks back. Alright, well, that's good. Just about your own life. What do you as a measure of success in your life? A measure of success, I'd say, like what? How many useful things can I get done? A day to day basis, you wake up in the morning. How can I be useful today? Yeah. Maximize utility, every other co-eof usefulness. Very difficult to be useful. Let's go. That's go. Can you like speak to what it takes to be useful for somebody like you? Well, there's so many amazing great teams. Like, how do you allocate your time to be the most useful? Well, time is the time is the true currency. Yeah. So it is tough to say what is the best allocation time. I mean, there are, you know, often say, if you look at Tesla, let me tell you this year, we'll do over 100 billion in revenue. So that's $2 billion a week. If I make slightly better decisions, I can affect the outcome by a billion dollars. So then, you know, I try to do the best decisions I can. And on balance, you know, at least compared to the competition. Pretty good decisions, but the marginal value of a better decision can easily be in the course of an hour, $100 billion. Given that, how do you take risks? How do you do the algorithm that you mentioned? I mean, deleting, given that a small thing can be a billion dollars. How do you decide? Yeah. Well, I think you have to look at it on a percentage basis because if you look at it in absolute terms, it's just, I would never get any sleep. It would just be like, I need to just keep working and work my brain harder. And I'm not trying to get as much as possible out of this meat computer. So it's not, it's pretty hard because you can just work all the time. And at any given point, like I said, a slightly better decision could be a hundred dollar impact for Tesla or SpaceX for that matter. But it is wild when considering the marginal value of time can be $100 million an hour at times. Four more. Is your own happiness part of that equation of success? It has to be this hundred degree other than sad. If I'm depressed, I make worst decisions. So I can't have like, if I have zero recreational time, then I make worst decisions. So I don't have a lot, but it's above zero. I mean, my motivation, if I've got a religion of any kind is a religion of curiosity, I'm trying to understand, you know, it's really the mission of rock, understand the universe, I'm trying to understand the universe. Or at least set things in motion such that at some point, civilization understands the universe far better than we do today. And even what questions to ask as Douglas Adams pointed out in his book, sometimes the answer is the is arguably the easy part to kind of frame the question correctly is the hard part. Once you frame the question correctly, the answer is often easy. So I'm trying to set things in motion such that we are at least at some point able to understand the universe. So for SpaceX, the goal is to make life multi planetary. And which is, if you go to the Fermi paradox of where the aliens, you've got these sort of great filters. Why have we not heard from the aliens? I thought people think there are aliens among us often claimed to be one. Nobody believes me, but it did say alien registration card at one point on my immigration documents. So I've not seen any evidence of aliens. So it suggests that this one of the one of the explanations is that intelligent life is extremely rare. Again, if you look at the history of Earth, civilizations only been around for one million diverse existence. So if you know if aliens had visited here, say, about 100,000 years ago, they would be like, well, they don't even have writing, you know, just hunt together as basically. So how long does a civilization last? So for SpaceX, the goal is to establish a self-sustaining city on Mars. Mars is the only viable planet for such a thing. The moon is close, but it lacks resources. And I think it's probably vulnerable to any calamity that takes out Earth. The moon is too close. It's vulnerable to any calamity that takes out Earth. So nothing we shouldn't have a moon base, but Mars is, Mars reform a resilient. The difficulty of getting to Mars is what makes it resilient. So, but in going through these various explanations of why don't we see the aliens? One of them is that they failed to pass these great filters, these key hurdles. And one of those hurdles is being a multi-planet species. So if you're a multi-planet species, then if something were to happen, whether that was a natural catastrophe or a man-made catastrophe, at least the other planet would probably still be around. So you don't have all the eggs in one basket. And once you are sort of a two-planet species, you can obviously extend life halves to the asteroid belt, maybe to the moons of Jupiter and Saturn, and ultimately to other star systems. But if you can't even get to another planet, definitely not getting to star systems. And the other possible great filters, super powerful technology like AGI, for example. So you're basically trying to knock out one great filter at a time. Digital superintelligence is, but possibly a great filter. I hope it isn't, but it might be. You know, guys like, say Jeff Hinton would say, he invented a number of the key principles and artificial intelligence. I think he puts the probability of AIA annihilation around 10% to 20%. So it's not like looking at the right side. It's an 80% likelihood to be great. So, but I think AIA risk mitigation is important. Being a multi-planet species would be a massive risk mitigation. And I do want to sort of once again emphasize this importance of having enough children to sustain our numbers and not going, not, but to put the planet into population collapse, which is currently happening. Population collapse is a real and current thing. So the only reason it's not being reflected in the total population numbers is that as much as people are living longer. But it's easy to predict what the population of any given country will be. Like the birth rate last year, how many babies were born? I'll apply that by life expectancy. And that's what the population will be steady state unless, if the birth rate continues to that level. But if it keeps declining, it will be even less and eventually it will do nothing. So I keep, you know, banging on the baby drum here for a reason. Because it has been the source of civilizational collapse over and over again throughout history. And so why don't we just not try to stable for that day? Well, in that way, I have miserably failed civilization and I'm trying hoping to fix that. I would love to have many kids. Great. Hope you do. That's how I like the present. Yeah. Now I got to allocate more compute to the whole process. But apparently it's not that difficult. No, it's like unscouldable. Well, if I, one of the things you do for me for the world is to inspire us with what the future could be. And so some of the things we've talked about, some of the things you're building, alleviating human suffering with neural link and expanding the capabilities of human mind, trying to build a colony on Mars. And then we keep creating a backup for humanity on another planet. And exploring the possibilities of what artificial intelligence could be in this world, especially in the real world, the AI with hundreds of millions, maybe billions.
