 Why do things feel like stuff? Why do we engage in the behaviors we behave in? You know, not why in the normally scientific, you know, reductionist sense, what are the mechanisms, once we hold the behavior fixed? But instead, if we don't hold the behavior fixed, what are you or any other organism going to choose and why that choice instead of something else? There's sort of this problem where in Neuro, we are often doing paradigms or tasks that from a pure AI point of view might be considered almost trivial. But from a biological plausibility point of view, that often makes them hard again. I had actually been prepared for the concept that you might walk arrogantly into experimentation with some grand theory and think this is going to totally be right and you do your first experiment and it's totally wrong. And in fact, that happened. This is Brain Inspired, powered by the transmitter. Good day to you. I am Paul. This is Brain Inspired podcast, as you just heard. Eli Sanesh is a postdoc at Vanderbilt University, one of my old stomping grounds. Eli is currently in the lab of Andre Bostos. Andre's lab focuses on understanding brain dynamics within cortical circuits, particularly how communication between brain areas is coordinated in things like perception and cognition and behavior. Eli is busy doing work along those lines these days as you'll hear more about in a moment. But the original impetus for having him on this podcast is his recently published proposal for how predictive coding might be implemented in brains. In that sense, this episode builds on the last episode with Rajesh Rao, where we discussed Raj's active predictive coding account of predictive coding. I've said predictive coding multiple times now, so as a super brief refresher, predictive coding is the proposal that the brain is constantly predicting what's about to happen. Then stuff happens and the brain uses the mismatch between its predictions and the actual stuff that's happening to then learn how to make better predictions moving forward. So I refer you to the previous episode for more gruesome details about that process. Eli's account of predictive coding and how it might be implemented in brains, along with his co-authors, of course, they call it, quote unquote, divide and conquer predictive coding. And you'll hear why in our discussion. The divide and conquer approach among other things uses a probabilistic approach to account for how predictive coding might be implemented in brains. But we also talk quite a bit about the difference between practicing theoretical and experimental neuroscience and Eli's experience moving into the experimental side from the theoretical side, which, well, you'll hear, it turns out everything has its own challenges, let's say. All right, show notes for this episode, our braininspired.co slash podcast slash 200 and two. As always, thank you for being here. Thank you for listening. Thank you to the transmitter for your support of this podcast. And thank you to the patrons who also reach out and support. Here's Eli. So Eli, are you ready? Yes. We were just chatting about how you are just a few floors up from where I did my postdoc. And this is your first postdoc, right? Yes. Yeah. And in Nashville, Tennessee. And I'm curious. And so this is kind of a, in some sense, a follow-up episode, a follow-up episode, because I just had Roger Shroud on to talk about his active predictive coding work from, which updates the original predictive coding framework from 1999, that focused all on sensory. Right. And so what he did here was like basically bring in an action part of the story into the predictive coding story. Yeah, very lucky timing. We actually just read his APC paper in journal club. Oh, really? We did it a few weeks ago. Yeah. It was helpful. But so, and so we'll get to your related work, compare, contrast, et cetera. But first, I kind of, I know you have a computer science background. And I kind of, I'm trying to understand your world view. People ask me, well, my world view, and I can't describe it because it assumes I have a world view. But like how you approach the world, because I know you have that background in computer science. And so that's, there's kind of a computational, I don't mean dry in a bad way, but a very computational kind of algorithm centric approach that I thought, well, maybe that's kind of where he's coming from. But then I know you did some work with Lisa Feldman Barrett. It's all about feelings and how that drives so much of what, how we interact with the world. So I'm just curious what your kind of world view in the neuroscience is. And those sciences is, oh man, he's getting comfortable. Yes. Okay, so I mean, there is actually, I don't know if I have a world view, but I sort of have a direction and vibe. Okay, oh, I like that. That's a good way to phrase it. Like I feel things out for what I think could be a workable scientific approach to try and address, you know, the questions I'm sort of interested in. And overall, I feel like, you know, the question I'm interested in is like, this is going to sound even sillier than saying consciousness. I'm sorry to say, but why do things feel like stuff? Oh, why do we engage in the behaviors we behave it? But why in the, you know, not why in the normally scientific, you know, reductionist sense, what are the mechanisms, what to be hold the behavior fixed? But instead, if we don't hold the behavior fixed, what are you going, you know, what are you or any other organism going to choose and why that choice instead of something else? What does that mean hold the behavior fixed? Oh, okay. So now I just get to channel these up straight up. Okay. So often in neuroscience experiments, and I'm thinking particularly actually, you know, some of the animal experiments we do here at Vandy, we basically, you know, head fix your animal. You know, like first you chair the animal, head fix, then you train them to fix it on a dot on screen. Monkeys are much smarter than mice so they can do this in exchange for juice. Right. Yeah, just described my entire academic career there. Yeah, an increasing portion of mine. Right. And you know, then you basically have them move their eyes as the only motor output of whatever you're having them do. And most highly constrained lab experimental setup as you can so that when you're asking the question does, for example, frontal I field do in code, some sort of decision process related to the behavior, you don't have to worry about all of the other conflating factors that are involved in the other behaviors. Yes. And so, you know, I'm very, I'm a strong believer that experiment is theory laden. And this means that if you're doing one of these highly constrained experiments and you have a theory about what frontal I field is doing, great. You've controlled everything else so that you can test your theory about frontal I field. Now back to channeling Lisa. You know, if what you're trying to investigate is not something that you can leave, you know, something that you've left unconstrained in your setup, then you can't actually test theories about it. So I would say for instance, you know, like can you use a head fixed monkey and a chair to strongly test, you know, these physiological theories about allostasis, interception, these other nice keywords that I wrote about. With like Lisa and Karen. Questionable. That is really how I ended up. Gosh, there's a whole story actually of how I ended up working with Lisa and Karen. Yeah, let's hear it. If you're willing to divulge. Yeah. So the short version is the stars aligned in a way that they never have before since. Obviously, it doesn't every academic have that story. That's right. But, you know, really it's that I had this computer science background. And then late in my master's actually, I started getting interested in like cognitive science, sort of very like Brendan Lake, Josh Tenenbaum type of stuff. And so I had to like spend a couple years studying things to sort of go back and try and give myself the background to engage with any of this, try to change direction. And I discovered that like what I was really interested in was sort of the feeling and the why. And so I started trying to figure out, well, okay, who has an approach that is kind of like this to these subjects. Where the kind of like this is sort of, you know, very probabilistic. You know, they were using like probabilistic programs to model concept learning. And this was all working very nicely for them. You know, they had that science paper in 2015. I was so impressed. You know, I started reading neuroscience. And you decided to continue. Oh, no, it just gets so much worse. I'm kind of embarrassing myself here. You're going to, you could probably guess now if someone's looking for probabilistic approaches in neuroscience mid 20, mid to late 2010s, who are they running into? Oh, well, not many people, but you've already named some of them. But that I was about to ask you why probabilistic. Maybe we could start there. Because I was just, I mean, at the time I was a amateur and I was just sort of vibing and trying to go. You know, trying to go from one thing that I felt like I could kind of understand to another thing I felt like I could kind of understand. And, you know, at least partly at the beginning, you know, the interesting part about the 10 and bomb and late kind of work to me was, hey, unlike that old field of AI that I took a course in in undergrad. And hated it. This is symbolic style old field or connectionism old field. Oh, I mean, I went to undergrad at UMass Amherst. So the AI class was symbolic search heuristics, all of that. Yeah. Logic, then the machine learning classes that I didn't take at the time were like random forest SVMs. You know, I think there was some neural networks, but they've hired a lot more people doing neural networks since then. You know, and like to be, oh, RL, RL was absolutely huge at UMass Amherst to the point that they hosted the RL conference, you know, in Amherst this past year. And like, I eventually realized like, oh, those big guys, Sutton and Bart, wait, Bart, oh, like Andy Bart, who would just walk through the hall. Yeah, that in Bart. That's isn't that a super interesting thing about academia when you meet, I don't know, you know, maybe hero is the wrong word, but these sort of God heads of classic things. And then, oh, they're just regular folks. I mean, that's why I say this is so embarrassing is like, I actually went to school in a department full of such great people. When you don't know, you don't know. Right, and I just like, I was honestly kind of dismissive about it because I was like, okay, this is all just, you know, heuristic search. Like it's heuristic search, you throw a lot of processing power at it, and maybe sometimes it kind of works, but like this is really, like this is not actually how a brain or a mind would work. You know, this isn't the real thing. And then when I started reading those like 10 and down and Blake things, you know, they were saying, well, we've fit to behavior. You know, we've done an actual experiment and checked. So we're not just defining some toy task that we can then solve computationally with reasonable ease and then go back and forth between approximations and heuristics. You know, for the rest of our careers until an AI winter hits and wipes us out. Gosh, maybe I did take something from you mess at first, actually. Like maybe I took some residual post trauma from the AI will turn. But yeah, they were, they were fitting behavior and actually fitting old white variety or a reasonable variety of experimental tasks with human participants. I said, OK, now there's something here. Like now there's a real world to compare against. So then how, how did that take you to like Lisa? Oh, sorry, yes. So I was trying to prompt you for the name, Friston. Yeah, sure. Carl Friston just to be. Yes, Carl. Yeah, so actually via, let's see, I was working with this embedded electronics company. I still have the hoodie over there. And like they had an MIT post doc. He mentioned some of the Carl Friston stuff around the same time that Andy Clark's book came out. So that surfing uncertainty. Is that that one? And that one had a lot of citations to people that I already, you know, names I already recognized. So I read it. I went absolutely wild for it. And he was sort of mentioning in the book, like, you know, there's some people who are actually applying this approach to emotion. I see. And even better. The people who were applying this approach to emotion, you know, Lisa and Karen. Or at least Lisa and Karen locally to me, right? I was in Boston at the time. You know, had a collaborator in this big interdisciplinary group that they had tried to form and maintain with varying success. It really shown for a while. And I think the pandemic might have done it in a little bit. But you know, they had a collaborator, Jan Villam Vandamaint, who actually did the computational side, probably holistic programming. So of all damn things, I wrote a cold email. Knowing no better way to go about this. Yeah. And they actually answered. Well, they were probably fairly thirsty for someone, you know, interested in it. Because it's not still not that widespread, right? Yeah, none. I mean, as far as I know, like none of this is widespread. If you take the first and stuff too seriously, people say you're in a cult. I actually didn't join the cult until later. When I met Maxwell Ramsted, he's like eventually convinced me of a lot of free energy stuff. Wait, so, so, yeah, Carl was famous for the free energy principle. And he considers it a framework, not a theory, by the way. When, when pressed, at least a couple years ago, he considers it a framework for thinking about the globe overall function of the brain instead of a theory for what it's worth. And, and it has a lot of detractors and a lot of cheerleaders. But, and so you drank the cool aid eventually. I sift the cool aid didn't go all in. And at the time I was being given it to sift, I had sort of been around Lisa and Karen enough that I had really absorbed like, nope, you gotta have your evo divo, your neuro anatomy. You're mapping onto actual biology. It's the biology that really, really, really counts. Right. Okay. So I drunk my advisors cool aid instead of the cult's cool aid. Okay. Good for, you know, good for them, good for your advisors. But, but some people with your background would then instead of embracing the biological neuro plausibility would go the other direction, right? Back to where it feels safer. I mean, I, I'll just say like right before, you know, we spoke for two minutes before I press record and you were talking about how neuro AI is hard. Is it the neuro part that's hard? So I'm, I don't want to make like the public announcement, right? But like, I mean, it's not like, okay, you know what? No one cares. No one is ever thinking about you, right? You're on camera. You're in front of an audience, but no one's ever thinking about you. Sure. Okay. I think I might well end up heading in sort of the neuro AI direction. I don't want to say as just like a career, like just for the money or, you know, for a career prospects thing. But what I have noticed is that a lot of computational neuroscientists are sort of renaming their work that now. So yeah, it's a big, I just, I just got back from a brain initiative workshop called neuro AI. I just got back from a Norway workshop called neuro AI and that term is really being embraced. Because it sounds cool, I think, mostly. Yeah. And I've sort of got this impression that like the real difference between one thing and another is basically what was your training and what department are you looking for a job in? And the number of departments, I think the number of departments that would do my completely ideal thing is null. You know, and I'm sure most people end up saying that well before they go on the job market, but. And I'm not going on the job market right now. So luckily lucky me, but. What would that be? Can you describe what that would be? Ideally, like really, really question based or question driven science, something close to cognitive science in my PhD, I used to make up a fantasy field computational affective science. Okay. By, you know, by analogy to computational cognitive science. Now, computational cognitive science is already a fairly small subfield. And that often overlaps, you know, into the computer science departments, because that's who will give some of them jobs. And the number of cognitive science departments at universities. You know, that do like the full six discipline, you know hexagonal multi handshake thing. Is a handful or less, yeah, or less like. So there's psychology departments who want you to do psychology experiments. There's neuroscience departments who often want you to do neuroscience, either theory or experiment, but they're defining the discipline. Often quite narrowly. Like I had a culture shock when I came to Vanderbilt and found out that what they mean by computational modeling or theory. Is basically like biophysical or bust. Just like a bunch of people who you're talking with, right, because you have people like Gordon Logan there also who that's that's I'm not sure if you run around run past him much. If the, how active he even is still, I don't run into him, but yeah, you know, at least I'm talking, let's say, about my lab and a couple other labs that they interact with. Yeah. you know, B-biophysical or don't do anything at all, or B-biophysical or give up theory and become an experimenter. So how, so okay, so then where do you sit in relation to that push, right? I'm trying to suss out your like your level of abstraction and what you think is important. So my level of abstraction is that when I reached the end of my PhD, I said, okay, I formally did my PhD in a computer science department. If I'm ever going to really investigate questions, I need to go get experimental training. Oh, yeah. I think you told me this a while back. Yeah, yeah. So, you know, I basically said, all right, I'm going to go get as hardcore a postdoc as I can. And that was the biggest mistake you've made. No, just kidding. But, but is that what is that what you're saying? Like the difficulty of neuro AI is the joining of the two kind of like that experimental and computational approach? Yeah, like it's not a mistake to go and get experimental experience, but it is a culture shock. It took me about six months to really be able to make progress on absolutely anything on the experimental side. Why is that? Why is that? I mean, I know these things and people who do experimental work, we all kind of cry together. You know, I'm going to talk about how hard everything is and, you know, but it, but it, yeah. No, in my case, they're, you know what, I'd rather not talk about it. It's sort of private to allow stuff. Sure. Okay. You know, I don't want to. But, so if I said to say that you run into way more problems than you would imagine you might, would that be a summary of it? Yes. Yeah. Yes. Way, way, way more. And the thing is I had been prepared for the, I had actually been prepared for the concept that you might walk arrogantly into experimentation with some grand theory and think this is going to totally be right and you do your first experiment and it's totally wrong, complete and all result. And in fact, that happened. And I was prepared for that. The part that I was much less prepared for is how do I even connect a theory to an experiment? So the part that I wasn't, you know, no results were sort of a thing that I like, steeled myself, you know, work it out on, you know, work it out exercising basically. Just try to sweat until you can't be frustrated anymore that your theory is wrong. Oh, well, the theory is wrong. Even while you're submitting a theory paper about it. But see, that is in the pop area in sense. That is the best kind of progress, right? Because it's an answer. It's an answer though. I hate to say it, but now that I'm looking at another way of analyzing the data, it might get more complicated again. Sure. Yeah. Let me tell you about the actual experiment that we have in both mice and macaques. You know, we have this thing called the glow paradigm, global local oddball. So you know, first to give three identical stimuli per trial, AA, this used to be done in auditory. Now we're doing it in, you know, we've been doing it in visual. And then, you know, the local oddball is that fourth stimulus is B. It's something different. Well, okay. What the heck is a global oddball? You know, in our manuscripts, we describe it as more complex oddballs. Well, a global oddball is where we set up the expectation for the animal, right? We try to intervene on the internal model and, you know, make it think there's a B coming, but then we give it an A. So let's say what we end up doing is testing. These are intermixed for the animal about 80-20. So 80% local, 20% glow. So you're really setting up the expectation? Yes. Actually, there's, you know, 50, there's like days and days of habituation followed by 50 trials of pure local oddball at the beginning of recording. So that we're basically, you know, habituating and queuing the expectations as powerfully as we can. And so what we're trying to do is disentangle, you know, what happens if you have a predictable change versus an unpredictable repetition. And the idea is from a neurophysiologist's point of view is that, you know, then at the end, you're going to have a bunch of controls, like those come after the main block. So after the main block, we record a series of essentially control sequences that are going to allow us to do statistical contrasts. And the idea is to then eventually say, all right, well, if you can figure out, if you can control for every other mechanism you can think of. So adaptation of the sensory neurons and V1, you know, like, this is where it starts to get really messy and hard also. Well, not just messy and hard, but like if you can control for everything you think of, and there's still some difference between global oddball, a, a, a, unexpected a, and just pure repetition or adaptation a, a, a, a, a, then ah, now you've found a signature of surprise processing. And for a long time, I have just been staring at this experimental set of going, how is that surprise processing? Or like what theory have we articulated about predictive coding in the Rowan-Boward sense that says this is surprise processing, you know, rather than, I mean, you know, who says the brain is tuned to look at angled gradings, moving angled gradings on a screen that flash on and off? Well, you, okay, so in other words, you can't control for everything. Or it's not just that you can't control for everything. It's that as I said, I believe, you know, experiments is theory laden. And if your theory is about the brain, you know, predicting the continuous stream of sensory input, then flashing a series of angled gradings that are optimized essentially to drive, you know, V1 to a maximum degree. Well, under predictive coding theory, that's saying you're trying to drive, you're trying to optimize prediction error. Right. So how do we expect to simultaneously optimize prediction error while also provoking another kind of prediction error? That being surprise? Yeah. Or like, well, that's the thing. Our setup, you know, conflates, like prediction error, surprise, you know, visual change. Yeah, right. Because you're using that oddball. There's a visual difference in oddball that you're using. Oh, and I didn't yet, I should have said actually, this is pretty much the standard paradigm as it turns out for studying predictive coding and goes back to about oh nine. Can you, you said that surprise and prediction errors are often conflated? So what is the difference then between surprise and prediction error? Theoretically, perhaps, maybe if I would, I would say you need to commit yourself to a theory in order for there to be a difference. But then the problem is if you're trying to test a particular theory, you should use the definitions from within that theory. Okay. So prediction errors within predictive coding theory, you know, they're the residual when you subtract the prediction from the data. Yeah, what what the organism expects top down signals, then it gets some observational data, bottom up signals, and then there's a difference in the mismatch between the prediction and the actual observate observed data. And that's what gets passed forward. Exactly. And I guess I would, well, okay, so how to relate that to surprise. You know, I would reach for my information theoretic definition because I'm a quant person. Okay. And say, okay, well, surprise is the negative log probability of the stimulus. You know, and essentially, those would be two different quantities. You know, when I eventually wrote my own like computational modeling paper prediction error was the gradient of surprise. So they're related, but distinct, and you sort of have to use math to talk about how. But you know, I'm I guess I'm trying to just describe the culture shock of going from you know, sort of this environment that was wasn't oil and water, you know, we mixed, but like there was a very quantitative side that I worked on and a very biological side. And then, you know, I come to this like glow paradigm, this experiment, and I find that oh, the quantitative side is just moved out from underneath. I have to reconstruct it entirely myself. So that's what you were getting at when you were talking about how what we'll call it neuro AI is hard. Yeah, like actually taking there's sort of this problem where in neuro, we are often doing paradigms or tasks that from a pure AI point of view might be considered almost trivial. Yeah. But from a biological plausibility point of view, that often makes them hard again. And then if you're actually trying to explain neuronal data, or worse, trying to map some real theory of the brain onto neuronal data, rather than just, you know, suggest that there could exist some mechanism explaining this behavior. Because you know, like there's been multiple computational models of same, you know, of the same behaviors. I'm sort of thinking of like the famous drift diffusion models of, you know, decision making. Yeah. Like how do you know if the brain is doing a drift diffusion, you know, accumulate evidence to a threshold and then decide algorithm for decision making or, you know, resource constrained reinforcement learning algorithm for decision making. There are experiments that have been fit with both these kinds of models. Yeah, that's right. How do you know massive, massive shock for me that there's just like, oh, wait, is everyone just pretending? What do you mean pretending? Pretending that what they're doing is valid and what everyone else is doing is not or what? Well, pretending that like just taking data and, oh, you know, fitting it such that you can claim to use your theory to explain behavior, but you haven't actually tested it against substantive alternative theories rather than some kind of null hypothesis. Like what the heck is our null hypothesis regarding behavior and the brain? Or alternative hypotheses doesn't even have to be null, just a clear alternative. Yeah. Yeah. There's something that actually that Jeff Shaw I'll just elevate him in this regard. Like every year when I was a postdoc, there's a fundamental set of papers, one of which is like the method of alternative hypotheses where we tried to base, but I think because of these things, because it's hard, like you mentioned drift diffusion and I was doing drift diffusion work essentially stochastic accumulator work, which is exactly what you're saying. Does the neuron like ramp up to some threshold? And then that actuates the behavior. And that's one of the things that Jeff Shaw is famous for. And so, you know, his idea is to look in the brain and test it and ask it, right? Through recordings. And of course, it's not super clean. Because we're dealing with different kinds of stimuli in this very controlled environment, the frontal eye field, as we know now, any given brain area doesn't just have a single function. Right? So there's, you know, mixed selectivity in brain areas where they're doing overlapping populations of neurons or doing overlapping functions things. So, but anyway. Oh, yeah. I mean, any talk of like frankly, any talk of selectivity slightly makes me want to scream and I've just been reoculturating myself to an environment where like the word degeneracy and, you know, to an environment where these things are not the assumptions anymore. Wait, where degeneracy is not an assumption? Where degeneracy isn't the assumption, you know, top down influences often aren't the assumption. Like it's a very, and I'm not saying this as a negative thing. Oh, you know, a certain way I like it, even though I don't think I can make a career out of it. Like very Andy Clark quoting, Quine, you know, had this thing about desert landscapes. Like a neurophysiologist point of view is a very desert landscape point of view. There's the things I can measure. Nothing else. Nothing else exists. I'll talk about selectivity because I think I can measure it. And if you tell me that that's actually caused by what I do rather than an observation of a causally independent system, then I will get an argument with you because I think I'm measuring something real. I see. So what you're describing, it's interesting that you find yourself in that world now because in some sense, that's kind of the old school world, which is still very much alive and thriving. Whereas there's been this recent push into a much more, you know, more naturalistic types of tasks and removing the constraints from the lab, you know, the lab-based experimental stuff. And that's hard in a very different way. So let me, you know, make some applause, or give some applause to Andre here, right? I think he doesn't do that kind of experiment yet because he's actually pushing something that's already very risky and innovative. He calls it medallion, multi-area high-density laminar electrophysiology, which basically amounts to saying, you know, let's have like not just one neuropixels probe in one area. Let's just cover the brain in neuropixels probes. Yeah. So neuropixels probes are like these really high-density multi-electrode probes so that when you put them in any given area of the brain, you're getting recordings of hundreds to sometimes thousands of neurons. Exactly. Yeah. You know, and all of our work includes the LFP, the local field potential, as well as, you know, the individual spiking signals. You know, and then we analyze both together, which, you know, I won't say who, but like someone I really, really respect a lot. I went and visited their lab. Actually, one of my scientific heroes, you know, I went and visited their lab at one point. Can't say who. You can't say who? Yeah, I'm realizing I can't even specify this little, well, the point being at one point I asked, you know, do you analyze the LFP? And they said, no, we just look at the spiking. You know, and I think, you know, respect to Andre, like he's, I didn't talk about it before because like it's not as native a part of my worldview. It's what I'm learning. But, you know, this is actually a very ambitious thing. You know, even for a simple experiment, we'll have like two full neuropixels probes taking, you know, multi-unit activity, individual spikes that we sort with kill us or, you know, than LFP. You know, the sort of LFP is what people talk about as measuring when people use the term oscillations. Sorry, I said, yeah. No, I was saying population level signal. Oh, there's that too. Yeah, but, but it's a different, it's a kind of a complimentary signal. The other thing is spikes are definitely the outputs of neurons, whereas LFP is thought to more, more closely track that population level input. Yeah. So then we also, you know, and then we like analyze both. So we're often doing, you know, cross correlation or coherence measures of like LFP to spike. Yeah. And this actually tells you quite a lot. And it's, you know, it's difficult. It's ambitious. And my understanding is that it's also not easy to get grants in. Like I think Andre won his NSF career just this year. And that was the first grant that the lab had gotten in, I think, possibly three years of operation. Four joint specifically for joint spike LFP analyses. For Madeline as a whole. Yeah. Okay. For like this research program of, you know, let's measure in multiple areas, let's measure the LFP's and the spikes. Let's try to capture as much as we can. So to speak as many times as we can. Let's really try to push the limits on how dense the sampling can be an electrophysiology. Because of, you know, essentially the resolution issues with imaging or EEG that you would not want to use those, you would want to use electrophysiology. Yeah. So, okay. So backing up here. So I was just at this brain initiative workshop. And it was brought up multiple times. You know, so the idea was to think in terms of like, well, what would we need in 10 years? Lesson ambitious goal for 10 years in early eye. And two people, one person suggested this. And then it was echoed by another person that what we need is to be able to record synaptic strengths. So, you know, for example, neural networks, the strength between the units is where all the parameters are. That's those billions and billions of parameters that in these large language models, et cetera, those are what get changed. That that's strength between in the connections. And if there was just a way for us to measure that in the brain, then that's an ambitious goal and it's a worthwhile goal. My immediate thought was, you know, there's that age old question like, what would you do if you could measure all of the spiking from all of the neurons? Would you even know what to do with it? And no, the question's no, we don't because because you because it goes back to the theory ladenness, like you have to have you have to come from some sort of framework or theory to then ask questions of that data. So just collecting the data is not going to get you that, right? Yes, and I think that's where that's where I'm just going to put my cards on the table and say, I think that's an open challenge for the field. And I'm happy to be working on it. What is the open challenge? Sorry to figure out how the heck you analyze your data in a properly you know theory driven or question driven way rather than just I don't want to say this like it's too bad of a thing, right? But rather than just running statistics and then saying I found an effect. Well, that's interesting, interesting because that's kind of what the AI side does in neuro AI. It's like throwing a bunch of statistics at the data and even Terry Sinaliski brought this up at the workshop like what what principles have we learned? What principles are there to gain from this approach? Right? Yes, so here's where I would sort of reach back into my training with young Billum as a probabilistic programmer and say for God's sakes we need to be writing down generative models fitting them to data and then doing model comparison. You know, we need to actually have some measure of how well does something fit the data? What theory motivates it? And then you know compare them in a principled way and I think that you know machine learning can actually help with that and I've seen a lot of very very productive you know and like a flurry of new work essentially in just analyzing neural data. But then you also have to convince here's the hard part those things can get published in machine learning conferences and then you have to both teach the experimenters to use them and convince them to use them and teach it to them in such a way that they don't need you as a statistician or machine learner to actually you know stand over their shoulder telling them how to encode every little hypothesis because you want them to use it a dozen different times and they can't just keep you around forever as some kind of consulting machine learner. Right well you know actually so I'm going to it's not name dropping because I wasn't like talking with them but I remember Jeff Hawkins years ago at a giving a keynote I think at the annual Society for Neuroscience lecture and I'm sure he's made this point over and over again. You know the traditional physics approach is you have your theorists and you have your experimentalists and they're sort of happy to play together and that's not the case necessarily in neuroscience that we need to get to a point where the experimentalists are happy gathering the data to feed to the theorists who then can analyze it but that sounds awful to me too. Right I mean I so I will actually say I would much rather that experimentalists be capable and happy of analyzing their own with analyzing their own data and the reason is that you know if I say I'm going to be a theorist or a computationalist then you know data analysis is something that pays the bills perhaps it's something that can help get a routine number of papers out the door you know for like a machine learning person I'm I am actually thinking of someone Scott Linderman over at Stanford like you know you'll notice that a lot of his papers are basically just machine learning based data analysis for neural data and that's great that's the thing like that can build a career now personally is that what I would want to think about as a theorist how do we analyze data no no like you know that is not the thing that I have you know a secret manuscript that I've been trying to finish for a year you know the the thing where I have a secret manuscript that I've been trying to finish for a year is you know how do we explain emotion in a quantitative way or affect core affect valence and arousal in a quantitative way by going all the way back to you know the herb bilaterian and then picking c elegance as a model organism yeah good luck with that exact yes see exactly like good luck with that but people like you mentioned Scott Linderman and so he develops a lot of tools that are being used in these naturalistic kinds of tasks right and that skill set is seems seems to be what is really valuable in the academic marketplace at least these days do you think I have that right yes yeah like when I was so I'm going to use myself as an example instead of him because you know I know myself better right and I don't think I could speak for the narrative arc of his career but I know that when I started my PhD the starter project that I got put on was here's a new way of analyzing fmri data in a little bit more theory driven way and it worked what was sorry but what was the oh you just needed to employ that method no I mean it wasn't just oh there was some method and we employed it we were building something new because you know our collaborator on the psychology side had some data and he wanted to analyze it and the standard ways of analyzing it were inadequate to the theoretical question he wanted to ask yeah so he wanted us to build something new we built it we published it you know that gets citations there was a follow-up you know I think there's now follow-ups to the follow-up like by other groups right you know that like that stuff is this is going to sound horrible but I don't mean it in a bad way that stuff is good commodity science but it's also necessary I can I can make it sound even better yeah it's like the it's the Toyota of science right like I drive a Toyota I only bought a car this past year but I drive a Toyota because you know what it's practical yeah yeah you know that is very practical science that you can reliably like never run out of new reasons to do more of it and therefore never run out of publications well that's right that's right but this goes back to the to the idea of so does that contribute to progress in theory progress in understanding principles or is it just a very practical way to harness and say something about the data that's being generated I think a lot of I think it has the potential to do both but by default it mostly does the second one and that's not a criticism that's to say I think the field has you know the ingredients for a really great synthesis sort of laying around in different people's labs and what we need is essentially like a small conference or workshops worth of cross-pollination where you can get the people with the appropriate skills all in the same room give them the incentives to work together and I think it's actually the incentives that are the hard part this idea of getting the proper the people with the proper skill sets in the same room for a couple days it's awesome the proper skill set is a shifting landscape itself right now we have a very specific one like people like you and and Scott whom you mentioned and stuff like where these commodities these tools are extremely valuable widely used but you know going back to cubal and weasel right they're on transparency's they're putting like just little shapes and trying to listen for the sound of neurons even like Jeff Shaw who I mentioned earlier would tell us stories about you know you're in lab you'd make like a little hole out of like a wooden cut out and you'd like put a light up in there and it is the neuron active or not it's a very different world back then very different skill set and so I don't know how we track that and I mean that's a meta problem yeah I mean that's why I say like if you're going to have a division of people's jobs or departments into theorist and experimenter then I would want the experimenters to be able to analyze their own data because you know then they can do that even if it's a bit quantitative and even if that's something of a moving frontier sometimes and then the theorists you know they can focus on asking questions like well how does the brain actually work now that we've measured it you know now that we're able to interpret the measurements let's get back to predictive coding though I mean are you so are you now you don't want to pin yourself into a very narrow corner but I mean where are you in terms of so the idea of predictive coding predictive processing is that we are constantly predicting what are what is coming into our senses and so we have to have sort of a model to use the term loosely of what we infer to be causes of things coming into our senses infer to be a cause in the world so we're making these predictions from our world model Bayesian brain hypothesis is one way to say it free energy principle is another sort of framework implementation so are you on board with like this being the function of the brain a major function of the brain where does this sit in the let's say major function of sensory cortex major function of sensory cortex yes less sensory so there's okay gonna lapse into neurophysiology vocabulary for a little bit you know sensory cortex is usually well-liminated like let there's laminar sensory cortex down in these low areas and then as you move both up the hierarchy towards cognitive areas what we think of as cognitive areas yeah nice and also sideways over to motor you get different patterns of lamination so the cortex is a laminar structure meaning it has a fairly repeated well very repeated motif of like six layers like a layer set yeah now the one that raw sensory stimulus comes into is layer four and the thing is that when we talk about different lamination patterns you know we're talking about I believe they're called a granular and disc granular and those have either much less layer four or they're entirely missing it I think that that's right I think a granular is has no layer four and disc granular maybe has a weaker either yeah like a weaker layer four but now if you were asking yourself you know okay so if I'm doing Bayesian computation then my observed random variable which is the stimulus it has to come in somewhere and if I'm you know using this hypothesis about the laminar micro circuit doing predictive coding then where's that coming in it's coming in in a layer four so what is the circuit doing if it doesn't have layer four that's where the generative network is right maybe like logically it can't be doing you know variable by variable Bayesian inference it could just store priors but then why does it have you know a layer two three because that's the one that you know computes errors and thereby updates the predictions no so I actually really you know since we're following on Rajesh Rao's episode I actually really like his hypothesis that oh two three is the one that handles sensory data you know five six is actually handling chiefly motor data and when you compute an updated sensory prediction you might route it through there on its way somewhere else but then fundamentally he would be saying okay now you know oh and he also notes that there's philamic projections into a cortical column that don't have to go through layer four right so so the the the desire is to bypass layer four bypass layer four being a necessary part of predictive coding is that well or ways of reformulating the predictive coding hypothesis so that you can still have sensory data coming in even when there isn't a layer four sure and then you just have you know physiological and evolutionary questions about why are these areas you know a granular disc granular laminar what are the differences between them and the similarities but you haven't totally abandoned your framework whereas if you're committed to layer four being where sensory observations come in then logically the Bayesian computation can only be done in linear sensory cortex okay I see so when I say I think I'm committed to this being you know an explanation of laminar sensory cortex I'm being kind of minimalist sure okay okay but so you're on board with um Roger's story about like the incoming two three layer two three outgoing layer five and how that's that's one way that it's biologically plausibly could be implemented um but you're divide and conquer predictive coding uh also strives to be biologically plausible maybe we can start with like what is divided and what is conquered in divide and conquer predictive coding and then and then maybe talk about a plausible plausibility okay so if you go look at some of the free energy papers I think there's even one called the graphical like the graphical brain you know they tell a story about how a probabilistic graphical model has these different nodes representing different you know unobserved random variables and these get mapped onto cortical areas and then the communication between areas is you know a series of messages and a belief propagation algorithm that eventually gets down to primary sensory areas where the random variable is observed now this kind of algorithm makes a very specific assumption that they call the mean field assumption about essentially saying we're going to approximate the posterior distribution with a product of independent um representations so we'll have one representation for the visual one for the audio you know one that represents the integration of visual and audio but they're actually all going to sort of be statistically independent in you know the approximate posterior scare quoting as implemented in the brain and by the way on the you know machine learning side we know that this is quite a bad representation of a posterior distribution why is that you know essentially it can't represent correlated posterior because because of the independence assumption yeah like it's making a very strong independence assumption that was necessary to simplify the math in like 2003 literally the first time variational inference was published was in a PhD thesis from 2003 or so like you know all my respect to people who are developing new things and make simplifying assumptions right but of course the point of science is that we always want to try and relax our simplifying assumptions and ask can we come up with a way to essentially can we assume that the real world is really complex and complexify our models over time so as to accommodate the real world well but but then you're also dealing with Alchem's razor you're dealing with trying to figure out well what can we abstract away what are what are the important things that we can abstract and and so when you make assumptions like that mean field assumption you are you you are making tradeoffs it's just whether they're the right tradeoffs given what you're trying to answer right yeah and you know sort of what I have learned through my PhD on the machine learning side was that if you have a complex structured graphical model has might be used in some cognitive science task then mean field variational inference doesn't work very well and I thought well you know if I take a theory or sorry if I take a hypothesized model from neuroscience and I applied an AI and it just doesn't work very well is that what the brain does no I don't think the brain you know fails at things that are doable with current AI methods or rather I don't think the brain fails at doing things that we've observed it to be able to do an actual behavior you know I think that's a case where the algorithmic model is just inadequate so I said okay um let's make a better one instead of mean field you know independent independence assumptions let's instead try to break down the random variables from one another so that you maintain their correlations when you update them is this the dividing part yeah yes that's just say it again so what are you you're dividing go ahead you say take this you know a probabilistic graphical model so it's a mathematical analogy to the brains internal model of the world and you say this consists of a bunch of different variables that are connected to each other in various ways you know kind of like cortical columns we can imagine so this is actually how I imagined it was you know one cortical column one random variable and then when they communicate with each other you know those are conditional dependencies and all that and then I said okay let's try to divide this so that we can update each random variable in a way that takes into account the correlations with the other random variables that's a that's a character part that's the divide part well yeah or yeah then the update is like the first step of conquer then the real conquer is that we have all of these importance weights from the world of like Monte Carlo methods for Bayesian statistics that then let us eventually write out you know here's how good a fit to the joint model we have to the whole probabilistic graphical model so we're saying we want to do local updates that maintain some kind of global coherence and it gets called divide and conquer because well frankly NURP's is ultimately a computing conference now yeah yeah and like all computing people have taken an algorithms class where they talk about divide and conquer methods hi I see I didn't realize that so that this is a well-known phrase in in the algorithmic world yeah like if you talk to algorithmicists and say divide and conquer they'll say oh okay so you're taking some kind of huge data structure and recursively performing the same computation on each component before going on to the connected bits okay that makes a lot of sense you know and it just sort of happened that like you needed a lot of Monte Carlo tricks to make this work but when you do it's very sort of intuitive why you would want to do it that way if you were then going to map your probability probability model onto a physical circuit structure where the different random variables are spatially separated and have to signal to each other so what is what is in in the divide and conquer model what is required for it to be biologically plausible so the claim of biological plausibility made is to say the computations are purely local right instead of the the local updates instead of globally right so you know people have talked about you know code back propagation be implemented in the brain Tomaso our senior author has this paper on using Gaussian predictive coding to actually implement back propagation as a substrate for back propagation and in this paper we're sort of saying well let's assume you can't do back propagation you don't have any kind of global you know computation graph or computation automatic differentiation tape in the brain but let's assume that you know one cortical column can signal to another and that if you're representing one random variable locally then you can do really three things with it sample from its distribution measure the log density of its distribution so the log probability density where density just means that you're talking about continuous random variables and not discrete ones and three take the gradient of the log probability density and if you can do those three things locally then you have the primitives necessary for our algorithm and you can thereby obtain global coherence out of local computations and jumping back prop since we were talking about that that experiment versus theory metastatic it's topic earlier I mean does it does this make clear predictions about what kinds of signals that you would expect to see now here's where it gets biologically impulsible these were still rate coded neurons right so yeah so they can still cross between positive and negative right so so brains use spikes among other signals like LFP's but the essentially all of modern machine learning or AI models use rate codes and there you know there are a lot of people working on spiking neural networks also but I assume that if you're going to implement it in like a spiking network then you know you have to go I mean it's plausible with the sampling approach right because that's what spikes are all about spikes are all about sampling well you can so going back to the old debate on like how probability is implemented in brains there's a sampling approach versus the approach where the spike spike counts map on to some probability distribution types etc oh yeah um but with the twist so with the twist yeah so I know there's a lot of sampling approaches where you essentially say a neuron has a preferred stimulus and implement a likelihood function right and the priors are actually represented in the developmental program of the genome not in the neurons themselves and then those eventually make the prediction that they make the opposite prediction to predictive coding they say when the posterior probability of what the neuron prefers is higher the neuron will fire more and predictive coding actually and the free energy principle and all of those approaches are much more information theoretic they say that when the stimulus is thoroughly expected you should see much less neuromal fire right right and so we're in that family of theories though we do use random sampling my you know my dispute with spikes being about sampling is that of course if you patch clamp a neuron like in vitro then what is it like 96% of the variance in its spiking you know is explicable deterministically there's stochasticity in the real brain but we don't know that the single neuron isn't intrinsically stochastic that way right that way we do know it's stochastic but yeah but it's okay so but then going back to you started by saying that the major this is where it gets into non-biologically plausible mechanisms is that it doesn't use spiking yeah and actually I think Blake Richards group has recently ridden to our rescue with their paper on what is it brain-like learning with expedentuated gradients brain-like because it uses spiking so in their case brain-like because of obeys dales law oh so they'll have inhibitory neurons which are negative and excitatory neurons which are positive and the signs will never flip and they show they still use rate but yeah they're still using rates there yeah and you know how realistic do I think that is I don't really know like I mean there's areas that could use rate codes but there's also too many experimental findings showing that precise timing matters yeah so what it could be you know and this is not an original thought to me this is coming from a computational brain and behavior paper I can send you the name it's from 2020 um you know it could be a prefix-free code oh what uh sorry say that again a prefix-free code prefix-free what does that mean so that means that once you send a certain pattern of spikes and by certain pattern I mean you know the precise timing determines which code word it is but once you've sent a certain pattern of them then that code word is over so prefix-free means that no code word is a prefix of another code word so if I say a b a b then that's either a full code word that now tells you something or there's no full code word that starts a b a b accept the one I'm already sending but what so what would that mean is that just because a rate code go ahead sorry so a rate code would say you listen over a certain period of time right whereas the timing oriented out of the way you get m spikes you divide by time t yeah whereas a timing oriented code is like you get a time a spike at time t now you think well I what comes next spike at delta t delta t prime delta t prime prime right and you look for you know very specific timing like with musical notes and your lookup table you figure out oh I was just received this particular message yeah I just received taught tt tt tt you know it's gosh has someone actually tried using third grade music class on timing codes but yeah a prefix-free code would then be a timing-based code where you say once I've received a full code word that's it I know that I've received a full code word I can interpret the whole message clean your cash and move on yeah clean my cash and move on exactly but really I mean gosh on the other hand that doesn't see this is the thing that bugs me is like there's also evidence that you know dendrites right I sort of accumulating this precise spike timings into something more like a continuous signal that gets fed up to the cell so much so how can it be that there's precise spike timing and there's dendrites that convert from spike timing to spike rate or less well I don't know that those are necessarily problems right I mean so when you're going to say you know is it as a spike timing code or a rate code and because we know that some things require precise spike timing like the inter-orial differences right the underlying how owls here locate sound for example timing is very important but maybe timing is not as important in I don't know frontal cortex or prefrontal cortex or something and it could be both yeah depending on what you're needing to accomplish a a an organ like the brain is fairly complicated it turns out and it might be implementing lots of that degeneracy you were talking about that could be the case in in terms of how it computes it's not maybe one or the other but just depends on what's needed yeah like that's very very possible that essentially so actually not only is that possible I could go very well with you know some of our recent preprints that basically say predictive coding is a much more cognitive computation that can take place in frontal areas you know back to our glow paradigm those global odd balls seem to get detected in frontal areas but non in lower sensory cortex so maybe the laminar cortical column you know is something like a big stack of universal computational primitives that don't tell us much from just reading off the anatomy about what it is doing oh god yeah you know if we broadcast this the modular mind people are gonna crawl out from under the rocks we spend so much time banishing that that's all right that's all right there's room for everybody what one of the things I wanted to ask you about is so so you're mindful of you know what is and what isn't biologically plausible in this you you think it's important if you're gonna understand this sounds silly to say if you're gonna understand the brain that you need to implement through a model you need to implement something that is biologically plausible and but you're willing to forego the spikes but so inevitably any project is going to have hurdles what what what hung you guys up the most in getting this thing to work and or getting it feared out properly so two big things you know the first time was when I tried to write out all those waiting rules essentially saying like how do you accumulate you know the weights from doing a dozen successive updates to a random variable over a dozen passes and I got something that looked really complicated and eventually just exceeded the numerical the numerical precision of floating point numbers in the computer okay and what I eventually did was just like have a meeting with how and talk out some options and he pointed out that one of them was essentially just cheating for getting the old importance weights and just saying you know I start with some particles that is I start with some samples I do a computation step on them now I have new samples I'm gonna do the same thing next time I don't save any weights and we ended up going with that because it turns out you know once we like both prove to ourselves that this was legal to do within all the rules of the game this just turned out to be the simpler thing that was able to work and so you're okay I mean so storing the weights over time maybe is not even as biologically plausible as throwing the current and doing yeah we said so there there were two things that you said so the other one is that between the first pre-print draft and the second one that represents our camera ready we added like this preconditioner that helps the optimization go in the right directions and respect the geometry of like the latent space and you know this very mathematical like technical itchy thing and the thing is without that stuff doesn't work and you just don't perform very well on your test tasks now we did manage to rig this up in such a way that it could be biologically plausible you know it's effectively like calculating a certain function of the prediction errors so if the prediction errors are locally available then this thing is locally available and you could even you know nod to the free energy principle and say ah there's that precision of the prediction errors that these free energy guys are always on about but really it was just motivated by getting the damn thing to work in the end you have to have a product a working product yeah and you know this is where I forget which famous person said that no two famous people have said this okay it's Richard Feynman and Daniel Dennett have both you know said if you want to understand it you've got to be able to build it did Dennett say that also I mean Feynman he said a version of that did he okay yeah oh Feynman says I do not understand what I cannot build no and then Daniel Dennett says completely different he actually said at one point AI keeps philosophy honest that's what I was remembering well that's interesting which is a whole other can of worms so my mistake but you know what I would say is if you want to say that predictive coding is a thing that happens at the brain based on your experimental observations then it should hypothetically be possible to build an algorithm that does predictive coding and actually works for you know some of the toy tasks that we use in AI which are still vastly more simplified than the tasks we use in neuroscience or rather the task of the brain you know an AI image generating network does not have saccades well unless it's one of rouse in which case it does have saccades now but you know that's very new for AI and completely trivial for neuroscience and so I think you have to be able to build up AI to the point that it's able to do things that are trivial for neuroscience before you can really say oh a computational theory is viable now now it has to do the things that are most trivial for the brain well all right so then I have to kind of broader questions for you before we end our conversation today and one just going off of what you just said and I've sort of been building up to this do you need to understand the brain or brain processes or implement things in a similar manner to how the brain does things to build the best artificial intelligence do we do we need to mimic the brain and at what level if so so I think that depends on how you define I'm sorry to be philosophical about this but it really does depend on how you it depends on how you define artificial intelligence right and I don't like to commit to a definition of that at all because what I personally want to do is understand the brain that is the motivation for me I want to understand the thing that actually exists try to draw you know so to speak laws and principles from it and then maybe I could engineer something with those in the same way that you can you know engineer a steam engine with Newton's laws and thermodynamics right but you do have to you know in my view the interesting part is to do the fundamental science before the engineering now if you are engineering first then you know an intelligent task is whatever the heck you have a benchmark for and you know sort of there's this alternation between making a harder benchmark and beating the current benchmark and in that case do you really need the brain who will know you need to understand your benchmark task like there's a lot of tasks where if you have a very deep understanding of the task itself you don't necessarily have to understand how the brain would solve that task but there's all the talk of AGI right in the AI world we're going to get the AGI by next Tuesday it's going to be the Tuesday after that no and then it's like five years no it's just 20 years you know I mean I personally I feel like going away from definitions again I don't know what AGI is but I think that the humans are the wrong benchmark it's like just well what what's the right analogy all we're doing is like staring at ourselves in the mirror and yeah that's real intelligence it's only because it's us we think we're great I guess oh there I totally agree because you know what is it we got you know optimal chess playing at superhuman level maybe was that a decade before we got you know neural networks that could pass image net classification at a human level yeah half a decade maybe like just two thousand you know and that but at the time you know chess was sort of the king desk where we thought if we understand how to play chess we computationally we understand cognition computationally or we've like built you know intelligence and then well I don't even have to say end then there's a cliche for it more of it's as paradox yeah you know like I am very much a more of a chess paradox person where I say understand embodiment first sensory motor stuff first feeling first and then maybe later in retrospect you'll turn around and say here's all these normative principles we derived from our empirical study and we understand now how those tell us how to build what intelligence is and how to build it but the term aji almost feels like it I admire the people I admire the sheer ambition of the people who are trying to do that and going to conferences like the aji conference and the other angle on it is unfortunately that I do think in the era of large language models there's been a tendency to fool ourselves and define aji down so that instead of being a name for something we don't understand and have to come to understand you know only through working at it over time it's become you know a name for something that we say has happened oh yeah yeah like the latest you know model from wherever is aji is it aji it's gal yeah right and it's like okay but that's because it talks like that's because it talks and we know the Eliza effect we know that if you talk and talk and talk people will project personhood onto the words and to be fair to people prior to the invention of LLMs 100% of all linguistics stimulus we ever received came from other people will accept maybe for like bad Markov chains and Eliza and that sort of thing right yeah yeah Eliza is a really well-exhausted majority so you know for an optimal probabilistic reasoner if you heard language then the rational conclusion was that there's a person well we also know that some of us aren't that bright for example I've said I think only ever more of that and you say more of that which is it so more than I do I do oh really so fast oh I'm sure I'm wrong anyway that's the paradox that um it turns out that it's easy to build that I blanked from my memory where somewhere like Mitch corrected me on this oh I don't know but anyway that paradox is that it the things that we think are hard to do like chess yeah turn out to be easy and the things that we think we're easy out that are easy to do like walking on two legs wait like be yeah be like a waiter balancing a train moving walking through restaurant don't list that as easy talk to a waiter before you call that easy that's hard well what I mean are the sensorimotor everyday things the continuous sorts of behavior yeah but something is hard even for embodied human beings so that's one of them yeah talk to me go get a friend who works in food service I've been a I've been a server I've been a waiter okay that was at the poor example see again I say more of that I give bad examples what do you do well maybe not of us I'm sorry I'm not I'm not supposed to be shaming you on your own show yeah what are you shaming me on my own show sorry no okay you've been a waiter yeah it's easy for you because you practiced I'm I also have a ungodly balancing talent no that's not true all right but I do have another question because you you are interested in how did you phrase that earlier not consciousness but feeling why anything feels the way it does right another way of yeah to say it is like it's just subjective experience in general or affect I guess the affective component of it like why do some things feel the classical dimensions of core affect our valence in a rouseau so why do things feel pleasant versus unpleasant why do things feel exciting versus relaxing okay we could say or a rousing versus sedate it so okay so my question then is and I was thinking about a Neil Seth who ties predictive coding into consciousness and that that's going to solve consciousness essentially what do you think about sort of maybe that but also it's predictive coding's relation possible relation to affect the way you just described it so I have to say I think the second one the relation to affect through interreception homeostasis alastasis this stuff is a lot easier to establish than anything about consciousness and that's why I've sort of said like well I'm not going to touch consciousness with a 10 foot pole right it's much too hard like I'm not everyone's a little bit of a philosopher but I'm not very much of a philosopher so I'm just not going there as to the connection between predictive coding and consciousness I mean here's one of the reasons I think consciousness is so hard to think about is that oh what is there this like classic thought experiment about consciousness like couldn't you imagine a philosophical zombie who has the same input output mapping and the same observable behavior possibly even the same electrophysiological readouts as a real person but isn't conscious but what about the affect aspect then they wouldn't have affect either right right I mean if they don't have consciousness it possibly makes sense to right like well that's what I would ask is you know does a philosophical zombie have a predictive internal model do they have interreception like and I ask myself you know can I imagine someone who has the same internal states and control systems at a physical level but doesn't experience them at all the dancers know yeah the answers just know because I'm like but there's a latent variable there there's like you know representations and computations going on there's internal states maintained over time and internal dynamics I can't imagine how there could be no one home and that's past that's you know like I said I don't study consciousness because I recognize that this is very likely a limitation of my imagination rather than some kind of answer it's just the way my intuitions work and so I prefer to be at least on the engineering end where like I can bang an intuition against an experiment that doesn't work and bruise it until it's softer and can be re-bolded into another intuition now that you're doing experimental work how do you think about the role of intuition sorry I know this is another question and I've got I actually have to go in a minute but do you feel that your intuition has served you better from the computational world theoretical world or the experimental world because it all comes down to that to make any progress you have to make a guess and that's from intuition actually I would say I don't know a good way to put those two together right now I'm sorry I just don't with him what the intuitions from both ends because maybe if I was doing experiments with naturalistic behaviors I would develop more of an intuition for how to dry it let the experimental and drive but with the highly constrained experiments you know I just don't I get an intuition for the task and the setup yeah and like the way that a particular data set or animal might behave but not one for how does you know not one from for like how do I pass from you know these spike trains to psychology to like the mentalizing I can do about the animal right I have no bridging intuition there whatsoever we'll see now now that I do what I'm quote naturalistic experiment meaning we just there's just a mouse running around in a box and we measure measure measure measure and now we're trying to relate neural activity to that ongoing behavior which is continuous they groom slightly differently they move their paws slightly differently are we going to call that the same groom as the other one how do we define that my intuitions about experimental neuroscience which were forged in that controlled constrained environment I think are not serving me well so I'm trying to build new intuitions yeah like you know if there's one thing I've learned in my life it's really the limits of raw intuition and how you just kind of have to bang up against experience long enough to start developing you know what you let's end on a pun you know call it posterior intuition rather than prior intuition right exactly you have to you have to take action and get get um update your posterior in the way that you phrased it yeah yeah you like did we miss anything what uh we went half-hastard we we we're quite technical there we remained out in the forest some is there anything crucial that we missed that you want to end on oh actually yes so there's this thing I always keep in my twitter bio abolish the value function if I'm doing a podcast I should tell people what that means yeah what does that mean that's a great way that okay so that means that at one point in grad school um Jordan terryo who will probably listen to this high Jordan you know recommended this book to me entitled more heat than light by Philip Morovsky okay and Philip Morovsky is like a very philosophical leaning part economist part historian and he wrote this whole book about the analogy between energy and the conservation of energy and economic behavior so all of this notion of like there's an economic agent who maximizes utility or minimizes cost that's the value function yeah all that stuff is the value function and what he pointed out is that essentially if you think like a rigorous physicist the analogy is bunk like it's not you know economic value is not a conserved substance you know people produce things that are valuable and then consume them the amount of value is not a fixed constant number that stays the same all through all of this well thinking like a rigorous physicist would it be called an emergent property of production then what I mean like I'm not sure what Morovsky would say there but his point was that in order to get all the math that was imported into economics and then by the way into cognitive psychology into reinforcement learning into optimal control into all these things that we use in psychology and neuroscience imported from economics and to get that from physics to economics in the first place you have to assume a conserved substance oh so a conserved quantity which represents a physical substance on which you can then have a gradient flow a certain kind of dynamical system so absent that where do we go what is the what is the result of abolishing the value function right and so if that's just the wrong metaphor then I think we need to go into a much more controlled theoretical frame of mind where some signals represent references and they can be directly compared to input signals from the bottom up by a comparator yeah and then when I shift from folks yeah I've come around to get three things as well so then when I shifted my point of view from you know all of these decision-making tasks they're about grabbing more value imaginary gold coins like in super Mario neuro economics that's more economics yes versus they're about measuring the distance between a desired outcome and a actual outcome much more perceptual control theory the reference signal is somehow internally generated by which you compare which is amenable to predict the coding yeah and then I thought okay well now we've gone from substance to distance these are completely different metaphors distance is the superior one because as soon as you set up a mathematical model you can measure the distance in the parameter space right and by the way that's actually the difference between reinforcement learning and active inference you know in all of that free energy literature is that the active inference people are saying let's specify desired outcomes as target capability distributions then measure the relative entropy distance from one to the other and then just try to get closer to the desired outcome distribution that's abolishing the value function substance to distance all right Eli I appreciate your time look forward to more work coming out and good luck with the experience you'll be in touch but good luck with the more learning more experimental research the latest analysis seems to draw a very different conclusion than the ones we preprinted so yeah all right so yeah I knew you have an office mate there also need you to get back in the office so thanks tell them thank you for letting me take up some of your time so thanks for coming on yep thank you brain inspired is powered by the transmitter an online publication that aims to deliver useful information insights and tools to build bridges across neuroscience and advanced research visit the transmitter dot org to explore the latest neuroscience news and perspectives written by journalists and scientists if you value brain inspired support it through patreon to access full-length episodes join our discord community and even influence why and bite to the podcast go to braininspired dot co to learn more the music you're hearing is little wing performed by Kyle Dunovan thank you for your support see you next time bye