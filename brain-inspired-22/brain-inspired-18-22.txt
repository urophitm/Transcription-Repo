 So how come neural scientists have failed so badly at explaining behavior? So obviously they've been trying to do this for at least a century and a lot of smart people have worked very hard but the result is I would say very disappointing. I think it's healthy in the sense that okay so there are people who are perhaps mainstream and they believe that the paradigm is healthy. You know they want to maintain the status quo. Others, you know people like me, perhaps in the minority but we think there's a crisis and we would like to start a revolution. I think it's exciting and I'm quite out there. This is Brain Inspired. Hello it's Paul and today I bring you Henry Yin. Henry runs his lab at Duke University where he studies learning and behavior in rodents using techniques like optogenetics and electrophysiology. But that's not why he's on the podcast today. He's on the podcast because he's written a few pieces in which he argues that we need a new paradigm in neuroscience to explain behavior. That essentially we are barking at the wrong tree trying to study the brain like an input output device which creates representations of objects in the world and then programs the body to act accordingly. Instead Henry looks to control theory and suggests that the brain is basically one big hierarchical set of control loops, each of which is trying to control its input so that the input matches a set of internal reference signals. So control theory came out of the early cybernetics work but Henry argues that they made a key mistake due to their engineering like approach and the mistake was that they failed to consider that the reference signal, the signal that the system needs to control itself to obtain is generated internally by our autonomous biology. Instead the cybernetics approach and in much of the rest of neuroscience Henry argues places the reference signal outside of the body in the hands of our experimental control but we need to be looking inside. Okay, so that will make more sense when Henry explains it more and I link to his work in the show notes at braininspired.co slash podcast slash 119 where you can join the awesome group of Patreon supporters as well. Thank you Patreon supporters. Also just a quick announcement, I am finally going to be releasing my brain inspired course which is all about the conceptual landscape of neuro AI. So all the topics that we talk about on the podcast but in the form of a series of video lessons. So next week on my website I'll be releasing a limited time video series and in those three short videos I'll discuss why this marriage between neuroscience and AI is so exciting. I'll show some examples of what to expect from the course some of the topics that the course contains and then the details of the full content of the course and how to purchase it. But the videos will only be available from November 17th to November 20th. So if you're interested head to braininspired.co slash bi-workshop like brain inspired dash workshop bi-workshop and I'll put that link also in the show notes for this episode and it's during that time span November 17th through 20th that the course will actually be available to purchase while the video series is live. So check that out if it sounds interesting. Alright, here's Henry. Henry, thanks for being here. So I know that by day you are not a crisis counselor but the main topic I suppose that we're going to talk about today is comes from a chapter that you wrote in a book on perceptual control theory and the title of the chapter is the crisis in neuroscience. So there's a lot to talk about actually it's really interesting stuff. But by day can you tell us a little bit about what you do in the empirical side? Yes, by day I'm a systems neuroscientist. I work on the role of the basic anglia circuits in behavior in particular instrumental gold-directed behavior and I use mice for the most part in my research. Oh yeah, so I'm an experimental neuroscientist. Was it your research that brought you to think about these things that you write about? You've been writing about these topics since at least 2013. I'm not sure if you wrote about it earlier as well. Yeah, I've been thinking about these topics for probably since grader school. So for probably 20 years or so. And I started writing about them as you said in 2013 or a little earlier than that. Right. Yeah, so it's been a while. Okay, well let's not wait any longer then. What is? And there's a lot to unpack so I don't expect you to summarize the entire chapter here. But can you give us the overall picture of what the crisis in neuroscience is that you write about? So I used to work crisis in a coonians and so's based on coons book on scientific revolutions. So the idea is that as we all know, there's scientific paradigm, which is a set of common assumptions that most scientists in the field take for granted. And when you have a crisis, it's usually due to discrepancies between new observations and the accepted model, these assumptions that everybody accepts. So then the idea is that you can either maintain the status quo or you can start a scientific revolution. So that's sort of the nature of the crisis in general for in science. And the question that I raised in the chapter was, so how come neural scientists have failed so badly at explaining behavior? So obviously they've been trying to do this for at least a century. And a lot of smart people have worked very hard. But the result is I would say very disappointing. After a century of work, there is no accepted model of any behavior. Things that we have learned about the brain don't seem to explain how behavior works. So that is disappointing and surprising in my opinion. So I think that's basically the crisis. I think the reason of course is not because the brain is too complicated. It's not because as people normally say, the brain is the most complex object in the universe and therefore it will take forever to understand how it works. I don't think that's the reason. Although that's the common excuse. So I think the problem is that the accepted paradigm in neuroscience and in psychology is wrong and I would call this paradigm the linear causation paradigm in which essentially you accept that the organism receives inputs and generates outputs. The input is sort of sensory in nature and the output is motor. So the output is behavior and there is a causal relationship so that the inputs are somehow responsible for the outputs. So the goal in neuroscience is simply to discover the function that will link the inputs with the outputs. So the input would be the cause, the output would be the effect. According to this paradigm, the brain or the nervous system is somehow responsible for a sensory motor transformation. It will compute various things. It would probably take many steps but somehow the product is your behavior. So I argue in the chapter that this assumption is basically wrong and that's the reason that people have failed to explain behavior. It's not because the brain is too complex. How did you get into control theory? Yeah, good question. So I talked about control theory as an alternative explanation. So that is the model that I would use to explain behavior because there is only one class of systems in the universe that actually does not obey this kind of linear causation model. So cause effect explanations do not really apply when you have a closed loop negative feedback control system. And that's why I talked about control theory. But it's interesting and we'll talk more about the control theory approach. You do an analysis on the cybernetics of old Norbert Weiner and company and describe what they got wrong. So cybernetics it seems like is having kind of a comeback but I suppose you're worried that it's coming back and is still wrong. What's the difference between that old cybernetics approach of control theory? What did they get wrong? What were they missing that you argue for? Well, I think let's start with the basic control loop model. So the basic control loop is quite simple. In fact, I think it's simplicity is part of the problem because everybody assumes that they understand it when they don't. So the basic control loop has essentially three components. You have this input function. You have a comparison function. You have the output function. And the comparison function will take the input and compare it with some reference input, reference signal and generate, you know, the error signal which is really the discrepancy, the difference between these two signals. And then the signal is used to drive the output. And if there is negative feedback, then the output will have a certain effect on the input. And so that closes the loop. I think the problem with cybernetics and with Weiner's model is he was actually under the influence of the linear causation paradigm. So his approach is very much the standard engineering control theory approach. And the problem is not the, you know, with the mathematics or with the equations of control. The problem is what I would call a systems identification problem where they are accustomed to treating the reference input as the input to the controller. So in other words, if you are a user of some serval system, then, you know, let's say you're using, for example, a thermostat, then of course, you, as a user, you would set the temperature. And it seems like the setting, when you set the temperature, that's the input to the system. And then of course, the output is whatever the, you know, AC will do to control the temperature. Now this is quite misleading because the reference signal in a biological organism is actually inside the organism, right? Yeah. Literally, it's inside of your brain. It's not something that you can inject into the system as if you're gone. So we do generate those signals, those reference signals in a sense we autonomously generate. Yes. So the key is autonomy. The key is that the reference signals are extremely important in control systems. And they must be generated within the system. And that's actually according to my model, at least, that's the job of the nervous system. So essentially what you have is a hierarchy of neural control systems, which can generate different reference signals at each level. And these reference signals are usually changing all the time, with the exception of a few, relatively few homeostatic control systems, which are important for things like body temperature. Yeah. So I guess the big picture is that you conceive of the brain or brains in any species, I suppose, as a set of hierarchical control systems with each level having its own reference signals. Right. I think that's straightforward to understand for homeostatic mechanisms, like you mentioned, our internal thermometer, our temperature reference signal. But then you extend it to behavior. So you make the comparison between the classical neuroscience, which model, which you've already described, where we see something happen. And then we have some sort of internal representation or model of that thing. And then we act on it. But in your scheme, we have no internal model of what we're acting on. Or do I have that wrong? Do you have room for a model that's generated through these hierarchical control processes, or is it control processes all the way down or up? Great question. I think first we have to be clear on what a model is. We're just talking about representations. Then yes, we have representations. We need representations. But I think what you're talking about is very common in the field of motor control, where they're using all these models, which in my opinion are completely unnecessary. And their models are actually very detailed models of the external environment. And that's actually due to a mistake in the analysis of the interaction between the system and the environment, which I mentioned in the chapter. So this is actually a direct consequence of the cybernetic model. This need for just sort of computing the environmental properties, I think it's imaginary. And it doesn't work very well in practice. So for example, in robotics, if you rely on this kind of inverse and forward computation, the computational challenge would quickly overwhelm you. And that's why we still don't have very good robots. Especially when the wind blows. Yes, exactly, especially in any kind of unpredictable environment, when the disturbance cannot be computed ahead of time. So we've talked about homeostatic mechanisms and you've talked about the motor domain. Do you think of, I guess my question is how much of, well, let me back up. It seems that there is room, and I know you said the brain is not too complicated, but it is pretty complex. And it seems like there's room for a lot of different kinds of representations and a lot of different algorithms being run. And I'm wondering how much of the brain do you see as devoted to control systems? Well, first, the principle is that in a control system, what is controlled is the input and not the output. And if you accept that, you have to understand that basically you can only control what you're able to sense. So that means to the extent that you need to control some complex variable, you must have a fairly good representation of it. And so that means the input function, so I mentioned earlier that you have three components, I would say that the input function is by far the most complex part of a control system in the brain. The comparison function is relatively trivial because you're just doing a subtraction. Yeah, you found out there's a linear relationship, yeah. Right. And the output function, there could be some complexity, but for the most part, it would probably involve some integration or maybe differentiation or a combination. But the input function is tricky because you do there, you do need to represent whatever variable that you're trying to control. Simplest example, of course, is temperature. And that's not a big deal. Of course, if you're trying to represent, if you're trying to control something more complex, for example, if you're trying to follow someone, then you have to represent this person somehow. And that's not as easy because the sensory representations and the higher level object in varying representations are needed. Essentially, then you just perform control on that variable. And then so as that person ducks around a corner, you actively try to, I guess your reference signal would be to have them in zero degree line of sight, right, directly in front of you, let's say. And when they turn a corner, your brain's job as a control system then is to move your body so that it returns it to direct line of sight. Exactly. And then you would have problems. If, for example, there's something that's blocking your view, right, you might need some memory, things like that. Right. Well, yeah. So, first of all, watch out people. If Henry's following you, it's really just a scientific experiment. It's, don't be creeped out. So you just mentioned memory. What about the case where, and you know, I don't want to badger you all day with this kind of questioning, but you know, what about the case where you're not actually following the person, but you have to imagine where they might be going based on, on their history, right, or, you know, they love ice cream. So you imagine they're going to the ice cream shop. And you have to sort, then you have to, do you not have to then represent, let's say, the path to the ice cream shop, right, to then close in on that person. Is that still a control problem? Do you see that as a control problem that is just a hierarchical version of it? Yeah. I think what you're suggesting is that can you predict where they, they're going to be in the future and then act accordingly? Of course, it's a control problem, but I think the difference is that, you know, the you don't, you're not getting direct sensory input. But instead, you're trying to predict based on your experience and learning where they're going to be. That's a slightly different problem, but in principle, the control problem is still the same, but the prediction problem, yeah, I mean, I think the prediction problem, it's not excluded from the model. I would say that, you know, in the control hierarchy, you do have so called imagination, which is basically when a control loop is able to send its output to its own input function without going through the world through the environment. So that's called imagination. And then, you know, for these higher functions, you do need memory, as I said. So I don't, I think these can be viewed as additional functions that you add to the control loop in order to help you control. But to be honest, I'm currently I'm not concerned with these questions because I think they are sort of advanced. They're not necessarily difficult, but I think it's more important to understand the basic function of the nervous system, which I argue is to control various inputs. That's my perspective. Yeah. So this is in some sense, this is a unified grand theory of the brain, I suppose. Yes, indeed. Okay. All right. Great. You mentioned the word prediction, and you were talking about it for a moment there. So I want to go ahead and I'll interrupt us and play you a question from a listener, actually. This is the person who recommended you come on the podcast. So then you can answer the question and then we'll get back on track here. Okay. Hi, Dr. Yen. My name is Jeffrey Short and I'm a mechanical engineer who's just started to explore field with neuroscience. I really appreciate the thought of open perspective you share in the book chapter as I try to get oriented to the field. Now, question is around the potential role of prediction in a hierarchical control system model of the brain. As I'm sure you know, there are other models involving minimization of error, resulting from comparison of top down and bottom up signals. Many of the other ones I've seen so far though, emphasize prediction. For example, Paul recently had a Neocethe on the podcast, who spoke about a predictive control based model. I didn't see any mention of prediction in the model you put forward in the chapter though. So can you comment on why you favor a model that doesn't emphasize prediction and if there are any experiments that could be or have been done to my credence, you know, like, thank you. Do you feel like taking a stab at that? Yeah, I suppose I can do that. So yeah, as I said, I'm not against prediction. I think there's a role for prediction in this type of model, but what people often call prediction is actually not prediction. So at least it's not achieved by predicting the future. What people are usually talking about is can be achieved at least by controlling a different set of variables. So in other words, what through learning what you're trying to control changes. So you're trying to control another aspect of the environment that, of course, is maybe causally related to the variable that initially you were trying to control. The classic example is Pavlovian conditioning, where you have, you know, let's say a bell and flute, right, meat powder. And there, I think what's happening is you are reorganizing the input function of the control system so that you no longer trying to control for the impact of the food on your in your mouth, dry meat powder. So normally you have to salivate. And instead, you know, the input function now is incorporating the auditory input. And so whenever the auditory input, you know, the neutral stimulus is presented, now you're turning on this kind of meat powder controlling system. So that's a very good example of prediction. And people traditionally have viewed Pavlovian conditioning as sort of a simple example of prediction, right? And there are a lot of models that attempt to explain Pavlovian conditioning. But I think according to my analysis, it's really representing an attempt to control a different aspect of the environment. So I'm not against prediction, but I think there is a very important alternative that people have not really thought about, which is just online control of a different set of sensory variables that are actually predictive. You know, so that's for example, when you see a dark cloud, then you turn on your avoidance, you know, control systems in order to avoid the rain, right? But that's after learning the causal relationship, the predictive relationship between the cloud and the rain. So in essence, you spend your life learning, a large part of learning is generating new reference signals and or adjusting your reference signals. Do I read you correctly? Yes, that's correct. So in the chapter, you talk a little bit about how we can move forward without giving you know, a full blown research program, for instance. And I know that you know, in your own research that you're using these principles and applying them to study behavior. So I'm wondering if you can just summarize what you think the way forward is. Well, you ask very difficult questions. So my vision for the future neuroscience, in other words, or for, well, because you outline like first steps in the chapter, right? And some principles that you could follow. And you know, essentially, you give three, three steps of what will need to be looking for and how to test for control variables, right? Yes, I think to begin with, we have to first identify the control variables. And I would start with very basic variables that are not learned or perhaps don't require too much learning because they're easier to study. And then you have to apply the test for the control variable in order to study those. And of course, then you would have to discover the different components of the control system and how they're implemented by the brain. Yeah, so the test for the control variable is simply a test that is mandatory when you analyze the biological control systems. And you first have to come up with a hypothesis about what the control variable might be. And because we know that the output of a controller will systematically mirror the environmental disturbance. So once you know what the control variable might be, and then you can introduce disturbance to that variable so that you would see if there's any resistance from the control system. And if you're correct, then of course, you would have compensatory outputs that will resist the effect of the disturbance. So you basically are applying disturbances that would affect the control variable as if that were not, if it were not under control. And if you're experiencing some sort of compensatory output, then that is probably the right control variable. If not, you have to start over and repeat this whole process. You have to come up with a different hypothesis about the control variable. So yeah, so initial steps toward a whole new neuroscience. One of the things you write in the chapter toward the end is if the above analysis is correct, then a disturbingly large proportion of work on the neural substrates of behavior will have to be discarded. So is the chapter being well read? And if so, what kind of feedback are you getting from the neuroscience community and or other communities? Oh, no. First of all, I don't think many have read the chapter, but obviously you have. And I get this uncomfortable feeling that maybe after this, more people will read it. Likely so. But you wrote it so it can't be that uncomfortable, right? Right. But you know, these book chapters, they're not usually read by a lot of people. Okay. So so far, I haven't received much feedback from other neuroscientists at least. I'm not sure if most of my colleagues even know that I wrote this. So it's hard to anticipate what people might say. I don't know. I mean, what is your reaction? You were once upon a time you were a neuroscientist. Well, right. And we could use some of my own work as needing to be discarded, for example, under this proposed paradigm. So I have multiple thoughts. So that's why I asked you how much of the brain do you think is devoted to, you know, this control aspect? Because it's hard to reconcile, for example, what I consider my own rich subjective experience, right? My thoughts and my imagination is hard to reconcile that with a control system approach. So it seems like there needs to be, and I don't know how you get from a hierarchical control system to what I consider my fairly rich subjective experience. Do you see a path forward through that? And you know, that's just one example. There are, of course, other examples like, you know, different areas of the brain being devoted to different cognitive functions, et cetera. But to you, these are all in the service of control. Right. I'm not sure exactly which aspects of your subjective experience is well, like right now, I can have a bike with control. Okay. I'm sure you're talking about a lot of sensory experience, like you, you see that desk over there, you're not actively trying to control it, right? Right. But I would say that, well, yeah, it seems like your sensory system can provide you with a lot of options, and each of those perceptions might, in principle, be controllable. So remember, the principle is that you can only control what you can perceive. So, you know, of all the perceptions that you have right now, it could be very rich subjective experience. I'm not you, of course, so I don't know for sure. And some of them could be controlled. And of course, we can demonstrate that. So the question is really what happens is when you try to control one of these perceptions. So for example, if I don't like that desk, it's offensive. I, you know, it can turn around or I can walk out or, you know, or if the temperature in the room is too low, if you're cold, then you can leave or you can put on the sweater. And these are all behaviors that I think are generated by control systems. But I'm not sure if the richness of your subjective experience per se is incompatible with the control hierarchy anyway. Well, what about, let's say, let's, okay, so I know that these words are fraught, but the concept of mental representation, right? So I can close my eyes and we talked about imagination earlier. I can close my eyes and I can imagine my future house giant mansion on a hill, you know, in Costa Rica or something like that. So it's that kind of subjective experience as well, just being, it feels like I have a rich representation of not only, you know, my immediate perceptual experience, but of possibilities and I can, you know, of memories, et cetera, those feel like they are mental representations. And you know, the concept of representation I know is philosophically tricky as well. Actually, I don't think representations are tricky in any way. I think they're just literally true because you have signals and you're bringing that representing things, including this big mansion. You know, for example, if that's a real goal that you have and you're working very hard, you're interviewing all these people and let's say your podcast becomes the most popular show. And then of course, you can reach that goal, right? If you're actually doing this for that house. Now, so in that sense, yeah, I mean, I think goals, especially in humans, could be relatively abstract and fancy. But that in itself, I think it's sort of independent of whether you can exert control over it. In fact, I think some goals, obviously, you do try to control. I mean, that's the definition of goal-directed behavior. Go direct to behavior is just a control process. And we say that because you're always comparing, you're ongoing inputs with your desire state. So let's say you imagine that there's this nice house that you like, but your current house is too small and that's something that you're working towards. So that's what I mean by a control process. You know, whether you can imagine something 40 years from now or have fantasies about, you know, anything in the world, I don't think that's so relevant because that in itself does not falsify any control model. Hmm. I guess my recurring question is just, you know, how much to think about the brains functioning as being devoted to control processes. Yeah, I mean, as I said, I think the input function is the most complex part. And all these rich representations that you mentioned are really part of the input function, even when you imagine things. You're using perceptual channels. They're just vague sort of perceptions. And the source is not coming, is not in the external world, but coming from your own brain. Right. So that's the major difference. And that's why imagination, imaginary inputs and actual perceptual inputs will compete because they use the same perceptual channels at the higher levels. So that's why when you're daydreaming, you can't perceive what's in front of you. So I think that actually supports the idea that, you know, even imaginary imaginations can be used as some sort of input to a higher level control system. I actually, I buy that. Before we move on, the word, you drop the word tealiology in the chapter. And I believe you've used it in the past as well. And actually, my last guest, Johannes Jager talks a lot about how we need to, and a lot of other people seem to be talking about this, although this is my bias, I suppose, as my own interests have taken me down a path that is crowded with tealiology advocates. But can you talk a little bit about why we need to reinvigorate the notion of tealiology and accept it as a valid scientific concept? Yes. I think tealiology simply means gold direct. So of course, there's a long history of tealiology, but, you know, telos is basically that the goal were in state. So that has always been a dominant concept used to explain behavior. But I think something happens, you know, after Galileo and Newton, so in physics, in the modern scientific revolution, right, the first scientific revolution, the findings of Galileo and others, appear to falsify this notion of tealiology because the Newtonian physical laws do not contain any element of the final cause. So final cause is that for the sake of which. So for example, you know, Aristotle's example was I'm running in order to become healthy, right? And so what follows in order, in other words, the state of being healthy is the goal or telos. And so that's the purpose of your behavior and your behavior is explained by this purpose. Now, according to modern physics, that can't possibly be true because, again, as I mentioned, there's linear causation. So afficles MA, there's no final cause there. So it seems like everything in the universe can be explained by these simple physical laws and you don't need tealiology to explain behavior. And therefore, people have reached the conclusion that you have to abandon tealiology. In fact, the whole history of modern psychology and neuroscience is the history of various attempts to abandon tealiology, both in the vocabulary and also in the mechanistic explanations. And so in my chapter, I argue that this is simply wrong. This is a huge mistake because it's very simple. It's that tealiology is the main property of control system. So you have everything in the universe follows, basically follows Newtonian laws, okay, with some minor exceptions. But the problem is that there is this class of systems called feedback control systems, which are sort of the exception in that you have to use circular causation to describe their properties because at the same time that the input is affecting the output, the output is also affecting the input. Actually, and the way that the output is affecting the input is quite different. But they're certainly simultaneous and because you have these two equations, things are changing simultaneously, you can't use linear causation to describe the properties of this type of system. So that's the exception. So basically, that means in physics, you study an open loop or things with no feedback, if you will. And in biology, everything has feedback. Everything is telelogical. So I would say that, yeah, in that sense, Aristotle was right. There is final cause. As long as you're talking about control system, of course, he didn't know how it worked. So that's the distinction because the way that it was used by people like Aquinas and a lot of people in history was to argue that, okay, this is sort of a religious argument. So this is the basis for how God is all knowing and knows the purpose for everything on earth. And the reason that the rock is falling is because the God intended the rock to fall. So that's sort of another type of misunderstanding, in my opinion. And that's also why there is this conflict between the so-called scientists and people who believe in teleology because teleology is considered to be unscientific. So I'm not advocating teleology per se. I'm just saying that the properties of teleological systems are basically the properties of control systems. And if you think that the nervous system is a control hierarchy, then obviously you have to agree that it's teleological because, yeah, but it's literally true because the way these things run is that you need this internal state, this internal reference signal to be there first before you can generate the right behavior to reach the desired state. It is the, okay, so the telos is not the reference signal per se, but it is the in result of controlling for the reference signal. Is that fair to say? Right. I mean, I think before you understand control systems, you always get confused about the consequence and the purpose as they're sort of the same thing, but of course they're not, because one is just the signal inside of your brain and you might fail. It's not like you guarantee to succeed in your attempt to control, right? And of course this also explains the difference between accidental and intentional behavior and all that. So I think, yeah, traditionally people get very confused about the concept purpose of consequence, of goal, but once you understand control systems, it's not a big deal. It's very straightforward. So, anyway, that's just my take. Yeah, I know that a lot of philosophers will have a problem with this. Yes, I don't care. Yeah, oh, all right, great. I like the attitude. Before we, I want to ask you about AI, actually, but one more thing on the neuroscience side, or at least one more thing, we can talk about more if you like, thinking about the circular causation in biological autonomous agents. One of the things that you advocate is that actually, what we need to do is instead of studying 40 different animals and averaging their behavior or looking for effects through that, that what we need to do is it would be more fruitful to study one individual, but to do it for a long time and study it continuously in a continuous time frame because of the circular causation, because the inputs are affecting the outputs and the outputs are affecting the inputs because of the closed loop control circuit. Yeah, that's a tough question. So, traditionally, as you know, very well, for example, monkey work. Two is the golden number in monkeys. Yeah. Yeah, so it's funny because a lot of people, a lot of neuroscientists, they like to criticize monkey research because the end is too low. Right. I hear that a lot. Yeah, they use two animals, or maybe three monkeys, and how can you believe the data because they're so few animals? I think that's completely misguided because it's not really the number of animals. It's actually, in the way it's the amount of data that you collect, and the more importantly, the quality of the data. So, in the traditional analysis, you're basically doing some sort of input output analysis. You're manipulating the input because the input is the so-called independent variable, and then you have output behavior output, which is dependent variable. So, you're always testing the effect of variable x on measure y, essentially, right? And so, when you're trying to identify as the function that will connect these two, so if I vary the amount of reward, what happens to the fine rate of the cell, right? That's kind of... Yeah. Or if I manipulate the attentional demand of some task, what happens to the fine rate, and that's sort of research. And this is difficult. Yeah. If what I suggest is correct, then all this work is not worth your time. And the problem is, of course, that the variable that you manipulate is not necessarily the input. Usually, people are trying to identify some effective stimulus, but the effective stimulus, as traditionally defined, is something that will reliably produce the behavior that you like to study. And then, in reality, it's actually not input from the perspective of the organism, but it's the sort of the inferred input from the perspective of the scientist of the observer, and the third person perspective. And that's very dangerous because there is an illusion, what I call... I think Bill Howard's called, the behavioral illusion, which is that... So basically, if you treat the disturbance, which is the input from the eyes of the observer as the input, and the behavior as the output, it looks like you have identified the organism function, or the neural function that's expressing the behavioral output, or the neural output as a function of the input. But that's the illusion. This is not true. In reality, this function does not describe the property of the organism. It actually describes the environmental feedback function. It's mirroring the environmental feedback function. So when the disturbance is considered the independent variable, the output, the dependent variable, this function that you discover is not the real input output function, whenever there is control, it actually reflects the inverse of the environmental feedback function. I know that that's not very easy to understand, but basically, what you think is a property of the nervous system, if you use this approach, is actually a property of the environment. This is probably the most vicious... Miss Step. Yes, the vicious trap in the history of neuroscience. All right, so anything else from the chapter, so we didn't cover... You actually give a lot of examples from history. You talk about Sherrington, Sherrington, and his experiments, and Adrian, and lots of people from the history as well, giving examples of how some famous people got it wrong from this perspective. There's a lot more in the chapter. Do we miss anything that you think we should cover here, or do you think you've dug yourself a deep enough hole? Oh, I think one of the things I suggest, if I remember correctly, for future research, is this concept of using continuous measures, right? Right. Right, I think you mentioned that. And just sorry, I have to use the monkey experiment again. Sorry. Use the monkey example, as you know, you do chair training. The monkey is restrained, and then usually only a limited set of behaviors are measured. Let's say hand movements, are you pressing a button or moving a joystick or eye movements, sacades? But the most important problem, the most important limitation, is that the measures are discrete events, they're timestamps. And then what you do is you require your single, your wrong activity, you get the single units, and you plot these per event histograms, right? I'm sure you did this. I'm quite familiar, yes. And so there's this strange assumption that essentially the only thing that matters in behavior are these timestamps. These events which are actually, of course, created by the scientist, it's not, I think, a reflection of the actual behavior of the animal. It's whatever the scientist considers important or relevant in this particular behavioral task. And then what you look at is the newer activity before or after, or you know, peri this event, and then you reach conclusions based on various manipulations, right? So I think that is very problematic, and this has nothing to do with the theory of control or anything like that. I'm just saying that this is a clear limitation of the experimental approach that you're not even attempting to measure behavior. So I think that's a big problem because traditionally, whenever you look at the relationship between neuroactivity and behavior, you use this kind of approach, and your conclusion, I think, is going to be very limited because you're not looking for, you know, you're not measuring behavior continuously. You might be recording your activity continuously. So for example, in our work, one of the things that we found was that when we measured behavior, behavioral variables continuously, for example, kinematics. And we actually allowed the animal to move. Then there is a remarkable linear relationship between the new activity, between firing rate and kinematics. And this kind of correlation, as much higher than anything ever reported in the history of neuroscience. So I think that in itself is a major discovery, is the nature of this correlation because it's completely unknown. You understand that for many decades, neuroscientists have been trying to find a relationship between your activity and behavior, right? And for the most part, they failed. Whenever they come up with a correlation or coding or encoding, so to speak, the relationship seems quite, let's say subtle. I mean, there is no clear relationship. The correlations are low. And in part, because of these failures, they have largely given up, right? But our results suggest that in fact, every time you measure behavior properly, there is a remarkable linear relationship between certain variables, behavior variables and the new activity. And this is not that surprising because behavior is continuous. Even though we might represent behavior as discrete events at a very high level, for example, that might be what you're consciously aware of. That's not necessarily the case when you're measuring the actual behavior generated. There is a duration, there's a star, you know, it starts at some point, it takes some time and then it stops, right? So calling this a discrete event, I think, is misleading. And at least our results show that you can get very interesting data if you simply measure, if you attempt to measure the behavior. And I think, once you get these novel results, then you have to explain them, right? So how do you explain the fact that you have newer activity that actually slightly precedes the kinematics that's achieved by the body? And it's basically a direct representation of something that hasn't been achieved, but is, you know, with the short lag, it is being achieved by your body, right? So how is that possible? How do you achieve the desired positions if these signals are not literally the representation of the descending reference signals? So Henry, by the way, I love the chapter. And I also recommend it, of course, to everyone else. Can I ask you about how this relates to current artificial intelligence? So on the one hand, you have reinforcement learning. And in this sense, this is, and I know that you've made robots or a robot using, and I'll link to that paper as well, using this kind of control theory approach. And the robot, I know is made of, you know, very cheap parts, but actually performs really well in this continuous manner. And it's a system of hierarchical control processes. What I'm curious about is how this kind of approach could help inform artificial intelligence? It's a great question, but it's too big. It probably requires a separate session. I guess the short answer is that, yeah, I don't think current AI is very useful. And so the main problem is actually the same problem that I talked about before. So for example, reinforcement learning is just another example of the classic paradigm. It's an attempt to do, to explain teleology without using teleology. And so that's why I reinforcement, the concept of reinforcement is circular. So actually, that's sort of my background. I did the learning theory reinforcement learning. So we can talk about that in the future maybe. So obviously, there are limitations there. I will say that what people don't realize is how bad these systems are, how bad current AI is, how bad reinforcement learning is. And that's because they never think about the computational power and the energy, environment, and things like that. So obviously, there has been progress. So it's better than let's say, you know, 20 years ago. But I think a lot of it, a lot of the progress is just in computational power. If you basically use computers from 20 years ago, if you're forced to use those computers, you're going to run these current AI, it just wouldn't work. But I don't think, for example, that the biological brain has a lot of computational power. It's significant, but it's not even close to what these digital computers can do. So I think in a way, current approaches in AI and robotics are irrelevant. But again, that's why I don't know if I'm comfortable talking about that. It's a really big question. It's complicated. And again, I don't want to offend everybody. Of course, there are AI people who care about efficiency, but they just don't have enough constraints. Do you know whether there are AI competitions that respect power usage, power consumption, and sort of normalize for that? Or whether, you know, like not that you can aim to use a system that uses the same amount of power as the human brain, for instance, or something like that. But there could be I think you should, honestly, I think that you should try to do that. And if you have such a constraint, then you probably come up with smart design. And so at least, you know, something in the ballpark, I would say. Yeah. Which is interesting because everybody cares about energy these days, right? So we say AI is where they don't care about energy use, electricity. So, so let me put it this way. In terms of, well, AI and robotics, I mean, you can ask any expert in robotics, whether it would be trivial to build, let's say, a robot with more than 50 degrees of freedom. And I guarantee you that they will say that it's extremely difficult, at least if not impossible. To my knowledge, nobody has done it. But using our approach, it would be trivial. That's the major difference. And it doesn't even require much computational power. It doesn't require anything that's significantly different from, you know, what we used in the published paper. But that's all I can tell you. But you can ask an AI expert or robotics expert how difficult that would be. And I imagine they would have it as impossible. So all right, Henry, there's been a lot of pessimism, I'll say, right? But I want to come back to as a last moment, I want to come back to Cunian revolutions and crises, right? Because on the one hand, crisis, that sounds bad. On the other hand, I hear a lot of this sort of talk in neuroscience for one reason or another. Yours is a specific, unique take actually, which is, you know, why it's so interesting. But it's also a sign potentially of a healthy field, right? Because if people are turning inward and thinking, oh, we're doing this wrong, because what happens after a crisis is the revolution and then a new paradigm. So what I'm wondering is whether you feel optimistic about the future or if you feel like we're going to be mired in this crisis moving forward for another century or so. I would say that overall, I'm very optimistic. I think there is going to be a revolution. That's the short answer. On the other hand, do you think there are a lot of obstacles? In part, because a lot of people don't think there's a crisis, right? A lot of people, they're also optimistic, but for the wrong reasons, they think the current paradigm is good. And now that we have all these new techniques in neuroscience, you just have to use these new techniques. You can generate big data. Obviously, the brain is so complex, so we can map everything. We can map all the connections, all the snaps, we can record all the activity from every cell. That's sort of thing. Obviously, as I mentioned in the chapter, I think that's a misguided approach. You never make any progress in science that way. For the same reason, Galileo did not measure every object in the universe. He didn't drop every stone in the world and measure how long it took them to fall. I don't think that's the right approach, but I think it's healthy in the sense that there are people who are perhaps mainstream and they believe that the paradigm is healthy. They want to maintain the status quo. There are others, people like me, perhaps in the minority, but we think there's a crisis and we like to start a revolution. So I think that's healthy because there could be competition, so we can see who will get their first. So yeah, I think it's exciting and I'm quite optimistic. Oh, that's okay. That's a great place to end it. Henry, thank you for coming on the show. And thanks for your thoughtful work. Okay, thank you. Thanks for having me. Brain Inspired is a production of me and you. I don't do advertisements. You can support the show through Patreon for a trifling amount and get access to the full versions of all the episodes plus bonus episodes that focus more on the cultural side but still have science. Go to braininspired.co and find the red Patreon button there. To get in touch with me, email Paul at braininspired.co. The music you hear is by the New Year. Find them at thenewyear.net. Thank you for your support. See you next time. The covers of the past that take me wherever