 The goal of the brain, at least one goal of the brain is to learn a generative model of the world, an internal model of the world. And it's constantly making these predictions or doing essentially hypotheses testing, right? So it's essentially generating hypotheses and is trying to then match those hypotheses of what's coming in through the senses. And when their deviations are mismatches, those are called prediction errors, and those errors are what are used to then update the hypotheses. If you want to have a very rich way of modeling the world, then what you want to do is have the higher level modulate the dynamics of the lower level. So you need to change the function being computed at the lower level, depending on the task. And so we said, okay, why do we use this primitive modes of interacting with the brain? So EEG and TMS, and let's build a brain to brain, you know, direct brain to brain communication system with them. This is Brain Inspired, powered by the transmitter. Hello, I'm Paul. Today I am in conversation with Rajesh Rao. Rajesh is a distinguished professor of computer science and engineering at the University of Washington, where he also co-directs the Center for Neuro Technology. Back in 1999 Raj and Dana Ballard published what became quite a famous paper, which proposed how predictive coding might be implemented in brains. What is predictive coding? You might be wondering, it is roughly the idea that your brain is constantly predicting, or at least back then, it was roughly the idea that your brain is constantly predicting incoming sensory signals. And it generates that prediction as a top down signal that meets the bottom up sensory signals. And when those two signals meet the top down prediction with the bottom up sensory input, the brain computes a difference between the prediction and the actual sensory input. And that difference, that error, is sent back up to the quote unquote top, where the brain then updates its own internal model to make better future predictions. So that was 25 years ago, and it was focused on how the brain handles sensory information. But Rajesh just recently published and proposed an update to the predictive coding framework, one that incorporates perception and action, suggesting how it might be implemented in the cortex, specifically which cortical layers do what? Something that he calls active predictive coding. So we discussed that new proposal. We also talked about his engineering work on brain computer interface technologies, like brain net, which basically connects to brains together. And like neural co processors, which use an artificial neural network as a prosthetic essentially that can do things like enhance memories, optimize learning and help restore brain function after strokes, for example. Finally, we discussed Rajesh's interest and work on deciphering an ancient Indian text, the mysterious Indus script. All right, I link to all of the work that we discussed in the show notes at braininspired.co slash podcast slash 200, 1, 201. I'm in the process of setting up our next live discussion for Patreon supporters. So if you're a Patreon, check your Patreon messages soon or check in on the brain inspired discord. Thank you for listening. Here's Rajesh. Raj, by the way, I'm, this is the first long motorcycle ride I've taken since I got a motorcycle and I'm in a hotel. So I may not be on the top of my game, not that there is a top of my game, but anyway. You look great. And yeah, I think, yeah, I think it should be, you know, interesting to see what kind of interesting questions come out of the granddad long motorcycle ride. Well, I actually wanted to start with, well, maybe you won't tell me this, what year are you born? Well, I mean, it's on the internet, right? It's on my appropriate Wikipedia period. It's 1970. Okay. So when it was the 60s and you were already good at academia, perhaps before you're born, I understand that you were, you excelled in early years in your schooling. But here's what I want to get to. I would like you to tell me the origins of the predictive coding story. That's what I, yeah, when you were, when it was in the 60s and you were, before you were born and you were thinking about predictive coding, how did you start thinking about that? That's right. Yeah, it was in my previous, you know, life, right? It's a green part, and now to bring up predictive coding. So basically it was, you know, the story is essentially that I grew up in India in Hyderabad and in my high school there. And I got a chance to come to the US as a, you know, 11th grader because I got a rank in the Indian, you know, central science exam that they have. And as part of that rank, they were able to send me with another group of people to do some research. And so basically I got hooked on to research right at, you know, on 11th grade, went to University of Maryland, did some research. I would call that, you know, put them codes research and superconductivity. It was the time of high temperature. Superconductivity at the University of Maryland. And I got a taste of research then. And then, you know, took the SAT exam. Never applied to an university. So I was just waiting for universities to contact me, thinking if my city scores high enough, somebody will contact me. And obviously that never happened. Because that's the way it works in the IIT exams in India, right? You write an exam, the rank is high enough, you get to go to an IIT. And so they'll contact you. They'll contact you. They'll let you know, at least they'll be like a ranking, the announcement and things like that of who got in who didn't. Right. So I was under that, you know, impression. And then luckily for me, there were a couple of universities that did write to me, saying, hey, look, we have scholarships for international students. And one of them was in Texas, a tiny university called Angela State University. Another one was in Alaska, University of Alaska Fairbanks. And given my, you know, preference for, for weather, you can imagine where I went. So that's some family in Texas as well. So I went to Texas from undergrad. All right. I grew up in Texas. So I was, I was curious about that aspect of your development and how you found Texas in general. But that was in the, what early 80s? Yes. And now in our early 80s, I'm not that old. I'm kind of old, but I'm not that it's, it was like late 80s. Late 80s. So it was basically late 80s. And it was the time before the internet. And you know, it was interesting. It was an interesting culture. Somebody coming from, you know, bustling plays in India to like a small town in Texas with cowboys for roommates. Right. You can imagine all the interesting things that happened. And I could talk about that over beer sometime. Yeah, yeah. We'll do that over a beer. Okay. Well, all right. So maybe fast forward. I suppose. Because I do want to buy you a beer now about, and talk about Texas. But. Predictor coding, right? Yeah. Like what? I don't understand the origins of it. Right. Right. I mean, I understand Helmholtz. So I mean, we don't have to go that far back. So, or monvone Helmholtz with inference and predicting the best. Yes. Predicting predicting the best outcome predicting, sorry predicting what you will perceive. And I know that origin story. But in terms of neurons, do you like what is that origin story? Yeah, I think for for me and my advisor at the time, Dana Ballard. So I went to University of Rochester for my PhD. And you know, I was going to do a PhD in theoretical computer science. But then I happened to meet Dana Ballard in the copy room. And he said, hey, you know, I have the summer R.A. So can you work with me for a summer? I said, OK, I'll give that a try and sure enough, you know, that got me hooked to at that time computer vision. And we were looking at this problem of, you know, how do you reconstruct objects that are behind conclusions. Right. So the idea was, you know, let's take the representation from the visual cortex. You have these gobbler filters, these oriented filters. Now if you can recognize objects using this representation. Based on the responses of these filters, can you now also reconstruct what's behind these these occlusions that the objects may be, you know, behind. And then it turned out that, you know, those filters, you cannot just combine them linearly with, you know, the responses of the filters and then reconstruct an image like you would do for a PCA filters, right principle component analysis or the Eigen vectors, right. Because they're not just linear, which is linear. I'll just. Yeah. But even if you do a linear combination of these gobbler filters, they are non orthogonal to each other. So that's when we got into so the idea was, can we then do gradient descent on a reconstruction error cost function. And so you have this idea that, okay, we can reconstruct images that are based on non orthogonal filters, right, the responses. So then you at least to this idea of optimization of the responses of neurons that are trying to reconstruct an image that's been presented based on these gobbler filters. And then if you flip that and say, okay, what if you can not just estimate the responses, but also learn those filters. Then you get this really interesting idea of, you know, at a fast timescale, you do inference, which is similar to what, you know, Helmholtz was talking about, which is inference of what object you're proceeding right now. And you do that using this dynamical system, which is based on gradient descent, right. So the interesting thing there, which was not very appreciated at that time. And I even I didn't appreciate as much was the equation that you get from gradient distance. You have this cost function of, you know, minimizing the prediction error, the reconstruction error. When you do the gradient descent equations, it basically falls out of the equation that you need an architecture that has feed forward and feedback connections. And the feed forward connections in the architecture would be carrying the prediction errors and the feedback connections would be carrying the predictions or the reconstruction of the image. Let's worry about for fear of losing the audience. I'm just going to back up and we'll go Lego bricks. Sure. Yeah. Right. So the, so what is the idea of predictive coding the idea. Do you want me to say it and then you can correct me. Yeah. Yeah. So predictive coding is basically that you have some idea forward in the brain somewhere forward in the brain, some idea of what you're expecting. And you're sending that backward through the brain. And those, those incoming sensory signals that are coming up toward forward of the world of shapes, if we're talking about vision, then they get met with this prediction. And then there's a, a difference between what you're expecting and what those signals are propagating forward. And it's the difference in the predict between the prediction and the signals that gets propagated forward. Is that how does that sound? Yeah. So I guess we were good at conveying the message in those papers. So I'm glad to hear that that's so yeah. So basically the idea is the traditional model going back to Hubell and Vista was always that you have this feed forward pass. So you flash an image, you get a feed forward pass, you know, all the way from V1 V2 V4 and the visual system up to IT. And then you get recognition and then you get cognition of that. You can make a decision. Maybe you press a button. Right. So that's action. But was it back in those days, was it always like voila? There's the cognition of it. Like if it just builds up to an abstract enough edges to a table leg to a table. Right. Oh, there's a table and it magically happened. And that's the way it was thought even in the AI field, right. The whole field of AI was partitioned into all these different, you know, there's people doing vision. There's people doing motor control robotics. There's people doing, you know, higher level AI based on logic. It was very similar to how even in neuroscience and cognitive science, we have these, you know, people focusing on particular modalities and so on. And then the for me as somebody coming into that area of neuroscience and looking at the anatomy. It seemed really surprising that people were completely ignoring the feedback connection. So if you look at every critical area, it's sending not just the feed forward connections, but also receiving feedback connections from a higher order area. And then if you talk to people at the time, you know, who are really famous visual neuroscientists and ask them, okay, what about those feedback connections and they're like, no, no, no, that's maybe doing attention. They're doing something really. Would they really say that? Yeah, yeah, sure. I mean, people thought that those were not really critical for, you know, the traditional kind of perception of objects and those where maybe brought into play when you're doing something like very specific kinds of attention, maybe during sleep and things like that. So a lot of people were not necessarily even acknowledging that those feedback connections could be playing a very dominant role. And so predictive coding flips it on the head. It says, the goal of the brain, or at least one goal of the brains to learn a generative model of the world, an internal model of the world. And it's constantly making these predictions or doing essentially hypotheses testing, right. So it's essentially generating hypotheses and is trying to then match those hypotheses is what's coming in through the senses. And when when their deviations are mismatches, those are called prediction errors and those errors are what are used to then update the hypotheses. So you're sending them back in the feed for pathways. So the feed for pathways are actually not carrying the raw signals, but they're carrying the deviations or errors mismatches. I'm very inside. I think yeah, that was different from what the conventional thinking was at that time. Well, okay. So, all right, let's stick with that insight for a second. I mean, did you. Was that insights and how moment for you? I would say the idea was in the air, right. So I was at that time reading papers by people like David Mumford, for example, who was also, you know, talking about things like that between the talismas and the cortex and cortex to other cortical areas. There were people like James Albus, who was talking about in the context of, you know, AI and he'd already done work, obviously in the cerebellum. That was his, you know, main contribution neuroscience with the model, right, the the more Albus model of the system. That's the cerebellum. But he also had really interesting ideas about hierarchies hierarchies in AI and in robotic controllers and things like that. And then finally, if you really go back in time, there was, you know, someone named Donald McCoy, right. He's actually the father of David McCoy, who wrote that book on AI information theory. So he actually proposed, you know, he had a paper called the epistemological problem for a tomorow back in the 1950s. And even he proposed this kind of idea that what if you can send air signals from one module to another, you know, and then you could then build up this sort of abstract representations at multiple levels of the hierarchy. So what we did was essentially take many of those ideas that have been around and then say, okay, let's actually implement that mathematically. Let's see what comes out of it. And then we showed that some of the things that come out of it, if you interpret neural responses as prediction errors is that you can explain some of these puzzling effects like and stopping contextual modulation, you know, orientation contrast effects, things like that that, you know, would be harder to explain if you just have a feed forward model. This actually gives you a normative explanation in terms of natural images and in terms of natural behaviors. But even if you look back at the McCulloch pits, articles, they knew feedback was important. And they said it was sort of maybe you can educate me on this a little bit better, but it was almost like a nod to the fact when they were drawing their little neuron diagrams, McCulloch pits neurons, right. One to the other. And then, you know, there'd be a feedback loop. And I think they wrote about how it would be important one day perhaps. Yes, yes, I think they they called them loops, right. And they definitely add this idea that loops are pretty important. I think that at that time, there were a lot of people interested in characterizing essentially what we call dynamical systems now. But they were trying to characterize the properties of these these loop loopy networks, right. I think what the the correspondence between the that kind of work, which is, you know, very fundamental rigorous basic elementary work. To now trying to map that on to anatomy is, is I think the leap, right. So you have to that's what Mumford had suggested and that's what, you know, we also tried to suggest was that, okay, let's try to map some of those ideas now onto the cortical anatomy, right. The idea of, you know, there's six layers in the cortical area. There's feed forward connections coming into the middle layers layer four and then there's feedback coming from the superficial deep layers. And if you look at that, you have the vanis and fellman and vanis and hierarchy, right. So can we on stress that monstrosity of the diagram. So so the way that we looked at that fellman, Madison hierarchy was, okay, what if you interpret that as a generative model that evolution came up with for essentially modeling the world, right. And once you interpret in that sense, then it says, okay, if you have this idea that you can sample from that generative model and generate, you know, examples of what the animal faces, right. And it's interactions with the environment. Then inference becomes this idea of, you know, trying to update those estimates you have, those hypotheses you have by the world. So I think the key, the key idea there was, you know, inference as a fast update of the neural responses at the population level in all the different cortical areas. And at a slower timescale using the same, you know, mismatch or errors to then update the weights, right. The learning part, the synaptic plasticity part. That was happening at a very much slower timescale. So your famous paper is the 1999. That must be the most cited paper. Am I correct? Yeah. Yeah. Yeah. So you have that. And in fact, I've seen you in a talk point to it with optimism for graduate students saying, see stick to your ideas. And eventually perhaps they will come to fruition. Or perhaps the keywords. Well, perhaps. I mean, maybe what do you think is the, oh gosh, I would say 5% no, no, 3% what do you think? Yeah. So I think it's hard to say, right. So I would say one of the reasons why that paper, you know, it was, it was published at a time when I think there were still not the kind of techniques you would need to really, you know, test some of these predictions, like, for example, these prediction error neurons, right. So can we look at specifically layer two and three, which is where you would expect these prediction error neurons to be because those are the feed forward connections to the next cortical areas. Similarly, can you look at the deeper like layer five neurons and look at what kind of response is, because in the predictive coding model, the deeper layers of the ones that are storing the estimates of state or in a motor kind of responses and so on. So you have to have the techniques, which were not available at that time. But I think you fast forward, you know, 10 years from then and then start looking at, you know, in the late 2000s, you start to see more citations of that paper. And then now I think it's, you know, there's so many people trying to look at different aspects of that theory. With evidence, you know, for some people against right, so I think it's become very, very, you know, a rich area of research. So I think the theory was maybe a little too early for it's time at that time. But I think the fact that, you know, the nature neuroscience, which is where it was published was, you know, willing to publish it, right, as opposed to saying it's just pure speculation, right, which they could have done. I think it's credit to them for having, you know, taken that that particular paper paper. Yeah, I mean, Occam's razor. It's theoretically great. Right. Yeah. So we had an elegant stew it, which I think was, you know, we ourselves didn't quite appreciate as much. And I think, first and actually wrote like a news and views on it 10 years, the 10 or 20 years after it was published talking about how that one paper really influenced him as a researcher. To really, you know, pick, pick up the, I guess the mantle at that point, because we had actually, I mean, I had sort of moved on to more general models on the Bayesian brain hypothesis and belief propagation in Bayesian networks and things like that. But then, of course, Fristan went on to do the free energy principle based on predictive coding ideas. And then more recently active inference and, you know, there's a whole bunch of work principle. Yeah. But so at the time, I'm sorry to press every on this, but at the time, did you know that it was going to be so influential or not, not, not, no, but did you have some confidence, some, some sense that this is, I know you had a sense that it was a good idea, but I have good ideas every day and they're never good ideas. Yeah, I think it's at that time, I would say, you know, I was not, you know, too confident that it would actually be something that would inspire people to do experiments because there was a news and news that was written on that paper by Coke and Poggio. And it's an interesting news and news. You can see them, you know, they, they, they code Sherlock Holmes in a story and then talk about how the fact that the dogs were not barking at night in the silver place was a story of Sherlock Holmes is an example of predictive coding because, you know, the person was not surprising. So then the deduction is that the person who stole, I guess the horse called silver place. So that's a very positive review. Yeah. So it was a positive review. But before that, I was told by the editor that the previous person out at the as refused to write and use the views. Right. So I was like, oh, there's already people that are, you know, not necessarily going to like this, right. It goes against their way of thinking about how the cortex works. But, but yeah, but, but I think it, like I said, there was not as many citations. There was not like a huge number of people, you know, writing to me. And saying, hey, you know, that's a great thing. So, it's like, okay, so we wanted to get it out. It's out there. Let's see what happens. And then it took, you know, 10, 15 years before it really caught on. Caught on, but were there early detractors also. Yeah, I think there's always been distract, detractors, right. So there's been people, I mean, even now, right. So basically a lot of people don't buy into this notion of the feedback, really influencing the responses. And then the prediction error would be, how can that even? Oh, well, specifically with the prediction errors. That's a different. Yeah. So feedback is obvious in the brain, but even feedback carrying predictions from a higher area. Right. So even that's not option of that is still debated for particular tasks. Right. I think there's really clear evidence now that for sensory motor tasks where there's the animal makes a motor movement. And then there's an difference copy that allows you to make a prediction. Right. I think there's a lot of evidence now coming from, you know, David Schumann. From, you know, David Schneider's lab from New York, your killer's lab and so on showing that, you know, when there's local motion or there's a four lamp press of a lever and there's an auditory response. You get a prediction in the artery cortex. There's a suppression that looks like a prediction error signal there. So they definitely for the motor, I think you see that if it's purely, you know, sensory, which is, I would say I would argue that since some sense, you know, a purely sensory, you know, experiment typically has like a fixation and then you're flashing something. It may not necessarily be, you know, the kind of naturalistic behavior that would elicit predictions and prediction errors. Right. So, but there have been some reports about these error like responses in those situations as well. Right. So, yeah. Yeah. That's the, that's where I think we, there were initially, you know, there was initially some resistance in terms of the fact that there wasn't at that time, you know, any evidence for feedback, conveying predictions and feed forward, conveying prediction errors. Except for these contextual effects like these extra classical receptive field effects. And even that some people are explaining it just through lateral inhibition, right. Which can be one way to explain that. Yeah. So, I just want to, so what is the lesson here? It's not that predictive coding is universally accepted still, but now the technology is better and we can have better and better, better measurements of hypotheses generated by predicting the data. So, I think that the data is generated by predictive coding framework. So, one lesson is keep going grad students, it might get better, but for a, so the jury's still not out, I guess, right. Yeah, I would say there's evidence for some parts of the theory. And I think as a theorist, you know, I feel like our job, you know, all the traditions out there and our job is to propose theories that are, you know, explicit enough in terms of connecting to the anatomy. And just what specific enough that they can be shot down right they can be falsified right we basically want to have the ability to falsify theories and in the process of that if it generates some new data that then really sparks a new theory right. And then leads to feel forward I think that's the job right and we should not be afraid to propose these theories as long as they're sensible they match the existing data right which is what we were trying to do at that time was saying, okay, we have these puzzling responses called end stopping or contextual effects. So, we have the anatomical evidence saying there's feedback connections so let's propose this theory and let's see what happens right if you start doing experiments. So, I would say the same thing now right look at what's out there what people have collected in terms of the data and look at the computational aspects also right so what is a brain really trying to do. Let's look at it and yeah, I mean, that's what I was about to ask you because so do you see predictive coding or the family of predicting coding approaches as some sort of general theory about. What the brain is supposed to do you know what the brain is doing because you know there's the free energy principle now. There's Jeff Hawkins everything is prediction. You know these things go back years obviously and everyone points to Helmholtz and there is someone before him. And there's chat GPT and transformers which are also based on prediction right that's right and we love them. I would say it's just part of the story right so prediction is important because you know animals have to predict to survive I mean ultimately it goes down goes up. It's this idea of you know at some certain point in evolution you know the brain start building models of the world to be able to predict to anticipate right and so I think that's an integral part of if you're learning a model of the world that comes with this you know benefit of you know you can use that to generate hypotheses you can use that to generate predictions. And that I think is an integral component you know this idea of world models or predictive models of you know intelligence you know either artificial or natural right it gives you a lot of benefits and it would be surprising if evolution came up with that you know way of handling the uncertainties of the world and you know to compensate for delays as well from you know your sensors and your your muscle sensors all the way to the brain right so there's always going to be delays. So if you're too late to react you're probably going to get killed right if you if you you know also if you you know have the ability to predict and have a model then you can do planning right you could essentially go forward in time and then you can do planning and that and then that leads to abilities that allow you to have much more sophisticated behavior is then if you're just a reactive organism right. So I think there are a lot of reasons of at least from a computational point of view but probably also from a evolutionary you know biological point of view to have something like an internal model and prediction that comes with it. Okay so so so Ralland Ballard was a 1999 and then the sensory motor theory of the cortex I think I have the name wrong but I will write no flash it up there which you've recently presented which you've been working on for I think a long time now. Not so long I would say maybe like four years like three four years that's not so long at all in turn and research to age. Okay well so that's what I wondered like I'm not sure if you flipped in that regard it sounds like you've somewhat flipped but if you if you have like how that. Who did did someone drag you out of perception or did you climb out yourself or. I think it was multiple things so you know I think it was just this realization that you know if you think about what is the the purpose of you know having a brain the context of evolution right so going back to some of the early you know. Creatures that were trying to for example you know move to towards places that have more nutrients because you don't have enough nutrients so. But hang on let me just stop you there I'm so sorry to interrupt but they're moving to a place with more nutrients. Because they can already perceive whether there are nutrients there right so the. You need perception way to minimize the air right so ultimately you're trying to. Perception came first. You need both right so you in order to you can you can do you can do random movements but you still have some notion of perception because when you. Taste the nutrients or when you actually sample the nutrients then that is like perception ready for the call out perception so. I think the it's kind of like a the sensory and motor part are integrally tied right so. The motor part allows you to change your location or you know sample a different part of your environment but then. If you want to know was that successful or not right then you don't need you don't need sensation right of some sort to know okay what I did was. You know good for me or bad for me right and that's what we're calling perception in a very. In a courses level right but so do you think all right so I guess we have sensation without brains. Or perception sensation perception we can use the minute changeably all those dangerous but let's say. Light sensors right. Artificial sensors no well you could do artificial but I meant biological right pre movement what I guess what I'm wondering is like. You know that evolutionarily why did brains develop and that is in some sense. Moot point because they are integrated like you said. But I think you have to perceive before you can move. No I think it's I mean I don't think it's one on the other right so essentially I mean you could say perceive because you're you're perceiving the fact that maybe you're low. In nutrients inside your body right so you're hungry I mean you could think of that as a kind of internal perception right. And that drive you to then move right but then when you go out and you actually consume some nutrients then your internal state may change because you're not perceiving it as okay I've consumed food and so I'm more. But if you move without any perception then you can't. You can't you don't know exactly exactly so you do need perception but at the same time you know. If it just I mean it's just a creature that doesn't move at all but it's just perceiving I mean that also doesn't quite make sense right does a venous fly trap move to you. In the sense that it does have an action right of you know grabbing the insect and digesting so I guess but it doesn't move in the sense of you know creatures moving right but but in some sense maybe it does. If you consider the movement but again it's it's you know it's not a moving organism right like the one that be associated with brains right yeah right yeah. Yeah. But it's been interesting yeah go ahead well these are great questions to think about right in terms of oh no I'm sorry I'm getting a soft I'm telling you man I had a long motorcycle ride and my brain is fried and I'm sorry if I'm a little squishy myself. But sensory motor coordination that's what. Yeah. Back to this was a 25 year divide between these two papers I'm just going to focus on these two. It's like two of I think you've published in total probably four papers or something like that slightly over on. Yeah I guess in total. Sorry. All right so but but it felt like a big reveal when you added the motor aspect to the predictive coding and we just talked at length about how you have come around to thinking that action and motor behavior is important. So can you maybe just give a summary of how you incorporated it and what people can expect if they read this paper. Yeah so I think the the first observation that really prompted me to go on that whole journey was the fact that there were all these new results coming in showing that even primary you know sensory areas or quote unquote sensory areas like V1 you know S1 or a1. We're being influenced by motor you know activity or actions like you know there was papers from the Korean Dini Harris lab there was you know papers from. David Schneider's lab showing that you can actually get these responses that are motor related but they're happening in the traditional sensory areas like V1 or a1 right. Not only that but then the other interesting observation was anatomically again right if you look at anatomy the layer five cells right there's like five a five e but the layer five cells even in the primary sensory areas like V1 a1 S1 right some of sensory cortex primary from a sensory the layer five in all these areas are sending axons to motor sub cortical motor areas right like as the V1 sensor to superior callicles A1 sensor in pure callicle is. It's all completely connected it's a ridiculous system if you want for an engineer I mean it's it's not completely connected in the sense that you don't have like the superficial cells sending you know axons to superior callicle is it's. Yeah we don't know that yet well okay so there's always the possibility right but I think that was the other you know interesting anatomical constraint that we were looking at and then the funny thing there is okay it's not just that you know you're going from layer four to layer two three and then to layer four. And then the layer five and then that's right now layer five is sending information back to layer two three right there's a loop there between the superficial deep layers what is that loop doing right so and if the if the superficial layers are receiving sensory information from layer four right and then the deeper layers are sending you know so that's the way we're going to do that is to the most basic version of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the basic idea of the insecure information. quoted at the end, the master the things. written a, the didn't go to General Miller court....this image model, therefore, there's some very limited 이거를...) focus. the moral of the pro organizations is that this was the process of the general 만들어 words. the moral of theotte...colon micro-colon... może means the basic figured analysis of the basic idea of the basic idea of the freed... emphasis on the basic and the medium... Oooh! You established calculations was given, had a Malum and no bad Movie YouTubers on this..and when you get the ideal or not right, you have to explain the following class, which is commonly because of high изб tapa or kid groups etc. And I was going to be using the Frogs to explain this project...the doll what the shit is supposed to happen in pasa like a fantasy episode inishi the student who's been had another blacked one in manly nature.... An intermediated reading and modernства.... So as far as the scientists really question the basic idea of the But then reinforcement learning, the goal is to learn a policy, which is given a state of the world, what is the best action I can take? So that is called a policy. It's a function, right? So for any state, the animal is in, it's going to say, okay, I want to take this action because that action is the one that'll let me achieve my current task, right? And so if you now combine that the model, which is at the top and then the policy at the bottom, right? So you have one that is making predictions of what the next state is going to be based on your sense reinputs. And the other that is saying, given that I'm in this state, here's what the action is, is that's most suitable, right? Then you can have this kind of a cycle between, okay, prediction, action, prediction, action, prediction, action, right? And that is the general idea. And that's what we suggested as a module, like a sensory motor module for any cortical area, right? And it's going to operate at its own spatial temporal scale, depending on the kind of inputs it is getting, right? So every cortical area has its own spatial temporal scale and modality, depending on the kinds of inputs, it's getting in the kinds of outputs, it's controlling, right? Or potentially controlling. And then the last thing we threw in there was, okay, what about the different hierarchy and the different cortical areas interacting? Why is there a feedback connection or a reciprocal connection? And so it turns out that from a computational point of view, if you want to have a very rich way of modeling the world, then what you want to do is have the higher level, modulate the dynamics of the lower level. So you need to change the function being computed at the lower level, depending on the task. So if my task is to drive to the grocery store, right? Then you basically want to load up the program, right? For getting into your car, figuring out where you're going and then driving. So you have all those, you know, quote unquote programs that are policies, right? These are these policies that are already been learned that are being plugged in to achieve your current goal. But if your goal is now to go to your friend's house, it'll be similar programs, but the sequence may be different, right? Or if it's a cook something, right? Again, it's the same idea, right? You load up a different program. So we're suggesting that that kind of, you know, schema or in a loading up new programs can be done through top down modulation, maybe prefrontal cortex loads up in the lower areas, these programs and corresponding dynamics of what to expect, right? All right. So we'll just say it's in the prefrontal cortex. So how does the prefrontal cortex come to be that way? Yeah. So our hypothesis is that it starts off with all areas operating, you know, in terms of their respective, you know, spatial and temporal scales, right? But by the time you get to the prefrontal cortex, you know, you already converge, you have information that is now operating at a much longer time scale. And the abstraction level has gone to the point where it's now operating at the level of abstract actions. So there could be a population of neurons that are coding the current context or task, which is saying right now, okay, I want to go to the grocery store. That's like a goal that got instantiated, right at the highest level. But it's maintained until that goal is achieved, right? And while it's being maintained, it is modulating all the other areas that are involved in achieving that goal, right? And that involves even like the basic lower level somatic, even somatic sensory cortex, we show cortex auditory cortex, they're all now have that context from the higher area saying, here's what my car and goal is. Now let's see if we can achieve that goal, right? And then you get your, I don't know what you would get. My grandmother would get cookies definitely at the grocery store. You get those cookies. And then how does it switch? Yeah, so the idea is it's a hierarchy. So as you achieve the sub goal. So basically the idea is that a complex problem, right? A complex task is split up into its sub goals, sub tasks. And those are intense, split up into sub tasks all the way until you get to the point where you're operating at the level of, you know, milliseconds and controlling your muscles, right? And that's happening in the spinal cord loops, right? So the spinal cord is controlling things at a very fast timescale. But then as you go up the hierarchy through the different, you know, areas, including, you know, the midbrain and then you go all the way up to the cortex. You start to get longer and longer timescales. And then that's where you start to get, you know, these sub tasks being achieved. And then those in turn cause a flip to the higher level thing. We go to the next goal. So you're going from one goal to the next goal to the next goal, right? But the other goals get programmed. Yeah, so that's all about learning, right? So you have to learn, and that's what, you know, some people call that curriculum learning in the AI literature. But as babies after we're born, or even before we're born, the wounds, we're starting to learn these, you know, modules of, okay, what happens if I move my hand in this way, my arm in that way. But then once you're born, you're starting to grab objects, you're trying to reach for objects, you're trying to grasp different kinds of things. So you're building up this repertoire of, you know, action policies, right? And the corresponding dynamics that go with the action policies. And the idea is as you go, you know, through learning through your, you know, toddler years and so on, you're building up a very rich, you know, a set of primitives that eventually be composed for solving more and more complex problems, right? There's so a lot of rules, but I think that's kind of the way, yeah, right? Right. Right. We had, I guess what I was asking was what, so, I mean, I think we've all had the feeling like once you're done with a goal, you're like, well, all right, what now? And you kind of feel lost for a moment until you realize what else you have to do. But what I'm wondering is like, how those sequence of abstract goals, if you have an abstract goal, how does it switch? Once you accomplish one, you're going to do the next one. And then the next one, how do you, how does your prefrontal cortex go? Well, that's a great question. I think they're in the, in the model at least you start off with some higher level goal, which I guess we give it or we say here's a task, right? And then the way it decomposes that is, as you know, as you go down each higher level abstract action or policy, it generates a function at the lower level. And that function basically has as the outputs that remember functions are basically state to action mappings each of those actions is now another abstract action, which is like a sub goal, right? And then that in turn generates another function at the lower level all the way down to the spinal cord level, right? And that is what we're saying has to be learned, right? You have to learn each of those sequence sequences, those functions that capture the sequence of sub goals. But we're saying it's the same module replicated at all the levels. And that's one of the things that, you know, for me, you know, the mound castles whole idea of the cortex has something similar across, you know, the algorithm may be similar across different cortical areas. I mean, as a theorist, I mean, you always like, you know, have that fascination with those kinds of ideas. And so the challenge here was, you know, is there something like that that we can come up with from a computational point of view? And then of course, the brain may or may not implement it, but let's try to come up with something like that, right? And it turns out that this active predictive coding idea seems like it is versatile enough to tackle many, many different kinds of problems. But it remains to be seen if, you know, how well does it map to something that the brain actually be doing? Do you believe it? Do you believe Mount Castle that? Yeah, sorry. Not like, you know, exactly the cortical column is something that where everything is, right? But what I believe in this more broader idea that, you know, if you take any piece of cortex, you know, chunk of it. And then you give it even to trained, you know, neuroscientists, it may be hard to figure out which part of cortex that is, right? And of course, there's, you know, more M1 versus V1. Yeah, yeah. But 90% is that is who they're connected to, not what they're doing, probably. Exactly. Yeah, yeah. And I think that's a really interesting finding because I mean, if you would think, you know, that language area should be programmed very differently from vision areas and so on. And if you sort of train traditionally, you would think, okay, visual cortex is doing edge detection, right? But then if you look at the very cortex, there's no edges. So they can be doing edge detection. Right. You're doing something completely different motor cortex, right? It must be doing something very different, right? Right. But it's really intriguing if you think about it in terms of, okay, what if they all have components of this kind of, you know, sensory and motor aspects to them. And it's just that in some areas, some got more emphasized than others, but they still have the basic primitives, right? Of sensory, you know, inference as well as motor control, right? And they're operating together at multiple levels. You're a BCI brain computer, brain computer interface person, an engineer minded person. This is maybe a throwaway question, but given, all right. So what you just described is maybe it's somewhere in the prefrontal cortex. There's this higher level, more abstract goal. And then it gets implemented at more at lower and lower levels until it pans out in musculoskeletal system. Where would you, if you were evolution, where would you move next? Like, do we just get more and more abstract? What does that mean more and more abstract? What would be a more abstract goal than, you know, make honoring my great, great, great, great grandmothers legacy by, I don't want to be stereotypical, but by doing something the way that she would do it, right? Yeah, yeah. So basically you're saying, okay, what is the next sort of evolutionary mind? Yeah, I will be, you know, in 10,000 years, yeah, what, how can we can't guess that? Because we've been very bad at it. We can guess it, but we've been pretty bad in terms of, we can't, we're very good at guessing and being wrong. Yeah, so I would say, I think, I mean, in terms of, at least human evolution, we see that we're essentially, you know, biologically, we may not have added, you know, new cortical areas or new brain structures, but we have been really making amazing strides in terms of adding tools, right? And the cultural knowledge and tools. Perfect segue, by the way, to BCI, but yeah, yeah, exactly. So, so basically I think if you think about it in terms of, you know, we basically augmented ourselves, right? So humans augmented themselves, originally using tools like rocks, right? And sort of made these little blades to cut meat and so on. And then we, of course, augmented ourselves in terms of wheels to move faster because our legs can only go so fast. And then of course, we went beyond that to, you know, we had, we were able to fly with airplanes, I mean, more recently, right? And then a similarly memory, right? So memory augmentation. So, you know, we could only hold so much in our memories, but then we started writing, we had language, so we started writing things down. And then we were able to pass it from generation to generation. So that's another big, you know, tool, right? In terms of cultural knowledge accumulating over time. This is the most beautiful thing about language, I think. Yes, it's an amazing thing, which other animals, unfortunately, don't have, right? So I think the, that sort of leads to this idea of, okay, so if it's really tool, you know, it's really tool use, right? And nowadays, we all, you know, hang around with the, you know, these devices, you know, in our hands and, you know, in our pockets. And basically augmented ourselves in terms of knowledge and access to information with these kinds of devices, right? And so people in the BCI world and brain computer interfaces, you know, thing, maybe there is a progression there. And if you really take that idea to the extreme, then if the brain itself biologically is limited in terms of its speed, right? And in terms of its memory capacities, then would it make sense to then augment it with, you know, artificial memories and artificial processing capacities and artificial communication capacities, right? And that sort of leads into the whole augmentation side of brain machine interfaces or brain computer interfaces, which is an area that is, you know, not something most, I think academics want to really go too much, because there's a lot of ethical applications. So most of us tend to stay on the medical application side, right? That's where the funding is, and that's where, you know, a lot of important contributions have been made and need to be made. But, you know, there are companies, you know, and people in the tech world that are really, you know, interested in that aspect, the augmentation aspect, right? Yeah, and uninterested in ethics, but so how do you navigate that? Yeah, so I co-directed Center for New York Technology here. We were funded by NSF for about 10 years as part of an engineering research center. And we had a team, a new ethics team, right? We still have them, but during the grant, what we did was for all the projects, we embedded a member from the new ethics team into the engineering team itself, right? So every engineering team that was developing a brain computer interface application had an analysis who was giving them active feedback about, okay, you know, what is the end user going to think about this? Where are the long-term implications? And the engineer? Did your team hate the ethicist? How did that work? I mean, I don't need to ask you how you feel personally about it, because it is a conundrum, I think from a technological point of view. But that's like embedding a philosopher into a research lab or something like... There were actually many of them. Of course, of course there. Well, that's all philosophy has left is ethics, right? No, I'm just kidding. But, okay, but yeah, I mean, was the resistance, I mean, you know... No, I think I don't want to have to deal with that kind of stuff. This is what I'm saying. And I admire you for doing it. No, I think it's important because as engineers, we're really excited about building the next great thing and, you know, doing something very novel. But at the same time, the consequences may not be anticipated by engineers as much as, you know, people that are more trained to anticipate those consequences. Yeah, but the consequences are always bad. Right? Not always, right? I think there are some constructive, you know, things you could do. For example, you know, there were actually, you know, some interesting observations that this is made when they talk to the families of patients that had, for example, deep brain stimulation, right? And many times a family member provides insights that may not be very obvious, like they may be the personality of my partner change right after they got the DVS or the mistake, you know, the actual patient may say, you know, sometimes I feel like I've lost my sense of agency, right? Because there's this device in there. So, so then the question becomes, okay, what are the ways in which, you know, you could restore that sense. If it gets the point where the person feels like they've lost their sense of agency, then is it okay to have a kill switch or some other way to at least provide them some relief. Right? So there are ways to have, you know, engineering solutions. If you know about some of these things that the patients are going through, right? And I think at least that's a good way to then find ways to address issues before they become, you know, too bad to really, you know, address the commercialized right the technology gets commercialized maybe too late right point in time. So that's one of the hopes, right? But you're right that many companies may not necessarily look into any of these issues, right? Or like even academically and research wise. So we're talking about you mentioned agency. We're talking about concepts that not the philosophy has settled on anything ever, but concepts that are very much in the air in terms of like, well, if I mean my personality has changed. But if I add a BCI or, you know, some sort of prosthetic to my brain, and then it will, is it the press then is it the fault of the prosthetic or was that a deep seeded thing in me or what, you know, so how who's responsible and, oh, ethically, I don't want to deal with it. So yeah, yeah, those are great questions that I mean, we've been, you know, talking about them and we've been discussing those and I think it gets even more trickier. Just think about it in terms of, okay, now we have DBS, which is, you know, open loop stimulation, just delivering some constant current. Let's talk about AI, right? So if you add AI into the picture that adapts. Well, hang on before you do that. So this is something that you've done. Yes. And are continuing to do. So just, and I'll introduce this in the beginning, but I mean, there's brain net, there's neural, neural co processors. I don't know. I'm not sure how you would like to describe it as sort of an introductory idea, but you've done two people, you've done three, I don't know how many, how many people of you got up to in terms of collaborating. Yeah, so I think the idea there. So we're talking about brain to brain direct communication or, you know, brain net person. We had three people collaborating directly using their brain signals to solve a problem that was, you know, in that case, which is just a Tetris video game, right? And this is one person gets their has their brain signals, you know, indicated, yeah, and stimulated and the other two get to interact. Right. So the idea here was, you know, the technology is not there yet in terms of actually doing brain to brain communication, but the idea was if we take up this challenge of, okay, let's see what we can do with the technology we have now as a way to spur people to talk about this technology so that you can put safeguards now, or at least start thinking about safeguards before it gets too far away. Right. So we said, why don't we take technology we have now like EEG, so we all have many people have EEG equipment in their lab. So we can use the EEG to decode simple things like, you know, the, you know, the, I mean, we have a lot of things, you know, we have to do a lot of things. You know, the, if you have like a flashing light, it's called steady state visually work potentials, you can decode the frequency at which you're staring, right. So if you're staring at two different flashing lights, one of them will trigger, you know, oscillations in your visual cortex and we can decode your intention. Or if you imagine making your movement like move your hand, right, or imagine moving your hand, you can decode that from the motor cortex. So what we said was, okay, we can use EEG for decoding and let's use TMS, so transcreenial magnetic stimulation to deliver information directly to the brain, right. Which is just for people listening to TMS is like when there's a coil outside of your brain and there's a pulse aimed at a very small part of your brain. It delivers a non invasive, non damaging pulse in your brain and then depending on what function or the effects, potentially effects how you think or your behavior. Yeah, and especially if you deliver it to the back of your head, the visual cortex, and you see what is called a phosphine, which would be a little spot of light or a bar or something like that. And so he basically used like a more scot kind of idea. So the flash was, you know, just conveying binary a bit of information, right. And so we said, okay, whatever we use is primitive modes of interacting with the brain. So EEG and TMS and let's build a brain to brain, you know, direct brain to brain communication system with that. And this was several years ago and we did some proof of concepts and publish a few papers on that. Just as a way of, you know, not necessarily saying, look, we can, you know, actually commercialize this technology because obviously it's we cannot. It's too bulky. But if you just think about companies that are now developing implants, then you can imagine once they have implants on multiple people, then they can start doing this if they can stimulate the brain and record from the brain, right. It's by directional BCI by directional brain computer interface. Then you can start to do these kinds of experiments and you can start to implement these kinds of systems of recording from one brain, stimulating another brain, decoding and encoding the information in another brain and so on. And that's where we get into augmentation, right. So now we're using technologies, neuro technology for augmenting the, in this case, the communicative and processing capacity of the human brain. So, so where are you now right now with these? Right. So once again, I think so we are not the business of really like going on the commercial routes of what we're doing is a lot of theory. So what we're talking about. People usually ask you that and their question is really like what future or human are you creating? Is that their question? Yeah, I mean, some people are very much interested in that, the singularity and works like that, right. What's that going to be in the future? Of course, there's some people who want to merge with AI. So that's the whole other crowd, right. Who want to actually do you want to merge with the AI? No, not really. Yeah, I don't understand it. But I think that what we're doing is in some sense, you know, we're saying, OK, if you really are thinking about processing information from the brain and, you know, making sense of it and sending information back to the brain, that's what we call a co processor for a brain. And working on as a brain co processor, because this idea that there's a device that essentially a tool for the brain that can both decode information from the brain and encode information back into the brain. So that what that means is like, so it's listening to the brain and then it goes into an algorithm in it. So in terms of modern AI, it sort of categorizes what that brain process is signaling. I almost said understands it and then transforms it into a signal to inject into the brain. I'm sorry, if these are two low level descriptions, but. I think that's just one way to think about it. And of course, the way it would have to work would be that that that co processor has to have AI in it of some form. And so we suggested a neural co processor, which was a neural network, so an artificial neural network. And so what we have there is an interaction between artificial and biological neural networks, where both of them are adapting. So it's a co adaptive system. Right. So. And the challenge there is how do they co adapt to really achieve a goal. Right. So. And from a point of view of medical point of view, if you, for example, are trying to replace lost function, like somebody had stroke and you want to be able to restore their movement, then this could be a device that could replace that lost function of the cortical or other subcortical circuitry. And the AI has to train itself and the person now has to command this AI replacement circuit, right, to do what it, what the person wants it to do. So then that becomes an interesting AI problem, right. So how do you ensure that the communication between the human brain and this artificial device achieves a common goal, right. And that's what we did with the neural co processor was we say, hey, look, you know, if the goal is, for example, reach for an object when the person cannot reach the object, but then you can stimulate, let's say, the spinal cord make the person reach that particular object. Then the error is now in the space of, you know, visual error or so there's an error signal. Can you do back propagation, for example, right, which is a standard thing people do in AI, right. But the problem is back propagation here, you'd have to do it through your body and your brain, right. You have to do it through the back propagation by definition. Yeah, but what I mean in terms of ideally, if you want to train your neural network, that's delivering the stimulation. Right. Then you have to get that error signal somehow and the error signal unfortunately is now in the space of an external task, right. So what we suggested was, okay, for all of these AI is they need to have an internal model, this forward model of in this case, your brain dynamics, right. So how your brain reacts to stimulation. So it's like a forward model of, you know, the action here is stimulation and then it's going to cause your brain dynamics to move in a particular way. And if you're able to predict that dynamics, then you can come up with the best stimulation to give for achieving a particular goal, right. So it becomes again a control problem, right. So how imperfect, so I mean, these are things, I just, I'm a neuroscientist, but I pondered these things, you know, like, I mean, one of the most amazing things about the brain is how adaptive it is. And sometimes I think, well, maybe that is the function of the function as if there was a function, but the adaptability is like almost the answer. So what I was going to ask is, how wrong, you know, can it be for the brain to still be able to deal with it, right. Is that a testable question? Like how bad can you make the signal relative to how quickly the brain can learn it as a terrible poorly phrased question. It's actually a very important question in, especially in the sensory stimulation area. So people that are trying to restore the sense of touch, for example, from an artificial prosthetic device, you know, stimulating the somatosensory cortex, right. There's a big question there in terms of, you know, should we make the stimulation be as natural as possible. So we make the sense of touch, right. When you stimulate the somatosensory cortex, you typically, patients typically report, okay, I feel like it's pins and needles, right. It's not quite the nice sense of touch I get when I use my own hand, right. And then you say, well, just wait a week or two and that won't be or something like that. You could say, hey, you know, you just not used to it. It's a novel signal right now. But if you keep using it, maybe you get used to it and that becomes a natural, you know, sense of touch. This is like training. This is like trying to convince my children that, oh, don't worry. Keep practicing. It'll get easier, you know. But it sounds pretty painful. Yeah. So that's the painful as a key part of part there because if you are not really delivering, you know, a current code naturalistic stimuli, then it may take much, much longer. Right. So I think there's a trade off there in terms of if you're able to speak the language of the brain in some way, right. Basically, you're, you're delivering the pulses electrical stimulation, optical stimulation, the way that the brain can parse it more easily. Then you may be able to learn much more quickly than it's if it's an artificial set of, you know, pulses like stimuli. But it's interesting problem in terms in terms of natural then is that just noise or is it like the natural statistics of the world. It's more the way that the neurons in that particular area are receiving information from other neurons, right. So for example, if you know that, you know, in the population level, there's a particular sort of frequencies that are operating at that scale, right. Like, you know, beta frequency oscillations or something. So then you, you can think of delivering the stimulation at some particular phase of that oscillation or you're trying to synchronize with that oscillation. Maybe that is better than you just delivering it at irrespective of what's happening in that brain area. So the bottom line is you need to be recording as well as stimulating. You can't just be stimulating the brain area. You need to be recording to know what's happening in that brain area and then change the stimulation according to what's happening at that point in time. To consistently deliver, you know, intelligible stimulation within a window because that's anti-fetical to the idea that the brain can handle a bunch of a wide range, right. So a brain area doesn't get to decide the signal incoming. But what you just said is that you need to do it in a way that it's expecting it's a very predictive coding outlook, by the way. Otherwise, it might not work. Yeah, it's a way to enable the brain to learn faster. Like I said, I mean, it's possible that you could you could not pay attention just to keep delivering something and eventually the brain may figure out how to interpret that stimulation pattern, right. But the question is how long will that take, right. And so it may happen, you know, quickly, it may take very, very long or maybe it'll take forever. Right. So in general, it makes sense to have some feedback about what's happening in that brain area and as you're delivering the stimulation. Can we partially get to this by doing learning studies and maybe just probing the historical literature and learning studies. So, you know, there's a modern learning studies are becoming more better and better. And I don't know if there is an answer to the proper way to learn X yet, like the most optimal. I know that there's a lot of people who make a lot of money who say that there is, but I mean, I sort of intuitively think you got to do it. I think I feel really bad at first. And that's how you're going to eventually learn. But it also depends on the goal. But do you think that we can, is this an experimentally behaviorally tractable problem that could help answer these issues because you're speaking about the activity in the brain. But then we're eventually talking about behavior. Yeah, it's an interesting question in terms of, you know, how do you study what's happening as the brain is interacting now with this external device that is sending direct input into the brain. Right. Or just the optimal input to, yeah, if you're going to use these external devices, right. And so the neural co-processor idea was one way to get at it in terms of saying, okay, if you are able to adapt the neural network that's delivering this stimulation to minimize the error, you know, in the external's task space, then you're leaving the brain of having to do a lot of that learning. But of course, the brain is already trying to learn. So it will be changing as a non stationary system, right, which is why we call it a co-adaptive system. And that's where it becomes tricky. So if it's only one side is adaptive, right, let's say the brain is adaptive, but then you have a fixed mapping for your stimulation pattern, then that all the burden is on the brain to learn that, right. But then if you do it where the both the systems are able to adapt, then the challenges, can you make it, you know, they're both optimizing the same cost function or same optimization function. And that's where the interesting engineering challenges, right, to make it an adaptive co-evolving system, right. And that's where I think the future is probably going to go if you're going to use AI for these brain computer interfaces. You want to do a quick segment of epiphenomenon or causal. What was that again? You want to do a quick segment of, is this an epiphenomenon or is it causal? Oh, OK, I get quiz ready. Yeah, yeah. Well, yeah, opinion ready oscillations. It's, it's, I would say it's causal. Yeah, consciousness. I'm happy phenomenon. Oh my God, we're done. I just, I just, I just heard someone say that. But I'm taking the like the most liberal definition there. OK, there's a little only two. I just, I heard someone I respect say consciousness was that be phenomenal. And you're talking about oscillations. I just want to be a little bit of that cutting guys there. So yeah, let's go with that. OK, all right, great. That's staying in, by the way, I'm not going to edit that out unless you force me to. Sure. OK, before we, so, all right. So I'm looking at the time right now. And first of all, what have we missed about the neural? I'm going to point everyone to all of your work. But I've been punchy and jumping around. So what, what have we missed in terms of the neural co-processing and or, you know, brainnet and the. We haven't used the term telepathy, right, which is sort of the coup de gras, the pinnacle, you know, what people, the spooky term, right, that these things imply. I mean, is that a goal? Well, I'm going to stop interjecting. You know, what have we missed in terms of what we haven't spoken about with with the neural co-processors? Yeah, so the neural co-process or idea, I mean, there was relationships to the brain to brain communication work that we had done early on, right. And that work, of course, got us, you know, both people that were, you know, quite interested and quite intrigued by it. But also, I think a lot of scientists were like, oh, yeah, that's like, you know, just the old, you know, using TMS is like frogs legs being stimulated, right. So, so we've got people saying, you know, why did you even do that? Right. I think the, oh, really? Yeah, yeah. So the, so the main point is, it's not that we were claiming that, hey, you know, this is like a grand new discovery or invention, right. The idea was to say, okay, you know, we have been talking about things like mind to mind, you know, communication or telepathy for a long time in science fiction, right. And then BCI really progressing at the rate that it's progressing with companies getting interested in it. This may be a good time to have that conversation, right. So, and I think one of the interesting things there is, you know, we may actually get something like very primitive forms of brain to brain communication. If these companies have, you know, multiple patients with implants, right. Because it doesn't take much to send really simple kinds of information from one person's brain to another. As soon as you have the ability to stimulate, right, which is something I haven't seen yet. But if one's that has started happening, then I think it's only a small step towards starting some really primitive kinds of what you may call like, I mean, I'm sure the companies will claim is telepathy, right. But they'll be called tele. What will they be called because there was the telephone beforehand. Well, a good company name for that. Right, right. Yeah, so what about this one? It will be like telling you Rhanik's or something there, right. Telling. Yeah. Why can't we come over something, Raj? I mean, this is. I think it works. Yeah. It's going to be trademarked first before we can talk about it. Right. No, I'm just kidding. So. I know you have it. You have it in your back pocket and you're not letting on. But yeah, I think the unfortunate consequence of some of these kinds of, you know, claims, right by companies and even nothing some of the experiments that we've done is that there's a lot of people who are probably schizophrenics who think that they're implanted. But these devices already. And so a lot of us get emails every day, right. From people saying, hey, you know, can you help us? We think the garment has implanted something in me or there's a chip in my brain. Or the word did, you know, or yeah. I mean, people actually even come to campus, right. So there's people who've driven miles just to come to campus to our center to say, hey, you know, hey, the doctor says there's nothing there. Here's an X ray. There's nothing in the X ray. But I firmly believe it's this microscopic thing that's in my brain that's controlling my actions, right. So unfortunately, I think that's, you know, the price you have to pay you start to push that frontier. There's going to be people who, you know, also think that, you know, that's happening to them. Even though we can assure them that that's not really possible at this point in time, right. And we don't have the technology to do something like that. But that is something we're faced with as well. So it's part of the whole ethical, you know, issue and communication issues with this field. Yeah. So you said that we can't telepathically communicate yet. And we can't stimulate each other's brains. What we do all the time you and I were doing it right now through language. Yeah. And you have an interest in, I don't know where your interest in the endus script came from. And or now you've, at some point you learned a ton about language and just how language works and some of the statistical properties that are indicative of what a language is. But so is this a hobby of yours? It's beyond a hobby now. But how did you get involved in the endus script and. Mm hmm determining trying to decipher this thing. Yeah, I've always been interested in ancient history. And so I was doing one of my sabbaticals. I think I'm a first sabbatical when I said, OK, no, what if I indulge in that, you know, fascination with ancient history, right. So the ancient Indian history goes on from India and we have the civilization there that's, you know, more than 4,000 years old that we know very little about. Partly because the script of that civilization is not yet deciphered, right. And this was a civilization that was, you know, much bigger than the Egyptian and the Mesopotamian civilization. So we must mess. So so I took I'm sorry to interrupt, but one of my favorite classes that I took when I was an undergraduate was the origins of writing. Denise, small vessel at taught the course and we learned all about kuneha form and how early writing might have been. I brought about by economic exchanges with little clay tablets where people put little marks to show how many goats or cattle need to be old or exchanged and stuff. Where does this and I can't remember how. So what you're talking about is for there's like 2000 BC. Yeah, before I think starting from 2000, you know, probably 2000 800 BCs when they believe the civilization started evolving to the point where it was mature enough and then it ended or, you know, the demise of the civilization started to be more like 1800 BC like 1800 BC. But but the curious thing about them is that the that was not yeah was it was not like a huge amount of time and there were some precursors, you know 3000 BC and so on, but the prime of the civilization when they were really, you know, in their prime was probably, you know, 2800 to 1800 or so like 1500 BC, right. And I think the interesting thing about the civilizations, the fact that they, I mean, they were actually trading actively with the misopotamian civilization, right, the Sumerians and you know a card and those civilizations in the Middle East. And they've found these seals you mentioned, you know, they had these stamp seals so you can stamp, you know, information about typically trade, you know, the kind of goods that they may have been, you know, stamped on. So I think the the intriguing thing there is of course we know uniform and you know the kind of history of writing did evolve from the Middle East, right, and then the Egyptians, of course, followed suit with their hieroglyphics. And it's believed that the, you know, the Indus civilization also evolved their own set of symbols about, you know, 500 to 700 symbols that are very pictographic in many cases. And unfortunately there are no long inscriptions. So most of the inscriptions they're found have been on these stamp seals, which are only about five symbols long on average. Some of them kind of squished in different. Yeah, so there was like there's usually an animal imprint which may have been like a symbol of a clan, like a unicorn is the most common animal symbol. Really? Yes, a unicorn, yes. But you know, people in ancient times thought it originated in India, right, so unicorns. I didn't know that. I don't know that. Yeah, yeah. So perhaps it was because of the Indus civilization and their seals, right, but the seals always had the very top a set of symbols, a sequence of symbols, which were typically on average length five. symbols long. But there have been no long inscriptions on tablets. And so unfortunately we cannot apply many of our, you know, AI techniques, right, because there's only about 6000 of these. How do you tokenize that? Yeah. So what we did do, we did do some kind of, you know, analysis of it, which is, which is we looked at the entries, the block entropy of these symbol sequences in terms of which symbol follows which other symbol sequence. And then we show that the block entries tend to match the block entries of linguistic scripts as opposed to DNA, for example, or, you know, proteins, which are much more, you know, current code random, they're more flexible, right. So the entropy is are much higher. Music is slightly above language, right. So music is a little is more flexible, but not as much as DNA or, you know, proteins. What's less flexible? Lease flexible is, you know, computer programming language is like 4,000, right? It's below. Oh, you're going to say 4,000. Yeah, that was the original one that they did, right? So we followed that. But, but I'm sure it may start to fall. I mean, especially with now more different kinds of programming. Naturalistic, yeah. Naturalistic, you're probably getting closer to the entropy of natural languages, right? It's an interesting way to think about it. So what we did was said, okay, here's an undisciplined script. Let's look at all the symbol sequences and see if they're they fall in any of those ranges. And it turned out that they fall right in the middle of the range of linguistic scripts, which means that perhaps there's at least one piece of evidence that. They may have used it to encode, you know, language, but we still don't know what language that was there's a huge political debate in India about whether it was, you know, the Indo-Aryan language Sanskrit. As the topic, you know, civilization or is it the South Indians have a Dravidian language family? So some people think, is that language that's encoded in there? So political factions are trying to claim it or something is. In some sense, yeah, in some sense, there's that there's also this notion of, you know, Aryan invaders coming to India, people don't like that, right? Any kind of migration to India, especially if it was these Indo-European invaders coming to India, that was the original colonial interpretation of it. But the genetic evidence seems to indicate there was actually migrations happening from Central Asia into India, and that's possibly how, you know, these languages like, you know, Sanskrit and many of the North Indian languages will have similarities in grammar with the Indo-European language family, right? Compared to the South, which is more Dravidian language family, which is not related to the North Indian language families. So there's some amount of friction there, and even now you'll see people claiming decipherment of the Vedas, right, in the seals, but it stretches more. But you're an expert now, so you can touch those things, right? To some extent, yeah, I mean, I've definitely dealt into that for a long time now, so I can look into it, and unfortunately, most of the time, you can see that, you know, they're stretching it, and it's just not a plausible decipherment, right? So I think you're just going to have to wait for more excavations and maybe a Indus Rosetta stone that will help us decipher that script. But I doubt will find it. Do you think we'll find it? Not, I mean, it's a difficult task, right? I mean, it's possible it's already been found, and it's just lying in some warehouse in Iraq somewhere in a museum, because they were trading with these folks. So maybe there were some inscriptions that had both uniform and the indescript, but so far nobody has found anything like that, right? They have found indescripts with really odd sequences. So it seems like they were using the indescript to express the language in Iraq, like a foreign language, maybe in. Oh, yeah, so that's really interesting. But they're only with like five characters, five, five. The single sequences are very different from what you'd find in the Indus Valley in the finds there. So they were using it in a different way, at least. So I think there are some really intriguing suggestions like that, right? So is this going to be a lifelong project for you? For me, I mean, it's, I think at this point, it's, you know, it kind of, it's been from being a hobby to more of, you know, really getting drawn into the literature and the history of it. So I do spend a lot of time reading about it, but, but yeah, but I have no funding for it. And it's, you know, it's more of a sabbatical project, right? But it keeps me interested in something very different from what I typically do. I sort of look at myself that somebody is interested in, you know, the past, which is this indescript, and then the present is like, let's figure the brain out and then the future is like the BCI augmentations. I'd like to keep, you know, looking at all of those aspects, right? And keeps me, keep my brain at least, I know, occupied and interested. So one obvious question to me then is, I mean, not many people who use or, sorry, not many people who engineer large language models, our linguists or have a sense of what language is or how it may have come about or it's early post origins, etc. Even its origins, I mean, do you has this affected how you think about large language models? And I'll preface this also by saying that, you know, whatever great AI model is working, people are going to say, well, maybe the brain is like that. And then map whatever AI model is currently working to brain processes and often it works and stuff. And do you, has this affected how you think about large language models or how do you situate how you think about large language models, maybe is a better question? Yeah, I was quite intrigued. I mean, when the paper came out, the, the additional all you need paper and then also the fact that prediction was a very key aspect of it, right? It's not. Yeah, you must have been elated. Yeah, so it was like it was basically predictive coding except for the fact that, you know, they were not using the prediction errors to do inference. I mean, there was no like update of the internal representation. But the learning was obviously, you know, driven by prediction errors, right? And the fact that there was a hierarchy there as well, so that there's these stop detention layers, which is building up these dynamic representations over time. And you're doing sending out the representation to every layer, like every talk. I mean, it's just massive, right? Exactly. Exactly. In some sense, beautiful, probably to you. Yeah, it was actually very, you know, interesting to know that, you know, there is now this artificial system that just purely based on prediction, right? By predicting the next word, it was able to do so much. Not even recurrent, like there's no feedback. Yeah, I mean, it's not a regressor model, but yeah, yeah, you're right. But effectively, it was like taking into account everything in the past, well, processing the future and the future and the past were all getting processed simultaneously, right? But, but I think the cool thing there was the fact that I was able to really learn these very impressive, you know, predictive models and then generate these sequences, which seems to be, it seemed to be quite in line, but you know, the kind of thing we were thinking about for our, you know, the, you know, our active predictive coding model, this idea that there's a sensory processing aspect that's constantly predicting the next state. Based on the previous state and action, but there's no action here, right? The action was missing, right? Action is just output. It's just like a token, basically, that the previous token, maybe like being put in or you know, you sort of all the tokens in the past have been are being used to process the current token, right? So, but I think that that's also something that's missing is, you know, my sense is the controller is missing, right? So in the active predictive coding architecture, there's a policy network that is controlling the generation of the next input, right? So we have the predictive network and the controller network and they're closely interacting with each other and depending on the task, right? The controller network is feeding in the action to the predictive network saying, okay, generate this next, right? Because I'm going to take this action. And I think we've lost that in the transformer model, right? And I think that's where, you know, some of these RL approaches are applying now to the transform models. It's kind of getting the controller back in the picture. So I think that's where I see your relationship and more recently people have shown that transformer networks implement a special kind of hyper networks, which is what we are using for. We are using for active predictive coding. So when I said that the higher areas are modulating the lower areas in active predictive coding, right? The higher critical areas may be modulating the function being computed the lower areas. That is basically what is called a hyper network in the AI literature where the vector and input at the higher level is transformed by a by neural network called a hyper network, right? And then we take to another neural network, which is the function, right? It's basically a whole new network is being generated. And it appears that transformers are doing something like that in a simple way, right? Like a linear hyper network model. So I think if that's true, then I would say there's probably a closer link between what you suggested and what transformers are doing, except we were trying to model the cortical architecture in terms of, you know, hierarchy and laminar structure. So, you know, the transformers don't have that, right? And they don't have the controller aspect either. Yeah. Yeah. So, so then overall, our transformers, I'm trying to get a sense of your judgment on them. They're great, but they're not enough, right? They're great as a principle of how predictive models can really, you know, capture a lot of information about the, essentially the statistics of the world, right? The physics of the world or the dynamics of the world, they can be used to capture that, but that's not enough for, you know, intelligence, right? So I would say, you know, I go back to that, you know, notion that, you know, people have suggested, you know, policies that can. And so, you know, there's that, you know, ultimately it's all about actions and movements. And so, if you don't have the controller there, telling you what to do, right? Then you, like transformers don't have, like chat GPT and transformers, they don't have a sense of agency, right? And that comes. How do you get that? What's that? How do you get that? How do you get a sense of agency? Well, I think we get it from being able to act in the world and being able to actively use action as a way to generate language, right? And we get that because we actually act upon the world and we, you know, we use speech, right? And that's actual motor actions, right? Yeah, but squirrels have agency, right? And then I have speech. Yeah, yeah. So you have to have action, you don't have to have speech, but in order to have agency, you need to be able to act upon the world and be able to, you know, cost consequences. You have to be able to see the consequences of your action. And then maybe achieve goals. So you start to see, okay, you know, if I take these actions, I achieve my goals. And then if I do these actions, I get something else. And that's how you build a sense of agency, right? And for a purely predictive system, which is only predicting, but, but not really using actions as a way to guide those predictions and get to a particular goal, right? Then it becomes hard to argue it has agency, right? I mean, some people do, but I think it's a missing piece, right? So you think that we could build agency? Yeah, I think I think any, you know, system that starts to interact with the world with its own actions and, you know, generate goals. I mean, those are all things that you associate with an agent, right? So I think you do require to have that policy or controller and, you know, potentially a model of the world to go along with it. I have two more questions for you and I promise I'll let you go. Oh, it's been way earlier. I'm sorry. It's been fun. So I could probably go on. So yeah, go ahead. Okay. What do you want to learn? I have to, I have to be up for the bra, I'm doing a brain initiative workshop tomorrow where I participate. So I have to, I have to like, yeah. One, so way earlier on we were talking when we were talking about active predictive coding or predictive processing. In general, you were talking about, you know, back then back in 1999, they're, you know, when we were when people, I said, we were recording single neurons. And that's when I grew up, I recorded single neurons. And the technology wasn't quite there to be able to begin testing the hypotheses that might be issued from a theoretical framework like predictive coding. Since then, we now have, we're starting to get connect homes, which everyone always said like, well, man, once we have a map of every of all the connections we can do everything. So we're starting to come to pass. We now have super high density recording techniques, neuronal recording techniques so that we can put high density electrodes in different parts of the brain and get lots of lots of neurons. And then we have, sorry, there's like five things, right? Those two and then we have AI models. We have high compute. We have lots of more, a lot more statistical models that we can employ. That's the same as AI in terms of modeling. Which of those, if any, like has been, do you think is the most important that is happening right now? That's a trick question, because I think if I choose one, it's probably gonna alienate a whole bunch of people working on the others. I would say we need to call them. No, no, no, no, no, no, no, no, no, nomassage differently, which of those do you, like, when you wake up, you're like, oh, man, I could use this to do that. Right. But in your current, I know that all necessary and awesome. Yes. Yeah, I think I mean, it changes, right? So for me, the amazing part, I mean, it's a fantastic time to be a third edition and neuroscience right now, because there's so much data, right? And this is a great time to really think about these larger scale theories. So when I was a grad student, you know, there were books and papers by Mumford. There was a book called Large Scale Neuralin theories of the brain by Christophe Koch and Joel Davis. And these were all like at that time, you know, there were these theories, but then the data's data just was not there to test these theory. But now I think we're at a time where we can actually start to test some of these theories. So I would say, you know, from one day to another, right? I feel like in some days when I'm thinking about a particular theory, I may go into the literature on large scale neural recordings. Really try to find, okay, is this supported or not? And what are the things out there? But then the next day, I'm actually be looking at connectomics to see, okay, is that connectivity and anatomy still, you know, is that there? Right? Is support some of these other theories, right? And of course, AI is a well spraying of new ideas always. I mean, there's so much going on in AI that is hard to keep up, right? But then of course, there's some gems there that you can pick out and then see if that's relevant to understanding the brain. So I think it just feels like, you know, we're at a time where it's this explosion of information and, you know, really to make advances is almost like you have to train your brain to essentially, you know, forage and find the right kinds of information to really build up, you know, new theories, right? It's a tough task, but I think it's it's actually better than not having any data like when I was a grass to and we didn't really have that kind of data. We had like you said single neuron, you know, response and so on. It was very difficult to say, okay, what's the system doing, right? The systems level. Yeah. Now, I think we're getting the point where we can actively collaborate. I think the, the, the your generation, the generation, you know, that's, that's actually, you know, training right now. I mean, they're much more, I think savvy with computational models. They're much more, you know, computational models. I think that's really great, right? That means that these ideas like predictive, predictive coding, hopefully, you know, can be tested more quickly and they're not going to lie dormant for 10 years, right? Before people start taking an interest in them. So, so I feel like this is a great time for, you know, people like I encourage people in many different areas that they can be computer scientists, they can be people doing AI, they can be people, you know, in neuroscience psychology. I think they should all, you know, feel in a comfortable with coming up with theories and computational models. And I think we have the training now in many areas. But this is a great time to start thinking big, right? Think across just one area and one the kitchen. Right. Can you? So there's maybe a paradox here, right? So if you have tons and tons of tools, it may be harder to think big, like it may be harder to think theoretically. I'm wondering how, how you might think to foster someone's theoretical bent or how to think theoretically given this deluge of tools. Yeah, so that's a great question again. So I think it's something that you, for me, at least it comes from thinking about it first from a computational point of view saying, okay, here's a particular problem that, you know, let's see if we think of solving this problem, how would you do that from a normative point of view or from a AI point of view, right? But then I think you can then say, okay, let's look at some of the data from the brain in terms of where these kinds of problems have been explored, right? And then that's one way to do it is to start from the computational and then go more deeper and deeper into the neuroscience. The other way is to go bottom up, right? So you could say, okay, you know, I'm working on these areas. But then, you know, I want to actually go beyond just as one area from a theoretical point of view, right? Even though I'm just recording from this area, but let's think of it in terms of this area interacting with all the other areas that are connected to it. And then the bigger picture of behavior, right? And how is that going to work? Right? And so maybe look at people working in those other areas as well, right? It is a hard problem, but I think it's worth, you know, looking at it beyond just, I remember like when I was a postdoc, I went to the lab of a very famous neuroscientist. And then, you know, I was asking, I was doing a postdoc in Sanawski's lab in Sagu, but I was visiting another lab somewhere else, right? That's a different famous neuroscientist. Yes, there was another, I was doing a postdoc in Terry's lab, but then I went to a different, visiting a lab, right? Many different labs were visiting at the time as a theoretician. And then I was asking them, you know, hey, you know, the person who was working in V1 and then so I said, okay, what about V2, right? When V2 and V1 are connected, you know, shouldn't you be considering the interactions between the two? But the person said, no, no, I'm going to figure out V1 first. I'm going to understand V2, right? But what if you cannot do that, right? What if we cannot reduce? It's not a, you know, reduce ability in that sense, right? What if V1's properties are intimately connected with V2 and other structures, right? Then it becomes really hard to understand just one area. Right? So I think that's the challenge we have, right? As neuroscientists is, you know, the brain is a very complex, you know, piece of machinery that's been evolving or millennia. And if you use, you know, sort of reductionism, then it becomes very hard, right? To understand what's happening across the brain. At the same time, maybe we don't have the capacity to understand the whole brain, like what's happening everywhere. So then we have to find ways of picking the right abstraction level to understand and hopefully connect those abstraction levels, like from the behavior level all the way down to like the molecules, right? But one person may not be able to do all of that, but hopefully as a community, we can start to understand, you know, the brain at multiple levels of understanding. It's hard. It's hard. And even people who like you who are like super good at it, you will admit it. It's a little difficult. Definitely. Definitely. Especially with all the information that's now coming out and trying to, but I think we can lose hope, right? So I'm optimistic that, you know, it's going to happen, right? I don't know if it's in my lifetime, but I think we're on our way, right? It may be sort of that we think, right? So I think we should be optimistic about that. All right. Well, that's a great note to end it on. I meant to mention this up at the top. What I'm going to do when we're done here, I'm going to email you an invitation to join me again, because I know it takes about a year to get you on. So it took a long time to get you on the man. I really appreciate it, Raj. You're coming on. It was fun. Yeah, it was fun. Thanks again for having me. Brain Inspired is powered by the transmitter, an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advanced research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives written by journalists and scientists. If you value Brain Inspired, support it through Patreon to access full-length episodes, join our Discord community and even influence while you invite to the podcast. Go to Braininspired.co to learn more. The music you're hearing is Little Wing, performed by Kyle Dunovan. Thank you for your support. See you next time.