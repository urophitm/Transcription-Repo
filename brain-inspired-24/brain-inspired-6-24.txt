 The goal of the brain, at least one goal of the brain is to learn a generative model of the world, an internal model of the world. And it's constantly making these predictions or doing essentially hypotheses testing, right? So it's essentially generating hypotheses and is trying to then match those hypotheses of what's coming in through the senses. And when their deviations are mismatches, those are called prediction errors, and those errors are what are used to then update the hypotheses. If you want to have a very rich way of modeling the world, then what you want to do is have the higher level modulate the dynamics of the lower level. So you need to change the function being computed at the lower level, depending on the task. And so we said, okay, why do we use this primitive modes of interacting with the brain? So EEG and TMS, and let's build a brain to brain, you know, direct brain to brain communication system with them. This is Brain Inspired, powered by the transmitter. Hello, I'm Paul. Today I am in conversation with Rajesh Rao. Rajesh is a distinguished professor of computer science and engineering at the University of Washington, where he also co-directs the Center for Neuro Technology. Back in 1999 Raj and Dana Ballard published what became quite a famous paper, which proposed how predictive coding might be implemented in brains. What is predictive coding? You might be wondering, it is roughly the idea that your brain is constantly predicting, or at least back then, it was roughly the idea that your brain is constantly predicting incoming sensory signals. And it generates that prediction as a top down signal that meets the bottom up sensory signals. And when those two signals meet the top down prediction with the bottom up sensory input, the brain computes a difference between the prediction and the actual sensory input. And that difference, that error, is sent back up to the quote unquote top, where the brain then updates its own internal model to make better future predictions. So that was 25 years ago, and it was focused on how the brain handles sensory information. But Rajesh just recently published and proposed an update to the predictive coding framework, one that incorporates perception and action, suggesting how it might be implemented in the cortex, specifically which cortical layers do what? Something that he calls active predictive coding. So we discussed that new proposal. We also talked about his engineering work on brain computer interface technologies, like brain net, which basically connects to brains together. And like neural co processors, which use an artificial neural network as a prosthetic essentially that can do things like enhance memories, optimize learning and help restore brain function after strokes, for example. Finally, we discussed Rajesh's interest and work on deciphering an ancient Indian text, the mysterious Indus script. All right, I link to all of the work that we discussed in the show notes at braininspired.co slash podcast slash 200, 1, 201. I'm in the process of setting up our next live discussion for Patreon supporters. So if you're a Patreon, check your Patreon messages soon or check in on the brain inspired discord. Thank you for listening. Here's Rajesh. Raj, by the way, I'm, this is the first long motorcycle ride I've taken since I got a motorcycle and I'm in a hotel. So I may not be on the top of my game, not that there is a top of my game, but anyway. You look great. And yeah, I think, yeah, I think it should be, you know, interesting to see what kind of interesting questions come out of the granddad long motorcycle ride. Well, I actually wanted to start with, well, maybe you won't tell me this, what year are you born? Well, I mean, it's on the internet, right? It's on my appropriate Wikipedia period. It's 1970. Okay. So when it was the 60s and you were already good at academia, perhaps before you're born, I understand that you were, you excelled in early years in your schooling. But here's what I want to get to. I would like you to tell me the origins of the predictive coding story. That's what I, yeah, when you were, when it was in the 60s and you were, before you were born and you were thinking about predictive coding, how did you start thinking about that? That's right. Yeah, it was in my previous, you know, life, right? It's a green part, and now to bring up predictive coding. So basically it was, you know, the story is essentially that I grew up in India in Hyderabad and in my high school there. And I got a chance to come to the US as a, you know, 11th grader because I got a rank in the Indian, you know, central science exam that they have. And as part of that rank, they were able to send me with another group of people to do some research. And so basically I got hooked on to research right at, you know, on 11th grade, went to University of Maryland, did some research. I would call that, you know, put them codes research and superconductivity. It was the time of high temperature. Superconductivity at the University of Maryland. And I got a taste of research then. And then, you know, took the SAT exam. Never applied to an university. So I was just waiting for universities to contact me, thinking if my city scores high enough, somebody will contact me. And obviously that never happened. Because that's the way it works in the IIT exams in India, right? You write an exam, the rank is high enough, you get to go to an IIT. And so they'll contact you. They'll contact you. They'll let you know, at least they'll be like a ranking, the announcement and things like that of who got in who didn't. Right. So I was under that, you know, impression. And then luckily for me, there were a couple of universities that did write to me, saying, hey, look, we have scholarships for international students. And one of them was in Texas, a tiny university called Angela State University. Another one was in Alaska, University of Alaska Fairbanks. And given my, you know, preference for, for weather, you can imagine where I went. So that's some family in Texas as well. So I went to Texas from undergrad. All right. I grew up in Texas. So I was, I was curious about that aspect of your development and how you found Texas in general. But that was in the, what early 80s? Yes. And now in our early 80s, I'm not that old. I'm kind of old, but I'm not that it's, it was like late 80s. Late 80s. So it was basically late 80s. And it was the time before the internet. And you know, it was interesting. It was an interesting culture. Somebody coming from, you know, bustling plays in India to like a small town in Texas with cowboys for roommates. Right. You can imagine all the interesting things that happened. And I could talk about that over beer sometime. Yeah, yeah. We'll do that over a beer. Okay. Well, all right. So maybe fast forward. I suppose. Because I do want to buy you a beer now about, and talk about Texas. But. Predictor coding, right? Yeah. Like what? I don't understand the origins of it. Right. Right. I mean, I understand Helmholtz. So I mean, we don't have to go that far back. So, or monvone Helmholtz with inference and predicting the best. Yes. Predicting predicting the best outcome predicting, sorry predicting what you will perceive. And I know that origin story. But in terms of neurons, do you like what is that origin story? Yeah, I think for for me and my advisor at the time, Dana Ballard. So I went to University of Rochester for my PhD. And you know, I was going to do a PhD in theoretical computer science. But then I happened to meet Dana Ballard in the copy room. And he said, hey, you know, I have the summer R.A. So can you work with me for a summer? I said, OK, I'll give that a try and sure enough, you know, that got me hooked to at that time computer vision. And we were looking at this problem of, you know, how do you reconstruct objects that are behind conclusions. Right. So the idea was, you know, let's take the representation from the visual cortex. You have these gobbler filters, these oriented filters. Now if you can recognize objects using this representation. Based on the responses of these filters, can you now also reconstruct what's behind these these occlusions that the objects may be, you know, behind. And then it turned out that, you know, those filters, you cannot just combine them linearly with, you know, the responses of the filters and then reconstruct an image like you would do for a PCA filters, right principle component analysis or the Eigen vectors, right. Because they're not just linear, which is linear. I'll just. Yeah. But even if you do a linear combination of these gobbler filters, they are non orthogonal to each other. So that's when we got into so the idea was, can we then do gradient descent on a reconstruction error cost function. And so you have this idea that, okay, we can reconstruct images that are based on non orthogonal filters, right, the responses. So then you at least to this idea of optimization of the responses of neurons that are trying to reconstruct an image that's been presented based on these gobbler filters. And then if you flip that and say, okay, what if you can not just estimate the responses, but also learn those filters. Then you get this really interesting idea of, you know, at a fast timescale, you do inference, which is similar to what, you know, Helmholtz was talking about, which is inference of what object you're proceeding right now. And you do that using this dynamical system, which is based on gradient descent, right. So the interesting thing there, which was not very appreciated at that time. And I even I didn't appreciate as much was the equation that you get from gradient distance. You have this cost function of, you know, minimizing the prediction error, the reconstruction error. When you do the gradient descent equations, it basically falls out of the equation that you need an architecture that has feed forward and feedback connections. And the feed forward connections in the architecture would be carrying the prediction errors and the feedback connections would be carrying the predictions or the reconstruction of the image. Let's worry about for fear of losing the audience. I'm just going to back up and we'll go Lego bricks. Sure. Yeah. Right. So the, so what is the idea of predictive coding the idea. Do you want me to say it and then you can correct me. Yeah. Yeah. So predictive coding is basically that you have some idea forward in the brain somewhere forward in the brain, some idea of what you're expecting. And you're sending that backward through the brain. And those, those incoming sensory signals that are coming up toward forward of the world of shapes, if we're talking about vision, then they get met with this prediction. And then there's a, a difference between what you're expecting and what those signals are propagating forward. And it's the difference in the predict between the prediction and the signals that gets propagated forward. Is that how does that sound? Yeah. So I guess we were good at conveying the message in those papers. So I'm glad to hear that that's so yeah. So basically the idea is the traditional model going back to Hubell and Vista was always that you have this feed forward pass. So you flash an image, you get a feed forward pass, you know, all the way from V1 V2 V4 and the visual system up to IT. And then you get recognition and then you get cognition of that. You can make a decision. Maybe you press a button. Right. So that's action. But was it back in those days, was it always like voila? There's the cognition of it. Like if it just builds up to an abstract enough edges to a table leg to a table. Right. Oh, there's a table and it magically happened. And that's the way it was thought even in the AI field, right. The whole field of AI was partitioned into all these different, you know, there's people doing vision. There's people doing motor control robotics. There's people doing, you know, higher level AI based on logic. It was very similar to how even in neuroscience and cognitive science, we have these, you know, people focusing on particular modalities and so on. And then the for me as somebody coming into that area of neuroscience and looking at the anatomy. It seemed really surprising that people were completely ignoring the feedback connection. So if you look at every critical area, it's sending not just the feed forward connections, but also receiving feedback connections from a higher order area. And then if you talk to people at the time, you know, who are really famous visual neuroscientists and ask them, okay, what about those feedback connections and they're like, no, no, no, that's maybe doing attention. They're doing something really. Would they really say that? Yeah, yeah, sure. I mean, people thought that those were not really critical for, you know, the traditional kind of perception of objects and those where maybe brought into play when you're doing something like very specific kinds of attention, maybe during sleep and things like that. So a lot of people were not necessarily even acknowledging that those feedback connections could be playing a very dominant role. And so predictive coding flips it on the head. It says, the goal of the brain, or at least one goal of the brains to learn a generative model of the world, an internal model of the world. And it's constantly making these predictions or doing essentially hypotheses testing, right. So it's essentially generating hypotheses and is trying to then match those hypotheses is what's coming in through the senses. And when when their deviations are mismatches, those are called prediction errors and those errors are what are used to then update the hypotheses. So you're sending them back in the feed for pathways. So the feed for pathways are actually not carrying the raw signals, but they're carrying the deviations or errors mismatches. I'm very inside. I think yeah, that was different from what the conventional thinking was at that time. Well, okay. So, all right, let's stick with that insight for a second. I mean, did you. Was that insights and how moment for you? I would say the idea was in the air, right. So I was at that time reading papers by people like David Mumford, for example, who was also, you know, talking about things like that between the talismas and the cortex and cortex to other cortical areas. There were people like James Albus, who was talking about in the context of, you know, AI and he'd already done work, obviously in the cerebellum. That was his, you know, main contribution neuroscience with the model, right, the the more Albus model of the system. That's a rebel. But he also had really interesting ideas about hierarchy hierarchies in AI and in robotic controllers and things like that. And then finally, if you really go back in time, there was, you know, someone named Donald Mackay, right. He's actually the father of David Mackay, who wrote that book on AI Information Theory. So he actually proposed, you know, he had a paper called the epistemological problem for a tomahawk back in the 1950s. And even he proposed this kind of idea that what if you can send error signals from one module to another, you know, and then you could then build up this sort of abstract representations at multiple levels of the hierarchy. So what we did was essentially take many of those ideas that have been around and then say, okay, let's actually implement that mathematically. Let's see what comes out of it. And then we showed that some of the things that come out of it, if you interpret neural responses as prediction errors is that you can explain some of these puzzling effects like end stopping contextual modulation. You know, orientation contrast effects, things like that that, you know, it would be harder to explain if you just have a feed forward model. This actually gives you a normative explanation in terms of natural images and in terms of natural behaviors. But even if you look back at them, a colic pits. articles of they knew feedback was important. And they said it was sort of maybe you can educate me on this a little bit better, but it was almost like a nod to the fact when they were drawing their little neuron diagrams, muclequits neurons, right, one to the other. And then, you know, there'd be a feedback loop. And I think they wrote about how it would be important one day, perhaps. Yes, yes, I think they they call them loops, right, and they definitely add this idea that loops are pretty important. I think that at that time, there were a lot of people interested in characterizing essentially what we call dynamical systems now. But they were trying to characterize the properties of these these loop loopy networks, right. I think what the the correspondence between the that kind of work, which is, you know, very fundamental rigorous basic elementary work. To now trying to map that on to anatomy is, is I think the leap, right. So you have to that's what Mumford had suggested and that's what, you know, we also tried to suggest was that, okay, let's try to map some of those ideas now onto the cortical anatomy, right. The idea of, you know, there's six layers in the cortical area. There's feed forward connections coming into the middle layers layer four. And then there's feedback coming from the superficial deep layers. And if you look at that, you have the vanishing fell men have an as an hierarchy, right. So can we have that monstrosity that monstrosity of a diagram. So so the way that we looked at that fell men, Madison hierarchy was, okay, what if you interpret that as a generative model that evolution came up with for essentially modeling the world, right. And once you interpret in that sense, then it says, okay, if you have this idea that you can sample from that generative model and generate, you know, examples of what the animal faces, right. And it's interactions with the environment. Then inference becomes this idea of, you know, trying to update those estimates you have, those hypotheses you have by the world. So I think the key, the key idea there was, you know, inference as a fast update of the neural responses at the population level in all the different cortical areas. And at a slower timescale using the same, you know, mismatch or errors to then update the weights, right. The learning part, the synaptic plasticity part. That was happening at a very much slower timescale. So your famous paper is the 1999. That must be the most cited paper. Am I correct? Yeah. Yeah. Yeah. So you have that. And in fact, I've seen you in a talk point to it with optimism for graduate students saying, see stick to your ideas. And eventually perhaps they will come to fruition. All right. This is a keyword. Well, perhaps. I mean, maybe what do you think is the, oh gosh, I would say 5% no, no, 3% what do you think? Yeah. So I think it's hard to say, right. So I would say one of the reasons why that paper, you know, it was, it was published at a time when I think there were still not the kind of techniques you would need to really, you know, test some of these predictions, like, for example, these prediction error neurons, right. So can we look at specifically layer two and three, which is where you would expect these prediction error neurons to be because those are the feed forward connections to the next cortical areas. Similarly, can you look at the deeper like layer five neurons and look at what kind of response is because in the predictive coding model, the deeper layers of the ones that are storing the estimates of state or in a motor kind of responses and so on. So you have to have the techniques, which were not available at that time. But I think you fast forward, you know, 10 years from then and then start looking at, you know, in the late 2000, you start to see more citations of that paper. And then now I think it's, you know, there's so many people trying to look at different aspects of that theory with evidence, you know, for some people against right. So I think it's become very, very, you know, a rich area of research. So I think the theory was maybe a little too early for its time at that time. But I think the fact that, you know, nature neuroscience, which is where it was published was, you know, willing to publish it, right. As opposed to saying it is pure speculation, right. Which they could have done. I think it's credit to them for having, you know, taken that, that particular paper. Yeah, I mean, Occam's razor. It's theoretically great. Right. Yeah. So we had an elegant to it, which I think was, you know, we ourselves didn't quite appreciate as much. And I think first and actually wrote like a news and views on it 10 years, the 10 or 20 years after it was published, talking about how that one paper really influenced him as a researcher. To really, you know, pick, pick up the, I guess the mantle at that point, because we had actually, I mean, I had sort of moved on to more general models on the Bayesian brain hypothesis and belief propagation in Bayesian networks and things like that. But then of course, Fristan went on to do the free energy principle based on predictive coding ideas. And then more recently active inference and, you know, there's a whole bunch of work principle. Yeah. But so at the time, I'm sorry to press every on this, but at the time, did you know that it was going to be so influential or not, not, not, no, but did you have some confidence, some, some sense that this is, I know you had a sense that it was a good idea, but I have good ideas every day and they're never good ideas. Yeah, I think it's at that time, I would say, you know, I was not, you know, too confident that it would actually be something that would inspire people to do experiments, because there was a news and news that was written on that paper by Coke and Poggio. And it's an interesting news and news. You can see them, you know, they, they coat a Sherlock Holmes in a story and then talk about how the fact that the dogs were not barking at night in the silver blaze was a story of Sherlock Holmes is an example of predictive coding because you know, the person was not surprising. So then the deduction is that the person who stole, I guess the horse called silver blaze. So that's a very positive review. Yeah. So it was a positive review. But before that, I was told by the editor that the previous person out at the as refused to write and use the views, right. So I was like, oh, there's already people that are, you know, not necessarily going to like this, right. It goes against their way of thinking about how the cortex works. But yeah, but, but I think it, like I said, there was not as many citations, there was not like a huge number of people, you know, writing to me and saying, hey, you know, that's a great thing. So it's like, okay, we wanted to get it out. It's out there. Let's see what happens. And then it took, you know, 10, 15 years, right, before it really caught on. But were there early detractors also? Yeah, I think there's always been distract a detractors, right. So there's been people, I mean, even now, right. So basically a lot of people don't buy into this notion of the feedback, really influencing the responses and then the prediction. And there would be how can that even? Oh, well, specifically with the prediction errors. That's a different. Yeah. So feedback is obvious in the brain, but even feedback carrying predictions from a higher area, right. So even that's not a notion of that is still debated for particular tasks, right. I think there's really clear evidence now that for sensory motor tasks, where there's the animal makes a motor movement. And then there's an difference copy that allows you to make a prediction, right. I think there's a lot of evidence now coming from, you know, David Schneider's lab from New York. Your killer's lab and so on showing that, you know, and there's local motion or there's a four lamp press of a lever and there's an auditory response. You get a prediction in the artery cortex. There's a suppression that looks like a prediction error signal there. So they're definitely for the motor. I think you see that if it's purely, you know, sensory, which is, I would say I would argue that since some sense, you know, a purely sensory, you know, experiment typically has a fixation and then you're flashing something. It may not necessarily be, you know, the kind of naturalistic behavior that would elicit predictions and prediction errors, right. So, but there have been some reports about these error like responses in those situations as well. So, yeah, that's the that's where I think we there were initially, you know, there was initially some resistance in terms of the fact that there wasn't at that time, you know, any evidence for feedback conveying predictions and feed forward conveying prediction errors. Except for these contextual effects like these extra classical receptive field effects. And even that some people are explaining it just through lateral inhibition, right. Which can be one way to explain that. Yeah. So, I just want to show what is the lesson here. So it's not that predictive coding is universally accepted still, but now the technology is better and we can have better and better measurements of hypotheses generated by predictive coding. Framework. So one lesson is keep going grad students it might get better, but for a so the jury still not out, I guess, right. Yeah, I would say there's evidence for some parts of the theory. And I think as a theorist, you know, I feel like our job, you know, all the traditions out there and our job is to propose theories that are, you know, explicit enough in terms of connecting to the anatomy. Just what specific enough that they can be shot down right they can be falsified right we basically want to have the ability to falsify theories and in the process of that if it generates some new data that then really sparks a new theory right. And then leads to feel forward I think that's the job right and we should not be afraid to propose these theories as long as they're sensible they match the existing data right which is what we were trying to do at that time was saying, okay, we have these puzzling responses called end stopping or contextual effects. We have the anatomical evidence saying there's feedback connections so let's propose this theory and let's see what happens right if you start doing experiments. So I would say the same thing now right look at what's out there what people have collected in terms of the data and look at the computational aspects also right so what is a brain really trying to do. Let's look at it and yeah, I mean, that's what I was about to ask you because so do you see predictive coding or the family of predicting coding approaches as some sort of general thing. So some sort of general theory about what the brain is supposed to do you know what the brain is doing because you know there's the free energy principle now there's Jeff Hawkins everything is prediction. You know these things go back years obviously and everyone points to Helmholtz and there is someone before him. There's chat GPT and transformers which are also based on prediction right that's right and we love them. I would say it's just part of the story right so prediction is important because you know animals have to predict to survive I mean ultimately it goes down goes up it's this idea of you know at some certain point in evolution you know the brain start building models of the world to be able to predict to anticipate right and so I think that's an integral part of if you're learning a model of the world that comes with this you know benefit of you know you can use that to generate hypotheses you can use that to generate predictions and and that I think is an integral component you know this idea of world models for predictive models of you know intelligence you know either artificial or natural right it gives you a lot of benefits and it wouldn't be surprising if evolution came up with that you know way of handling the uncertainties of the world and you know to compensate for delays as well as you know the world. As well from you know your sensors and your your muscle sensors all the way to the brain right so there's obviously be delays so if you're too late to react you're probably going to get killed right if you if you you know also if you you know have the ability to predict and have a model then you can do planning right you could essentially go forward in time and then you can do planning and that and then that leads to abilities that allow you to have much more sophisticated behaviors then if you're just a reactive organism right so I think there are a lot of. Reasons at least from a computational point of view but probably also from a evolutionary you know biological point of view to have something like an internal model and prediction that comes with it. Okay so so so Rallem Ballard was a 1999 and then the sensory motor theory of the cortex I think I have the name wrong but I will I'll write no flash it up there which you've recently presented which you've been working on for I think a long time now. I'm not so long I would say maybe like four years like three four years that's not so long at all in turn in research to age. Okay well so that that's what I wonder like I'm not sure if you flipped in that regard it sounds like you've somewhat flipped but if you if you have like how that. Who did did someone drag you out of perception or did you climb out yourself or. I think it was multiple things so you know I think it was just this realization that you know if you think about what is the purpose of you know having a brain the context of evolution right so going back to some of the early you know. Creatures that were trying to for example you know move to towards places that have more nutrients because you don't have enough nutrients so. But hang on let me just stop you there i'm so sorry to interrupt but they're moving to a place with more nutrients. Because they can already perceive whether there are nutrients there right so the. You can do you can do you can do random movements but you still have some notion of perception because when you. Taste the nutrients or when you actually sample the nutrients then that is like perception ready for the call out perception so i think the it's kind of like a the sensory and motor part are integrally tied right so. Change your location or you know sample a different part of your of your environment but then. If you want to know was that successful or not right then you didn't you didn't need sensation right of some sort to know okay what I did was you know good for me or bad for me right and that's what we're calling perception in a very. In a courses level right but so do you think alright so I guess we have sensation without brains or perception sensation perception we can use the minute changeably although dangerous but let's say. Light sensors right. No well you could do artificial but I meant biological right pre movement what I guess what i'm wondering is like you know that evolutionarily why did brains develop and that is in some sense. Moot point because they are integrated like you said. But I think you have to perceive before you can move. No I think it's I mean I don't think it's one on the other right so essentially I mean you could say perceive because you're you're perceiving the fact that maybe you're low. In nutrients inside your body right so you're hungry I mean you could think of that as a kind of internal perception right i'm not going to drive you to then move right but then when you go out and you actually consume some. Nutrients then your internal state may change because you're not perceiving it as okay I've consumed food and so i'm more. But if you move without any perception then you can't. You can't decide exactly exactly so you do need perception but at the same time you know. If it's just a I mean it's just a creature that doesn't move at all but it's just perceiving I mean that also doesn't quite make sense right does a venous fly trap move to you. In the sense that it does have an action right of you know grabbing the insect and digesting so i guess but it doesn't move in the sense of you know creatures moving right but but in some sense maybe it does. If you consider the the movement but again it's it's you know it's not a moving organism right like the one that be associated with brains right yeah right yeah. Interesting yeah go ahead no these are great questions to think about right in terms of um oh no i'm sorry i'm getting a soft i'm telling you man i had a long motorcycle ride and my brain is fried and i so i'm sorry if i'm a little squishy myself but. Sensory motor coordination that's what. Yeah back to this was a 25 year divide between these two papers i'm just going to focus on these two that's like two of i think you've published in total probably four papers or something like that slightly over on yeah i guess in total. Sorry. All right so but but it felt like a big reveal when you added the motor aspect to the predictive coding and we just talked at length about how you have come around to thinking that action and motor behavior is important. So can you maybe just give a summary of how you incorporated it and what people can expect if they read this paper. Yeah so i think the the first observation that really prompted me to go on that whole journey was the fact that there were all these new results coming in showing that even primary you know sensory areas or couldn't code sensory areas like v one you know s one or a one. We're being influenced by motor you know activity or actions like you know there was papers from the Korean Dini Harris lab there was you know papers from. David Schneider's lab showing that you can actually get these responses that are motor related but they're happening in the traditional sensory areas like v one or a one right and only that but then the other interesting observation was anatomically again right if you look at an enemy. The layer five cells right there's like five a five e but the layer five cells even in the primary sensory areas like v one a one s one right so metacensare cortex primary so metacensare the layer five in all these areas are sending axons to motor sub cortical motor areas right like as the v one sensitive to super because a one sense to inferior color is it's all like completely connected it's really it's a ridiculous system if you want it for an engineer i mean it's it's not completely connected in the sense that you don't have like the superficial cells sending you know axons to superior color is it's actually yet we don't know that yet well okay so there's always the possibility right but i think that was the other you know interesting anatomical constraint that we were looking at and then the funny thing there is okay it's not just that you know you're going from layer four. To layer two three and then to layer five and then that's it right now layer five is sending information back to layer two three right there's a loop there between the superficial deep layers what is that loop doing right so and if the superficial layers are receiving sensory information from layer four right and then the deeper layers are sending you know so you know so quote unquote outputs to motor centers then there is this loop going on between the sensory and motor within each cortical area right and that was the first inside was okay what if I know we take our we take some you know inspiration from reinforcement learning right so we all know about the markup position process idea and the fact that there is we don't all know about it if you can even for non scientists like the most basic version yeah yeah so the basic idea with reinforcement learning is that there's a world and there's something called the state that the animal or agent is in and then when you take an action that state changes right and and basically you have that's called a mark of assumption because you're saying the next state only depends on my current state and current action but that is typically called the forward model or the dynamics of the world right you're saying the world is in this state or I'm in this state and then I take this action the world changes to this next state and that if you repeat that it becomes like a dynamics like the physics of the world right and that is the forward model or the what we call the generative model of the world but then reinforcement learning the goal is to learn a policy which is given a state of the world what is the best action I can take so that is called a policy it's a function right so for any state the animal is in it's gonna say okay I want to say I want to take this action because that action is the one that'll let me achieve my current task. Right? And so if you now combine that the model, which is at the top and then the policy at the bottom, right? So you have one that is making predictions of what the next state is going to be based on your sense reinputs. And the other that is saying given that I'm in this state, here's what the action is, is that's most suitable, right? Then you can have this kind of a cycle between, okay, prediction action, prediction action, prediction action, right? And that is the general idea and that's what we suggested as a module, like a sensory motor module for any cortical area, right? And it's going to operate at its own spatial temporal scale, depending on the kind of inputs it is getting, right? So every cortical area has its own spatial temporal scale and modality, depending on the kinds of inputs, it's getting in the kinds of outputs, it's controlling, right? Or potentially controlling. And then the last thing we threw in there was, okay, what about the different hierarchy and the different cortical areas interacting? Why is there a feedback connection or a reciprocal connection? And so it turns out that from a computational point of view, if you want to have a very rich way of modeling the world, then what you want to do is have the higher level, modulate the dynamics of the lower level. So you need to change the function being computed at the lower level, depending on the task. So if my task is to drive to the grocery store, right? Then you basically want to load up the program, right? For getting into your car, figuring out where you're going and then driving. So you have all those, you know, quote unquote programs that are policies, right? These are these policies that are already been learned that are being plugged in to achieve your current goal. But if your goal is now to go to your friend's house, it'll be similar programs, but the sequence may be different, right? Or if it's a cook something, right? Again, it's the same idea, right? You load up a different program. So we're suggesting that that kind of, you know, schema or you know, loading up new programs can be done through top down modulation, maybe prefrontal cortex loads up in the lower areas, these programs and the corresponding dynamics of what to expect, right? All right. So we'll just say it's in the prefrontal cortex. So how does the prefrontal cortex come to be that way? Yeah. So our hypothesis is that it starts off with all areas operating, you know, in terms of their respective, you know, spatial and temporal scales, right? But by the time you get to the prefrontal cortex, you know, you've already converged, you have information that is now operating at a much longer time scale. And the abstraction level has gone to the point where it's now operating at the level of abstract actions. So there could be a population of neurons that are coding the current context or task, which is saying right now, okay, I want to go to the grocery store. That's like a goal that got instantiated, right? At the highest level. But it's maintained until that goal is achieved, right? And while it's being maintained, it is modulating all the other areas that are involved in achieving that goal, right? And that involves even like the basic lower level somatic, even somatic sensory cortex, facial cortex, auditory cortex, they're all now have that context from the higher area, saying here's what my current goal is. Now let's see if we can achieve that goal, right? And then you get your, I don't know what you would get. My grandmother would get cookies, definitely at the grocery store. You get those cookies and then how does it switch? Yeah, so that is, it's a hierarchy. So as you achieve the sub goal, so basically the idea is that a complex problem, right? A complex task is split up into its sub goals, sub tasks, and those are in terms of split up into sub tasks all the way until you get to the point where you're operating at the level of milliseconds and controlling your muscles, right? And that's happening in the spinal cord loops, right? So the spinal cord is controlling things at a very fast timescale. But then as you go up the hierarchy through the different areas, including the mid brain and then you go all the way up to the cortex, you start to get longer and longer time scales. And then that's where you start to get these sub tasks being achieved. And then those in turn cause a flip to the higher level thing. We go to the next goal. So you're going from one goal to the next goal to the next goal, right? But how does goals get programmed? Yeah, so that's all about learning, right? So you have to learn, and that's what, you know, some people call that curriculum learning in the AI literature. But as babies after we're born, or even before we're born, the wounds we're starting to learn these modules of, okay, what happens if I move my hand in this way, my arm in that way? But then once you're born, you're starting to grab objects, you're trying to reach for objects, you're trying to grasp different kinds of things. So you're building up this repertoire of action policies, right? And the corresponding dynamics that go with the action policies. And the idea is as you go through learning, through your toddler years and so on, you're building up a very rich, you know, a set of primitives that eventually be composed for solving more and more complex problems, right? There's so a lot of unknowns, but I think that's going to be, yeah, right? Right. Right. I guess what I was asking was what, so I mean, I think we've all had the feeling like once you're done with a goal, you're like, well, all right, what now? And you kind of feel lost for a moment until you realize what else you have to do. But what I'm wondering is like how those sequence of abstract goals, if you have an abstract goal, how does it switch? Once you accomplish one, you're going to do the next one and then the next one. How does your prefrontal cortex go? But that's a wonderful question. I think in the model at least, you start off with some higher level goal, which I guess we give it or we say here's the task, right? And then the way it decomposes that is as you go down each higher level abstract action or policy, it generates a function at the lower level. That function basically has as the outputs that remember functions are basically state to action mappings. Each of those actions is now another abstract action, which is like a sub goal, right? And then that in turn generates another function at the lower level all the way down to the spinal cord level, right? And that is what we're saying has to be learned, right? You have to learn each of those sequence sequences, those functions that capture the sequence of sub goals. But we're saying it's the same module replicated at all the levels. And that's one of the things that for me, the mound castles whole idea of a the cortex has something similar across the algorithm, maybe similar across different cortical areas. I mean, as a theorist, I mean, you always have that fascination with those kinds of ideas. And so the challenge here was, is there something like that that we can come up with from a computational point of view? And then of course, the brain may or may not implement it, but let's try to come up with something like that, right? And it turns out that this active predictive coding idea seems like it is versatile enough to tackle many, many different kinds of problems. But it remains to be seen if, you know, how well does it map to something that the brain may actually be doing? Do you believe it? Do you believe Mount Castle that? Not like, yeah, sorry. Sorry. Not like, you know, exactly the cortical column is something that where everything is, right? But what I believe in, there's more broader idea that, you know, if you take any piece of cortex, you know, chunk of it, and then you give it even to trained, you know, a neuroscientist, it may be hard to figure out which part of a cortex that is, right? And of course, there's, you know, motor M1 versus V1, you know, the difference. But I think it has, but 90% is that as who they're connected to, not what they're doing probably. Exactly. Yeah, yeah. And I think that's a really interesting finding because I mean, if you would think, you know, that language area should be programmed very differently from vision areas and so on, if you sort of train traditionally, you would think, okay, visual cortex is doing edge detection, right? But then if you look at the outer cortex, there's no edges. So they can be doing edge detection, right? You're doing something completely different. Motor cortex, right? Must be doing something very different, right? Right. But it's really intriguing if you think about it in terms of, okay, what if they all have components of this kind of, you know, sensory and motor aspects to them. And it's just that in some areas, some got more emphasized than others, but they still have the basic primitives, right? Of sensory, you know, inference as well as motor control, right? And they're operating together at multiple levels. You're a BCI brain computer, brain computer interface person, an engineer minded person. This is maybe a throwaway question, but given, all right. So what you just described is maybe it's somewhere in the prefrontal cortex. There's this higher level, more abstract goal. And then it gets implemented at more, at lower and lower levels until it pans out in a muscular skeletal system. Where would you, if you were evolution, where would you move next? Like, do we just get more and more abstract? What does that mean more and more abstract? What would be a more abstract goal than, you know, make honoring my great, great, great, great, grandmothers legacy by... I don't want to be stereotypical, but by doing something the way that she would do it, right? Mm-hmm. Yeah, yeah. So basically you were saying, okay, what is the next sort of evolutionary milestone? Yeah, it will be, you know, in 10,000 years, yeah, well, how can we can't guess that? Because we've been very bad at it. We can guess it, but we've been pretty bad in terms of... Well, we can. We're very good at guessing and being wrong. Yes, sure. So I would say, I think, I mean, in terms of, at least human evolution, we see that we're essentially, you know, biologically, we may not have added, you know, new cortical areas or new brain structures, but we have been really making amazing strides in terms of adding tools, right, and the cultural knowledge and tools. Perfect segue, by the way, to BCI, but structure interrupt you. Yeah, exactly. So basically, I think if you think about it in terms of, you know, we basically augmented ourselves, right? So humans augmented themselves, originally using tools like rocks, right? And sort of made these little blades to cut meat and so on. And then we, of course, augmented ourselves in terms of wheels to move faster because our legs can only go so fast. And then, of course, we went beyond that to, you know, we had, we were able to fly with airplanes, I mean, more recently, right? And then a similarly memory, right? So memory augmentation. And so, you know, we could only hold so much in our memories, but then we started writing. We had language, so we started writing things down. And then we were able to pass it from generation to generation. So that's another big, you know, tool, right? And in terms of cultural knowledge accumulating over time. This is the most beautiful thing about language, I think. Yes. It's an amazing thing, which other animals, unfortunately, don't have, right? So I think the, that sort of leads to this idea of, okay, so if it's really tool use, right? We all, you know, hang around with the, you know, these devices, you know, in our hands and, you know, in our pockets. And basically, we augmented ourselves in terms of knowledge and access to information with these kinds of devices, right? And so, people in the BCI world and brain computer interfaces, you know, thing, maybe there is a progression there. If you really take that idea to the extreme, then if the brain itself biologically is limited in terms of its speed, right? And in terms of its memory capacities, then would it make sense to then augment it with, you know, artificial memories and artificial processing capacities and artificial communication capacities, right? And that sort of leads into the whole augmentation side of brain machine interfaces or brain computer interfaces, which is an area that is, you know, not something most, I think academics want to really go too much in because there's a lot of ethical applications. So most of us tend to stay on the medical application side, right? That's where the funding is and that's where, you know, a lot of important contributions have been made and need to be made. But, you know, there are companies, you know, and people in the tech world that are really, you know, interested in that aspect, the augmentation aspect, right? Yeah, and uninterested in ethics. But so how do you navigate that? Yeah, so I co-directed Center for New York Technology here. We were funded by NSF for about 10 years as part of an engineering research center. And we had a team, a new ethics team, right? We still have them. But during the grant, what we did was for all the projects, we embedded a member from the new ethics team into the engineering team itself, right? So every engineering team that was developing a brain computer interface application had an analysis who was giving them active feedback about, okay, you know, what is the, and you are going to think about this, where are the long-term implications? And the engineering team? Did your team hate the ethicist? How did that work? I mean, I don't need to ask you how you feel personally about it because it is a conundrum, I think, from a technological point of view, but that's like embedding a philosopher into a research lab or something like... There were a lot of them. Actually, many of them. Of course, of course there. Well, that's all philosophy has left is ethics, right? No, I'm just kidding. Just kidding. But, okay, but yeah, I mean, was the resistance, I mean, you know, I don't want to have to deal with that kind of stuff. This is what I'm saying. And I admire you for doing it. No, I think it's important because as engineers, we're really excited about building the next great thing and, you know, doing something very novel. But at the same time, the consequences may not be anticipated by engineers as much as, you know, people that are more trained to anticipate those consequences. So... Yeah, but the consequences are always bad. Right? Not always, right? I think there are some constructive, you know, things you could do. Like, for example, you know, there were actually, you know, some interesting observations that the ethicists made when they talked to the families of patients that had, for example, deep brain stimulation, right? And many times, a family member provides insights that may not be very obvious, like they made the, the personality of my partner change, right? After they got the DBS or they made a, you know, the, the, the actual patient may, may say, you know, sometimes I feel like I've lost my sense of agency, right? Because there's this device in there. So, so then the question becomes, okay, what are the ways in which, you know, you could restore that sense? If it gets the point where the person feels like they've lost their sense of agency, then is it okay to have a kill switch or some other way to at least provide them some relief? Right? So, there are ways to have, you know, engineering solutions. If you know about some of these things that the patients are going through, right? And I think at least that's a good way to then find ways to address issues before they become, you know, too bad to really, you know, address it, they're commercialized, right? The technology gets commercialized, maybe too late at point in time. So that's one of the hopes, right? But you're right that many companies may not necessarily look into any of these issues, right? Because they're not, or like even academically and research wise. So we're talking about, you mentioned agency, we're talking about concepts that not that philosophy has settled on anything ever, but concepts that are very much in the air in terms of like, well, if, if, I mean, my personality has changed, but if I add a BCI or, you know, some sort of prosthetic to my brain, and then, well, is it the prosthetic, then is it the fault of the prosthetic? Or was that a deep-seated thing in me? Or, you know, so how, who's responsible and, oh, ethically, I don't want to deal with it. So, yeah. Yeah, yeah. Those are great questions that, I mean, we've been, you know, talking about them and we've been discussing those. And I think it gets even more trickier, just think about it in terms of, okay, now we have DBS, which is, you know, open loop stimulation, just delivering some constant current. Let's talk about AI, right? So, if you add AI into the picture that adapts. Well, hang on, before you do that, so this is something that you've done. Yes. And are continuing to do. So just, and I'll introduce this in the beginning, but I mean, there's brainnet, there's neural, neural co-processors. I don't know, I'm not sure how you would like to describe it as sort of an introductory idea, but you've done two people. You've done three, I don't know how many. How many people have you gotten up to in terms of collaborating? Yeah, yeah. So, I think the idea there, so we're talking about brain-to-brain direct communication or, you know, brainnet person, we had three people collaborating directly using their brain signals to solve a problem that was, you know, in that case, which is a Tetris video game, right? And this is, one person gets their, has their brain signals communicated and stimulated in the other two get to interact? Right. So the idea here was, you know, the technology is not there yet in terms of actually doing brain-to-brain communication, but the idea was if we take up this challenge of, okay, let's see what we can do with the technology we have now, as a way to spur people to talk about this technology so that they can put safeguards now or at least start thinking about safeguards before it gets too far away, right? So we said, why don't we take technology we have now like EEG? So we all have, many people have EEG equipment in their lab. So we can use EEG to decode simple things like, you know, if you have like a flashing light, it's called steady state visually work potentials, you can decode the frequency at which you're staring, right? So if you're staring at two different flashing lights, one of them will trigger, you know, oscillations in your visual cortex and we can decode your intention. Or if you imagine making your movement like move your hand, right, or imagine moving your hand, you can decode that from the motor cortex. So what we said was, okay, we can use EEG for decoding. And let's use TMS, the trans-cleanial magnetic stimulation to deliver information directly to the brain, right? Which is just for people listening, TMS is like when there's a coil outside of your brain and there's a pulse aimed at a very small part of your brain, it delivers a non-invasive, non-damaging pulse in your brain and then depending on what function or effects, potentially effects how you think or your behavior. Yeah, and especially if you deliver it to the back of your head, the visual cortex, then you see what is called a phosphine, which would be a little spot of light or a bar or something like that. And so he basically used like a Morse code kind of idea. So the flash was, you know, just conveying binary a bit of information, right? And so we said, okay, whatever we use, these primitive modes of interacting with the brain, so EEG and TMS, and let's build a brain to brain, you know, direct brain to brain communication system with that. And this was, you know, several years ago. We did some proof of concepts and published a few papers on that. Just as a way of, you know, not necessarily saying, look, we can, you know, actually commercialize this technology because obviously it's, we cannot, it's too bulky. But if you just think about companies that are now developing implants, then you can imagine once they have implants on multiple people, then they can start doing this. If they can stimulate the brain and record from the brain, right? It's bidirectional BCI, bidirectional brain computing interface, then you can start to do these kinds of, you know, experiments and you can start to implement these kinds of systems of recording from one brain, stimulating another brain, decoding and encoding the information in another brain, so on, right? And that's where we get into augmentation, right? So now we're using technologies, neuro technology for augmenting the, in this case, the communicative and processing capacity of the human brain. So, so where are you now, right now with these? Right. So once again, I think so we are not, the business of really like going on the commercial routes of what we're doing is a lot of theory. So what we're talking about, people usually ask you that and their question is really like what future or human are you creating? Is that their question? Yeah, I mean, some people are very much interested in that, the singularity and the work is like that, right? What's that going to be in the future? Of course, there's some people who want to merge with AI, so that's the whole other crowd, right? Who want to actually do you want to merge with AI? No, not really. I don't either. Yeah, I don't understand it. But I think what we're doing is in some sense, you know, we're saying, okay, if you really are thinking about processing information from the brain and, you know, making sense of it and sending information back to the brain, that's what we call a co-processor for a brain. And that's what we're working on as a brain co-processor because this idea that there's a device that essentially a tool for the brain that can both decode information from the brain and encode information back into the brain. So what that means is like, so it's listening to the brain and then it goes into an algorithm and it, well, in terms of modern AI, it sort of categorizes what that brain process is signaling. I was almost that understands it and then transforms it into a signal to inject into the brain. I'm sorry, if these are two low-level descriptions. Right. Well, I think that's one way to think about it. And of course, the way it would have to work would be that that co-processor has to have AI in it of some form. And so we suggested a neural co-processor, which was a neural network, so an artificial neural network. And so what we have there is an interaction between artificial and biological neural networks where both of them are adapting. So it's a co-adaptive system, right? So and the challenge there is how do they co-adapt to really achieve a goal, right? So and from a point of view, a medical point of view, if you, for example, are trying to replace lost function, like somebody had stroke and you want to be able to restore their movement, then this could be a device that could replace that lost function of the cortical or other sub cortical circuitry. And the AI has to train itself and the person now has to command this AI replacement circuit, right, to do what the person wants it to do. So then that becomes an interesting AI problem, right? So how do you ensure that the communication between the human brain and the sort of shell device achieves a common goal, right? And that's what we did with the neural co-processor was we said, hey, look, you know, if the goal is for example to reach for an object when the person cannot reach the object, but then you can stimulate, let's say, the spinal cord and make the person reach that particular object, then the error is now in the space of, you know, visual error or so there's an error signal. Can you do back propagation, for example, right? Which is a standard thing people do in AI, right? But the problem is back propagation here, you'd have to do it through your body and your brain, right? You have to do it through the, that's not back propagation by definition. Yeah, but what I mean in terms of ideally, if you want to train your neural network, that's delivering the stimulation, right? And you have to get that error signal somehow. And the error signal unfortunately is now in the space of an external task, right? So what we suggested was, okay, for all of these AI is they need to have an internal model, this forward model of, in this case, your brain dynamics, right? So how your brain reacts to stimulation. So it's like a forward model of, you know, the action here is stimulation. And then it's going to cause your brain dynamics to move in a particular way. And if you're able to predict that dynamics, then you can come up with the best stimulation to give for achieving a particular goal, right? So it becomes again a control problem, right? How imperfect, so I mean, these are things, I just, I'm a neuroscientist, but I pondered these things, you know, like, I mean, one of the most amazing things about that is, what the brain is, how adaptive it is. And sometimes I think, well, maybe that is the function of the function as if there was a function. But the adaptability is like almost the answer. And so what I was going to ask is, how wrong, you know, can it be for the brain to still be able to deal with it, right? Is that a testable question? Like how bad can you make the signal relative to how quickly the brain can learn it as a terrible, poorly phrased question? It's actually a very important question in, especially in the sensory stimulation area. So people that are trying to restore the sense of touch, for example, from an artificial prosthetic device, you know, stimulating the somatic sensory cortex, right? There's a big question there in terms of, you know, should we make the stimulation be as natural as possible? So we make the sense of touch, right? When you stimulate the somatic sensory cortex, you typically, patients typically report, okay, I feel like it's pins and needles, right? It's not quite the nice sense of touch I get when I use my own hand, right? And then you say, well, just wait a week or two and that won't be or something. You could say, hey, you know, you just start used to it. It's a novel signal right now. But if you keep using it, maybe you get used to it and that becomes a natural, you know, sense of. This is like training. This is like trying to convince my children that, oh, don't worry. Keep practicing. It'll get easier, you know, but it sounds pretty painful. Yeah. So that's the painful as a key part of part that because if you are not really delivering, you know, a current code naturalistic stimuli, then it may take much, much longer. Right? So I think there's a trade off there in terms of if you're able to speak the language of the brain in some way, right? Basically, you're delivering the pulses, electrical stimulation, the way that the brain can parse it more easily, then you may be able to learn much more quickly than it's if it's an artificial set of, you know, pulses like stimuli. But it's interesting problem in terms, in terms of natural then is that just noise or is it like the natural statistics of the world? It's more the way that the neurons in that particular area are receiving information from other neurons, right? So, for example, if you know that, you know, in the population level, there's a particular sort of frequencies that are operating at that scale, right? Like, you know, beta frequency oscillations or something. So then you, you can think of delivering the stimulation at some particular phase of that oscillation or you're trying to synchronize with that oscillation. Maybe that is better than you just delivering it at irrespective of what's happening in that brain area. So the bottom line is you need to be recording as well as stimulating. You can't just be stimulating the brain area. You need to be recording to know what's happening in that brain area and then change the stimulation according to what's happening at that point in time to consistently deliver, you know, intelligible stimulation. But within a window because that's anti-fetical to the idea that the brain can handle a bunch of a wide range, right? So a brain area doesn't get to decide the signal incoming. But what you just said is that you need to do it in a way that it's expecting it's a very predictive coding outlook, by the way. Otherwise, it might not work. Yeah, it's a way to enable the brain to learn faster. Like I said, I mean, it's possible that you could not pay attention just to keep delivering something and eventually the brain may figure out how to interpret that stimulation pattern, right? But the question is how long will that take? And so it may happen, you know, quickly, or it may take very, very long or maybe it'll take forever, right? So in general, it makes sense to have some feedback about what's happening in that brain area and as you're delivering the stimulation. Can we partially get to this by doing learning studies and maybe just probing the historical literature and learning studies? So, you know, there's a modern learning studies are becoming more better and better. And I don't know if there is an answer to the proper way to learn X yet. Like the most optimal, I know that there's a lot of people who make a lot of money who say that there is, but I mean, I sort of intuitively think you got to do it. It's got to be feel really bad at first. And that's how you're going to eventually learn, but it also depends on the goal. But do you think that we can, is this an experimentally, behaviorally tractable problem that could help answer these issues? Because you're speaking about the activity in the brain, but then we're eventually talking about behavior. Yeah, it's an interesting question in terms of, you know, how do you study what's happening as the brain is interacting now with this external device that is sending direct input into the brain, right? Or just the optimal input to, yeah, if you're going to use these external devices, right? And so the neural co-processor idea was one way to get at it in terms of saying, okay, if you are able to adapt the neural network that's delivering this stimulation to minimize the error, you know, in the external task space, then you're leaving the brain of having to do a lot of that learning. But of course, the brain is already trying to learn. So it will be changing as a non stationary system, right? Which is why we call it a co-adaptive system. And that's where it becomes tricky. So if it's only one side is adaptive, right? Let's say the brain is adaptive, but then you have a fixed mapping for your stimulation pattern, then that all the burden is on the brain to learn that, right? But then if you do it where the both the systems are able to adapt, then the challenges, can you make it, you know, they're both optimizing the same cost function or same optimization function. And that's where the interesting engineering challenges, right? To make it an adaptive co-evolving system, right? And that's where I think the future is probably going to go if you are going to use AI for these brain computer interfaces. You want to do a quick segment of epiphenomenon or causal? What was that again? You want to do a quick segment of, is this an epiphenomenon or is it causal? Oh, okay, I get quiz. Ready? Yeah, yeah. Well, yeah, opinion. Ready? So, I'm going to do the oscillations. It's, I would say it's causal, yeah. Consciousness. Epiphenomenon. Oh, my God, we're done. I just, I just heard someone say that. But I'm taking the most liberal definition there. Okay, there's only two. I heard someone I respect say consciousness was epiphenomenal and you were talking about oscillations. I just want to be a little bit of that cutting-ass there. So yeah, let's just go with that. Okay, all right, great. That's staying in, by the way. I'm not going to edit that out unless you force me to. Sure. Okay. Before we, so, all right, so I'm looking at the time right now. And first of all, what have we missed about the neural? I'm going to point everyone to all of your work. But I've been punchy and jumping around. So what have we missed in terms of the neural co-processing and or, you know, brainnet and the, we haven't used the term telepathy, right? Which is sort of the coup de gras, the pinnacle, you know, what people, the spooky term, right? That these things imply. I mean, is that a goal? Well, I'm going to stop interjecting. You know, what have we missed in terms of what we haven't spoken about with the neural co-processors? Yeah, so the neural co-process or idea, I mean, there was relationships to the brain-to-brain communication work that we had done early on, right? And that work, of course, got us, you know, both people that were, you know, quite interested and quite intrigued by it. But also, I think a lot of scientists were like, oh, yeah, that's like, you know, just the old, you know, using TMS is like frog legs being stimulated, right? So, so we've got people saying, you know, why did you even do that, right? I think the, oh, really? Yeah, yeah. So the main point is, it's not that we were claiming that, hey, you know, this is like a grand new discovery or invention, right? The idea was to say, okay, you know, we have been talking about things like mind-to-mind communication or telepathy for a long time in science fiction, right? And then with BCI, really progressing at the rate that it's progressing, that companies getting interested in it, this may be a good time to have that conversation, right? So, and I think one of the interesting things there is, you know, we may actually get something like very primitive forms of brain-to-brain communication if these companies have, you know, multiple patients with implants, right? Because it doesn't take much to, you know, send really several kinds of information from one person's brain to another, as soon as you have the ability to stimulate, right? Which is something I haven't seen yet. But if one's that has, starts happening, then I think it's only a small step towards starting some really primitive kinds of what you may call, like, I mean, I'm sure the companies will claim is telepathy, right? But, yeah, they'll be called tele, what will they be called? Because there was the telephone beforehand. Well, it'll be a good company name for that. Right, right. Yeah, so what, but this one, it would be like telling you, eronics or something there, right? So, yeah. Oh, why can't we come over something, Raj? I mean, this is... I think it works. Yeah, it's about to be trademarked first before we can talk about it. No, I'm just kidding. So... I know you have it. You have it in your back pocket and you're not letting, letting on. But yeah, I think the unfortunate consequence of some of these kinds of, I know, claims, right, by companies and even, I think some of the experiments that we've done is that there's a lot of people who are probably schizophrenics who think that they're implanted with these devices already. And so, a lot of us get emails every day, right, from people saying, hey, you know, can you help us? Do you think the garment has implanted something in me? Or there's a chip in my brain? Or the Lord did, you know, or... Yeah. I mean, people actually even come to campus, right? So, there's people who've driven miles just to come to campus to our center to say, hey, you know, hey, the doctor says there's nothing there. Here's an X-ray. There's nothing in the X-ray. But I firmly believe it's this microscopic thing that's in my brain, that's controlling my actions, right? So, unfortunately, I think that's, you know, the price you have to pay, you start to push that frontier. There's going to be people who, you know, also think that, you know, that's happening to them. Even though we can assure them that that's not really possible at this point in time, right? And we don't have the technology to do something like that, but that is something we're faced with as well. So, it's part of the whole ethical, you know, issue and communication issues with this field. Yeah. So, you said that we can't telepathically communicate yet, and we can't stimulate each other's brains what we do all the time. You and I are doing it right now through language. And you have an interest in, I don't know where your interest in the, in this script came from. And, or now you've, at some point you learned a ton about language and just how language works and some of the statistical properties that are indicative of what a language is. But so, is this a hobby of yours? It's beyond a hobby now, but how did you get involved in the indiscrypt and determining trying to decipher this thing? Yeah, I've always been interested in ancient history. And so, I was doing one of my sabbaticals. I think I'm a first sabbatical when I said, okay, you know, what if I indulge in that, you know, fascination with ancient history, right? And especially ancient Indian history goes on from India. And we have the civilization there that's, you know, more than 4,000 years old that we know very little about partly because the script of that civilization is not yet deciphered, right? And this was a civilization that was, you know, much bigger than the Egyptian and the Mesopotamian civilization. So, yeah, so, we're less mes, so, so I took, I'm sorry, I didn't wrap it, but one of my favorite classes that I took when I was an undergraduate was the origins of writing. Denise Schmaltz-Besselrett taught the course and we learned all about Kuneha form and how early writing might have been brought about by economic exchanges with little clay tablets where people put little marks to show how many goats or cattle that need to be owed or exchanged and stuff. Where does this, and I can't remember how, so what you're talking about is for, there's like 2000 BC. Yeah, and before I think starting from 2000, you know, probably 2000, 800 BCs when they believe the civilization started evolving to the point where it was mature enough and then it ended or, you know, the demise of the civilizations thought to be more like 1800 BC, like, 1800 BC, right? But the curious thing about them is that that was not, yeah, it was not like a huge amount of time. I mean, there were some precursors, you know, 3000 BC and so on, but the prime of the civilization, when they were really, you know, in their prime was probably, you know, 1800 to 1800 or so like 1500 BC, right? And I think the interesting thing about the civilization is the fact that they, I mean, they were actually trading actively with the Mesopotamian civilization, right? The Sumerians and, you know, Akad and those civilizations in the Middle East and they've found these seals, you mentioned, you know, they had these stamp seals, so you can stamp, you know, information about typically trade, you know, the kind of goods that they may have been, you know, stamped on. So I think the intriguing thing there is, of course, we know Cuneiform and, you know, the kind of history of writing did evolve from the Middle East, right? And then the Egyptians, of course, followed suit with their hieroglyphics. And it's believed that the, you know, the Indus civilization also evolved their own set of symbols about, you know, 500 to 700 symbols that are very pictographic in many cases. And unfortunately, there are no long inscriptions. So most of the inscriptions they're found have been on these stamp seals, which are only about five symbols long on average. Some of them kind of squished in different. Yeah, so there was like, there's usually an animal imprint which may have been like a symbol of a clan, like a unicorn is the most common animal symbol. Yes, a unicorn, yes. But you know, people in ancient times thought it originated in India, right? So unicorns. I didn't know that. I don't know that. Yeah, yeah. So perhaps it was because of the Indus civilization and their seals, right? But the seals always had at the very top a set of symbols, a sequence of symbols, which were typically on average length five symbols long. But there have been no long inscriptions on tablets. And so unfortunately, we cannot apply many of our, you know, AI techniques, right? Because there's only about 6,000 of these. Right. How do you tokenize that? Yeah. But what we did do, we did do some kind of, you know, analysis of it, which is, which is we looked at the entries, the block entropy of these symbol sequences in terms of which symbol follows, which other symbols sequence. And then we show that the block entries tend to match the block entries of linguistic scripts as opposed to DNA. For example, or, you know, proteins, which are much more, you know, current code random, they're more flexible, right? So the entries are much higher. Music is slightly above language, right? So music is a little is more flexible, but not as much as DNA or, you know, proteins. What's less flexible? Lease flexible is, you know, computer programming languages like Fortran, right? It's below you're going to say Fortran. Yeah, that was the original one that they did, right? So we followed that. But, but I'm sure it may start to fall. I mean, especially with now more different kinds of programming languages. Naturalistic. Naturalistic. You're probably getting closer to the entropy of natural languages, right? But it's an interesting way to think about it. So what we did was say, okay, here's an undisciplined script. Let's look at all the simple sequences and see if they're they fall in any of those ranges. And it turned out that they fall right in the middle of the range of linguistic scripts, which means that perhaps there's at least one piece of evidence that they may have used it to encode, you know, a language, but we still don't know what language that was. There's a huge political debate in India about whether it was, you know, the Indo-Aryan language Sanskrit as the Vedic civilization or is it the South Indians have a Dravidian language family? So some people think, is that language that's encoded in there? Subso political factions are trying to claim it or something? Some sense, yeah. In some sense, there's that. There's also this notion of, you know, Aryan invaders coming to India, people don't like that, right? Any kind of migration to India, especially if it was these Indo-European invaders coming to India, that was the original communal interpretation of it. But the genetic evidence seems to indicate there was actually migrations happening from Central Asia into India. And that's possibly how, you know, these languages like, you know, Sanskrit and many of the North Indian languages will have similarities in grammar with the Indo-European language family, right? Compared to the South, which is more Dravidian language family, which is not related to the North Indian language families. So there's some amount of friction there. And even now you'll see people claiming decipherment of the Vedas, right, in the seals, but it stretches more. But you're an expert now. So you can touch those things, right? To some extent, yeah. I mean, I've definitely dealt into that for a long time now. I can look into it. And unfortunately, most of the time, you can see that they're stretching it, and it's just not a plausible decipherment, right? So I think you're just going to have to wait for more excavations and maybe a Indus Rosetta stone that'll help us decipher that script. But I doubt we'll find it. Do you think we'll find it? Not, I mean, it's a difficult task, right? I mean, it's possible it's already been found, and it's just lying in some warehouse in Iraq, somewhere in a museum, because they were trading with these folks. So maybe there were some inscriptions that had both uniform and the indescript, but so far nobody has found anything like that, right? They have found indescripts with really odd sequences. So it seems like they were using the indescript to express the language in Iraq, like a foreign language, maybe in, oh, yeah. So that's really interesting. But they're only with like five characters, five, five, yes. But the simple sequences are very different from what you'd find in the Indus Valley in the finds there. So they were using it in a different way, at least. So I think there are some really intriguing suggestions like that, right? So is this going to be a lifelong project for you? For me, I mean, it's, I think at this point, it's, you know, it kind of, it's been from being a hobby to more of, you know, really getting drawn into the literature and the history of it. And so I do spend a lot of time reading about it, but, but yeah, but I have no funding for it, and it's, you know, it's more of a sabbatical project, right? But it keeps me interested in something very different from what I typically do. I sort of look at myself, I think somebody is interested in, you know, the past, which is this indescript, and then the present is like, let's figure out the brain out, and then the future is like the BCI augmentations. I'd like to keep, you know, looking at all of those aspects, right? And keeps me keep my brain at least, I know, occupied and interested. So one obvious question to me then is, I mean, not many people who use or, sorry, not many people who engineer large language models are linguists or have a sense of what language is or how it may have come about or it's early post origins, et cetera, or even its origins. I mean, do you, has this affected how you think about large language models? And I'll preface this also by saying that, you know, whatever great AI model is working, people are going to say, well, maybe the brain is like that. And then map whatever AI model is currently working to, brain processes and often it works and stuff. But so do you, has this affected how you think about large language models? Or how do you situate how you think about large language models? Maybe is it a better question? Yeah, I was quite intrigued. I mean, when the paper came out, the, the additional all you need paper, and then also the fact that prediction was a very key aspect of it, right? It's not. Yeah, you must have been elated. Yeah. So it was like, it was basically predictive coding, except for the fact that, you know, they were not using the prediction errors to do inference. I mean, there was no like update of the internal representation. But the learning was obviously, you know, driven by prediction errors, right? And the fact that there was a hierarchy there as well, so that there's these soft attention layers, which is building up these dynamic representations over time. And you're doing sending out the representation to every layer, like every talk, I mean, it's just massive, right? Exactly. But it's sort of in some sense beautiful probably to you. Yeah, it was actually very, you know, interesting to know that, you know, there, there's now this artificial system that just purely based on prediction, right? By predicting the next word, it was able to do so much. Not even recurrent, like there's no feedback. Yeah, I mean, it's not a regressor model, but yeah, yeah, you're right. But effectively, it was like taking into account everything in the past, well, processing the future and the future and the past were all getting processed simultaneously, right? But I think the cool thing there was the fact that I was able to really learn these very impressive, you know, predictive models and then generate these sequences, which seems to be, it seemed to be quite in line, but, you know, the kind of thing we were thinking about for our, you know, in our active predictive coding model, this idea that there's a sensory processing aspect that's constantly predicting the next state, based on the previous state and action, but there's no action here, right? The action was missing, right? Actions just output. It's just like a token, basically, that the previous token, maybe like being put in, or you know, you sort of all the tokens in the past have been are being used to process the current token, right? So, but I think that that's also something that's missing is, you know, my sense is the controller is missing, right? So in the active predictive coding architecture, there's a policy network that is controlling the generation of the next input, right? So we have the predictive network and the controller network and they're closely interacting with each other, and depending on the task, right, the controller network is feeding in the action to the predictive network, saying, okay, generate this next, right? Because I'm going to take this action. And I think we've lost that in the transformer model, right? And I think that's where, you know, some of these RL approaches are applying now to the transformer models. It's kind of getting the controller back in the picture. So I think that's where I see your relationship. And more recently, people have shown that transformer networks implement a special kind of hyper networks, which is what we are using for active predictive coding. So when I said that the higher areas are modulating the lower areas in active predictive coding, right? The higher critical areas may be modulating the function being computed at the lower areas. That is basically what is called a hyper network in the AI literature, where the vector and input at the higher level is transformed by a neural network called a hyper network, right? To another neural network, which is the function, right? It's basically a whole new network is being generated. And it appears that transformers are doing something like that in a simple way, right? Like a linear hyper network model. So I think if that's true, then I would say there's probably a closer link between what you suggested and what transformers are doing, except we were trying to model the cortical architecture in terms of, you know, hierarchy and laminar structure. Transformers don't have that, right? And they don't have the controller aspect either. Yeah. Yeah. So then overall, our transformers, I'm trying to get a sense of your judgment on them. So they're great, but they're not enough, right? They're great as a principle of how predictive models can really, you know, capture a lot of information about the, you know, essentially the statistics of the world, right? The physics of the world or the dynamics of the world, they can be used to capture that, but that's not enough for, you know, intelligence, right? So I would say, you know, I go back to that, you know, notion that, you know, people have suggested, you know, policies like and just bizarre, you know, there's that, you know, ultimately, it's all about actions and movements. And so if you don't have the controller there, telling you what to do, right? Then you like transformers don't have like chat GPT and transformers. They don't have a sense of agency, right? And that's how, what's that? How do you get that? How do you get a sense of agency? Well, I think we get it from being able to act in the world and being able to actively use action as a way to generate language, right? So, and we get that because we actually act upon the world and we, you know, we use speech, right? And that's actual motor actions, right? Yeah, but squirrels have agency, right? And they don't have speech. Yeah, yeah. So you have to have action, you don't have to have speech, but in order to have agency, you need to be able to act upon the world and be able to, you know, cost consequences. You have to be able to see the consequences of your action. And then maybe achieve goals. So you start to see, okay, now if I take these actions, I achieve my goals. And then if I do these actions, I get something else. And that's how you build a sense of agency, right? And then for a purely predictive system, which is only predicting, but, but not really using actions as a way to guide those predictions and get to a particular goal, right? Then it becomes hard to argue it has agency, right? I mean, some people do, but I think it's a missing piece, right? So you think that we could build agency? Yeah, I think I think any, you know, system that starts to interact with the world with its own actions and, you know, generate goals. I mean, those are all things that you associate with an agent, right? So I think you do require to have that policy or controller and, you know, potentially a model of the world to go along with it. I have two more questions for you in a promise I'll let you go. Oh, it's been fun. Way earlier. I'm sorry. It's been fun. So I could probably go on. So yeah, go ahead. Oh, that's okay. Okay. What do you want to learn? You just do that. I have to, I have to be up for the bra, I'm doing a brain initiative workshop tomorrow, where I have to participate. So I have to, I have to like, yeah, one. So way earlier on, we were talking, when we were talking about active predictive coding or predictive processing. In general, you were talking about, you know, back then, back in 1999, they're, you know, when we were, when people, I said, I said, we were recording single neurons. And that's when I grew up, I recorded single neurons. And the technology wasn't quite there to be able to begin testing the hypotheses that might be issued from a theoretical framework like predictive coding. Since then, we now have, we're starting to get connect homes, which everyone always said, like, well, man, once we have a map of every of all the connections, we can do everything. And that is starting to come to pass. We now have super high density recording techniques, neuronal recording techniques, so that we can put high density electrodes in different parts of the brain and get lots, get lots of neurons. But between those two, okay, and then now, and we have, sorry, there's like five things, right? Those two, and then we have AI models. We have high compute. We have lots of more, a lot more statistical models that we can employ. That's the same as AI in terms of modeling. Which of those, if any, like, has been, do you think is the most important that is happening right now? That's a trick question, because I think if I choose one, it's probably going to alienate a whole bunch of people working on the others. I would say we need to call... No, no, no, no, no, no, no. That's good differently. That's good differently. Which of those do you... when you wake up, you're like, oh man, I could use this to do that. In your current... I know they're all necessary and awesome. Yes. Yeah, I think I mean, it changes, right? So for me, the amazing part, I mean, it's a fantastic time to be a third edition in neuroscience right now, because there's so much data, right? And this is a great time to really think about these larger scale theories. So when I was a grad student, you know, there were books and papers by Mumford. There was a book called Large Scale Neuralin Theory of the Brain, by Christophe Koch and Joel Davis. And these were all like, at that time, you know, there were these theories, but then the data just was not there to test these theories. But now I think we're at a time where we can actually start to test some of these theories. So I would say, you know, from one day to another, right? I feel like, in some days, when I'm thinking about a particular theory, I may go into the literature on Large Scale Neuralin Recordings, really try to find, okay, is this supported or not? And what are the things out there? But then the next day, I'm actually be looking at connectomics to see, okay, is that connectivity and anatomy still, you know, is that there, right? Is support some of these other theories, right? And of course, AI is a wellspring of new ideas always. I mean, there's so much going on in AI that is hard to keep up, right? But then, of course, there's some gems there that you can pick out and then see if that's relevant to understanding the brain. So I think it just feels like, you know, we're at a time where it's this explosion of information and, you know, really to make advances, it's almost like you have to train your brain to essentially, you know, forage and find the right kinds of information to really build up, you know, new theories, right? It's a tough task, but I think it's actually better than not having any data. Like, when I was a grass-driven, we didn't really have that kind of data. We had, like you said, single neuron, you know, responses. And so one is very difficult to say, okay, what's the system doing, right? The systems level. Now, I think we're getting the point where we can actively collaborate. I think the, the, your generation, the generation, you know, that's actually, you know, training right now. I mean, they're much more, I think, savvy with computational models. They're much more receptive. Oh, yeah. You know, computational models. I think that's really great, right? That means that these ideas, like predictive coding, hopefully, you know, can be tested more quickly, and they're not going to lie dormant for 10 years, right? Before people start taking an interest in them. So, so I feel like this is a great time for, you know, people like I encourage people in many different areas that they can be computer scientists, they can be people doing AI, they can be people, you know, in neuroscience psychology. I think they should all, you know, feel, uh, in a comfortable, but coming up with theories and computational models. Um, and I think we have the training now in many areas. But this is a great time to start thinking big, right? Think across just one area and one the kitchen, right? Can you? So there's maybe a paradox here, right? So if you have tons and tons of tools, it may be harder to think big, like it may be harder to think theoretically. I'm wondering how, how you might think to foster someone's theoretical bent or how to think theoretically given this deluge of tools? Yeah. So, uh, that's a great question again. So I think, uh, it's something that you, uh, for me, at least it comes from thinking about it, uh, first from a computational point of view, saying, okay, here's a particular problem that, you know, let's see if we think of solving this problem, how would you do that from a normative point of view or from an AI point of view, right? But then I think you, you can, you can then say, okay, let's look at some of the data from the brain in terms of where, uh, these kinds of problems have been explored, right? And then that's one way to do it is to start from the computational and then go more deeper and deeper into the neuroscience. The other way is to go bottom up, right? So you could say, okay, you know, I'm working on these areas, but then, you know, I want to actually go beyond just as one area from a theoretical point of view, right? Even though I'm just recording from this area, but let's think of it in terms of this area interacting with all the other areas that are connected to it. And then the bigger picture of behavior, right? And how is that going to work? Right? And so maybe look at people working in those other areas as well, right? Uh, it is a hard problem. Uh, but, um, I think it's worth, uh, you know, looking at it beyond just, I don't remember like when I was, uh, uh, postdoc, I went to the lab of a very famous neuroscientist and then, you know, I was asking, is it? On the, yeah, I was doing a postdoc in San ASCII lab in SAUG, but I was sitting another lab somewhere else. Okay. Right? That's a different famous nerds. Yes. Yes. There's another, uh, I was doing a postdoc in Terry's lab, uh, but then I went to a different, visiting a lab, right? Many different labs were visiting at the time as a theoretician. Um, and then I was asking them, you know, hey, uh, you know, the person who was working in V1 and then said, okay, what about V2, right? I mean, V2 and V1 are connected, uh, you know, shouldn't be considering the interactions between the two, but the person said, no, no, I'm going to figure out V1 first. I'm trying to understand V1. I'm going to, I'm going to understand V2, right? Right. But what if you cannot do that, right? What if you cannot reduce, it's not a, you know, reduce ability in that sense, right? What if V1's properties are intimately connected with V2 and other structures, right? Then it becomes really hard to understand just one area, right? So, um, I think that's, that's the challenge we have, right? As neuroscientists is, um, you know, the brain is a very complex, you know, uh, piece of machinery that's been evolving or millennia. Uh, and if you use, uh, you know, sort of reductionism, then it becomes very hard, right? To understand what's happening across the brain. Uh, at the same time, maybe we don't have the capacity to understand the whole brain, uh, like what's happening everywhere. So then we have to find ways of picking the right abstraction level to understand and hopefully connect those abstraction levels, like from the behavior level all the way down to like the molecules, right? But one person may not be able to do all of that, but hopefully as a community, we can start to understand, you know, the brain at multiple levels of understanding. It's hard. It's hard. And even people who, like you who are like super good at it, uh, definitely, you will admit it. It's a little difficult. Definitely. Definitely. Especially with all the information that's now coming out and trying to, uh, but I don't think we can lose hope, right? So I'm optimistic that, you know, uh, it's going to happen, right? I don't know if it's in my lifetime, but, uh, I think we're on, on our way, right? It may be sort of that we think, right? So, um, I think I should be optimistic about that. All right. Well, that's a great note to end it on. Um, I meant to mention this up at the top, what I'm going to do when we're done here, I'm going to email you an invitation to join me again because I know it takes about a year to get you on. So, uh, it took, it took a long time to get you on, but man, I really appreciate it, Raj. You're coming on. It was fun. Yeah, it was fun. Thanks, again for having me. Yeah. Brain inspired is powered by the transmitter, an online publication that aims to deliver useful information, insights and tools to build bridges across neuroscience and advanced research. Visit thetransmitter.org to explore the latest neuroscience news and perspectives written by journalists and scientists. If you value brain inspired, support it through Patreon to access full-length episodes, join our discord community and even influence why and bite to the podcast. Go to braininspired.co to learn more. The music you're hearing is Little Wing, performed by Kyle Dunovan. Thank you for your support. See you next time.