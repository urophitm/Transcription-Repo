 The following is a conversation with Demis Hassabis, CEO and co-founder of DeepMind, a company that has published and built some of the most incredible artificial intelligence systems in the history of computing, including Alpha Zero that learned all by itself to play the game of Go better than any human in the world and Alpha Fold 2 that solved protein folding. Both tasks considered nearly impossible for a very long time. Demis is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general. This was truly an honor and a pleasure for me to finally sit down with him for this conversation and I'm sure we will talk many times again in the future. And now a quick few second mention of each sponsor. Check them out in the description. That's the best way to support this podcast. We got mail gun for email campaigns, inside tracker for longevity, on it for supplements, indeed for hiring, and magic spoon for breakfast. Choose wisely my friends. And now I want to the full ad reads. As always, no ads in the middle. I try to make this interesting but if you skip them, please still check out our sponsors. I enjoy their stuff. Maybe you will too. This show is brought to you by mail gun by SYNCH, an email delivery service that I've used for many many years to have an API that allows you to programmatically send emails. If you don't know what an API is, the point is it's a way for programs for code to interact with the service. You have an API for both transactional and marketing emails. Those are terms used by people might smarter about the stuff than me. But I think transactional means specific to the person emails, which is what I guess used. It's a way to email certain people to notify them about the status of whatever the heck they're doing on the website. And then there's marketing emails, which is when you send an email to a lot of people like the same email. I guess transactional is super customized to an action that a person took and marketing is like a push email that you send to a lot of people. And both of those two categories of how people often use email. And so mail gun is a service that makes it super easy for you to do that kind of thing. You can go to lexfreedman.com slash mailgun to learn more. This show is also brought to you by Inside Tracker, a service I use to track biological data data that comes from my body. A lot of their plans that you can send out for include blood tests. Why blood tests? Because a lot of really useful data comes from your blood. And then they use machine learning algorithms to analyze that data. So that includes blood data, DNA data and even data from your fitness tracker to provide your clear picture what's going on inside your body. This is the future. Anything you decide to do in your life should be based on data from your entity from your being. That means your biological body. Maybe one day that means from your brain as well. There'll be a brain computer interface device like neural length that collects data from your brain and is able to make suggestions of what kind of supplements to take, what kind of diet changes to make. You can go to inside tracker.com slash lex and for a limited time you get special savings for being a listener of this very podcast. This episode is also brought to you by Onnet, a nutrition supplement and fitness company. They have a thing called Alphabraine, which is a newtropic that helps you with the memory, mental speed and focus. You might know it because of Mr. Joe Rogan, which is probably the first time I heard an onnet read is one of the first podcasts actually, Joe's that I listen to religiously. I'm a huge fan of audiobooks and podcasts in general, but there's something about the authenticity of the Joe projects that immediately connected with me. Over time, his ability to be curious and empathetic, a good listener but also be able to change his mind, keep an open mind to some crazy ideas. Anyway, I mentioned that because the Joe Rogan experience introduced me to a lot of these kinds of products like Onnet that quickly became part of my life. I guess podcasts at Reeswork. Anyway, you can get a special discount on Alphabraine if you go to lexframing.com slash Onnet. This show is also brought to you by Indeed, a hiring website. I've used them as part of many hiring efforts I've done for the teams of lead in the past. They have indeed as the match that gives you quality candidates whose resumes that indeed fit your job description immediately. I've said this before. I'll say it again. There's very few things in life as important as the people you surround yourself with. I'm somebody for whom the work I've done brings a lot of meaning and joy to my life even when I sold shoes at Sears shoes in the women's section. That little community that you have as you try to figure out this new skill, those people are so instrumental to your happiness and to your effectiveness, to your growth as a human being. So hiring is really, really, really important. That's why you should use the best tools for the job. Indeed is one such tool. They have a special offer for listeners that this podcast only available for limited time. Check it out at Indeed.com slash Lex. This episode is also brought to you by an old but a goody magic spoon, a low carb keto-friendly cereal. They were there from the beginning. I really love magic spoon. It brings so much joy to my heart. I don't care if this is not your thing. Please get it and make it your thing because it's freaking delicious. It has all the deliciousness of a cereal without any of the negative stuff, like all the sugar. It has zero grams of sugar. 13 to 14 grams of protein, only 4-9 grams of carbs, 140 calories in each serving. It's like I said keto-friendly. It's magic. I don't understand how it works. I don't understand how it can be so delicious, but they have a lot of flavors. I would say peanut butter is up there for me. Maybe top three. Maybe it's my second favorite, but by far, my favorite is cocoa. Magic spoon has a 100 percent happiness guarantee, so if you don't like it, they'll refund it. Get a discount on your order if you go to magicspoon.com slash Lex and use code Lex. This is the Lex Reveman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Demis Hassabas. Let's start with a bit of a personal question. M-I and A-I program you wrote to interview people until I get good enough to interview you. M-Well, I'll be impressed if you were. I'll be impressed by myself if you were. I don't think we're quite up to that yet, but maybe you're from the future, Lex. M-If you did, would you tell me? Is that a good thing to tell a language model that's tasked with interviewing that it is, in fact, A-I? M-Maybe we're in a kind of meta-turing test. M-Probably, it would be a good idea not to tell you, so it doesn't change your behavior, right? M-This is a kind of vice and bird uncertainty principle situation. If I told you, you behaved differently. Maybe that's what's happening with us, of course. M-This is a benchmark from the future where they replay 2022 as a year before A-I's were good enough yet, and now we want to see, is it going to pass? M-Exactly. M-If I was such a program, would you be able to tell, do you think? To the touring test question, you've talked about the benchmark for solving intelligence. What would be the impressive thing? You've talked about winning a Nobel prize and asked, is the winning a Nobel prize. But I still return to the touring test as a compelling test. The spirit of the touring test is a compelling test. M-Yeah, the touring test, of course, it's been unbelievably influential in Cheering's one of my all-time heroes, but I think if you look back at the 1950 papers, original paper and read the original, you'll see, I don't think he meant it to be a rigorous formal test. I think it was more like a thought experiment. Almost a bit of philosophy he was writing, if you look at the style of the paper. And you can see he didn't specify it very rigorously. For example, he didn't specify the knowledge that the expert or judge would have. Not having to know how much time would they have to investigate this. So these important parameters, if you were going to make it a true formal test. By some measures, people claim the touring test passed several decade ago. I remember someone claiming that with a very bog standard, normal logic model, because they pretended it was a kit. So the judges thought that the machine was a child. That would be very different from an expert AI person interrogating a machine, and knowing how it was built and so on. So I think we should probably move away from that as a formal test and move more towards a general test where we test the AI capabilities on a range of tasks and see if it reaches human level or above performance on maybe thousands, perhaps even millions of tasks eventually, and cover the entire sort of cognitive space. So I think for its time, it was an amazing thought experiment. And also 1950s, obviously, there's barely the dawn of the computer age. So of course, he only thought about text. And now we have a lot more different inputs. So yeah, maybe the better thing to test is the generalizability. So across multiple tasks. But I think it's also possible as systems like God will show that eventually that might map right back to language. So you might be able to demonstrate your ability to generalize across tasks by then communicating your ability to generalize across tasks, which is kind of what we do through conversation. Anyway, when we jump around, ultimately what's in there in that conversation is not just you moving around knowledge. It's you moving around like these entirely different modalities of understanding that ultimately map to your ability to to operate successfully in all these domains, which you can think of as tasks. Yeah, I think certainly we as humans use language as our main generalization communication tool. So I think we end up thinking in language and expressing our solutions in language. So it's going to be very powerful mode in which to explain the system to explain what it's doing. But I don't think it's the only modality that matters. So I think there's going to be a lot of, you know, there's a lot of different ways to express capabilities other than just language. Yeah, visual, robotics, body language, yeah, actions, the interactive aspect of all that that's all part of it. But what's interesting with Gata is that it's sort of pushing prediction to the maximum in terms of like mapping arbitrary sequences to other sequences and sort of just predicting what's going to happen next. So prediction seems to be fundamental to intelligence. And what you're predicting doesn't so much matter? Yeah, it seems like you can generalize that quite well. So obviously language models predict the next word. Gata predicts potentially any action or any token. And it's just the beginning really. It's our most general agent one could call it so far. But you know, that itself can be scaled up massively more than we've done so far. And obviously, we're in the middle of doing that. But the big part of solving AGI is creating benchmarks that help us get closer and closer, sort of creating benchmarks that test the generalizability. And it's just still interesting that this fellow Alan Turing was one of the first and probably still one of the only people that was trying maybe philosophical people was trying to formulate a benchmark that could be followed. It is even though it's fuzzy, it's still sufficiently rigorous the way you can run that test. And I still think something like the Turing test will end at the end of the day be the thing that truly impresses other humans so that you can have a close friend who's an AI system. And for that friend to be a good friend, they're going to have to be able to play Starcraft. And they're going to have to do all of these tasks. Get you a beer so that the Gorbatax tasks play games with you. Use language, humor, all those kinds of things. But that ultimately can blow down to language. It feels like not in terms of the AI community, but in terms of the actual impact of general intelligence on the world, it feels like language will be the place where it truly shines. I think so because it's such an important input output for us. I think you're right. I think the Turing test, the philosophy behind it, which is the idea of can a machine mimic the behaviors of a human. And I would say wider than just language and text. Then in terms of actions and everything else, creativity, all these things, then if it can sort of mature, exceed human cognitive capabilities, then I think we have a true intelligence. So from that perspective, you're right. I think he did formulate the right kind of set up. I just, I think there'll be a kind of humor in the AI systems, the future, looking back to this conversation and thinking about the Turing test and also thinking about by that time, they would know which year they were finally able to sort of cross the threshold of human level intelligence and think how funny it is that we humans were still confused about this whole problem. That's a good long ago been solved. Hello to the AI agents of the future. Anyway, so go back to your journey. When did you fall in love with programming first? Well, it was pretty, it was pretty young age actually. So, you know, I started off, actually games was my first love. So starting to play chess when I was around four years old and then it was actually with winnings from a chess competition that I managed to buy my first chess computer when I was about eight years old. It was a ZX Spectrum, which was hugely popular in the UK at the time. And it was an amazing machine because I think it trained a whole generation of programmers in the UK because it was so accessible. You know, you literally switched it on and there was the basic prompt and you could just get going. And my parents didn't really know anything about computers. But because it was my money from a chess competition, I could say I wanted to buy it. And then, you know, I just went to bookstores, got books on programming and started typing in, you know, the programming code. And then of course, once you start doing that, you start adjusting it and then making your own games. And that's when I fell in love with computers and realised that they were a very magical device. In a way, I kind of, I don't want to be able to explain this at the time, but I felt that they were sort of almost a magical extension of your mind. I always had this feeling and I've always loved this about computers that you can set them off doing something, some task for you. You can go to sleep, come back the next day and it's solved. You know, that feels magical to me. So I mean, all machines do that to some extent. They all enhance our natural capabilities. Obviously, cars make us allow us to move faster than we can run. But this was a machine to extend the mind. And then of course, AI is the ultimate expression of what a machine may be able to do all that. So very naturally for me, that thought extended into AI quite quickly. You remember the programming language that was first started? Yes. Special to the machine. No, it was just the basic, I think it was just basic on the ZXBETRE. I don't know what specific form it was. And then later on, I got a Commodore Miga, which was a fantastic machine. Now you're just showing off. So yeah, well, lots of my friends had Atari STs and I managed to get Amiga's. It was a bit more powerful and that was incredible and used to do programming in assembler and also Amos Basic, this specific form of basic. It was incredible actually. So all my coding skills. And when did you fall in love with AI? So when did you first start to get an understanding that you can not just write programs that do some mathematical operations for you while you sleep, but something that's a keen to bringing an entity to life, sort of a thing that can figure out something more complicated than a simple mathematical operation. Yeah, so there was a few stages for me all while I was very young. So first of all, as I was trying to improve at playing chess, I was captaining various England junior chess teams and at the time when I was about, you know, maybe 10, 11 years old, I was going to become a professional chess player. That was my first thought. So that dream was there to try to get to the highest level of chess. Yeah, so I was, you know, I got to, when I was about 12 years old, I got to master standard and I was second highest rated player in the world to Judith Polga, who obviously ended up being an amazing chess player and a world women's champion. And when I was trying to improve at chess, what you do is you, obviously, first of all, you're trying to improve your own thinking processes. So that leads you to thinking about thinking, how is your brain coming up with these ideas? Why is it making mistakes? How can you, how can you improve that thought process? But the second thing is that you, it was just the beginning. This was like in the, in the early 80s, mid 80s of chess computers. If you remember, they were physical balls like the one we have in front of us and you pressed down the, you know, the squares. And I think Kasparov had a branded version of it that I got. And you were, you know, used to, they're not as strong as they are today, but they were, they were pretty strong and used to practice against them to try and improve your openings and other things. And so I remember, I think I probably got my first one, I was around 11 or 12. And I remember thinking, this is amazing, you know, how, how I saw one programed this, this chess board to play chess. And it was very formative book I bought, which was called the chess computer handbook by David Levy. So then came out in 1984 or something. So I must have got it when I was about 11, 12. And it explained fully how these chess programs were made. And I remember my first AI program being programming my Amiga, it couldn't, it wasn't powerful enough to play chess. I couldn't write whole chess program, but I wrote a program for it to play Othello, reverse it sometimes called I think in the US. And so a slightly simpler game than chess. But I used all of the principles that chess programs had, Alphabet, Assert, all of that. And that was my first AI program. I remember that very well. It was around 12 years old. So that brought me into AI. And then the second part was later on, on as around 1617, and I was writing games professionally, designing games, writing game called Theme Park, which had AI as a core gameplay component as part of the simulation. And it sold, you know, millions of copies around the world. And people loved the way that the AI, even though it was relatively simple, by today's AI standards, was reacting to the way you as the player played it. So it was a called a sandbox game. So it was one of the first types of games like that, along with SimCity. And it meant that every game you played was unique. Is there something you could say just on a small tangent about really impressive AI from a game design, human enjoyment perspective, really impressive AI that you've seen in games. And maybe what does it take to create AI system? And how hard of a problem is that? So a million questions that were just as a brief tangent? Well, look, I think games have been significant in my life for three reasons. So first of all, I was playing them and training myself on games when I was a kid. Then I went through a phase of designing games and writing AI for games. So all the games I professionally wrote had AI as a core component. And that was mostly in the in the 90s. And the reason I was doing that in games industry was at the time the games industry, I think, was the cutting edge of technology. So whether it was graphics with people like John Carmack and Quake and those kind of things or AI, I think actually all the action was going on in games. And we've seen we're still reaping the benefits of that even with things like GPUs, which you know, I find ironic, was obviously invented for graphics, computer graphics, but then turns out to be amazingly useful for AI. It just turns out everything's a matrix multiplication appeared in the whole world. So I think games at the time had the most cutting edge AI and a lot of the games we, you know, I was involved in writing. So there was a game called Black and White, which was one game I was involved with in the early stages of which I still think is the most impressive example of reinforcement learning in a computer game. So in that game, you know, you trained a little pet animal and yeah, and it sort of learned from how you were treating it. So if you treated it badly, then it became mean. And then it would be mean to your villagers and your population, the sort of a little tribe that you were running. But if you were kind to it, then it would be kind. And people fascinated by how that was. And so as I, to be honest, with the way it kind of developed. And especially the mapping to good and evil, yeah, made you, made you realize, made me realize that you can sort of in the way in the choices you make can define the where you end up. And that means all of us are capable of the good evil. It all matters in the different choices along the trajectory to those places that you make. It's fascinating. I mean, games can do that for a soft get to you. And it's rare. It seems rare. Yeah. Well, games are I think unique medium because you as the player, you're not just passively consuming the entertainment, right? You're actually actively involved as an agent. So I think that's what makes it in some ways can be more visceral than other other mediums like films and books. So the second, so that was designing AI in games. And then the third use, we've used of AI is in deep mind from the beginning, which is using games as a testing ground for proving out AI algorithms and developing AI algorithms. And that was a sort of a core component of our vision at the start of deep mind was that we would use games very heavily as our main testing ground, certainly to begin with because it's super efficient to use games. And also, you know, it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements. And because those games are often rooted in something that humans did for a long time beforehand, there's already a strong set of rules. Like it's already a damn good benchmark. Yes, it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things. And in some cases like Go, we've been playing it for thousands of years. And often they have scores or at least win conditions. So it's very easy for a reward learning system to get a reward. It's very easy to specify what that reward is. And also at the end, it's easy to test externally how strong is your system by, of course, playing against the world's strongest players at those games. So it's so good for so many reasons. And it's also very efficient to run potentially millions of simulations in parallel on the cloud. So I think there's a huge reason why we were so successful back in starting out 2010 how come we were able to progress so quickly because we'd utilize games. And at the beginning of DeepMind, we also hired some amazing game engineers who I knew from my previous lives in the games industry. And that helped to bootstrap us very quickly. And plus it's somehow super compelling almost at a philosophical level of Man vs. Machine over or over chessboard or a go board. And especially given that the entire history of AI is defined by people saying it's going to be impossible to make a machine that beats a human being in chess. And then once that happened, people were certain when I was coming up in AI that go is not a game that could be solved because of the combinatorial complexity is just two. It's no matter how much more is law you have, compute is just never going to be able to crack the game of go. And so then there's something compelling about facing sort of taken on the impossibility of that task from the AI researcher perspective, engineer perspective. And then as a human being just observing this whole thing, your beliefs about where your thought was impossible being broken apart. It's humbling to realize we're not as smart as we thought. It's humbling to realize that the things we think are impossible now perhaps will be done in the future. There's something really powerful about a game, AI system being a human being in a game that drives that message home for millions of people, especially in the case of go. Sure. Well, look, I think it's a, I mean, it has been a fascinating journey. And especially as I think about it from, I can understand it from both sides, both as the AI creators of the AI, but also as a games player originally. So it was a really interesting, I mean, it was a fantastic, but also somewhat bittersweet moment. The alpha go match for me, seeing that and being obviously heavily, heavily involved in that. But you know, as you say, chess has been the, I mean, Caspar, I think rightly called it the drosophila of intelligence, right? So it's sort of, I love that phrase. And I think he's right because chess has been hand in hand with AI from the beginning of the whole field. So I think every AI practitioner starting with Cheering and Claude Chanan and all those, the sort of forefathers of the field tried their hand at writing a chess program. I've got original audition of Claude Chanan's first chess program. I think it was 1949, the original sort of paper. And they all did that. And Cheering famously wrote a chess program that, but all the computers around then were obviously too slow to run it. So he had to run, he had to be the computer. Right. So he literally, I think, spent two or three days running his own program by hand with pencil and paper and playing playing a friend of his with his chess program. So of course, deep blue was a huge moment beating Caspar off. But actually, when that happened, I remember that very, very vividly, of course, because it was, you know, chess and computers and AI, all the things I loved. And I was at college at the time. But I remember coming away from that, being more impressed by Caspar off's mind than I was by deep blue. Because here was Caspar off with his human mind, not only could he play chess more or less to the same level as this brute of a calculation machine. But of course, Caspar off can do everything else humans can do. Right. A bike, talk many languages, do politics, all the rest of the amazing things that Caspar off does. And so with the same brain and yet deep blue, brilliant as it was at chess, it'd been hand coded for chess. And actually had distilled the knowledge of chess grandmasters into a into a cool program. But it couldn't do anything else. Like it couldn't even play a strictly simpler game like tick, tic, tac, toe. So something to me was missing from intelligence from that system that we would regard as intelligence. And I think it was this idea of generality and also learning. So, and that's what we should learn. We tried to do it with AlphaGo. Yeah. With AlphaGo and Alpha0, Muz0, and then God, all the things that we'll get into some parts of. There's just a fascinating trajectory here. But let's just stick on chess briefly on the human side of chess. You've proposed that from a game design perspective, the thing that makes chess compelling as a game is that there's a creative tension between a bishop and the knight. Can you explain this? First of all, it's really interesting to think about what makes a game compelling makes it stick across centuries. Yeah. I was sort of thinking about this and actually a lot of even amazing chess players don't think about it necessarily from a game's designer point of view. So it's with my game design hat on that I was thinking about this. Why is chess so compelling? And I think a critical reason is the the dynamicness of the different kind of chess positions you can have, whether they're closed or open and other things comes from the bishop and the knight. So if you think about how different the capabilities of the bishop and knight are in terms of the way they move and then somehow chess has evolved to balance those two capabilities more or less equally. So they're both roughly worth three points each. So you think that dynamics is always there and then the rest of the rules are kind of trying to stabilize the game. Well, maybe I mean it's sort of I don't know as chicken and egg situation probably both came together. But the fact that it's got to this beautiful equilibrium where you can have the bishop and knight that are so different in power. But so equal in value across the set of the universe of all positions. Somehow they've been balanced by humanity over hundreds of years. I think gives the game the creative tension that you can swap the bishop and knights for a bishop for a knight and they're more or less the worth the same. But now you aim for a different type of position. If you have the knight you want a closed position. If you have the bishop you want an open position. So I think that creates a lot of the creative tension in chess. So some kind of controlled creative tension. From an AI perspective, do you think AI systems could venture design games that are optimally compelling to humans? Well, that's an interesting question. Sometimes I get asked about AI and creativity. And the way I answer that is relevant to that question, which is that I think there are different levels of creativity. One could say, so I think if we define creativity as coming up with something original, right? That's that's useful for a purpose. Then I think the kind of lowest level of creativity is like an interpolation. So an averaging of all the examples you see. So maybe very basic AI system could say you could have that. So you show it millions of pictures of cats and then you say give me an average looking cat. Right? Generate me an average looking cat. I would call that interpolation. Then there's extrapolation, which something like AlphaGo showed. So AlphaGo played millions of games of Go against itself. And then it came up with brilliant new ideas like move 37 in game two, brilliant motif strategies in Go that no humans had ever thought of, even though we've played it for thousands of years and professionally for hundreds of years. So that I call that extrapolation. But then that's still there's still a level above that, which is you know, you could call out of the box thinking or true innovation, which is could you invent Go, right? Could you invent chess and not just come up with a brilliant chess move or brilliant Go move, but can you can you actually invent chess or something as good as chess or go? And I think one day AI could, but the what's missing is how would you even specify that task to a program right now? And the way I would do it if I was best to telling a human to do it or games designer to human games designer to do it is I would say something like go I would say come up with a game that only takes five minutes to learn, which Go does because it's got simple rules, but many lifetimes to master, right, or impossible to master in one lifetime because so deep and so complex. And then it's aesthetically beautiful and also it can be completed in three or four hours of gameplay time, which is you know, useful for our you know in a in a human day. And so you might specify these side of high level concepts like that. And then you know with that and there may be a few other things one could imagine that goes satisfies those those constraints. But the problem is is that we we're not able to specify abstract notions like that high level abstract notions like that yet two hour AI systems. And I think there's still something missing there in terms of high level concepts or abstractions that they truly understand and they're you know, combineable and compositional. So for the moment, I think AI is capable of doing interpolation and extrapolation, but not true invention. So coming up with rulesets and optimizing with complicated objectives around those rule sets we can't currently do. But you could take a specific rule set and then run a kind of self-play experiment to see how long just observe how an AI system from scratch learns how long is that journey of learning. And maybe if it satisfies some of those other things you mentioned in terms of quickness to learn and so on. And you could see a long journey to master for even an AI system that you could say that this is a promising game. But it would be nice to do almost like alpha codes with programming rules. So generating rules that kind of that that automate even that part of the generation of rules. So I have thought about systems actually that I think would be amazing for a game's designer if you could have a system that takes your game, plays it tens of millions of times, maybe overnight, and then self-balances the rules better. So it tweaks the rules and maybe the equations and the parameters so that the game is more balanced, the units in the game or some of the rules could be tweaked. So it's a bit of like giving a base set and then allowing a Monte Carlo tresearch or something like that to sort of explore it. And I think that would be super powerful tool actually for balancing, auto balancing a game, which usually takes thousands of hours from hundreds of games, human games testers normally to balance one game like StarCraft, which is blizzard amazing at balancing their games, but it takes them years and years and years. So one could imagine at some point when this stuff becomes efficient enough to you know you might better do that like overnight. Do you think a game that is optimal design by NAI system would look very much like a planet earth? So maybe, maybe it's only the sort of game I would love to make is and I've tried you know in my in my games career the games design career you know my first big game was designing a theme park and amusement park then with games like Republic I tried to you know have games where we design whole cities and and allowed you to play in. So and of course people like Will Wright have written games like Sim Earth trying to simulate the whole of earth pretty tricky, but I say, I haven't actually played that one. So what is it does it does it incorporate a revolution? Yeah it has a revolution and it sort of it tries to it sort of treats it as an entire biosphere but from quite high level. So it'd be nice to be able to sort of zoom in, zoom out, zoom in. Exactly. So obviously it couldn't do that was in the night. I think he wrote that in the 90s so it couldn't it you know it wasn't it wasn't able to do that, but that that would be obviously the ultimate sandbox game of course. On that topic do you think we're living in a simulation? Yes well so okay so I'm- We're gonna jump around from the absurdly philosophical to the technical. Sure, sure very very happy too. So I think my answer to that question is a little bit complex because there is simulation theory which obviously Nick Bostrom I think famously first proposed and I don't quite believe it in that sense so in the sense that are we in some sort of computer game or have our descendants somehow recreated Earth in the you know 21st century and and some for some kind of experimental reason. I think that but I do think that we that that we might be that the best way to understand physics and the universe is from a computational perspective. So understanding it as an information universe and actually information being the most fundamental unit of reality rather than matter or energy so physicists would say you know matter or energy you know e equals mc squared these are the things that are are the fundamentals of the universe. I'd actually say information which of course itself can be can specify energy or matter right matter is actually just you know we're we're just out the way our bodies and the molecules in our body are arranged as information. So I think information may be the most fundamental way to describe the universe and therefore you could say we're in some sort of simulation because of that. But I don't I do I'm not I'm not really subscriber to the idea that you know these are sort of throw away billions of simulations around. I think this is actually very critical and possibly unique this simulation. Particularly one. Yes. But and you just mean treating the universe as a computer that's processing and modifying information is is a good way to solve the problems of physics of chemistry of biology. Yes. In perhaps of humanity and so on. Yes. I think understanding physics in terms of information theory might be the best way to to really understand what's going on here. From our understanding of a universal term machine from our understanding of a computer do you think there's something outside of the capabilities of a computer that is present in our universe. You have a disagreement with Roger Penra. Yes. The nature of consciousness he thinks that consciousness is more than just a computation. Do you think all of it the whole shebangs can be can be a computer? Yeah. I've had many fascinating debates with Roger Penra. And obviously he's he's famously and I read you know Empress and you mind and and and his books his classical books and they were pretty influential and you know in the 90s and he believes that there's something more you know something quantum that is needed to explain consciousness and the brain. I think of what we're doing actually at DeepMind and what my career is being we're almost like ChewRing's champion. So we are pushing ChewRing machines or classical computation to the limits. What are the limits of what classical computing can do. Now and at the same time I've also studied neuroscience to see and that's why I did my PhD in was to see also to look at you know is there anything quantum in the brain from a neuroscience or biological perspective and and so far I think most neuroscientists and most mainstream biologists and neuroscientists would say there's no evidence of any quantum systems or effects in the brain as far as we can see it's it can be mostly explained by classical classical theories. So and then so there's sort of the search from the biology side and then at the same time there's the raising of the water at the bar from what classical ChewRing machines can do and including our new AI systems and as you alluded to earlier you know I think AI especially in the last decade plus has been a continual story now of surprising events and surprising successes knocking over one theory after another what was thought to be impossible you know from go to protein folding and so on and so I think I would be very hesitant to bet against how far the universal ChewRing machine and classical computation paradigm can go and my betting would be that all of certainly what's going on in our brain can probably be mimicked or approximated on a classical machine not you know not requiring something metaphysical or quantum and we'll get there with some of the work with alpha fold which I think begins the journey of modeling this beautiful and complex world of biology so you think all the magic of the human mind comes from this just a few pounds of mush of biological computational mush that's akin to some of the neural networks not directly but in spirit that deep mind has been working with well look I think it's you say it's a few you know of course it's this is the I think the biggest miracle of the universe is that it is just a few pounds of mush in our skulls and yet it's also our brains and the most complex objects in that we know of in the universe so there's something profoundly beautiful and amazing about our brains and I think that it's an incredibly incredible efficient machine and and it's you know phenomenon basically and I think that building AI one of the reasons I want to build AI and I've always wanted to is I think by building an intelligent artifact like AI and then comparing it to the human mind that will help us unlock the uniqueness and the true secrets of the mind that we've always wondered about since the dawn of history like consciousness dreaming creativity emotions what are all these things right we've we've wondered about them since since the dawn of humanity and I think one of the reasons and you know I love philosophy and philosophy of mind is we found it difficult is there haven't been the tools for us to really other than introspection to from very clever people in in history very clever philosophers to really investigate this scientifically but now suddenly we have a perel of tools firstly we have all the neuroscience tools f from our machines and also recording all of this stuff but we also have the ability computers and AI to build intelligent systems so I think that you know I think it is amazing what the human mind does and and and I'm kind of in awe of it really and and I think it's amazing that without human minds we're able to build things like computers and and actually even you know think and investigate about these questions I think that's also testament to the human mind yeah the universe built the human mind that now is building computers that help us understand both the universe and our own human mind right is exactly it I mean I think that's one we you know one could say we we are maybe where the mechanism by which the universe is going to try and understand itself yeah it's beautiful so let's let's go to the basic building blocks of biology that I think is another angle which you can start to understand the human mind the human body which is quite fascinating which is from the basic building blocks start to simulate start to model how from those building blocks you can construct bigger and bigger more complex systems maybe one day the entire to the human biology so here's another problem that thought to be impossible to solve which is protein folding and alpha fold or specific alpha fold two did just that it solved protein folding I think it's one of the biggest breakthroughs certainly in history of structural biology but in general in science maybe from a high level what is it and how does it work and then we can ask some fascinating sure questions after sure so maybe I to explain it to people not familiar with protein folding is you know I first of all explain proteins which is you know proteins are essential to all life every function in your body depends on proteins sometimes they call the workhorses of biology and if you look into them and I you know obviously as part of alpha fold I've been researching proteins and and and structural biology for the last few years you know they're amazing little bio nano machines proteins they're incredible if you actually watch little videos of how they work animations of how they work and proteins are specified by their genetic sequence called amino acid sequence so you can think it with their genetic makeup and then in the body in in nature they when they when they fold up into a 3d structure so you can think of it as a string of beads and then they fold up into a ball now the key thing is you want to know what that 3d structure is because the structure the 3d structure of a protein is what helps to determine what does it do the function it does in your body and also if you're interested in drug drugs or disease you need to understand that 3d structure because if you want to target something with a drug compound or about to block that something the protein is doing you need to understand where it's going to bind on the surface of the protein so obviously in order to do that you need to understand the 3d structure so the structure is mapped to the function the structure is mapped to the function and the structure is obviously somehow specified by the by the amino acid sequence and that's the in this since the protein folding problem is can you just from the amino acid sequence the one dimensional string of letters can you immediately computationally predict the 3d structure and this has been a grand challenge in biology for over 50 years so I think it was first articulated by Christian and Fienzen a Nobel Prize winner 1972 as part of his Nobel Prize winning lecture and he just speculated this should be possible to go from the amino acid sequence to the 3d structure he didn't say how so it's like you know being described to me as as equivalent to Fermat's lost theorem but for biology right you should as somebody that very well might win the Nobel Prize in the future but outside of that you should do more of that kind of thing in the margins just put random things that will take like 200 years so set people off at 200 years should be possible and just don't give any attention exactly I think everyone is that clear should be I'll have to remember that for future so yeah so he set off you know with this one throw away remark just like Fermat you know he he set off this whole 50-year field really of computation of biology and they hadn't you know they got stuck they hadn't really got very far with doing this and until now until alpha-foal came along this is done experimentally right very painstakingly so the rule of thumb is and you have to like crystallize the protein which is really difficult some proteins can't be crystallized like membrane proteins and then you have to use very expensive electron microscopes or x-ray crystallography machines really painstaking work to get the 3d structure and visualize the 3d structure so the rule of thumb in in experimental biology is that it takes one PhD student their entire PhD to do one protein and without for fall two we were able to predict the 3d structure in a matter of seconds and so we were you know over Christmas we did the whole human proteome or every protein in the human body or 20,000 proteins so the human proteins like the equivalent of the human genome but on protein space and and sort of revolutionize really what a structural biologist can do because now they don't have to worry about these painstaking experimental you know should they put all of that effort in or not they can almost just look up the structure of their proteins like a Google search and so there's a data set on which it's trained and how to map this amino acids. First of all it's incredible that a protein this little chemical computer is able to do that computation itself in a some kind of distributed way and do it very quickly. That's a weird thing and they evolved that way because you know in the beginning I mean that's a great invention just the protein itself. Yes. I mean and then there's I think probably a history of like they evolved to have many of these proteins and those proteins figure out how to be computers themselves in such a way that you can create structures that can interact in complexes with each other in order to form high level functions and it's a weird system that they figured it out. Well for sure I mean we you know maybe we should talk about the origins of life too but proteins themselves I think are magical and incredible as I said little bi banana machines and and actually Levanthal who is another scientist a contemporary of Amphinson he he he coined this Levanthal what became known as Levanthal's paradox which is exactly what you're saying he calculated roughly a protein an average protein which is maybe 2000 amino acids basis long is is is can fold in maybe 10 to the power 300 different confirmations so there's 10 to the power 300 different ways that protein could fold up and yet somehow in nature physics solves this solves this in a matter of milliseconds so proteins fold up in your body in you know sometimes in in fractions of a second so physics is somehow solving that search problem. And just to be clear in many of these cases maybe correctly if I'm wrong there's often a unique way for the sequence to form itself. Yes so among that huge number of possibilities yes it figures out a way how to stable. In some cases there might be a dysfunction miss so on which leads to a lot of the disorders and stuff like that but yes most of the time it's a unique mapping and that unique mapping is that obvious. No exactly. Which is what the problem is. Exactly so there's a unique mapping usually in a healthy in if it's healthy and as you say in disease so for example Alzheimer's one one conjecture is that it's because of misfolder protein protein that falls in the wrong way amyloybytoprotene and then because it falls in the wrong way it gets tangled up right in your in your neurons. So it's super important to understand both healthy functioning and also diseases to understand you know what what these things are doing and how they're structuring. Of course the next step is sometimes proteins change shape when they interact with something so they're not just static necessarily in in biology. Maybe you can give some interesting so beautiful things to you about these early days of alpha fold of of solving this problem because unlike games this is real physical systems that are less amenable to self-play type of mechanisms. Sure. The size of the data set is smaller that you might otherwise like so you have to be very clever about certain things is there something you could speak to what was very hard to solve and what are some beautiful aspects about the solution. I would say alpha fold is the most complex and also probably most meaningful system we've built so far. So it's been an amazing time actually in the last you know two three years to see that come through because as we talked about earlier you know games is what we started on building things like alpha go and alpha zero but really the ultimate goal was to not just to crack games it was just to to to build use them to bootstrap general learning systems we could then apply to real world challenges specifically my passion is scientific challenges like protein folding and then alpha fold of course is our first big proof point of that and so you know in terms of the data and the amount of innovations I had to go into it we you know it was like more than 30 different component algorithms needed to be put together to crack the protein folding I think some of the big innovations were that kind of building in some hard coded constraints around physics and evolutionary biology to constrain sort of things like the bond angles in the in the in the protein and things like that a lot but not to impact the learning system so still allowing the system to be able to learn the physics itself from the examples that we had and the examples as you say they're only about 150,000 proteins even after 40 years of experimental biology only around 150,000 proteins have been the structures have been found out about so that was our training set which is much less than normally we would like to use but using various tricks things like self distillation so actually using alpha fold predictions some of the best predictions that it thought was highly confident in we put them back into the training set right to make the training set bigger that was critical to to alpha fold working so there was actually a huge number of different innovations like that that were required to to ultimately crack the problem alpha fold one what it produced was a histogram so a kind of a matrix of the pairwise distances between all of the molecules in the in the in the protein and then there had to be a separate optimization process to create the 3D structure and what we did for alpha fold 2 is make it truly end to end so we went straight from the amino acid sequence of of of bases to the 3D structure directly without going through this intermediate step and in machine learning what we've always found is that the more end to end you can make it the better the system and it's probably because we you know the in the end the system's better at learning what the constraints are than than than we are as the human designers of specifying it so anytime you can let it flow end to end and actually just generate what it is you're really looking for in this case the 3D structure you're better off than having this intermediate step which you then have to hand craft the next step for so it's better to let the gradients and the learning flow all the way through the system from the end point the end output you want to the inputs so that's a good way to start and a new problem handcraft a bunch of stuff add a bunch of manual constraints with a small intern learning piece or a small learning piece and grow that learning piece until it consumes the whole thing that's right and so you can also see you know this is a bit of a method we've developed over doing many sort of successful outfits we call them Alpha X projects right is and the easiest way to see that is the evolution of AlphaGo to Alpha 0 so AlphaGo was a learning system but it was specifically trained to only play Go right so and what we wanted to do and with first version of AlphaGo is just get to world champion performance no matter how we did it right and then and then of course AlphaGo 0 we we we remove the need to use human games as a starting point right so it could just play against itself from random starting point from the beginning so that remove the the need for human knowledge about go and then finally Alpha 0 then generalized it so that any things we had in there the system including things like symmetry of the go board were removed so that Alpha 0 could play from scratch any two player game and then mu 0 which is the final latest version of that set of things was then extending it so that you didn't even have to give it the rules of the game it would learn that for itself so it could also deal with computer games as well as board games so that line of AlphaGo Alpha goes 0 Alpha 0 mu 0 that's the full trajectory of what you can take from imitation learning to full self supervised learning yeah exactly and learning the entire structure of the environment you put in from scratch right and and and and bootstrapping it through self play yourself but the thing is it would have been impossible I think or very hard for us to build Alpha 0 or mu 0 first out of the box even psychologically because you have to believe in yourself for a very long time you're constantly dealing with doubt because a lot of people say there's impossible exactly so it was hard enough just to do go as you were saying everyone thought that was impossible or at least a decade away from when we when we were did it in back in 2015-2014 you know 2016 and and so yes it would have been so psychologically probably very difficult as well as the fact that of course we learned a lot by building AlphaGo first right so it's I think this is why I call AI an engineering science it's one of the most fascinating science disciplines but it's also an engineering science in the sense that unlike natural sciences the phenomenon you're studying doesn't exist out in nature you have to build it first so you have to build the artifact first and then you can study how how and pull it apart and how it works this is tough to ask you this question because you probably will say it's everything but let's let's try let's try to think through this because you're in a very interesting position where deep mind is a place of some of the most brilliant ideas in the history of AI but it's also a place of brilliant engineering so how much of solving intelligence this big goal for deep mind how much of it is science how much is engineering so how much is the algorithms how much is the data how much is the hardware compute infrastructure how much is it the software compute infrastructure yeah what else is there how much is the human infrastructure and like just the humans interacting certain kinds of ways you know all the space of all those ideas and how much is maybe like philosophy how much what's the key if if you were to sort of look back like if we go forward 200 years look back what was the key thing that solved intelligence is that it's a sort of engineering I think it's a combination I first of all of course it's a combination of all those things but the ratios of them changed over over time so yeah so even in the last 12 years so we started deep mind in 2010 which is hard to imagine now because 2010 it's only 12 short years ago but nobody was talking about AI you know I don't know if you remember back to your MIT days I know when was talking about it I did a post-doc at MIT back around then and it was sort of thought of as well look we know AI doesn't work we tried this hard in the 90s at places like MIT mostly using logic systems and old-fashioned sort of good old-fashioned AI we would call it now people like minskie and and and Patrick Winston and you know all these characters right and used to debate a few of them and they used to think I was mad thinking about that some new advance could be done with learning systems and I was actually pleased to hear that because at least you know you're on a unique track at that point right even if every all of your you know professors are telling you you're mad and of course in industry you couldn't we couldn't get you know it was difficult to get two cents together and which is hard to imagine now as well given that's the biggest sort of buzzword in in VCEs and and fund raising ZZ and all these kind of things today so back in 2010 it was very difficult and what we the reason we started then and Shane and I used to discuss what was the sort of founding tenants of DeepMind and it was very various things one was algorithmic advances so deep learning you know Jeff Hinton and coer just had just sort of invented that in academia but no one in industry knew about it we we love reinforcement learning we thought that could be scaled up but also understanding about the human brain had advanced quite a lot in the in the decade prior with F from Rire machines and other things so we could get some good hints about architectures and algorithms and and and sort of representations maybe that the brain uses so as at a systems level not at a implementation level and then the other big things were compute and GPUs right so we could see a compute was going to be really useful and it got to a place where it become commoditized mostly through the games industry and and that could be taken advantage of and then the final thing was also mathematical and theoretical definitions of intelligence so things like AI XI A I C which Shane worked on with his supervisor Marcus Hutto which is this sort of theoretical proof really of universal intelligence which is actually a reinforcement learning system in the limit I mean it seems infinite compute in infinite memory in the way you know like a cheering machine proofs but I was also waiting to see something like that to to you know like cheering machines and computation theory that people like cheering in Shannon came up with underpins modern computer science you know I was waiting for a theory like that to sort of underpin a GI research so when I you know met Shane and saw he was working on something like that you know that to me was a sort of final piece of the jigsaw so in the early days I would say that ideas were the most important you know for us it was deep reinforcement learning scaling up deep learning of course we've seen transformers so huge leaps I would say like three or four from if you think from 2010 till now huge evolution things like AlphaGo and and and maybe there's a few more still needed but as we get closer to AI a GI I think engineering becomes more and more important and data because scale and of course that the recent you know results of GPT-3 in all the big language models and large models including our ones has shown that scale is a is and large models are clearly going to be a necessary but perhaps not sufficient part of an AGI solution and throughout that like you said and I'd like to give you a big thank you you're one of the pioneers in this is sticking by ideas like reinforcement learning that this can actually work given how she limited success in the past and also which we still don't know but proudly having the best researchers in the world and talking about solving intelligence so talking about whatever you call it AGI or something like this that speaking of MIT that's that's just something not you wouldn't bring up not not maybe you did in like 40 50 years ago but that was AI was a place where you do tinkering very small scale not very ambitious projects and maybe the biggest ambitious projects were in the space of robotics and doing like the DARPA challenge but the task of solving intelligence and believing you can that's really really powerful so in order for engineering to do its work to have great engineers build great systems you have to have that belief that threads throughout the whole thing that you can actually solve some of these impossible challenges yeah that's right and and back in 2010 you know our mission statement and still is today you know as it was used to be solving step one solve intelligence step two use it to solve everything else yes so if you can imagine pitching that to a VC in 2010 you know the kind of looks we we got we managed to you know find a few kooky people to back us but it was it was tricky and and I and I got to the point where we we wouldn't mention it to any of our professors because they were just I rolled and think we you know committed career suicide and and and you know so it was there's a lot of things that we had to do but we always believed it and one reason you know by the way one reason we I believe I've always believed in reinforcement learning is that that if you look at neuroscience that is the way that the you know primary brain learns one of the main mechanisms is the dopamine system implements some form of TD learning is very famous result in the late 90s where they saw this in monkeys and and as you know probably getting prediction error so we you know again in the limit this is this is what I think you can use neuroscience for is is you know any and mathematics you when you're when you're doing something as ambitious as trying to solve intelligence and you're you know it's blue sky research no one knows how to do it you you you need to use any evidence or any source of information you can to help guide you in the right direction or give you confidence you're going in the right direction so so that that was one reason we pushed so hard on that and that's just going back to your early question about organization the other big thing that I think we innovated with a deep mind to encourage invention and and and innovation was the multidisciplinary organization we built and we still have today so deep mind originally was a confluence of the of the most cutting edge knowledge and neuroscience with machine learning engineering and mathematics right and and gaming and then since then we built that out even further so we have philosophers here and and by you know ethicists but also other types of scientists physicists and so on and that's what brings together I tried to build a sort of new type of Bell labs but in its golden era right and and a new expression of that to try and foster this incredible sort of innovation machine so talking about the humans in the machine the mind itself is a learning machine with a lot of amazing human minds in it coming together to try and build these learning systems if we return to the big ambitious dream of alpha fold that maybe the early steps on a very long journey in in biology do you think the same kind of approach can use to predict the structure and function of more complex biological systems so multi protein interaction and then I mean you can go out from there yeah just simulating bigger and bigger systems that eventually simulate something like the human brain or the human body just the big mush the mess of the beautiful resilient mess of biology do you do you see that as a long term vision I do and I think um you know if you think about what are the things top things I wanted to apply AI to once we had powerful enough biology and curing diseases and understanding biology was right up there you know top of my list that's one of the reasons I personally pushed that myself and with alpha fold but I think alpha fold uh amazing as it is is just the beginning um and and and I hope it's a evidence of what could be done with computational methods so um you know alpha fold solve this this huge problem of of the structure of proteins but biology is dynamic so really what I imagine from here we're working on all these things now is protein protein interaction um protein ligand binding so reacting with molecules then you want to get build up to pathways and then pinch eventually a virtual cell that's my dream maybe in the next 10 years and I've been talking actually to a lot of biologists friends of mine Paul nurse who runs the quick institute amazing biologist no reprise when he biologist we've been discussing for 20 years now virtual cells could you build a virtual simulation of a cell and if you could that would be incredible for biology and disease discovery because you could do loads of experiments on the virtual cell and then only at the last stage validate it in the wet lab so you could you know that in terms of the search space of discovering new drugs you know text 10 years roughly to go from uh to to go from uh you know identifying a target to uh uh having a drug candidate um maybe that could be shortened to you know by an order of magnitude with if you could do most of that that that work in silico so in order to get to virtual cell we have to build up uh understanding of different parts of biology and the interactions and and um so we you know we every every few years we talk about this with I talked about this with Paul and then finally last year after alpha fold I said now's the time we can finally go for it and and alpha folds the first proof point that this might be possible uh and he's very excited and we have some collaborations with his with his lab and they're just across the road actually from us as you know wonderful being here in kings cross with the quick institute across the road and um and I think the next steps you know I think there's going to be some amazing advances in biology built on top of things like alpha fold uh we're already seeing that with the community doing that after we've open sourced it and released it um and uh you know I often say that I think uh if you think of uh mathematics is the perfect description language for for physics uh I think AI might be end up being the perfect description language for biology because um biology so messy it's so emergent so dynamic and complex um I think I find it very hard to believe we'll ever get to something as elegant as newtons laws emotions to describe a cell right it's just too complicated um so I think AI is the right tool for that you have to uh you have to start at the basic building blocks and use AI to run the simulation for how those building blocks so have a very strong way to do prediction of what given these building blocks what kind of biology how the the function and the evolution of that biological system it's almost like a cellular automata you have to run you can't analyze it from a high level you have to take the basic ingredients figure out the rules yeah and let it run but in this case the rules are very difficult to figure out yes exactly that's exactly it so it's the biology too complicated to figure out the rules it's it's too emergent too dynamic say compared to a physics system like the motion of a planet yeah right and and so you have to learn the rules and that's exactly the type of systems that we're building so you you mentioned you've open sourced alpha fold uh and even the data involved to me personally also really happy and a big thank you for open sourcing majaco the physics simulation engine that's that's often used for robotics research and so on so i think that's a pretty gangster move uh so what what what's the what's i mean this of very few companies or people do that kind of thing what's the philosophy behind that you know it's a case by case basis and in both those cases we felt that was the maximum benefit to humanity to do that and and the scientific community in one case the robotics uh physics community with majaco so we purchased it open four yes we purchased it for the express principle to open sourced so um so uh you know hope people appreciate that it's great to hear that you do and then the second thing was and mostly we did it because the person building it who's uh would not able to cope with supporting it anymore because it got too big for him is an amazing professor uh who who built it in the first place so we helped him out with that and then with alpha folds even bigger i would say and i think in that case we decided that there were so many downstream applications of alpha fold um that we couldn't possibly even imagine what they were so the best way to accelerate uh drug discovery and also fundamental research would be to to um give all that data away and and and the and the and the system itself um you know it's been so gratifying to see what people have done that within just one year which is a short amount of time in science and uh it's been used by over 500,000 researchers have used it we think that's almost every biologist in the world i think there's roughly 500,000 biologists in the world professional biologists have used it to to look at their proteins of interest um we've seen amazing fundamental research done so a couple of weeks ago front cover there was a whole special issue of science including the front cover which had the nuclear poor complex on it which is one of the biggest proteins in the body the nuclear poor complexes a protein that governs all the nutrients going in and out of your cell nucleus so so they're they're like little hot gateways that open and close to let things go in and out of your cell nucleus so they're really important um but they're huge because they're massive doughnut rings shaped things and they've been looking to try and figure out that structure for decades and they have lots of you know experimental data but it's too low resolution there's bits missing and they were able to like a giant Lego jigsaw puzzle use alpha fold predictions plus experimental data and combined those two independent sources of information uh actually four different groups around the world were able to put it together the set uh more or less simultaneously using alpha fold predictions so that's been amazing to see and pretty much every farmer company every drug company executive i spoken to has said that their teams are using alpha fold to accelerate whatever drugs uh uh they're trying to discover so i think the knock on effect has been enormous in terms of uh the impact that alpha fold has made and it's probably bringing in it's creating biologists it's bringing more people into the field um but both on the excitement and both on the technical skills involved in um it's almost like a gateway drug to biology yes it is you follow all the computational people involved too hopefully and and i think for us you know the next stage as i said you know in future we have to have other considerations too we're building on top of alpha fold and these other ideas i discussed with you about protein protein interactions and and genomics and other things and not everything will be open so some of it will will do commercially because that will be the best way to actually get the most resources and impact behind it in other ways other some other projects will do non-profit style um and also we have to consider for future things as well safety and ethics as well like but you know synthetic biology there are you know there is dual use and we have to think about that as well with alpha fold we you know we consulted with 30 different bioethicists and and other people expert in this field to make sure it was safe before um we released it so there'll be other considerations in future but for right now you know i think alpha fold is a kind of a gift from us to to to the scientific community so i'm pretty sure that something like alpha fold would be part of Nobel prizes in the future but us humans of course are horrible with credit assignment so we'll of course give it to the humans do you think there will be a day when AI system can't be denied that it earned that Nobel prize do you think we will see that in 21st century it depends what type of AI's we end up building right whether they're um you know goal seeking agents who specifies the goals uh who comes up with the hypotheses who you know who determines which problems to tackle right so i think we it's about it announcement yes it's an ounce of the results exactly it's part of it um so i think right now of course it's it's it's it's it's it's amazing human ingenuity that's behind these systems and then the system in my opinion is just a tool you know be a bit like saying with Galileo in his telescope you know the ingenuity that the credit should go to the telescope i mean it's clearly Galileo building the tool which he then uses so i still see that in the same way today even though that these tools learn for themselves um there i think of i think of things like alpha fold and that the things we're building as the ultimate tools for science and for for acquiring new knowledge to help us as scientists acquire new knowledge i think one day they will come a point where an AI system may solve or come up with something like general relativity off its own bat not just by averaging everything on the internet or averaging everything on pub med although that would be interesting to see what that would come up with um so that to me is a bit like our earlier debate about creativity you know inventing go rather than just coming up with a good go move and um so i think uh solving i think to to you know if we wanted to give it the credit of like a no-bar type of thing then it would need to event go and sort of invent that new conjecture out of the blue um rather than being specified by the the the human scientist or the human creator so i think right now that's it's definitely just a tool although it is interesting how far you get by averaging everything on the internet like you said because you know a lot of people do see sciences you're always standing on the shoulders of giants and the question is how much are you really reaching up above the shoulders of giants maybe it's just assimilating different kinds of results of the past with ultimately this new perspective that gives you this breakthrough idea but that idea may not be novel in the way that it can't be already discovered in the internet maybe the no-bar prizes of the next 100 years are already all there on the internet to be discovered they could be they could be i mean i think um this is one of the big mysteries i think is that uh uh i i first of all i believe a lot of the big new breakthroughs that are going to come in the next few decades and even in the last decade are going to come at the intersection between different subject areas where um there'll be some new connection that's found between what seemingly were disparate areas and and one can even think of deep mind as i as i said earlier as a sort of interdisciplinary between neuroscience ideas and and AI engineering ideas originally and so um so i think there's that and then one of the things we can't imagine today is and one of the reasons i think people we were so surprised by how well large models worked is that actually it's very hard for our human minds our limit human minds to understand what it would be like to read the whole internet right i think we can do a thought experiment and i used to do this of like well if i read the whole Wikipedia uh what would i know and i think our minds can just about comprehend maybe what that would be like but the whole internet is beyond comprehension so i think we just don't understand what it would be like to be able to hold all of that in mind potentially right and then uh active at once and then maybe what are the connections that are available there so i think no doubt there are huge things to be discovered just like that but i do think there is this other type of creativity of true spark of new knowledge new idea never thought before about can't be averaged from things that are known um that really of course everything come you know nobody creates in a vacuum so there must be clues somewhere but just a unique way of putting those things together i think some of the greatest scientists in history have displayed that i would say although it's very hard to know going back to their time what was exactly known uh when they came up with that i thought you're making me really think because just a thought experiment of deeply knowing a hundred Wikipedia pages i don't think i can um i've been really impressed by Wikipedia for for technical topics yeah so if you know a hundred pages or a thousand pages i don't think we can vision truly comprehend what's what kind of intelligence that is yeah it's a pretty powerful tell if you know how to use that and integrate that information correctly yes i think you can go really far yeah you can probably construct thought experiments based on that like simulate different ideas so if this is true let me run this thought experiment that maybe this is true it's not really invention it's like just taking literally the knowledge and using it to construct a very basic simulation of the world i mean i some argue it's romantic in part but i instead would do the same kind of things with a thought experiment yeah one could imagine doing that systematically across millions of Wikipedia pages plus pub med all these things i think there are many many things to be discovered like that they're hugely useful you know you could imagine and i want us to do some of these things in material science like room temperatures super conductors is something on my list one day that i'd like to like you know have an AI system to help build better optimize batteries all of these sort of mechanical things my sister i think a systematic sort of search could be guided by a model could be could be extremely powerful so speaking of which you have a paper on nuclear fusion magnetic control of talk about plasma is the deeper enforcement learning so you you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasma so can you explain this work and can AI eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and are really interesting problems scientific challenges in of themselves and this is energy so energy yes exactly so energy and climate so we talked about disease and biology is being one of the biggest places i think AI can help with i think energy and climate is another one so maybe they would be my top two and fusion is one one area i think AI can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do and whenever we go into a new field it up to apply our systems is we look for we talk to domain experts we try and find the best people in the world to collaborate with in this case in fusion we we collaborated with epfl in Switzerland the Swiss technical institute who are amazing they have a test reactor they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and and so it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our AI methods today yes right and and and and and and would be interesting from a research perspective from our point of view from an AI point of view and that would address one of their bottlenecks and in this case plasma control was was perfect so you know the plasma it's a million degrees Celsius something like that's hotter than the sun um and there's obviously no material that can contain it so they have to be containing these magnetic very powerful met super conducting magnetic fields um but the problem is plasma is pretty unstable as you imagine you're kind of holding a mini sun mini star in a reactor so you know you you kind of want to predict ahead of time what the plasma is going to do so you can move the magnetic field within a few milliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know you got controller you're going to move the magnetic field and and until we came along you know they were they were doing with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma is doing they have to be hard coded and again knowing that that's normally our go to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can AI eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in a specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of fusion sort of um solved so have a controller that's able to no matter the shape uh contain it contain yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next pump we can tackle uh in the fusion area so another fascinating place uh in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can AI model and simulate arbitrary quantum mechanical systems in the future yeah so this is another problem i've had my eye on for you know decade or more which is um uh sort of simulating the properties of electrons if you can do that you can basically describe how elements and materials and substances work so it's kind of like fundamental if you want to advance material science um and uh you know we have Schrodinger's equation and then we have approximations to that density functional theory these things are you know a famous and um people try and write approximations to to these uh uh to these functionals and and kind of come up with descriptions of the electron clouds where they're going to go how they're going to interact when you put two elements together uh and what we try to do is learn a simulation uh uh learn a functional that will describe more chemistry types of chemistry so um until now you know you can run expensive simulations but then you can only simulate very small molecules very simple molecules we would like to simulate large materials um and so uh today there's no way of doing that and we're building up towards uh building functionals that approximate Schrodinger's equation and then allow you to describe uh what the electrons are doing um and all materials sort of science and material properties are governed by the electrons and and how they interact so i have a good summarization of the simulation through the functional um but one that is still close to what the actual simulation will come out with so what um how difficult is that task what's involved in that task is it running those those complicated simulations yeah and learning the task of mapping from the initial conditions and the parameters of the simulation learning what the functional would be yeah so it's pretty tricky and we've done it with um you know the nice thing is we there are we can run a lot of the simulations that the molecular dynamics simulations on our compute clusters and so that generates a lot of data so in this case the data is generated so we like those sort of systems and that's what we use games it's simulator generator data uh and we can kind of create as much of it as we want really um and just let's leave some you know if any computers are free in the cloud we just run we run some of these calculations right compute cluster calculations oh that's all the the three compute times used up on quantum mechanics yeah quantum mechanics exactly simulations and protein simulations and other things and so um and so you know when you're not searching on youtube for video cat videos we're using those computers usefully and quantum chemistry the idea and uh pretty good use and then yeah and then all of that computational data that's generated we can then try and learn the functionals from that which of course are way more efficient it once we learn the functional then um running those simulations would be do you think one day AI may allow us to do something like basically crack open physics so do something like travel fast in the speed of light my ultimate aim is always being with AI is um the reason I am personally working on AI for my whole life it was to build a tool to help us understand the universe so I wanted to and that means physics really and the nature of reality so um uh I don't think we have systems that are capable of doing that yet but in when we get towards a GI I think um that's one of the first things I think we should apply a GI to I would like to test the limits of physics and our knowledge of physics there's so many things we don't know I this is one thing I find fascinating about science and you know as a huge proponent of the scientific method as being one of the greatest ideas humanity's ever had and allowed us to progress with our knowledge but I think as a true scientist I think what you find is the more you find out uh the more you realize we don't know and and I always think that it's surprising that more people don't aren't troubled you know every night I think about all these things we interact with all the time that we have no idea how they work time consciousness gravity life we can't I mean these are all the fundamental things of nature I think the way we we don't really know what they are to live life we uh pin certain assumptions on them and kind of treat our assumptions as if they're affect yeah that allows us to sort of box them off somehow yeah box them off somehow well your reality is when you think of time you should remind yourself you should put it off the take it off the shelf and realize like no we have a bunch of assumptions there's still a lot of there's even not a lot of debate there's a lot of uncertainty about exactly what is time is there an error of time you know there's there's a lot of other questions you can't just make assumptions about and maybe AI allows you to um not put anything on the shelf yeah not make any hard assumptions and really open it up and see what exactly I think we should be truly open minded about that and uh exactly that not be dogmatic to a particular theory um it'll also allow us to build better tools experimental tools eventually that can then test certain theories that may not be testable today about as things about like what we spoke about the beginning about the computational and nature of the universe how one might if that was true how one might go about testing that right and and how much uh you know there are people who've conjectured people like uh scot aronson and others about uh you know how much information can a specific plank unit of space and time contain right so one might be able to think about testing those ideas if you had um AI helping you build some new exquisite uh experimental tools this is what I imagine you know many decades from now we'll be able to do and what kind of questions can be answered to running a simulation of them so that there's a bunch of physics simulations you can imagine that could be run in an uh so some some kind of efficient way much like you're doing in the quantum simulation work and perhaps even the origin of life yeah figuring out how going even back before the work of alpha fold begins of how this whole whole thing um emerges from a rock yes from a static thing would would you would do you think AI will allow us to is that something you have your eye on is trying to understand the origin of life first of all yourself would would you think um how the heck did life origin and earth yeah well maybe we'll come to that in a second but I think the ultimate use of AI is to kind of use it to accelerate science to the maximum so I um think of it a little bit like the tree of all knowledge if you imagine that's all the knowledge there is in the universe to attain and uh we sort of barely scratch the surface of that so far in even though you know we've we've we've done pretty well since the enlightenment right as humanity and I think AI will turbocharge all of that like we've seen without a fold and I want to explore as much of that tree of knowledge as is possible to do and um and I think that involves AI helping us with with with understanding or finding patterns um but also potentially designing and building new tools experimental tools so I think that's all uh uh and also running simulations and learning simulations all of that we're already we're sort of doing it at a at a at a at a you know baby steps level here but I can imagine that in in in the decades to come as uh you know what's the full flourishing of of that line of thinking it's going to be truly incredible I would say if I visualized this tree of knowledge something tells me that that knowledge for tree of knowledge for humans is much smaller in the set of all possible trees of knowledge it's actually quite small giving our cognitive limitations um limited cognitive capabilities that even with with the with the tools we build we still won't be able to understand a lot of things and that's perhaps what non human systems might be able to reach farther not just as tools but in themselves understanding something that they can bring back yeah it could well be so I mean there's so many things that the the the sort of encapsulated in what you just said there I think first of all um there's there's two different things there's like what do we understand today yeah what could the human mind understand and what is the totality of what is there to be understood yeah right and so there's three concentric you know you can think of them as three larger larger trees or exploring more branches of that tree and I I think with AI we're going to explore that whole lot now the question is is you know if you think about what is the totality of what could be understood um there may be some fundamental physics reasons why certain things can't be understood like what's outside a simulation or outside the universe maybe it's not understandable from within the universe um so that's there may be some hard constraints like that you know could be smaller constraints like we think of space time as fundamental our human brains are really used to this idea of a three-dimensional world with time right maybe but our tools could go beyond that yeah they wouldn't have that limitation necessarily they could think in 11 dimensions 12 dimensions whatever is needed but um we could still maybe understand that in several different ways the example I always give is um when I you know play Gary cusp offer at speed chess or we've talked about chess and these kind of things um you know he if you if you if you're reasonably good at chess you can um you can't come up with the move Gary comes up with in his move but he can explain it to you and you can understand and you can understand post-hoc the reasoning yeah so so I think there's a there's an even further level of like well maybe you couldn't have invented that thing but but using like going back to using language again perhaps you can understand and appreciate that same way like you can appreciate you know the valdee or Mozart something without you can appreciate the beauty of that without being able to to construct it yourself right invent the music yourself so I think we see this in all forms of life so it'll be that times you know a million but it would you can imagine also one sign of intelligence is the ability to explain things clearly and simply right you know people I reach for five another one of my all time here as used to say that right if you can't you know if you can explain it something simply then you that's a that's the best sign a complex topic simply then that's one of the best signs of you understanding it yeah so um I can see myself talking trash in the AI system in that way yeah it's it's it's it's frustrated how dumb I am and in trying to explain something to me I was like well that means you're not intelligent because if you were intelligent you'd be able to explain it simply yeah of course as you know there's there's also the other option of course we couldn't enhance ourselves and and without devices we we are already sort of symbiotic without compute devices right without phones and other things and you know this stuff like neural link in accepture that could be could could advance that further um so I think there's lots of lots of really amazing possibilities uh that that I could foresee from here well let me ask you some wild questions out there looking for friends do you think there's a lot of alien civilizations out there so I guess there's also goes back to your origin of life question too because I think that that's key um my personal opinion looking at all this and and you know it's one of my hobbies physics I guess so so I you know it's something I think about a lot and talk to a lot of experts on and and and read a lot of books on and I think my feeling currently is that that we are alone I think that's the most likely scenario given what what evidence we have so um and the reasoning is I think that you know we've tried since things like sety program and I guess since the dawning of the the space age uh we've you know had telescopes open radio telescopes and other things and if you think about um and tried to detect signals now if you think about the evolution of humans on earth we could have easily been um a million years ahead of our time now or million years behind right easily with just some slightly different quirk thing happening hundreds of thousands years ago uh you know things could have been slightly different if the B2 would hit the dinosaurs a million years earlier maybe things would have evolved uh we'd be a million years ahead of where we are now so what that means is if you imagine where humanity will be in a few hundred years let alone a million years especially if we hopefully um keep you know solve things like climate change and other things and we continue to flourish and we build things like AI and we do space traveling and all of the stuff that that that humans have dreamed of forever right and sci-fi has talked about forever um we will be spreading across the stars right and void noemun famously calculated you know it would only take about a million years if you sent out void noemun probes to the nearest you know the nearest uh uh other solar systems and and then they built all they did was build two more versions themselves and sent those two out to the next nearest systems uh you you know within a million years I think you would have one of these probes in every system in the galaxy so it's not actually in cosmological time that's actually very short amount of time so and and you know we people like Dyson have thought about constructing Dyson spheres around stars to collect all the energy coming out of the star you know that there would be constructions like that would be visible across space um probably even across a galaxy so uh and then you know if you think about all of our radio television uh emissions that have gone out since since the you know thirties and forties um imagine a million years of that and now hundreds of civilizations doing that when we opened our ears at the point we got technologically sophisticated enough in the space age we should have heard a cacophony of voices should have joined that cacophony of voices and what what we did we opened our ears and we heard nothing and many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was like to be so different to what we're used to but you know I know I don't really buy that that it shouldn't be as difficult as that like we I think we've searched enough there should be everywhere if it was yeah it should be everywhere we should see Dyson spheres being put up suns blinking in and now you know there should be a lot of evidence for those things and then there are other people argue well the sort of Safari view of like well we're a primitive species still because they're not space fairing it and and and we're you know there's some kind of globe like universal rule not to interfere you know Star Trek rule but like look look we can't even coordinate humans to deal with climate change and we're one species what what is the chance that of all of these different human civilization you know alien civilizations they would have the same priorities and and and agree or cross the you know these kind of matters and even if that was true and we were in some sort of Safari for our own good to me that's not much different from the simulation hypothesis because what does it mean the simulation hypothesis I think in its most fundamental level it means what we're seeing is not quite reality right it's something there's something more deeper underlying it maybe computational now if we were in a if we were in a sort of Safari park and everything we were seeing was a hologram and it was projected by the aliens or whatever that to me is not much different than thinking we're inside of another universe because we still can't see true reality right I mean there's there's other explanations it could be that the way their communicating is just fundamentally different that we're too dumb to understand the much better methods of communication they have it could be I mean it's a silly to say but our own thoughts could be the methods by which they're communicating like the place for which are ideas writers talk about this like the muse yeah the it sounds like very kind of wild but it could be thoughts it could be some interactions with our mind that we think are originating from us is actually something that is coming from other life forms elsewhere consciousness itself might be that it could be but I don't see any sensible argument to the why why would all of the alien species be using this way yeah some of them will be more primitive they would be close to our level you know they would they should be a whole sort of normal distribution of these things right some would be aggressive some would be but you know curious others would be very historical and philosophical because you know maybe there are a million years older than us but it's not it shouldn't be like I mean one one alien civilization might be like that communicating thoughts and others but I don't see why you know potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the people the alien civilizations that become successful become gain the ability to be destructive in order magnitude more destructive but of course the sad thought well either humans are very special we took a lot of leaps that arrived at what it means to be human yeah there's a question there which was the hardest which was the most special but also others have reached this level and maybe many others have reached this level the great filter yeah that prevented them from going farther to becoming a multipleitary species are reaching out into the stars and those are really important questions for us whether whether there's other alien civilizations that there are not this is very useful for us to think about if we destroy ourselves how will we do it and how easy is it to do yeah well you know these are big questions and I thought about these a lot but the the interesting thing is that if we're if we're alone that's somewhat comforting from the great filter perspective because it probably means the great filters were a past us yeah and I'm pretty sure they are so the by going back to your origin of life question there are some incredible things that no one knows how happened like obviously the first life form from chemical soup that seems pretty hard but I would guess the multicellular I wouldn't be that surprised if we saw single else single cell sort of life forms elsewhere bacteria type things but multicellular life seems incredibly hard that step of you know capturing mitochondria and sort of using that as part of yourself you know when you've just eaten it would you say that's the biggest the most like if you had to choose one sort of hitchhiker's galaxy one certain summary of like oh those clever creatures did this there would be the multicellular I think that's probably the one that's the biggest I mean there's a great book called the 10 great inventions of evolution by Nicolay and he speculates on 10 10 of these you know what could be great filters I think that that's one I think the the advent of of of intelligence and conscious intelligence and in order you know to us to be able to do science and things like that is huge as well I mean there's only evolved once as far as you know in in in in earth history so that would be a later candidate but there's certainly for the early candidates I think multicellular life forms is huge by the way what it's interesting to ask you if you can hypothesize about what is the origin of intelligence is it that we started cooking meat over fire is it that we somehow figured out that we could be very powerful we started collaborating so cooperation between our ancestors so that we can overthrow the alpha male what is it Richard I talked to Richard Randham who thinks we're all just beta males who figured out how to collaborate to defeat the one the dictator the authoritarian alpha male that controlled the tribe is there other explanation did was there 2001's besides the type of monolith yeah they came down to earth well I think I think all of those things you suggested a good candidate's fire and and and cooking right so that's clearly important for and it for energy you know energy efficiency cooking our meat and then and then being able to to to be more efficient about eating it and getting it consuming the energy I think that's huge in then utilizing fire and tools I think you're right about the the tribal cooperation aspects and probably language as part of that yeah because probably that's what allowed us to outcompete in the andotholes and and perhaps less cooperative species so so that may be the case toolmaking spears axes I think that let us I mean I think it's pretty clear now that humans were responsible for a lot of the extensions of megafauna especially in in the Americas when humans arrived so you can imagine once you discovered tool usage how powerful that would have been and how scary for animals so I think all of those could have been explanations for it you know the interesting thing is that it's a bit like general intelligence to is it's very costly to begin with to have a brain and especially a general purpose brain rather than a special purpose one because you might have energy our brains use I think it's like 20% of the body's energy and it's it's massive and you're thinking chess one of the funny things that we we used to say is it's as much as a racing driver uses for a whole you know formula one race you're just playing a game of you know serious high level chess which you wouldn't think just sitting there because the brains using so much energy so in order for an animal and organism to justify that there has to be a huge payoff and the problem with with half a brain or half you know intelligence say an IQs of you know of like a monkey brain it's it's not clear you can justify that evolutionary until you get to the human level brain and so but how do you how do you do that jump it's very difficult which is why I think it's only been done once from the sort of specialized brains that you see in animals to this sort of general purpose cheering powerful brains that humans have and which allows us to invent the modern modern world and you know it takes a lot to to cross that barrier and I think we've seen the same with AI systems which is that maybe until very recently it's always been easier to craft a specific solution to a problem like chess then it has been to build a general learning system that could potentially do many things because initially that system will be way worse than less efficient than the specialized system so one of the interesting quirks of the human mind of this evolved system is that it appears to be conscious this thing that we don't quite understand but it seems very very special as ability to have a subjective experience that it feels like something to eat a cookie the deliciousness of it or see a color and that kind of stuff do you think in order to solve intelligence we also need to solve consciousness along the way do you think AI systems need to have consciousness in order to be truly intelligent yeah we thought about this a lot actually and I think that my guess is that consciousness in intelligence are double dissociable so you can have one without the other both ways and I think you can see that with consciousness in that I think some animals pets if you have a pet dog or something like that you can see some of the higher animals and dolphins things like that are have self awareness and a very sociable seem to dream you know those kinds of a lot of the traits one would regard as being kind of conscious and self aware and but yet they're not that smart right so they're not that intelligent by by say IQ standards or something like that yeah it's also possible that our understanding of intelligence is flawed like putting an IQ to it sure maybe the thing that a dog can do is actually gone very far along the path of intelligence and we humans are just able to play chess and maybe write poems right but if we go back to the idea of a g i in general intelligence you know dogs are very specialized right most animals are pretty specialized they can be amazing and what they do but they're like kind of elite sports sports people or something right so they do one thing extremely well because their entire brain is is optimized they have somehow convinced the entirety of the human population to feed them and service them so in some way they're controlling yes exactly where we co-evolved to some crazy degree right including the the way the dogs you know even even wag their tails and twitch their noses right we find we find in in the ultra-blig cute yeah but I think you can also see intelligence on the other side so systems like artificial systems that are amazingly smart at certain things like maybe playing go and chess and other things but they don't feel at all in any shape or form conscious in the way that you know you do to to me or I do to you and and I think actually building a i is these intelligent constructs is one of the best ways to explore the mystery of consciousness to break it down because we're going to have devices that are pretty smart at certain things or capable of certain things but potentially won't have any semblance of self awareness or other things and in fact I would advocate if there's a choice building systems in the first place AI systems that are not conscious to begin with just tools until we understand them better and the capabilities better so on that topic just not as the CEO of DeepMind just as a human being let me ask you about this one particular anecdotal evidence of the Google engineer who made a comment or believed that there are some aspect of a language model the lambda language model that exhibited sentience so you said you believe there might be a responsibility to build systems that are not sentient and this experience of a particular engineer I think I'd love to get your general opinion on this kind of thing but I think it will happen more and more and more which not one engineers but when and when people out there that don't have an engineer back then start interacting with increasingly intelligent systems we at the promorphize them they they start to have deep impactful interactions with us in a way that we miss them when they're gone and we sure us heck feel like they're living entities self-aware entities and maybe even we project sentience onto them so what's your thought about this particular system was is have you ever met a language model that sentient no I reckon no no what do you make of the case of when you kind of feel that there's some elements of sentience to the system yeah so this is you know an interesting question and a a very fundamental one so the first thing to say is I think that none of the systems we have today I would say even have one Iota of semblance of consciousness or sentience that's my personal feeling interacting with them every day so I think this way premature to be discussing what that engineer talked about I preach I think at the moment it's more projection of other way our own minds work which is to see a sort of purpose and direction in almost anything that we you know our brains are trained to interpret agency basically and things even the inanimate thing sometimes and of course with a language system because language is so fundamental to intelligence that's going to be easy for us to anthropomorphize that I mean back in the day even the first you know the dumbest sort of template chatbots ever Eliza and and and and the and the ilk of the original chatbots back in the 60s fooled some people under certain circumstances right it pretended to be a psychologist so just basically rabbit back to you the same question you asked it back to you and some people believe that so I don't think we can this is why I think the Turing test is a little bit flawed as a formal test because it depends on the sophistication of the of the judge whether or not they they are qualified to make that distinction so I think we should talk to you know the top philosophers about this people like Daniel Dennett and David Charmers and others who who've obviously thought deeply about consciousness of course consciousness itself hasn't been well there's no agreed definition if I was to you know speculate about that you know I kind of the the working definition I like is it's the way information feels when you know it gets processed I think maybe Max Tecmar came up with that I like that idea I don't know if it helps us get towards any more operational thing but it's it's it's I think it's a nice way of viewing it um I think we can obviously see from neuroscience certain prerequisites that require like self awareness I think is necessary but not sufficient component this idea of a self and other and set of coherent preferences that the coherent over time you know these things are maybe memory um these things are probably needed for a sentient or conscious being um but but the reason the the difficult thing I think for us when we get and I think this is a really interesting philosophical debate is when we get closer to a GI and and you know and and and much more powerful systems than we have today how are we going to make this judgment and one way which is the Turing test is sort of a behavioral judgment is is the system exhibiting all the behaviors um that a human sentient or a sentient being would would would exhibit um is it answering the right questions is it saying the right things is it indistinguishable from a human um and so on but I think there's a second thing that makes us as humans regard each other as sentient right why do we why do we think this and I debated this with Daniel Dennett and I think there's a second reason that's over often overlooked which is that we're running on the same substrate right so if we're exhibiting the same behavior uh more less as humans and we're running on the same you know carbon-based biological substrate the squishy you know few pounds of flesh in our skulls then the most parsimonious I think explanation is that you're feeling the same thing as I'm feeling right but we will never have that second part the substrate equivalence with a machine right so we will have to only judge based on the behavior and I think the substrate equivalence is a critical part of why we make assumptions that we're conscious and in fact even with with animals high level animals why we think they might be because they're exhibiting some of the behaviors we would expect from a sentient animal and we know they're made of the same things biological neurons so we're going to have to come up with explanations or models of the gap between substrate differences between machines and humans did to get anywhere beyond the behavioral but to me sort of the practical question is very interesting and very important when you have millions perhaps billions of people believing that you have a sentient AI believing what that Google engineer believed which I just see as an obvious very near term future thing certainly on the path to AGI how does that change the world what's the responsibility of the AI system to help those millions of people and also what's the ethical thing because you can you can make a lot of people happy by creating a meaningful deep experience with a system that's faking it before it makes it yeah and I don't is are we the right or who is to say what's the right thing to do should AI always be tools like why why are we constraining AI always be tools as opposed to friends yeah I think well I mean these are you know fantastic questions and and also critical ones and we've been thinking about this since the start of DeepMine and before that because we plan for success and you know how you know however remote that looked like back in 2010 and we've always had sort of these ethical considerations as fundamental at DeepMine and my current thinking on the language models is and and large models is they're not ready we don't understand them well enough yet and you know in terms of analysis tools and and guard rails what they can and can't do and so on to deploy them at scale because I think you know there are big still ethical questions like should an AI system always announce that it is an AI system to begin with probably yes it what what do you do about answering those philosophical questions about the feelings people may have about AI systems perhaps incorrectly attributed so I think there's a whole bunch of research that needs to be done first to responsibly before we're you know you can responsibly deploy these systems at scale that will be at least be my current position over time I'm very confident we'll have those tools like interpretability questions and and analysis questions and then with the ethical quandary you know I think there it's important to look beyond just science that's why I think philosophy social sciences even theology other things like that come into it where what you know arts and humanities what what what does it mean to be human and the spirit of being human and and to enhance that and and the human condition right and allow us to experience things we could never experience before and improve the the overall human condition and humanity overall you know get radical abundance solve many scientific problem solve disease so this is the era I think this is the amazing era I think we're heading into if we do it right um but we've got to be careful we've already seen with things like social media how dual use technologies can be misused by firstly by by by bad you you know people bad actors or naive actors or crazy actors right so that's that set of just the common common or guard and use you know misuse of existing dual use technology and then of course there there's an additional thing that has to be overcome with AI that eventually it may have its own agency so it could be a good or bad in it in it in it itself so I think these questions have to be approached very carefully um using the scientific method I would say in terms of hypothesis generation careful control testing not live a b testing out in the world because with powerful dual technologies like AI um if something goes wrong it may cause you know a lot of harm before you can fix it um it's not like a you know an imaging app or game app where you know that if it if something goes wrong it's relatively easy to fix and and the harm's relatively small so I think it comes with you know the the the the usual uh cliche of like with a lot of um power comes a lot of responsibility and I think that's the case here with things like AI given the the enormous opportunity in front of us and I think we need a lot of voices uh and as many inputs into things like the design of the systems and the values um they should have and what goals should they be put to um I think as wide a group of voices as possible beyond just the technologists is needed uh to input into that and to have a say in that especially when it comes to deployment of these systems which is when the rubber really hits the road it really affects the general person in the street rather than fundamental research and that's why I say I think as a first step it would be better if we have the choice to build these systems as tools to give and I'm not saying that it should never they should never go beyond tools because of course the potential is there for it to go way beyond just tools uh but um I think that would be a good first step uh in order for us to you know allow us to carefully experiment understand what these things can do so the lead between tool to sentient entity being as long as you take very care of yes let me ask a dark personal question so you're one of the most brilliant people in the community you also want one of the most kind and uh if I may say sort of loved people in the community that said uh creation of a super intelligent AI system would be one of the most powerful things in the world tools or otherwise and uh again as the old saying goes power corrupts and absolute power corrupts absolutely uh you are likely to be one of the people but I would say probably the most likely person to be in the control such a system do you think about the corrupting nature of power when you talk about these kinds of systems that um as all dictators and people have caused atrocities in the past always think they're doing good but they don't do good because the powers polluted their mind about what is good and what is evil do you think about this stuff or are we just focus on language model no I think about them all the time and and you know I think what are the defences against that I think one thing is to remain very grounded and sort of humble uh no matter what you do or achieve and I try to do that I might you know my best friends are still my set of friends from my undergraduate Cambridge days my families you know it's and and and friends are very important um I've always I think trying to be a multi-disciplinary person it helps to keep you humble because no matter how good you are at one topic someone will be better than you at that and and always relearning a new topic again from scratch is a new field is very humbling right so for me that's been biology over the last five years you know huge area topic and and and it's been and I just love doing that but it helps to keep you grounded like you can keep you open-minded um and uh and then the other important thing is to have a really group amazing set of uh people around you at your company or your organization who are also very ethical and grounded themselves and and help to keep you that way uh and then ultimately just to answer your question I hope we're going to be a big part of of birthing AI and that being the greatest benefit to humanity of any tool or technology ever and and getting us into a world of radical abundance and curing diseases and and and and and solving many of the big challenges we have in front of us and then ultimately you know help the ultimate flourishing of humanity to travel the stars and find those aliens if they are there and if they're not there find out why they're not there what what is going on here in the universe um this is all to come and and and that's what I've always dreamed about um but I don't think I think AI is too big an idea it's not going to be uh there'll be a certain set of pioneers who get there first I hope to we're in the vanguard so we can influence how that goes and I think it matters who builds uh who which which which cultures they come from and what values they have uh the builders of AI systems because I think even though the AI systems are going to learn for itself most of its knowledge there'll be a residue in the system of the culture and the values of the creators of that system um and there's interesting questions to discuss about that geopolitically you know different cultures as we were in a more fragmented world than ever unfortunately I think in terms of global cooperation uh we see that in things like climate where we can't seem to get our act together uh globally to cooperate on these pressing matters I hope that will change over time perhaps you know if we get to an era of radical abundance we don't have to be so competitive anymore maybe we can be more correct cooperative uh if resources aren't so scarce it's true that in terms of uh power corrupting and leading to destructive things it seems that some of the atrocities of the past happen when there's a significant uh constraint on resources I think that's the first thing I don't think that's enough I think scarcity is one thing that's led to competition disrupt you know sort of zero-sum game thinking I would like us to all be in a positive some world and I think for that you have to remove scarcity I don't think that's enough unfortunately to get well-piece because there's also other corrupting things like wanting power over people and this kind of stuff which is not necessarily satisfied by by just abundance but I think it will help um and I think uh but I think ultimately AI is not going to be run by any one person one organization I think it should belong to the world belong to humanity um and I think there'll be many there'll be many ways this will happen and ultimately um everybody should have a say in that do you have a device for uh young people in high school and college maybe um if they're interested in AI or interesting having a big impact on the world what they should do to have a career they can be proud of or to have a life that can be proud of I love giving talks to the next generation what I say to them is actually two things uh I think the most important things to learn about uh and to find out about when you're when you're young is what are your true passions is first of all as two things one is find your true passions and I think you can do that by the way to do that is to explore as many things as possible when you're young and you have the time and you and you can take those risks um I would also encourage people to look at the finding the connections between things in a unique way I think that's a really great way to find a passion second thing I would say advises know yourself so spend a lot of time understanding how you work best like what are them optimal times to work what are the optimal ways that you study um what are your how do you deal with pressure um sort of test yourself in various scenarios and um try and improve your weaknesses um but also find out what your unique skills and strengths are and then hone those so then that's what you will be your super value in the world later on and if you can then combine those two things and find passions that you're genuinely excited about that intersect with what your unique strong skills are then you're you know you're onto something incredible and and you know I think you can make a huge difference in the world so let me ask about know yourself this is fun this is quick questions about day in the life the perfect day the perfect productive day in life of demos as well yeah maybe uh maybe these days you're um there's a lot involved yeah maybe slightly younger demos as well yeah when you could focus on a single project maybe um how early do you wake up a unite all do you wake up early in the morning what are some interesting habits uh how many dozens of cups of coffees do you drink a day what's the computer um that you use uh what's the setup how many screens or kind of keyboard we're talking uh e-max vim or we're talking something more modern so there's a bunch of those questions so maybe uh day in the life yeah what what's the perfect day involved well these days is it's quite different from say 10 20 years ago back 10 20 years ago it would have been you know a whole day of um uh research individual research or programming doing some experiment neuroscience computer science experiment reading lots of research papers uh and then perhaps at night time you know um reading science fiction books or or uh playing uh some games but lots of focus so like deep focused work on whether it's uh programming or reading research papers yes so that would be lots of deep reflux you know uh focus work these days for the last sort of I guess you know five to ten years I've actually got quite a structure that works very well for me now which is that um I'm a night complete night owl always have been so I optimize for that so you know I get uh you know I basically do a normal days work get into work about 11 o'clock and sort of do worked about seven uh in the office uh and I will arrange back to back meetings for the entire time of that and with as many me as many people as possible so that's my collaboration management part of the day then I go home uh spend time with the family and friends uh have dinner uh uh relax a little bit and then I start a second day of work I call it my second day of work around 10 pm 11 pm and that's the time till about the small hours of the morning four five in the morning where I will do my thinking and uh reading of research writing research papers um sadly don't have time to code anymore but it's it's not efficient to to do that uh uh these days uh given the amount of time I I have um but that's when I do you know maybe do the long kind of stretches of of thinking and planning and then probably you know using using email other things I would set I would fire off a lot of things to my team to to deal with the next morning but actually thinking about this overnight we should go for this project or arrange this meeting the next day when you think it through a problem are you talking about sheet of paper or the pen pen is there some it depends structure yeah I like I still like I'm still like pencil and paper best for working out things but um these days it's just so efficient to read research papers just on the screen but I still often print them out actually I still prefer to mark out things and I find it goes into the brain quick um better and sticks in the brain better when you're you're you're still using physical pen and pencil and paper so you take notes with the I have lots of notes electronic ones and also um whole stacks of notebooks that that that um that I use at home yeah and some of these most challenging next steps for example stuff none of us know about that you're working on you're thinking there's some deep thinking required there right like what what is the right problem what is the right approach because they're you're gonna have to invest a huge amount of time for the whole team they're going to have to pursue this thing what's the right way to do it as is our are all gonna work here yes um what's the right thing to try what's the right benchmark to you yeah do you need to construct the benchmark from scratch all those kinds of things yes so I think all of those kind of things in the nighttime phase but also much more um I find I've always found the quiet hours of the morning um when everyone's asleep it's super quiet outside um I love that time it's the golden hours like between like one and three in the morning um put some music on some inspiring music on and then um think these deep thoughts so that's when I would read you know my philosophy books and uh spinos as my you know recent favorite can all these things and I you know read about a great uh uh a scientist of history how they did things how they thought things so that's when you do all your create that's when I do all my creative thinking and it's good I think I think people recommend you know you do your your your sort of creative thinking in one block and the way I organize the day that way I don't get interrupted because obviously no one else is up uh at those times so I can I can go uh you know it says I can sort of get super deep and super into flow the other nice thing about doing it nighttime wise is if I'm really uh onto something or I've I've got really deep into something I can choose to extend it and I'll go into six in the morning whatever and then I'll just pay for it the next day yeah because I'll be a bit tired and I won't be my best but that's fine I can decide looking at my schedule the next day that I'm given where I'm at with this particular thought or creative idea that I'm going to pay that cost the next day so so I think that's that's more flexible than morning people who do that you know they get up for in the morning they can also do those golden hours then but then their start of their schedule day starts at breakfast you know a a a and whatever they have their first meeting and then it's hard you have to reschedule day if you and flow yeah that's not why I don't have to do that special threat of thoughts that the you're too passionate about you that this is where some of the greatest ideas could potentially come is when you just lose yourself late in the day yeah and for the meetings I mean you're loading in really hard problems in a very short amount of time so you have to do some kind of first principles thinking here it's like what's the problem what's the state of things what's the right next yes you have to get really good at context switching which is one of the hardest things when because especially as we do so many things if you include all the scientific things we do scientific fields we're working in these are hot and tired feel you know complex fields in themselves and you you have to sort of keep up to up abreast of that but I enjoy it I've always been a sort of generalist in a way and that's actually what happened with my games career after chess I I I I one of the reasons I stopped playing chess was going to computers but also I started realizing there were many other great games out there to play too so I've always been that way in client multidisciplinary and there's too many interesting things in in the world to spend all your time just on one thing so you mentioned spinosa gotta ask the big ridiculously big question about life what do you think is the meaning of this whole thing why are we humans here you've already mentioned that perhaps the universe created us hmm is that why you think we're here to understand how the universe yeah I think my answer to that would be and at least that the life I'm living is to gain and to gain and understand the knowledge you know to gain knowledge and understand the universe that's what I think I can't see any higher purpose than that if you think back to the classical Greeks you know the virtue of gaining knowledge it's so I think it's that it's one of the few true virtues is to understand the world around us in the context and humanity better and and I think if you do that you become more compassionate and more understanding yourself and and more tolerant and all these I think all these other things may flow from that and to me you know understanding the nature of reality that is the biggest question what is going on here is sometimes the colloquial way I say what is really going on here it's so mysterious I feel like we're in some huge puzzle and and it's but the world is also seems to be the universe seems to be structured in a way you know why is it structured in a way that science is even possible that you know methods that the scientific method works things are repeatable it feels like it's almost structured in a way to be conducive to gaining knowledge so I feel like and you know why should computers be even possible isn't that amazing that computation or electronic devices can can be possible and they're made of sand our most you know common element that we have you know silicon that we're on the on the earth's crust it could have been made of diamond or something then we would have only had one computer yeah right so it's a lot of things are kind of slightly suspicious to me it sure it sounds this puzzle sure it's like sounds like something we talked about earlier what it takes to to design a game that's really fun to play for prolonged periods of time and it does seem like this puzzle like you mentioned the more you learn about it the more you realize how little you know so it humbles you but excites you by the possibility of learning more it's one heck of a one heck of a puzzle we got going on here so like I mentioned of all the people in the world you're very likely to be the one who creates the AGI system that achieves human level intelligence and goes beyond it so if you got a chance in very well you could be the person that goes into the room with the system and have a conversation maybe you only get to ask one question if you do what question would you ask her I would probably ask what is the true nature of reality I think that's the question I don't if I don't understand the answer because maybe it would be 42 or something like that but that's the question I would ask and then there'll be a deep sigh from the systems like all right how do I explain to the human all right let me I don't have time yeah explain maybe I'll draw you a picture that it is I mean how do you even begin to answer that question well I think it would what would you think the answer could possibly look like I think it could it could start looking like more fundamental explanations of physics would be the beginning you know more careful specification of that taking you walking us through by the hand as to what one would do to maybe prove those things out maybe giving you glimpses of what things you totally missed in the physics of today exactly just here here's glimpses of no like there's a much a much more elaborate world or a much simpler world or something how much deeper maybe simpler explanation yes of things right then the standard model physics which we know doesn't work but we still keep adding to so and and that's how I think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know consciousness dreaming life and gravity all of these things yeah giving us that glimpses of explanations for those things yeah well um damn it here one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you so much we really enjoyed it thanks thanks for listening to this conversation with Demisus Abbas to support this podcast please check out our sponsors in the description and now let me leave you with some words from Edskur Daikstra computer science is no more about computers than astronomy is about telescopes thank you for listening and hope to see you next time