 Alright, and finally... My favorite, almost irksome question, is your last. Do we already have... do we already have... Do we already have... The right vocabulary and concepts to explain how brains and minds are related. Why or why not? I mean, like... you've gotta be kidding me. That would be... I guess my favorite question, because I'm so... befuddled by it. This is Brain Inspired. Hi, Paul. This is Bill and Las Vegas. That's what is something we think differently about after listening to your podcasts. For me, this is the realization that neurons are not the simple summation devices that we see in artificial neural networks. Blake Richards in episode 9 talked about segregated dendrites, where he shows how apical dendrites can receive feedback signals, which could allow the neuron to learn without using back propagation. And after hearing your podcast with Jeff Hawkins, I read some of his papers, where he proposes additional dendrites segregation, splitting basal dendrites into near and far from the cell body. This could provide a way to allow context input to prime a neuron without actually triggering it. Combining those two things I can finally see how neural networks might do sophisticated learning and retrieval. Thanks for the first hundred episodes, and I'm looking forward to learning a lot of interesting things from your second hundred. Oh no. I have to do another hundred. Catherine! Pack up the kids! And the psychedelics! Let's get out of here. No, leave the dog. Leave the dog. Poor dog. Okay, welcome to the final hundredth episode installment here. I really enjoyed these collections, and I hope that you have as well. So the question of the day that a bunch of my previous guests have answered is, do we already have the right vocabulary and concepts to explain how brains and minds are related? Why or why not? As has been my custom, I will just answer this as well. I say no, not really, but it's kind of a split answer. I don't think we have all of the right concepts. I think that you can see this in a recent episode with David Sassillo and Omri Barak in the dynamical system's theory framework that's popular right now, which I love, and you should too. But even people who practice it, like David Sassillo, who recently articulated this on the show, even people who practice it, or at least some, see it not as an ultimate explanation of brains themselves or brain functioning to generate mind and behavior, but as something that constitutes progress toward understanding. One way, among likely others, that get toward satisfying explanations at all the equally special little levels that we talk about. I think it is important to acknowledge how language works, though. How our vocabulary can remain the same, while the concepts associated with our words definitely change over time. That's just the nature of language. It was Brian Christian recently on the podcast, who pointed out that even machine learning language networks when they're trained on newspaper articles from last year, say, can have trouble correctly sorting out the language from this year. So that's, again, just the nature of drifting semantics and concepts in our language usage. So in that sense, our language seems to be irrelevant, since it will continue to take on and throw away changing concepts. Even though I myself get plenty frustrated with language usage, since to me, it seems to lead to so much wasted time misunderstanding each other. And I think that's probably normal for areas of science where you're dealing with so much unknown and so much complexity. Okay, so that's my little answer. Now you get to listen in random order to many of my previous guests answer that question. So I do look forward very much to 100 more episodes. And I just want to say one more time. Thank you for listening. Thank you to my Patreon supporters. Please do consider supporting the podcast for super cheap. If you find it valuable, there's various things that you get when you support the podcast. Check out Brian Inspire.co and find the red Patreon button there. And thank you again to all the previous guests who said yes and showed up to talk to me. I feel very grateful and the audience does too. So thank you so much. Andrew Sacks here. Alright, and finally, do we already have the right vocabulary and concepts to explain how brains and minds are related? I don't think we're doing badly in the sense that I think we are using the vocabulary and concepts that we have so far in broadly productive ways. But I think we will come up with better concepts. And I think our ability to invent new concepts that clarify new phenomena is underappreciated actually at the moment. So you know, sometimes people say there's no way to describe what a deep network does in language. That's true today. We don't have the language for it today. But I don't think it recognizes that in the future we can invent new words. And this is just a beautiful aspect of human cognition, right? So if you think about the gas laws and physics, ideal gas laws, pressure times volume equals NRT, pressure is natural enough. We all know what that is. Volume, we know what that is. Temperature kind of have a sense of that. What about atomic number, though? You know, there was an epoch where couldn't you imagine someone saying we don't have the language to describe what gases do. And then eventually you invent concepts of an atom, you learn about the concept of atomic number. And now it seems routine and we teach it in high school. To my mind, you know, that is going to happen for our deep learning systems and other theories of cognition. And it's a grand challenge that spans neuroscience and AI to find these concepts that we need in order to explain the behavior of these nonlinear, high dimensional learned systems. Thomas Nossalaris, Department of Neuroscience University of Minnesota. Do we already have the right vocabulary and concepts to explain how brains and minds are related? I can't answer for we, but I certainly don't. I think even my own best ideas, I don't really know how to describe them yet. And even when I do have the right vocabulary to describe them, they are probably going to be wrong. So maybe someone else has the right words to write vocabulary, but I know that I don't. This is John Krakow. The assumption there is that there's going to be a set of concepts and vocabulary that will allow you to fuse and subsume talking about the mind and talking about the brain with that one language. Right. Now if it turns out that the question that you're asking in terms of the relevant question determines the language of explanation you're going to use. Because of what you've decided is relevant, then you're probably going to find that the language and the concepts changes with respect to the level of the question you ask. And so at a meta level, I think the concept and the vocabulary will be one that doesn't demand a single set of concepts or words for a single phenomena because there'll be multiple ways to talk about that single phenomena. And that feeds back into the idea that this notion would be less hard to swallow if one were to read a little bit more philosophy. Federico Tulkamer, at the Institute of Psychiatry, Psychology and Neuroscience, King's College in London. So the last time we talked, we discussed emergence. And I wrote something pretty basic, I would say, which simply stated that we needed to have a quantitative approach to emergence. And I don't exactly remember when was the last time we talked, but during this time, this has actually happened. And I was mentioning to you that, for example, the complexity group. I mean, there is a group of people interested in complexity science and imperial Oxford and I think Cambridge that have worked out a statistical approach to actually look at the context of the word. And actually look at emergence, quantifying emergent activity from brain, say standard functional MRIs. And there has been actually integrated with genetic data. And I'm also trying to understand how that comes out of the biology of the brain, which is the missing. But at least now we have maps. And there is this very fantastic map, they show on where they showed the two sides of the brain, the very modular brain. And the very synergistic brain. And this does correspond to differences in the genetics, genomics and biology of the associative courtesies versus the non associative courtesies. And the merits do confirm that this double sided nature of the brain seems to generate the kind of cognition that we call a mind or we call. And I'm trying, I'm doing a project at the moment where I'm trying to understand how that could evolve from the primary brain. How is that come out? What is the mover of those two sides? It must be something simple because evolution ultimately is not that complicated. But why are these associative courtesies so different? They have more connected, they have more synapses, they have less smiling than the others. And they are these hacks that is sitting on top on something which is more modular, standard primary and second courtesies. How is that, did that happen? This is Steve Potter from the Georgia Tech Laboratory for Neuroengineering. Do we have the right vocabulary, this is question five, do we have the right vocabulary and concepts to have a satisfying explanation for how brains and minds are related? We probably don't have the right vocabulary and concepts to do, have a satisfying explanation for how brains and minds are related. We need a lot more terminology and tools that have to do with complex emergent systems and their dynamics. For example, often here computational neuroscience is talking about brain states. But this concept is borrowed from digital computers which actually do have states, their transistors are either on or off allowing for a well-defined state during most of every clock cycle on the computer. The brain by contrast doesn't have a clock, it does not, yes there are rhythms and things oscillating in the brain but there's not a system clock like there isn't a computer. The brain is continually changing, continuously changing you could say. It doesn't go from state to state, it flows, it evolves. So we need more vocabulary to talk about what for example doesn't attract or mean when we're talking about the brain moving towards making a decision or coming up with an idea. I feel like all the terminology that we have for those right now are the same ones, William James was using 120 years ago. This is David Krakauer. My favorite, almost irksome question is your last which is do we have the right vocabulary and concepts to explain how brains and minds are related and the answer is obviously we do not. And it's interesting because it's a very old problem and it pops up everywhere. You ask the questioners brain to mind, evolutionary biologists ask the question in terms of life and non-life, geneticists in terms of genotypes and phenotypes, computer science in terms of hardware and software. And there are all instances of this same dichotomy between the material domain and the codical domain and most systems that are functional or adaptive permit of both types of description. And it's interesting it goes way back, you know, you see these distinctions being made in the middle ages by Thomas Aquinas when he's talking about intellectual operation or the soul as being quite distinct from the corporeal world. And that gets in some sense elaborated on by Descartes in his discourse on method where he introduced what we now know as Cartesian dualism where he argues that magic cannot have a perfect understanding of itself. And that has never gone away. And the question is why and I don't have an answer part of it has to do with a desire to always reduce an explanation to a single epistemological variety. So somehow the material domain is more appealing than an explanation provided in terms of information, for example, or computation or, you know, logical principles. It feels more satisfying because obviously the mental world sits on the physical world. On the other hand, most of what we do in our lives when we talk about the economy or history is articulated in these codical terms and we don't seem to be much bothered by it. And so that's all to say that I think we don't have as of yet the right vocabulary. I think Alan Turing in creating the Turing machine and Alonzo Church in creating the Lambda calculus were inching towards what we might need. The Turing machine is obviously a mathematical construct not a physical one, it's infinite after all, but it does somehow straddle a little bit of those two worlds. And the key concept for Turing was universality and I would guess that any adequate explanation of why these two alternative forms of description and explanation have to exist would turn on a concept like universality. So that would be I guess my favorite question because I'm so befuddled by it. This is Dean Boanemano. Do we already have the right vocabulary and concepts to explain how brains and minds are related? Why or why not? Okay, so by mind I'm going to assume you're including consciousness and in that case my answer is a clear no. I don't think we have the vocabulary of concepts. Understanding the human mind and the nature of consciousness is perhaps the most profound of all scientific questions and it is the mother of all recurrent problems. The brain is trying to understand itself. I think it's a perfectly valid question to ask if that's even possible. Any device can any system actually understand itself we don't expect chimpanzees or other primates to be capable of understanding themselves and for the most part we don't expect a eyes necessarily to be capable of understanding themselves. So I think this is something that's often not taken as seriously as it should be in this debate. But to see how far we are from having the right vocabulary and concepts to understand the relationship between the brain and mind when just has to look at the theories of consciousness. Well most neuroscientists certainly myself included believe that consciousness in the mind are emergent properties of our neural circuits. But oddly in some well-known neuroscientists and some of the most talked about theories of consciousness are panpsychist theories such as integrated information theory or IIT. Which place consciousness in the realm of physics? So this is a serious reason why we don't have the right vocabulary and concepts. So we don't even have general agreement or universal agreement that consciousness is attributable to neuroscience. So some people think it's in physics. And in my opinion I think this highlights the recursive nature of the task. If the brain is to understand itself it has to account for its own limitations and cognitive biases. One of our cognitive biases is to explain away things that we don't understand through supernatural forces or fundamental forces of physics. Like the notion of vitalism or a lumbic tall, we're used to explain the nature of life at the end of the 1800s. So I think in my mind panpsychism is more a symptom of how the mind works than a consistent theory of how the mind works. So overall I think we're a long way, we have a long way to go before the brain comes to understand itself. My name is Conrad Codding. I'm a neuroscientist at the University of Pennsylvania. Last point, do we already have the right vocabulary and concepts to explain how brains and minds are related? Why or why not? I mean like you've got to be kidding me, of course we don't. The vocabulary we use now is very different from 10 years ago. Why on earth would we believe that we are very close to solving things? No one is even pretending that they can meaningfully simulate the human brain. We can't really simulate the elegance for crying out loud. So why would we have the right concepts? Now I want to go to one step further. I think that because we are so strongly on the mechanistic train where we want to understand the brain in terms of the mechanisms there. And because we're so strongly reductionist, we might be missing a lot of the vocabulary that ultimately deals with the objectives of systems. Why are animals designed the way they are? And why did evolution get us there? And that allows us to argue from ecological niche about organization of the brain. And I believe we will need these kinds of arguments. How do you know that? Uri Hassan from Princeton University. No, back there. The $6 million question. First, we're still stuck in representation and an apparatus as classically high systems that we need to get rid of. Now when you switch representation with embeddings that some of your audience will know what is embedding is, you start to get to a more dynamical system. But embedding is not enough, right? It's the basis of action, but it's not enough. And then when you ask, how from this like blind embedding and direct fit, you get understanding. This is even missing in the current AI version. I think AI systems are more like system one intuitive and fast and fit to the statistics and act with understanding. You can get a long way with system one, but we also have system two right. We also slow and elaborate and thinking and deciding. And this is completely missing in current AI. So we're really missing out to get from system one over parameterized memorization interpolation to system two. And that the big question for the coming years. So I'm Rodrigo Canceroga, neuroscientist at the University of Leicester. Well, this is a center is long discussion. And the one that put it upfront was the card with his cultural dualism. I don't believe in this in this kind of like essential distinction between man and brain. I think it's just different levels of seeing the same problem. So sometimes you want to see behavior. I mean, I mean, like high level behavior. And this is more or less what psychology focus on. And then in some other cases, you want to go to the level of single neurons and see more detail mechanisms. And this is a little bit more the realm of neuroscience. So you can argue that neuroscience can encompass everything because you can also have cognitive neuroscience and so on. So I think basically is kind of like starting other people. So I think other people when I say that particularly the church, and some in my number and other same thing. I mean, the mind is nothing more than the activity of of neurons. And if we talk about the mind or if I talk about neurons is basically just choosing the right level of description to the brain. I mean, to describe or to try to understand some phenomenon. But I mean, in principle, I see my number in us as the same thing. My name's Jim DeCarlo. I clearly don't think we have the right vocabulary concepts because we don't even agree on concepts or goals of what it would mean to explain. I think there's an important thing to think about humans not having a vocabulary to explain something to each other in the terms that we thought we should. Versus humans having the ability to build systems that effectively act as explanations. Those are two different modes of understanding. And it's the latter that I think we need to figure out how to be comfortable with. That's again related to the idea that things are complicated. Explanations are going to be complicated and not held within human minds. Okay, so my name is Marcel von Kärfen. I'm a chair of the AI department at the Donlers Institute. So I think we have the right vocabulary to describe brains and to describe neuronal dynamics and to model that. I think that's there, but at the same time we have minds and they basically live on top of those neuronal dynamics. So these are a cognition is basically defined in terms of symbols, cognitive states, representations, etc. And these things live within the neuronal dynamics, but they unfold at much slower time scales than the time scales you typically associate with single neuronal dynamics. So we need to gain an understanding of how these dynamics within their own networks relates to more complicated stable states that do reflect something which has to do with cognition. And I think people have realized that a long time ago as well, right? So if you look back, there's a lot of work on linking recurrent neural networks to nonlinear dynamical systems theory. And actually finding descriptors that describe these higher level states that might be more related to cognition in the end. But we didn't nail it. So there's something missing still. Let's take a quick little break and then we'll get back to the responses. My name is Josh Sanderman. My introduction to your podcast was the crack hour episode and that drew me in. You know, I found it to be an incredibly thought provoking and engaging conversation about some very fundamental issues of how nature creates pattern and the difference between what nature is actually doing in all of its detail and how we're able to model it without losing finding that balance between the amount of detail we need, but also being able to extract the principles. In other words, finding the perfect degree of spirituality of the cow, you know, and that was, I think, one of the big take home points for me from that discussion when it just was it inspired me to continue to follow the podcast. And like I said before, I've heard listen to virtually everyone's sense and just always been able to take something from it in terms of some of these overall issues in terms of how brains can exist at all. How they extract information, process information, and then can act upon it and then how brains can study themselves as a result of that. And it's been very fascinating and edifying. Mazwita Chiramuta. Yeah, do I think we have the right vocabulary? No, I wouldn't say right now. I mean, the current, like best guess at the right level of simplification for understanding the brain has been the computational theory. But I think there are a lot of problems with just thinking that computation is going to be the final theory that will unlock all the secrets of the brains because I think it's bound to miss out a lot of the very important biological details that probably allow brains to do what they do and allow brains to be generating thoughts and be the basis of thought and being the substrate of the mind. So I think as long as our understanding of how the brain works is so closely tied to the computational framework, I don't think we're going to be able to make sense completely of how it relates to the mind. Just to give an example, I mean within the computational framework, people talk about the mind as a software and brain as the level of implementation. So they really directly take those concepts from computer science and I think there are so many disanalogies between brains and computers that that cannot be the right answer about how brains and minds are related. This is Brad Love from UCL. Do we already have the right vocabulary and concepts to explain how the brain and minds are related? Why or why not? Yeah, there's a lot of discussion about this and I think it's somewhat of a red herring. I know your listeners feel a soft, so if you look at quine and big and sign, how they talk about meaning arising within a larger system. So I think that's the same with vocabulary science vocabulary. I mean saying attention doesn't mean anything alone. It's within a system of other concepts. So right off the bat, it's not really about vocabulary itself, but about use and how it's used. And for me, these words change over time. It's not like attention means the same thing now than it does before. The meanings evolve with use and how they relate to other terms. And for me, someone that makes computational models, I just don't really care what things are called. So you could say attention is not meaningful or some outdated, but it's just a equation in the model that's doing something valuable. If you want to call it something else or not, that makes no difference. So you know, I think this is really not a real debate or something that we should be using our time on, you know, like as science progresses and evolves, maybe we get a new vocabulary, maybe the old words change meanings, some are lost, some are added, but I don't think this is really something that you just go out and try to redo or reject. It just doesn't really make sense to me. It's Patrick Mayo. Do we already have the right vocabulary and concepts to explain how brains and minds are related? Why or why not? I'm one of those people who doesn't really use the word mind. I majored in cognitive science in college. And one of the reasons I'm doing neuroscience is because I got a bit frustrated with the word mind and with people sitting around and talking about things, sort of like a philosophy class. So I learned a ton from those classes and it certainly had sparked my interest in how the brain works, but I don't really know what the mind is. There's the mind meld from, you know, the Vulcan star track mind meld. I know what that is. But otherwise, I'm studying the brain by doing extra cellular, electrophysiological recordings and whatever terms we have for that right now, I'm okay with. Hi, Paul. This is Yuri. What ideas, assumptions, terms, do you think is holding back neuroscience and so on? And the other one is related in my mind. Do we already have the right vocabulary and concepts to explain how brains and minds are related? My answer. Neuroscientists began to study the brain, buying into a system created by philosophers and psychologists for understanding the soul and the mind without ever asking how those terms whose brain functions we are trying to understand, such as consciousness, the brought into our thinking in the first place. And the neuroscience has inherited this paradigm from such philosophy driven framework, which portrays the brain or more precisely the soul and the mind as a tool to learn about the true nature of the world. And we think as used introspection and gave names to mental operations and now millennial later research for neural mechanism that might relate to their dream up ideas. Of course, an inevitable consequence of this framework, what I call outside in, is the assumption that the brain's fundamental goal is to perceive signals from the outside world, process such information correctly interpret them. In order to respond to these signals, an additional operation is needed. Wedged between the perceptual inputs and the organism response is the terrain of a hypothetical central processor. This is an entity that chooses what to do with the process the information. This poorly understood but often speculated about terrain has been referred to by various terms such as free will, homunculus, consciousness, executive functions, intervening variables, black box or more recently decision maker, depending on the experimenter's philosophical inclination or whether the hypothetical operation is applied to the human brain, brains of other animals or computer models. Yet, of course, they all refer to the same thing. The key assumption in this perception, decision, action paradigm is that information is processed properly so that something somewhere in the brain can decide to select the correct action. An implicit practical implication of this outside in framework is that the next frontier for progress in contemporary neuroscience should be to find the central processor somewhere in the brain and systematically elaborate the neural mechanisms of decision making. This is exactly what's going on at full speed in today's neuroscience. Over the past decade, decision making has become a bus term and applied to virtually all research without posing a bit and asking ourselves, do we know precisely what we are looking for? In my new book, The Brain From Inside Out, I argue that this outside in framework may not be the best strategy to understand the brain. Brain evolution didn't start out to generate a program where the end product should be the human level cognitive faculties. Instead, brains evolved to induce actions and learn to predict the consequences of those actions as afforded by a particular environment. The brain is not interested in the true nature of the world. Instead, its main preoccupation is to help its host to survive and prosper in its niche. I speculate that this action-centric approach is more strongly embedded in evolution. The neurophysiological findings are more compatible with it and the problems can be formulated differently, including the problem of the relationship between brains and minds. I suggest that by trying out this inside our strategy, perhaps some of the currently controversial terms may become dispensable. The choice of a particular framework is important in our everyday practice because frameworks shape our ideas both about experimental design and interpretation. I don't exist that my suggested strategy is perfect, yet I believe that this alternative is perhaps more fruitful than the currently dominant outside in framework that so strongly influences AI. It's a bit of a little bit of an issue. I mean, about the vocabulary, what I can say is definitely the way that we talk about concepts like consciousness and attention are really important. But they have a very complex relationship to the things we measure in neuroscience in neurons. Take, for example, attention as an example. When I started to work on vision, I tried to avoid toward attention because I thought it was completely misdefined or at least differently defined by different workers in the field. So I thought let's just not talk about attention because that will make my life easier. But at some point I came to realize that that's not good because there are many aspects in vision that are really related to how attention works. And there is a very important literature developed by psychologists that use the word attention and there's no way of writing it. So then you need to really find attention because there's selective attention, there is attention in terms of alertness and there are many types of attention. And you really have to keep these things in mind if you work on neuroscience and try to address questions about attention. Now for me then consciousness was basically aware that I then try to avoid. And I did that successfully for a number of years with at some point. I'm sorry, let's I cannot avoid it anymore. So, and I think there the problem is even more severe. So I think even categorizing the different types of consciousness and the different definitions is still in the beginning. So that will take some time to sort it out. David Pople and I work at NYU and at the Max Planck Institute. We have the right vocabulary for our particular concerns right now. So we have good vocabulary for certain parts of the cognitive sciences and we have good vocabulary for parts of the neuroscientists. What we lack are convincing linking hypotheses between the vocabulary. So we have coherent hypotheses about the ontological structure or the cognitive ontologies and cognitive science and the biological ontologies and neuroscience. But we do not have ontological linking hypothesis which makes us ontologically incommensurable. And then it raises questions about where do you start? Do you start with a psychological or computational or cognitive theories or the biological ones? Are you an inside out person like you or you want to be or are you an outside in person like I want to be? And where do you meet in the middle? So we have some good vocabulary actually, some good decomposition of the problems but we lack the links so far. Let's pay attention to that and maybe we'll move on a bit. This is Paul Chi's segment in the University of Montreal. So no, I don't think we quite have the right vocabulary. I think we are still influenced too much by pre-scientific concepts about the mind, sort of assuming that they'll happen to map one to one to one to one to realize the mechanism in the brain. But I don't think we can really make that assumption. But unfortunately, I think by the time a graduate student has the confidence to question the stuff they read in their textbooks or journal articles, they've already spent too much time being an undergraduate student just absorbing information how to think exclusively in terms of that kind of stuff. So it seems preposterous to question the idea that the brain is an information processing system or that concepts like memory or attention should define our research programs. That's just a vocabulary and irrelevant questions are phrasing those terms. But I think that some of those definitions might just be wrong and then they lead us the wrong way. So I think, as you know, that I think the best way to subdivide the problem of behavior is to do so with the guidance of evolutionary history. So in other words, the definitions of functions or systems can be done through the gradual differentiation of functions and systems that mirrors how ancestors transition to their descendants. Because that's how the functional architecture of the brain was actually constructed. So after all, and I think we all agree with that. So it seems like it's the right way for us to build models of that architecture. And that leads to rather different types of questions. You focus instead on specific transitions that occurred at specific times in our history, doing so from both in their own behavioral perspective. And so the example I'll use here is related to this question of memory. But it doesn't sound maybe like it. So the point is that the example I would give is I think it's a fascinating question of how our ancestors took the hippocampal complex, which evolved over hundreds of millions of years in the service of guiding navigation through physical space. At some point started using it for more abstract tasks, including constructing episodic memories of sequential events in our lives. In other words, I think we shouldn't think of memory as some kind of a thing that some kind of problem, some kind of abstract platonic solid that our brains finally succeeded in implementing after millions of years of trying different ways of encoding information. Instead, we should think of our brain as modifying its control systems in particular idiosyncratic ways that extended specific behavioral capacities like navigation. And at some point, certain things emerged. And some of those things that we call memory is just set of a phenomena that were produced by that gradually evolving system, which is still a work in progress. So in other words, rather than define the problem to be solved, think about the capacities that modifications enabled and then how those capacities have certain, produce certain phenomena like memory or attention or some of the things that we traditionally think about. I think it's possible to reconstruct the vocabulary so that you don't start with those things. You start with more fundamental biological processes. Now, most of that is just about neuroscience, right? It doesn't really apply to AI. In AI, if you want to build a system, then how it works, how well it works is the most important thing. You don't necessarily have to be concerned about biology. So you could make a memory module and work out what's an efficient way for it to store information. But I think if you want human-like AI, then you really want to add those additional constraints of biological plausibility and the way to do that, I think is to think about some of these evolutionary and philosophical issues that I think face neuroscientists. I think they'll provide the right kind of insights for AI as well. Talia Conkel Do we already have the right vocabulary and concepts to explain how brains and minds are related and why are we? Yes and no. Again, I think there's, I'm going to like just tweak the question a little bit. I think that hidden in the question is a sense that there's the right vocabulary and concepts to explain how minds and brains are related. And I think we need a lot of vocabulary. I think different levels of abstraction are really important. There's some sides that think like if we can build it, we've got a really detailed model, like a computational model that's almost a direct map, you know, silicon implementation of a brain. Well, then we're done. And in some sense, yeah, that's true. You can do a bunch of experiments on it. You can test it. You can make predictions. And I think that is a really useful level of representation and a level of an evoke and a particular kind of vocabulary. But I also want a level of understanding that lets me give sort of intuitive answers to questions like, well, how does this work? And why does that happen? You know, I kind of want them compressible into simple language and ideas, the kind that, you know, scaffold how we teach the next generations. You know, we talk about dorsal and federal stream and hierarchy. And these are really compressed concepts that, you know, clearly are making some simplifications that are hugely powerful for situating our concepts for how we think about what the next problems are and what are the problems we need to solve. So, yeah, I think you want sort of a multi-scale vocabulary, one that's really detailed and some that are super high level and really good for sort of conveying broad swathes of ideas and a few phrases. And I think that a multi-level vocabulary is going to be really important for understanding how brains and minds and models are related. I'm Steve Grossberg. Do we already have the right vocabulary and concepts to explain how brains and minds are related? Why or why not? Well, as you might guess for my previous answers, I reply, yes, my discoveries with many gifted colleagues over the past 63 years provide insights into most of the fundamental processes whereby brains do make our minds. There are over 550 articles on my webpage sites.bew.edu slash Steve G summarizing these discoveries. But for people who don't want to have to browse over so much stuff as well as lectures there, let me just remark that an introductory and non-technical overview of these discoveries is provided by my book, actually it's my magnum opus that's now impressed with Oxford University press. It'll be published this spring and its title is conscious mind, resonant brain, how each brain makes a mind. All you need to do to get started is to read my book or study a subset of the articles on my webpage that interest you both should stimulate a lot of thinking and new discoveries. So thanks very much for listening. To get in touch with me, email Paul at braininspired.co. The music you hear is by the New Year. Find them at thenewyear.net. Thank you for your support. See you next time.