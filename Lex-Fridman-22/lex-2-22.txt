The following is a conversation with Scott Arenson, a professor UT Austin, director of its Quantum Information Center, and previously a professor at MIT. His research interests center around the capabilities and limits of quantum computers and computational complexity theory more generally. He is an excellent writer and one of my favorite communicators of computer science in the world. We only had about an hour and a half of this conversation, so I decided to focus on quantum computing. But I can see us talking again in the future on this podcast at some point about computational complexity theory and all the complexity classes that Scott catalogs and his amazing complexity zoo wiki. As a quick aside, based on questions and comments I've received, my goal with these conversations is to try to be in the background without ego and do three things. One, let the guests shine and try to discover together the most beautiful insights in their work and in their mind. Two, try to play devil's advocate, just enough to provide a creative tension and exploring ideas to conversation. And three, to ask very basic questions about terminology, about concepts, about ideas. Many of the topics we talk about in the podcast I've been studying for years as a grad student as a researcher and generally as a curious human who loves to read. But frankly, I see myself in these conversations as the main character for one of my favorite novels, Badesta Yavsky, called The Idiot. I enjoy playing dumb. Clearly, it comes naturally. But the basic questions don't come from my ignorance of the subject, but from an instinct that the fundamentals are simple. And if we linger on them from almost a naive perspective, we can draw an inside full thread from computer science, to neuroscience, to physics, to philosophy, and to artificial intelligence. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it 5 stars and Apple podcasts, support it on Patreon or simply connect with me on Twitter, at Lex Friedman spelled F-R-I-D-M-A-N. As usual, I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. Quick summary of the ads, two supporters today. First, get CashApp and use the code Lex Podcast. Second, listen to the TechMeme Ride Home Podcast for Tech News. Search RideHome two words in your Podcast app. This show is presented by CashApp, the number one finance app in the App Store. When you get it, use code Lex Podcast. CashApp lets you send money to friends by Bitcoin and invest in the stock market with as little as $1. Broker services that are provided by CashApp investing, a subsidiary of Square and member SIPC. Since CashApp does fractional share trading, let me mention that the order execution algorithm that works behind the scenes to create the abstraction of fractional orders is an algorithmic marvel. So big props to the CashApp engineers for solving a heart problem that in the end provides an easy interface that takes a step up to the next layer of abstraction over the stock market, making trading more accessible for new investors and diversification much easier. So again, if you get CashApp from the App Store or Google Play and use the code Lex Podcast, you'll get $10 and CashApp will also do an $10 to first. One of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. This episode is also supported by the TechMeme right home podcast. It's a technology podcast I've been listening to for a while and really enjoying. It goes straight to the point, gives you the tech news you need to know and provides minimal but essential context. It's released every day by 5pm Eastern and is only about 15 to 20 minutes long. For fun, I like building apps on smartphones, most I'm Android, so I'm always a little curious about new flagship phones that come out. I saw that Samsung announced the new Galaxy S20 and of course right away TechMeme right home has a new episode that summarizes all that I needed to know about this new device. It also started to do weekend bonus episodes with interviews of people like A.W.F. Steve Case, an investing and Gary Marcus on AI who I've also interviewed on this podcast. You can find the TechMeme right home podcast if you search your podcast app for a ride home towards. Then subscribe, enjoy and keep up to date with the latest tech news. And now here's my conversation with Scott Arenson. I sometimes get criticism from a listener here and there that while having a conversation with a world class mathematician physicist, neurobiologist, aerospace engineer or theoretical computer scientist like yourself, I waste time by asking philosophical questions about free will, consciousness, mortality, love, nature of truth, super intelligence, whether time travels possible, whether space time is emerging from the mental, even the crazy questions like whether aliens exist, what their language might look like, what their math might look like, whether math is invented or discovered and of course whether we live in a simulation or not. So I tried with it. I tried to dance back and forth from the deep technical to the philosophical. So I've done that quite a bit. So you're a world class computer scientist and yet you've written about this very point, the philosophy is important for experts in any technical discipline, though they somehow seem to avoid this. So I thought it'd be really interesting to talk to you about this point. Why should we computer scientists, mathematicians, physicists, careball philosophy do you think? Well, I would reframe the question a little bit. I mean, philosophy, almost by definition, is the subject that's concerned with the biggest questions that you could possibly ask. So the ones you mentioned, are we living in a simulation? Are we alone in the universe? How should we even think about such questions? Is the future determined? What do we even mean by it being determined? Why are we alive at the time we are and not at some other time? And when you contemplate the enormity of those questions, you could ask, well, then why be concerned with anything else? Why not spend your whole life on those questions? I think in some sense that is the right way to phrase the question. And actually, what we learned throughout history, but really starting with the scientific revolution, with Galileo and so on, is that there is a good reason to focus on narrower questions, more technical, mathematical or empirical questions. And that is that you can actually make progress on them. And you can actually often answer them. And sometimes they actually tell you something about the philosophical questions that sort of maybe motivated your curiosity as a child. They don't necessarily resolve the philosophical questions, but sometimes they reframe your whole understanding of them. And so for me, philosophy is just the thing that you have in the background from the very beginning that you want to... These are the reasons why you went into intellectual life in the first place. The reason why I did. But math and science are tools that we have for actually making progress. And hopefully even changing our understanding of these philosophical questions, sometimes even more than philosophy itself does. What do you think computer scientists avoid these questions? We'll run away from them a little bit, at least in the technical scientific discourse. Well, I'm not sure if they do so more than any other scientist. I mean, Alan Toring was famously interested in his most famous, one of his two most famous papers was in a philosophy journal mind. It was the one where he proposed the Doring Test. He took a Wittgenstein's course that came bridge, argued with him. I just recently learned that little bit and it's actually fascinating. I was trying to look for resources in trying to understand where the sources of disagreement and debates between Wittgenstein and Toring were. That's interesting that these two minds have somehow met in the arc of history. Yeah. Well, the transcript of their... The course, which was in 1939, right, is one of the more fascinating documents that I've ever read because a Wittgenstein is trying to say, well, all of these formal systems are just complete irrelevancies. If a formal system is irrelevant, who cares? Why does that matter in real life? And Toring is saying, well, look, if you use an inconsistent formal system to design a bridge, the bridge may collapse. So Toring, in some sense, is thinking decades ahead, I think of where Wittgenstein is, the where the formal systems are actually going to be used in computers to actually do things in the world. And it's interesting that Toring actually dropped the course halfway through why because he had to go to Bledchley Park and work on something of more immediate importance. Fascinating. It could take a step from philosophy to actual... Like the biggest possible step to actual engineering with actual real impact. Yeah. And I would say more generally, right? A lot of scientists are interested in philosophy, but they're also busy, right? And they have a lot on their plate and there are a lot of sort of very concrete questions that are already not answered, but look like they might be answerable, right? And so then you could say, well, then why break your brain over these metaphysically unanswerable questions when there were all of these answerable ones instead? So I think, for me, I enjoy talking about philosophy. I even go to philosophy conferences sometimes, such as the FQXI conferences. I enjoy interacting with philosophers. I would not want to be a professional philosopher because I like being in a field where I feel like, you know, if I get too confused about the sort of eternal questions, then I can actually make progress on something. Can you maybe lean on that for just a little longer? Yeah. What do you think is the difference? So like the corollary of the criticism that I mentioned previously that why ask the philosophical questions of the mathematician is if you want to ask philosophical questions, then invite a real philosopher on and ask them. So what's the difference between the way a computer scientist and mathematician ponders of philosophical question and a philosopher ponders of philosophical question? Well, I mean, a lot of it just depends on the individual, right? It's hard to make generalizations about entire fields. But, you know, I think if we tried to, if we tried to stereotype, you know, we would say that scientists very often will be less careful in their use of words. You know, I mean, philosophers are really experts in sort of, you know, like when I talk to them, they will just pounce if I, you know, use the wrong phrase for something. And experts is a very nice word. You could say stichlers or... Stichlers, yeah, yeah, yeah. Or, you know, they will sort of interrogate my word choices, let's say, to a much greater extent than scientists would, right? And scientists, you know, will often, if you ask them about a philosophical problem, like the hard problem of consciousness or free will or whatever, they will try to relate it back to, you know, recent research, you know, research about neurobiology or, you know, the best of all is research that they personally are involved with, right? And, you know, and, and, and, you know, of course, they will want to talk about that, you know, and it is what they will think of, you know, and, of course, you could have an argument that maybe, you know, it's all interesting as it goes, but maybe none of it touches the philosophical question, right? But, you know, but maybe, you know, a science, you know, at least it, it, as I said, it does tell us concrete things. And, you know, even if, like a deep dive into neurobiology will not answer the hard problem of consciousness. You know, maybe it can take us about as far as we can get toward, you know, expanding our minds about it, you know, toward thinking about it in a different way. Well, I mean, I think neurobiology can do that, but, you know, with these profound philosophical questions, I mean, also art and literature do that, right? Uh, they're all different ways of trying to approach these questions that, you know, we don't, for which we don't even know really what an answer would look like, but, uh, and yet somehow we can't help but keep returning to the questions. And you have a kind of mathematical, beautiful mathematical way of discussing this with the idea of Q prime. Oh, right. You write that usually the only way to make progress on the big questions, like the full, the philosophical questions we're talking about now is to pick off smaller sub questions. Mm-hmm. Ideally, sub questions that you can attack using math and empirical observation are both. You define the idea of a Q prime. So given an un, an unanswerable philosophical, riddle Q, replace it with a merely, in quote, scientific or mathematical question, Q prime, which captures part of what people have wanted to know when they first asked Q. Yes. Then with luck, one solves Q prime. So you, you describe some examples of such Q prime sub questions in, uh, your long essay, titled, Why Philosopher Should Care About Computational Complexity. So you catalog the various Q primes on which you think, uh, theoretical computer science has made progress. Can you mention if you favor it's if any pop, if any pop to mind or the, or the other stuff. So I mean, I would say some of the most famous examples in history of that sort of replacement were, you know, I mean, I mean, to go back to Alan Turing, right, what he did in his, uh, computing machinery and intelligence paper was exactly, you know, uh, he explicitly started with the question, can machines think? Yeah. And then he said, uh, sorry, I think that question is too meaningless. But here's a different question, you know, could you program a computer so that you could tell the difference between it and a human, right? And so, yeah. So in the very first two sentences, he in fact just formed this to Q prime question. It precise, he does precisely that. Or, you know, we could look at, at, at, at Gertel, right, uh, where, you know, you had these, uh, philosophers arguing for centuries about the limits of mathematical reasoning, right, the limits of formal systems and, um, you know, then by the early 20th century, uh, uh, logicians, you know, starting with, you know, frage, rassal, and then, you know, most, uh, spectacularly, Gertel, you know, managed to reframe those questions. As look, we have these formal systems, they have these definite rules. Are there questions that we can phrase within the rules of these systems that are not provable within the rules of the systems and can we prove that fact, right? And, um, so that would be another example, uh, uh, you know, I, I, I had this essay called the Ghost in the Quantum Turing Machine. Uh, it's, you know, one of the crazier things I've written, but I, uh, I tried to do some things, or, you know, to, to advocate doing something similar there for free will, where, you know, instead of talking about, is free will, you know, real, where we get hung up on the meaning of, you know, what exactly do we mean by freedom? And can you have, can you be, you know, or do we mean compatibleist free will, libertarian free will? What do these things mean? You know, I, uh, suggested just asking the question, how well, in principle, consistently with the laws of physics, could a person's behavior be predicted, you know, without, so let's say, destroying the person's brain, you know, taking it apart in the process of trying to predict them. And, you know, and, and that actually, uh, asking that question gets you into all sorts of media and interesting issues, you know, issues of, what is the computational substrate of the brain, you know, or, uh, can you understand the brain, you know, just at the sort of level of the neurons, you know, at sort of the abstraction of a neural network, or do you need to go deeper to the, you know, a molecular level, ultimately, even to the quantum level, right? And of course, that would put limits on predictability if, if you did. So you need to reduce, you need to reduce the mind to a, a computational device, like formalize it so that you can make predictions about, you know, whether you could predict the behaviors. Well, if you were trying to predict a person, yeah, then presumably, you would need some model of their brain, right? And now the question becomes one of how accurate can such a model become? Can you make a model that will be accurate enough to really seriously threaten people's sense of free will, you know, not just metaphysically, but like really, I have written in this envelope, what you were going to say next, is accuracy the right term here? So it's also a level of abstraction has to be right. So if you're, yeah, if you're accurate at the somehow at the quantum level, that may not be convincing to us at the human level. Well, right, but the question is what accuracy at the sort of level of the underlying mechanisms do you need in order to predict the behavior, right? At the end of the day, the test is just can you, you know, foresee what the person is going to do, right? I am, you know, and, and, and, you know, and, and, and, and, and, and, and, and, and, and, and discussions of free will, you know, it seems like both sides want to, you know, very quickly dismiss that question as a relevant, well, to me, it's totally relevant, okay? Because, uh, you know, if someone says, oh, well, you know, I will, I will applause demon that knew the complete state of the universe, uh, you know, could predict everything you're going to do. Therefore, you don't have free will, you know, that, that, that, it doesn't trouble me that much because, well, you know, I've never met such a demon, right? I, you know, uh, you know, and, and, uh, we, you know, we even have some reasons to think, you know, maybe it, you know, it could not exist as part of our world. You know, it was only an abstraction, a thought experiment. On the other hand, if someone said, well, you know, I have this brain scanning machine, you know, you step into it, and then, you know, every paper that you will ever write, it will write, you know, every thought that you will have, you know, even right now about the machine itself, it will foresee, you know, it will, if you can actually demonstrate that, then I think, you know, that, that, you know, that, that sort of threatens my internal sense of having free will in a much more visceral way. You know, but now, you notice that we're asking an, uh, a much more empirical question. We're asking, is such a machine possible or isn't it? We're asking, if it's not possible, then what in the laws of physics or what about the behavior of the brain, you know, prevents it from existing? So if you could philosophize a little bit within this empirical question, at where do you think would enter the, the, by which mechanism would enter the possibility that we can't predict the outcome? So there would be something that would be akin to a free will. Yeah, well, you could say the, the sort of obvious possibility, which was, you know, recognized by adding to it and many others about as soon as quantum mechanics was discovered in the 1920s, was that if, um, you know, let's say a sodium ion channel, you know, in the, in the, in the brain, right, you know, it's, it's behavior is chaotic, right? It's sort of, it's governed by these, uh, uh, uh, hojuli, huxkin equations in neuroscience, right? Which are differential equations that have a stochastic component, right? Now, where does, you know, and this ultimately governs, let's say, whether in neuron will fire or not fire. That's the basic chemical process or electrical process by which signals are sent in the brain. Exactly. Exactly. And, and, uh, you know, and so you could ask, well, well, where does the randomness in the process, you know, that, uh, that, that neuroscientist, you're, but what neuroscientist would, would, would treat his randomness, where does it come from? You know, ultimately it's thermal noise, right? Where does thermal noise come from? But ultimately, you know, there were some quantum mechanical events at the molecular level that are getting sort of, uh, chaoticly amplified by, you know, a sort of butterfly effect. Uh, and so, uh, you know, even if you, uh, knew the complete quantum state of someone's brain, you know, at best, you could predict the probabilities that they would do one thing or do another thing, right? I think that part is actually relatively uncontroversial, right? The, the, uh, the controversial question is whether any of it matters for the sort of philosophical questions that we care about because you could say, if all it's doing is just injecting some randomness into an otherwise completely mechanistic process, well, then who cares, right? And more concretely, if you could build a machine that, you know, could just calculate the, even just the, the, the probabilities of all of the possible things that you would do, right? And, you know, um, um, you know, if all the things that said you had a 10% chance of doing, you did exactly a tenth of them, you know, and, and, and, and, and, and, and so on. Yeah, that somehow also takes away the feeling of free will. Exactly. I mean, I mean, I mean, to me, it seems essentially just as bad as if, uh, the machine deterministically predicted you. It seems, you know, hardly different from that. So, so, so then, um, uh, but a more, a more subtle question is, could you even learn enough about someone's brain to do that? Okay? Because, you know, another central fact about quantum mechanics is that, uh, uh, making a measurement on a quantum state is an inherently destructive operation. Okay? So, uh, you know, if I want to measure the, you know, position of a particle, right? It was, well, before I measured it, it had a superposition over many different positions. As soon as I measure, I localize it, right? So now I know the position, but I've also fundamentally changed the state. And so, so you, you could say, well, maybe in, in trying to build a model of someone's brain that was accurate enough to actually, you know, make, let's say even well calibrated probabilistic predictions of their future behavior. Maybe you would have to make measurements that were just so accurate that you would just fundamentally alter their brain. Okay? Or, or, or, or maybe not. Maybe you only, you know, you, it would suffice to just make some nano robots that just measured some sort of much larger scale, you know, macroscopic, uh, behavior, like, you know, is, you know, what is this neuron doing? What is that neuron doing? Maybe that would be enough. See, but now, you know, I, I, what I, what I claim is that we're now asking a question, you know, in which, you know, it is, it is, it is possible to envision what progress on it would look like. Yeah, but just as you said, that question may be slightly detached from the philosophical question in the sense, if consciousness somehow has a role to the experience of free will, because ultimately what, when we're talking about free will, we're also talking about not just the predictability of our actions, but somehow the experience of that predictability. Yeah. Well, I mean, a lot of philosophical questions ultimately, like, feedback to the hard problem of consciousness, you know, and as much as you can try to sort of talk around it or not write it. And, and, you know, and then, and there is a reason why people try to talk around it, which is that, you know, uh, democratists talked about the hard problem of consciousness, you know, in 400 BC in terms that would be totally recognizable to us today, right? And it's really not clear if there's been progress since or what progress could possibly consist of. Is there a Q prime type of sub question that could help us get it consciousness? It's something about consciousness. Well, I mean, well, I mean, there is the whole question of, you know, of AI, right? Of, you know, can you build a, a human level or super human level AI and, you know, can it, can it work in a completely different substrate from the brain? I mean, there's, you know, and of course, that was Alan Turing's point. And, you know, and even if that was done, it's, you know, maybe people would still argue about the hard problem of consciousness. Right? And yet, you know, my, my claim is a little different. My claim is that in a world where, you know, there were, you know, a human level AI is a, we'd been even overtaken by such AI's, the entire discussion of the hard problem of consciousness would have a different character, right? It would take place in different terms in such a world, even if we hadn't answered the question. And, and my claim about free will would be similar, right? If there, if this prediction machine that I was talking about could actually be built, well, now the entire discussion of the, you know, a free will is sort of transformed by that. You know, even if in some sense the, the metaphysical question hasn't been answered. Yeah. Exactly. Transformers are fundamentally because say that machine does tell you that it can predict perfectly. And yet there is this deep experience of free will. And then that changes the question completely. Yeah. And it starts actually getting to the question of the, the, the, the AGI, the touring questions of the demonstration of free will, the demonstration of intelligence, the demonstration of consciousness. Does that equal consciousness, intelligence, and free will? But see, Alex, if every time I was contemplating a decision, you know, this machine had printed out an envelope, you know, where I could open it and see that it knew my decision, I think that actually would change my subjective experience of making decisions. You know, I mean, this knowledge, change your subjective experience. Well, you know, I mean, I mean, the knowledge that this machine had predicted everything I would do, I mean, it might drive me completely insane, right? But at any rate, it would change my experience to act, you know, to not just discuss such a machine as a thought experiment, but to actually see it. Yeah. I mean, I mean, you know, you could say at that point, you know, you could say, you know, why not simply call this machine a second instantiation of me and be done with it, right? What we know, what, why even privilege the original me over this perfect duplicate that exists in the machine? Yeah. Or there could be a religious experience with it too. It's kind of what God throughout the generations is supposed to have that God kind of represents that perfect machine is able to, I guess actually, I don't even know what are what are the religious interpretations of free will? Yeah. So if God knows perfectly everything in religion in the various religions, where does free will fit into that? Do you know that has been one of the big things that theologians have argued about for thousands of years. Yeah. You know, I am, I am not a theologian, so maybe I shouldn't go there. So there's not a clear answer in a book like, I mean, I mean, this is, you know, the Calvinists debated this, the, you know, this has been, you know, I mean, different religious movements have taken different positions on that question, but that is how they think about it. You know, meanwhile, you know, a large part of sort of what what animates, you know, theoretical computer science, you could say, you know, we are asking sort of what are the ultimate limits of, you know, what you can know or, you know, calculate or figure out by, you know, entities that you can actually build in the physical world, right? And if I were trying to explain it to a theologian, maybe I would say, you know, we are studying, you know, to what extent, you know, God's can be made manifest in the physical world. I'm not sure my colleagues would like that. So let's talk about quantum computers for sure. Yeah, sure. Sure. As you said, quantum computing, at least in the 1990s, was a profound story at the intersection of computer science, physics, engineering, math and philosophy. So there's this broad and deep aspect to quantum computing that represents more than just the quantum computer. Yes. But can we start at the very basics? What is quantum computing? Yeah. So it's a proposal for a new type of computation, or let's say a new way to harness nature to do computation that is based on the principles of quantum mechanics. Okay. Now the principles of quantum mechanics have been in place since 1926. You know, they haven't changed. You know, what's new is, you know, how we want to use them. Okay. So what does quantum mechanics say about the world? You know, the the physicists, I think, over the generations, you know, convinced people that that is an unbelievably complicated question. And you know, just give up on trying to understand it. I can let you in not not being a physicist. I can let you in on a secret, which is that it becomes a lot simpler. If you do what we do in quantum information theory and sort of take the physics out of it. So the way that we think about quantum mechanics is sort of as a generalization of the rules of probability themselves. So, you know, you might say there's a, you know, there was a 30% chance that it was going to snow today or something. You would never say that there was a negative 30% chance, right? That would be nonsense. Much less would you say that there was a, you know, an i% chance, you know, a square root of minus 1% chance. Now the central discovery that sort of quantum mechanics made is that fundamentally, the world is described by, you know, these are let's say the possibilities for, for, you know, what a system could be doing are described using numbers called amplitudes, okay, which are like probabilities in some ways, but they are not probabilities. They can be positive for one thing. They can be positive or negative. In fact, they can even be complex numbers. Okay, if you've heard of a quantum superposition, this just means the some state of affairs where you assign an amplitude, one of these complex numbers to every possible configuration that you could see a system in on measuring it. So for example, you might say that an electron has some amplitude for being here and some other amplitude for being there, right? Now, if you look to see where it is, you will localize it, right? You will sort of force the amplitudes to be converted into probabilities that happens by taking their squared absolute value, okay? And then, and then, you know, you can say either the electron will be here or it will be there, you know, knowing the amplitudes, you can predict the, at least the probabilities that it will, that you'll see each possible outcome, but while a system is isolated from the whole rest of the universe, the rest of its environment, the amplitudes can change in time by rules that are different from the the normal rules of probability and that are, you know, alien to our everyday experience. So anytime anyone ever tells you anything about the weirdness of the quantum world, you know, or assuming that they're not lying to you, right? They are telling you, you know, and yet another consequence of nature being described by these amplitudes. So most famously, what amplitudes can do is that they can interfere with each other, okay? So, in the famous double slit experiment, what happens is that you shoot a particle like an electron, let's say, at a screen with two slits in it, and you find that there are, you know, on a second screen, now there are certain places where that electron will never end up, you know, after it passes through the first screen. And yet, if I close off one of the slits, then the electron can appear in that place, okay? So by, so by decreasing the number of paths that the electron could take to get somewhere, you can increase the chance that it gets there, okay? Now, how is that possible? Well, it's because, you know, as we would say, now the electron has a superposition state, okay? It has some amplitude for reaching this point by going through the first slit. It has some other amplitude for reaching it by going through the second slit. But now, if one amplitude is positive, and the other one is negative, then no, you know, I have to add them all up, right? I have to add the amplitudes for every path that the electron could have taken to reach this point. And those amplitudes, if they're pointing in different directions, they can cancel each other out. That would mean the total amplitude is zero, and the thing never happens at all. I close off one of the possibilities, then the amplitude is positive, or it's negative, and now the thing can happen. Okay, so that is sort of the one trick of quantum mechanics. And now I can tell you what a quantum computer is. Okay, a quantum computer is a computer that tries to exploit, you know, these exactly these phenomena, superposition, amplitudes, and interference in order to solve certain problems much faster than we know how to solve them otherwise. So, there's the basic building block of a quantum computer is what we call a quantum bit or a qubit. That just means a bit that has some amplitude for being zero, and some other amplitude for being one. So, it's a superposition of zero in one states, right? But now the key point is that if I've got, let's say, a thousand qubits, the rules of quantum mechanics are completely unequivocal that I do not just need one amp, but you know, I don't just need amplitudes for each qubit separately. Okay, in general, I need an amplitude for every possible setting of all thousand of those bits. Okay, so that what that means is two to the 1000 power amplitudes. Okay, if I had to write those down, let's say in the memory of a conventional computer, if I had to write down two to the 1000 complex numbers, that would not fit within the entire observable universe. Okay, and yet, you know, quantum mechanics is unequivocal that if these qubits can all interact with each other, in some sense, I need two to the 1000 parameters, you know, amplitudes to describe what is going on. Now, you know, now I can tell you know, where all the popular articles, you know, about quantum computing go off the rails is that they say, you know, they sort of say what I just said, and then they say, oh, so the way a quantum computer works is just by trying every possible answer in parallel. Right. You know, that sounds too good to be true, and unfortunately, it kind of is too good to be true. The problem is I could make a superposition over every possible answer to my problem, you know, even if there are two to the 1000 of them, right, I can I can easily do that. The trouble is for a computer to be useful. You've got at some point you've got to look at it and see and see an output. Right. And if I just measure a superposition over every possible answer, then the rules of quantum mechanics tell me that all I'll see will be a random answer. You know, if I just wanted a random answer, well, I could have picked one myself with a lot less trouble. Right. So the entire trick with quantum computing, with every algorithm for a quantum computer, is that you try to choreograph a pattern of interference of amplitudes. And you try to do it so that for each wrong answer, some of the paths leading to that wrong answer have positive amplitudes, and others have negative amplitudes. So on the whole, they cancel each other out. Okay. Whereas all the paths leading to the right answer should reinforce each other, you know, should have amplitudes pointing the same direction. So the design of algorithms in the space is the choreography of the interferences precisely. That's precisely what it is. Can we take a brief step back and you mentioned information? Yes. So in which part of this beautiful picture that you've painted is information contained? Oh, well, information is at the core of everything that we've been talking about. Right. I mean, the bit is, you know, the basic unit of information since, you know, collage hadn't paper in 1948. You know, you know, of course, you know, people had the concept even before that, you know, he popularized the name, right? But I mean, but a bit is zero or one. That's right. That's right. That's right. And what we would say is that the basic unit of quantum information is the qubit is, you know, the object, any object that can be maintained and manipulated in a superposition of zero in one states. Now, you know, sometimes people ask, well, but what is a qubit physically? Right. And there are all these different, you know, proposals that are being pursued in parallel for how you implement qubits. There is, you know, superconducting quantum computing that was in the news recently because of Google's quantum supremacy experiment, right? Where you would have some little coils where a current can flow through them in two different energy states, one representing a zero and another representing the one. And if you cool these coils to just slightly above absolute zero, like 100th of a degree, then they superconduct. And then the current can actually be in a superposition of the two different states. So that's one kind of qubit. Another kind would be, you know, just an individual atomic nucleus, right? It has a spin. It could be spinning clockwise. It could be spinning counter clockwise, or it could be in a superposition of the two spin states. That is another qubit. But so just like in the classical world, right, you could be a virtuoso programmer without having any idea of what a transistor is, right? Or how the bits are physically represented inside the machine, even that the machine uses electricity, right? You just care about the logic. It's sort of the same with quantum computing, right? Cubits could be realized by many, many different quantum systems, yet all of their systems will lead to the same logic, you know, the logic of qubits and how, you know, how you measure them, how you change them over time. And so, you know, the subject of, you know, how qubits behave and what you can do with qubits, that is quantum information. So just to linger on that. So the physical design implementation of a qubit does not does not interfere with the next level of abstraction that you can program over it. So the truth is, the idea of it is the A, is it okay? Well, to be honest with you, today they do interfere with each other. That's because all the quantum computers we can build today are very noisy, right? And so sort of the qubits are very far from perfect. And so the lower level sort of does affect the higher levels and we sort of have to think about all of them at once. Okay, but eventually, where we hope to get is to what are called error corrected quantum computers, where the qubits really do behave like perfect abstract qubits for as long as we want them to. And in that future, you know, the, you know, which, you know, a future that we can already sort of prove theorems about or think about today, but in that future, the logic of it really does become decoupled from the hardware. So if noise is currently like the biggest problem for quantum computing and then the dream is error correcting quantum computers, can you just maybe describe what does it mean for there to be noise in the system? Absolutely. So yes, so the problem is even a little more specific than noise. So the fundamental problem if you're trying to actually build a quantum computer, you know, of any appreciable size is something called decoherence. Okay, and this was recognized from the very beginning, you know, when people first started thinking about this in the 1990s. Now, what decoherence means is sort of unwanted interaction between, you know, your qubits, you know, the state of your quantum computer and the external environment. Okay, and why is that such a problem? Why I said talk before about how, you know, when you measure a quantum system. So let's say if I measure a qubit that's in a superposition of zero and one states to ask it, you know, are you zero or are you one? Well, now I force it to make up its mind, right? And now probabilistically it chooses one or the other. And now, you know, it's no longer a superposition. There's no longer amplitudes. There's just there's some probability that I get a zero and there's some that I get a one. And now the trouble is that it doesn't have to be me who's looking. Okay, in fact, it doesn't have to be any conscious entity. Any kind of interaction with the external world that leaks out the information about whether this qubit was a zero or a one sort of that causes the zeroness or the oneness of the qubit to be recorded in, you know, the radiation in the room, in the molecules of the air, in the wires that are connected to my device, any of that. As soon as the information leaks out, it is as if that qubit has been measured. Okay, it is, you know, the state has now collapsed. You know, another way to say it is that it's become entangled with its environment. Okay, but, you know, from the perspective of someone who's just looking at this qubit, it is as though it has lost its quantum state. And so what this means is that if I want to do a quantum computation, I have to keep the qubits sort of fanatically well isolated from their environment, but then at the same time, they can't be perfectly isolated because I need to tell them what to do. I need to make them interact with each other for one thing and not only that, but in a precisely choreographed way. Okay, and, you know, that is such a staggering problem, right? How do I isolate these qubits from the whole universe, but then also tell them exactly what to do? I mean, you know, there were distinguished physicists and computer scientists in the 90s who said, this is fundamentally impossible, you know, the laws of physics will just never let you control qubits to the degree of accuracy that you're talking about. Now, what changed the views of most of us was a profound discovery in the mid to late 90s, which was called the theory of quantum error correction and quantum fault tolerance. Okay, and the upshot of that theory is that if I want to build a reliable quantum computer and scale it up to, you know, an arbitrary number of as many qubits as I want, you know, and doing as much on them as I want, I do not actually have to get the qubits perfectly isolated from their environment. It is enough to get them really, really, really, really well isolated. Okay, and even if every qubit is sort of leaking, you know, its state into the environment at some rate, as long as that rate is low enough, okay, I can sort of encode the information that I care about in very clever ways across the collective states of multiple qubits. Okay, in such a way that even if, you know, a small percentage of my qubits leak, well, I'm constantly monitoring them to see if that leak happened. I can detect it and I can correct it. I can recover the information I care about from the remaining qubits. Okay, and so, you know, you can build a reliable quantum computer even out of unreliable parts. Right, now the, the in some sense, you know, that discovery is what set the engineering agenda for quantum computing research from the 1990s until the present. Okay, the goal has been, you know, engineer qubits that are not perfectly reliable, but reliable enough that you can then use these error correcting codes to have them simulate qubits that are even more reliable than they are. Right. That's it. The error correction becomes a net win rather than a net loss, right? And then once you reach that sort of crossover point, then, you know, your simulated qubits could in turn simulate qubits that are even more reliable and so on until you've just, you know, effectively, you have arbitrarily reliable qubits. So long story short, we are not at that break even point yet. We're a hell of a lot closer than we were when people started doing this in the 90s, like orders of magnitude closer. But the key ingredient there is the more qubits the better because, well, the more qubits the larger the computation you can do, right? I mean, I mean, a qubits are what constitute the memory of your quantum computer, right? But also for the, sorry, for the error correcting mechanism. Yes. So, so the way I would say it is that error correction imposes an overhead in the number of qubits. And that is actually one of the biggest practical problems with building a scalable quantum computer. If you look at the error correcting codes, at least the ones that we know about today, and you look at, you know, what would it take to actually use a quantum computer to, you know, I'm hack your credit card number, which is, you know, you know, the most famous application people talk about, right? Let's say to factor huge numbers in there by break the RSA crypto system. Well, what that would take would be thousands of several thousand logical qubits. But now with the known error correcting codes, each of those logical qubits would need to be encoded itself using thousands of physical qubits. So at that point, you're talking about millions of physical qubits. And in some sense, that is the reason why quantum computers are not breaking cryptography already. It's because of this, these immense overheads involved. So that overhead is additive or multiple, well, multiplicative. I mean, it's like you take the number of logical qubits that you need in your abstract quantum circuit, you multiply it by a thousand or so. So, you know, there's a lot of work on, you know, inventing better, trying to invent better error correcting codes. Okay, that is the situation right now. In the meantime, we are now in what the physicist John Preskel called the noisy intermediate scale quantum or NISC error. This is the error. You can think of it as sort of like the vacuum, you know, we're now entering the very early vacuum tube era of quantum computers. The quantum computer analog of the transistor has not been invented yet. Right? That would be like true error correction, right? Where, you know, we are not or something else that would achieve the same effect, right? We are not there yet. And, but, but, but where we are now, let's say as of a few months ago, you know, as of Google's announcement of quantum supremacy, you know, we are now finally at the point, we're even with a non-error corrected quantum computer with, you know, these noisy devices, we can do something that is hard for classical computers to simulate. Okay? So we can eek out some advantage. Now, will we in this noisy era be able to do something beyond what a classical computer can do that is also useful to someone that we still don't know people are going to be racing over the next decade to try to do that by people. I mean Google, IBM, you know, a bunch of startup companies and, you know, uh, and research labs and governments and, uh, yeah, you just mentioned a million things. Well, I'll backtrack for a second. Yeah, sure. Sure. Uh, so we're in these vacuum tube days. Yeah. Just entering and just entering. Wow. Okay. So yeah, how do we escape the vacuum? So how do we get to, how do we get to where we are now with the CPU? Is this a fundamental engineering challenge? Is there, is there breakthroughs in on the physics side that they're needed on the computer science side? What is there in, is it a financial issue where much larger just share investment and excitement is needed? Uh, so there's, you know, there's, there's our excellent questions. My guess is my, well, no, no, my, my, my, my, my guess would be all of the above. Yeah. I mean, my, my guess, you know, I mean, I mean, you know, because they fundamentally it is an engineering issue, right? The theory has been in place since the 90s, you know, at least, you know, uh, uh, you know, this is what, you know, error correction would, you know, it would look like, you know, we, we do not have the hardware that is at that level. But at the same time, you know, so you could just, um, you know, try to power through, you know, maybe even like, you know, if someone spent a trillion dollars on some quantum computing Manhattan project, right? Then conceivably they could just, you know, build a, a, an error corrected quantum computer as it was envisioned back in the 90s, right? I think the more plausible thing to happen is that there will be further theoretical breakthroughs and there will be further insights that will cut down the cost of doing this. So let's take a brief step to the philosophical. I just recently talked to Jim Keller, who's, uh, sort of, uh, like the famed architect on the in the micro processor world. Okay. And he's been told for decades every year that the Moore's law is going, going to die this year. And he tries, tries to argue that the, uh, the, the Moore's law is still alive and well and it'll be alive for quite a long time to come. So the long, how long did that, well, he's, the main point is it's still alive. Okay. He thinks, uh, there's still a thousand X improvement just on shrinking the transistors. That's possible. Whatever. The point is that the exponential growth we see it is actually a huge number of these S curves, just constant breakthroughs at the philosophical level. Why do you think we as a descendant of Apes were able to just keep coming up with these new breakthroughs on the CPU side? Is this something unique to this particular endeavor or will it be possible to replicate in the quantum computer space? Okay. All right. There was a lot there to, but just to, to, to a break off something. I mean, I think we are in an extremely special period of human history. Right. I mean, it's, it is, uh, you could say obviously special, you know, in, in, in many ways, right? There, you know, uh, you know, way more people live than there than there have been. And, and, you know, the, um, um, you know, the whole, you know, a future of the planet is in, is in, is in question in a way that it, it, it hasn't been, you know, for, for the rest of human history. But, but, uh, you know, in particular, you know, we are in, in the era where, you know, we, we finally figured out how to build, you know, universal uh, uh, machines, you could say, you know, the things that we call computers, you know, machines that you program to, uh, simulate the behavior of, of whatever machine you want. And, um, you know, and, and, and, and, and, and, and, and, and, and once you've sort of crossed this threshold of universality, you know, you've built, you could say, you know, touring, you've instantiated touring machines in the physical world. Well, then the main questions are, are ones of numbers. They are, you know, ones of how many, uh, how much memory, uh, can you access, how fast does it run, how many parallel processors, you know, at least until quantum computing, quantum computing is the one thing that changes what I just said. Right. But, you know, in, you know, as long as, as long as it's classical computing, then it's all questions of numbers. And, uh, uh, you know, the, the, you could say, at a theoretical level, the computers that we have today are, are the same as the ones in the 50s. They're just millions of times, you know, faster with millions of times more memory. And, you know, I mean, I think there's been an immense economic pressure to, you know, get more and more transistors, you know, get them smaller and smaller, get, you know, add more and more cores. And, um, you know, and, and, and, and, and, and, in, in, in, in some sense, like a huge fraction of sort of all of the technological progress that there is in all of civilization has gotten concentrated, just more narrowly into just those problems. Right. And so, you know, it has been one of the biggest success stories in the history of technology, right. There's, you know, I mean, it is, I, I am as amazed by it as, as anyone else is. Right. But at the same time, you know, we also know that it, you know, and I, I, I, I, I, uh, I really do mean we know that it cannot continue indefinitely. Okay. Because you will reach, you know, fundamental limits on, um, you know, how small you can possibly make a processor. And, you know, if you want a real proof, you know, that would justify my use of the word, you know, we know that, you know, more is the last to end. I mean, ultimately you will reach the limits imposed by quantum gravity. You know, you know, if, if you were doing, uh, if you tried to build a computer that operated at 10 to the 43 hertz, so did 10 to the 43 operations per second, that computer would use so much energy that it would simply collapse to a black hole. Okay. So, you know, that, you know, you know, you know, in reality, we're going to reach the limits long before that. But, you know, that is a sufficient proof that there's a limit. Yes. Yes. But it would be interesting to try to understand the mechanism, the economic pressure that you said, just like the cold war was a pressure on getting us, uh, getting us get, because I'm both, my us is both the Soviet Union and the United States. Yeah. Getting us the two countries to get, to hurry up to get the space to the moon, there seems to be that same kind of economic pressure that somehow created a chain of engineering breakthroughs that resulted in the Moore's law. Yeah. What? It'd be nice to replicate. Yeah. Well, I mean, I mean, some people are sort of, uh, uh, uh, uh, uh, get depressed about the fact that technological progress, you know, may seem to have slowed down in many, many realms outside of computing. Right. And there was this whole thing of, you know, we wanted flying cars and we only got Twitter instead. Right. And uh, yeah. Yeah. Girl Peter Tiel. Yeah. Yeah. Yeah. Yeah. Right. Right. So then jumping to another really interesting topic that you mentioned. So Google announced with their work in, uh, the, the paper in nature with quantum supremacy. Yes. Can you describe again, back to the basic? What is, perhaps not so basic? What is quantum supremacy? Absolutely. So, uh, quantum supremacy is a term that was coined by again by John Preskel in, uh, 2012. Uh, not, not everyone likes the name, you know, but, uh, you know, we, it, it, it's sort of stuck. Uh, uh, you know, we don't, uh, we sort of haven't found a better alternative. Technically quantum computational. Yeah. Yeah. supremacy. That's right. That's right. And, but, but the basic idea is actually one that goes all the way back to the beginnings of quantum computing when Richard Feynman and David Doige, people like that were talking about it in the,
