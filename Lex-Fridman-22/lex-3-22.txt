The following is a conversation of Vladimir Vapnik, part two. The second time we spoke on the podcast. He's the co-inventor of support vector machines, support vector clustering, VC theory, and many foundational ideas in statistical learning. He was born in the Soviet Union, worked at the Institute of Control Sciences in Moscow, then in the US, worked at AT&T, and he sea labs, Facebook AI research, and now is a professor at Columbia University. His work has been cited over 200,000 times. The first time we spoke on the podcast was just over a year ago, one of the early episodes. This time, we spoke after a lecture he gave titled Complete Statistical Theory of Learning, as part of the MIT series of lectures on deep learning and AI that I organized. I'll release the video of the lecture in the next few days. This podcast and lecture are independent from each other, so you don't need one to understand the other. The lecture is quite technical and math-heavy, so if you do watch both, I recommend listening to this podcast first, since the podcast is probably a bit more accessible. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it $5.00 on Apple Podcast, support it on Patreon, or simply connect with me on Twitter, at Lex Friedman spelled F-R-I-D-M-A-N. As usual, I'll do one or two minutes of ads now, and never any ads in the middle that can break the flow of the conversation. I hope that works for you, and doesn't hurt the listening experience. This show is presented by CashApp, the number one finance app in the App Store. When you get it, use code Lex Podcast. CashApp lets you sell money to friends, buy Bitcoin, and invest in the stock market with as little as $1. Broker services are provided by CashApp investing, a subsidiary of Square and member SIPC. Since CashApp allows you to send and receive money digitally, peer to peer, and security and all digital transactions is very important, let me mention the PCI data security standard, PCI DSS level one. A CashApp is compliant with. I'm a big fan of standards for safety and security, and PCI DSS is a good example of that, where a bunch of competitors got together and agreed that there needs to be a global standard around the security of transactions. Now, we just need to do the same for autonomous vehicles and AI systems in general. So again, if you get CashApp from the App Store, Google Play, and use the code Lex Podcast, you get $10, and CashApp will also donate $10 to first. One of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. And now, here's my conversation with Vladimir Vapnik. You and I talked about Alan Turing yesterday, a little bit. And that he, as the father of artificial intelligence, may have instilled in our field an ethic of engineering and not science, seeking more to build intelligence rather than to understand it. What do you think is the difference between these two paths of engineering intelligence and the science of intelligence? It's completely different story. Engineering is a mutation of human activity. You have to make a device which behaves as human behave, have all the functions of human. It does not matter how you do it, but to understand what is intelligence about, it's quite different problem. So I think I believe that it's somehow related to predicate, we talk yesterday about, because look at the Vladimir Props idea. He just found 31, he predicate, he call it units, which can explain human behavior, at least in Russian tales. Look at Russian tales and write from that. And then people realize that it more vids in Russian tales. It doesn't exist in movie cereals and so on and so on. So you're talking about Vladimir Prop, who in 1928 published a book, Morphology of the Folk Tale, describing 31 predickets that have this kind of sequential structure that a lot of the stories, narratives follow in Russian folklore and other content. We'll talk about it. I'd like to talk about predickets in a focused way, but let me if you allow me to stay zoomed out on our friend Alan Turing. And he inspired the generation with the imitation game. Yes. Do you think, if you can linger a little bit longer, do you think we can learn, do you think learning to imitate intelligence can get us closer to the science, to understanding intelligence? So why do you think imitation is so far from understanding? I think that it is different between you have different goals. So your goal is to create something, something useful. And that is great. And you can see how much things was done and I believe that it will be done even more. Yet self-driving cars and also the business. It is great. And it was inspired by Turing vision. But understanding is very difficult. It's more or less philosophical category. What means understands the world? I believe in him, which starts from Plato, that there exists a world of ideas. I believe that intelligence is a world of ideas. But it is a world of pure ideas. And when you combine these realities, it creates, as in my case, in variants, which is very specific. And that I believe the combination of ideas in way to constructing and variant is intelligence. But first of all, predicate. If you know predicate and hopefully then not too much predicate exists. For example, 31 predicate for human behavior. It is not a lot. Vladimir Prop. used 31. You can even call him predicate 31. Predicate to describe stories, narratives. Do you think human behavior how much of human behavior, how much of our world, our universe, all the things that matter in our existence can be summarized in predicates of the kind that Prop was working with? I think that we have a lot of form of behavior. But I think that predicate is much less. Because even in this example, which I gave you yesterday, you saw that predicate can be one predicate, can construct many different variants, depending on your data. They are applying to different data, and they give different variants. But pure ideas, maybe not so much. Not so many. I don't know about that. But my guess, I hope, that's why a challenge about digital recognition, how much you need. I think we'll talk about computer vision and 2D images a little bit in your challenge. That's exactly about intelligence. That's exactly about, no, that hopes to be exactly about the spirit of intelligence in the simplest possible way. Absolutely. You should start this simplest way, as the voice you will not be able to do it. Well, there's an open question whether starting at the M-NIST digit recognition is a step towards intelligence or it's an entirely different thing. I think that to beat records using 100, 200 times less examples, you need intelligence. You need intelligence. So let's, because you use this term, and it'll be nice, I'd like to ask simple, maybe even dumb questions. Let's start with a predicate. In terms of terms and how you think about it, what is a predicate? I don't know. I have a feeling formally that there exists. But I believe that predicate for 2D images, one of them is symmetry. Hold on a second, sorry, sorry to interrupt and pull you back. At the simplest level, we're not even, we're not being profound currently. A predicate is a statement of something that is true. Yes. Do you think of predicate as somehow probabilistic in nature, or is this binary, this is truly constraints of logical statements about the world? In my definition, the simplest predicate is function. Function, and you can use this function to make inner product, that is predicate. What's the input and what's the output of the function? Input is X, something which is input in reality. Say, if you consider a digit recognition, it picks up space. Yes, input. But it is function, which in picks up space. But it can be any function, from a pixel space. And you choose, and I believe that there are several functions, which is important to understand of images. One of them is symmetry. It's not so simple construction, as I describe with the leader of it, with all this stuff. But another, I believe, I don't know how many. Is how well-structured is picture? Structurized? Yes. What do you mean by structurized? It is formal definition. Say, something heavy on the left corner, not so heavy in the middle and so on. You describe in general concept of what you see. Concepts, some kind of universal concepts. Yes. But I don't know how to formalize this. Do you? So this is the thing. There's a million ways we can talk about this. I'll keep bringing it up. But we humans have such concepts. When we look at digits, but it's hard to put them just like you're saying now. It's hard to put them into words. You know, that is example. When critics in music, trying to describe music, they use predicate. And not too many predicate, but in different combination. But they have some special words for describing music. And the same should be for images. But maybe there are critics who understand essence of what this image is about. Do you think there exists critics who can summarize the essence of images, human beings? The I hope so, yes. But that explicitly state them on paper. The fundamental question I'm asking is do you do you think there exists a small set of predicates that will summarize images? It feels to our mind like it does. That the concept of what makes it two, in a three, in a four. No, no, no, it's not on this level. What it should not describe, two, three, four, it describes some construction which allow you to create invariance. And invariance, sorry, to stick on this, but terminology. Invariance, it is, it is property of your image. Say, I can say looking on my image, it is more or less symmetric. And I can give you a value of symmetry. Say, level of symmetry, using this function which I gave yesterday. And you can describe that your image have these characteristics. Exactly in the way how musical critics describe music. So, but this is invariant applied to specific data, to specific music, to something. I strongly believe in in this plateau ideas that there exists the world of predicate and the world of reality and predicate and reality is somehow connected. Let's talk about Plato a little bit. So, you draw a line from Plato to Hegel to Wagner to today. So, Plato has forms, the theory of forms. There's a world of ideas, a world of things, as you talk about. And there's a connection. And presumably the world of ideas is very small. And the world of things is arbitrarily big. But they're all what Plato calls them like, it's a shadow, the real world is a shadow from the world of forms. Yeah, you have projection. Projection. Of a world of ideas. Yeah, very important. In reality, you can realize this projection using these invariants because it is projection for on specific examples, which create specific features of specific objects. So, the essence of intelligence is while only being able to observe the world of things, try to come up with the world of ideas. Exactly. Like, and there's music story. Intelligent musical critics knows this all this world and have a feeling about what. I feel like that's a contradiction, intelligent music critics. But I think music is to be enjoyed in all its forms. The notion of critic like a food critic. No, I don't want touch emotion. That's an interesting question. There's a motion. There's certain elements of the human psychology of the human experience. Which seem to almost contradict intelligence and reason. Like emotion, like fear, like love, all of those things are those not connected in any way to the space of ideas. That's I don't know. I just want to be concentrated on very simple story, on digital recognition. So, you don't think you have to love and fear death in order to recognize digits? I don't know. Because it's so complicated. It is, it involved a lot of stuff which I never considered. But I know about digital recognition. And I know that for digital recognition, to get records from small number of observations, you need predicate. But not special predicate for this problem. But universal predicate, each understand world of images. Of visual, individual. But on the first step, they understand the world of handwritten digits or characters. So, something simple. So, like you said symmetry, is it interesting? That's what I think one of the predicated related to symmetry. But the level of symmetry. Okay, degree of symmetry. So, you think symmetry at the bottom is a universal notion. And there's degrees of a single kind of symmetry, or is there many kinds of symmetries? Many kinds of symmetries. There is a symmetry, anti-symmetry, say letter S. So, it has vertical anti-symmetry. And it could be diagonal symmetry, vertical symmetry. So, when you cut vertically the letter S, yeah, then the upper part and lower part in different directions. It's inverted along the y-axis. But that's just like one example of symmetry, right? Isn't it like... Right, but there is a degree of symmetry. If you play all this literative stuff to do tangent distance, whatever I describe, you can have a degree of symmetry. And that is what describing a reason of image. It is the same as you will describe this image. Saying about digital, it has anti-symmetry, digital symmetry, symmetric, more or less look for symmetry. Do you think such concepts like symmetry, predicates, like symmetry, is it a hierarchical set of concepts? Or are these independent distinct predicates that we want to discover as some set of... There is a D of symmetry. And you can, this idea of symmetry make very general, like the degree of symmetry. If the degree of symmetry can be zero no symmetry at all, the degree of symmetry say more or less symmetrical. But you have one of these descriptions. And symmetry can be different as I told, horizontal, vertical, diagonal, and anti-symmetry is also a concept of symmetry. What about shape in general? I mean symmetry is a fascinating notion, but... No, no, I'm talking about digit. I would like to concentrate on all I would like to know, predicate for digital recognition. Yes, but symmetry is not enough for digit recognition, right? It is not necessarily for digital recognition. It helps to create in variant which you can use when you will have examples for digital recognition. You have regular problem of digital recognition. You have examples of the first class, second class. Plus you know that there exists a concept of symmetry. And you apply when you're looking for decision rule, you will apply a concept of symmetry of this level of symmetry, which you estimate from... So let's talk. Everything comes from big convergence. What is convergence? What is weak convergence? What is strong convergence? I'm sorry, I'm going to do this to you. What are we converging from and to? You would like to have a function. The function which, say indicator function, which indicate your digit five, for example, a classification task. Let's talk only about classification. Classification means you will say whether this is a five or not or say which of the ten digits it is. Right, right. I would like to have these functions. Then I have some examples. I can consider property of these examples. Say symmetry. And I can measure a level of symmetry for every digit. And then I can take average and I, from my training data, and I will consider only functions of conditional probability, which I'm looking for my decision rule, which applying to to digits will give me the same average as I absorb on training data. So actually, there's this different level of description of what you want. You won't just, you show not one digit. You show this predicate, show general property of all digits which you have in mind. If you have in mind digits three, it gives you property of digits three and you select as admissible set of function only function which keeps this property. You will not consider other functions. So you immediately looking for smaller subset of function. That's what you mean by admissible functions. You have admissible function, exactly. Which is still a pretty large for the number three. It's a large. It's a pretty large but if you have one predicate. But according to, there is a strong and weak convergence. Strong convergence is convergence and function. You're looking for the function, on one function and you're looking for another function. And square difference from them should be small. If you take difference in any points, make a square, make an integral and it should be small. That is convergence and function. Suppose you have some function, any function. So I would say, I say that some function converges to this function. If integral from square difference between them is small. That's the definition of strong convergence. That definition of strong convergence. Two functions, the integral of the difference. Yes, small. It is convergence in functions. But you have different convergence in functionals. You take any function, you take some function phi and take inner product, this function, this F function. F zero function, which you want to find. And that gives you some value. So you say that set of functions converge in inner product to this function. If this value of inner product converges to value F zero, that is for one phi. But we convergence requires that it converges for any function of Hilbert's place. If it converges for any function of Hilbert's place, then you would say that there's a z-Vit convergence. You can think that when you take integral, that is property. Integral property of function. For example, if you will take sine or cosine, it is coefficient of say Fourier expansion. So if it converges for all coefficients of Fourier expansion, so under some condition it converges to function you're looking for. But Vick convergence means any property. Convergence is not point-wise, but integral property of function. So Vick convergence means integral property of functions. When I talking about predicate, I would like to formulate Vick integral properties. I would like to have for convergence. So, and if I will take one predicate, it's function, which I measure property. If I will use one predicate and say, I will consider only function, which give me the same value as with this predicate. I selecting set of functions, from functions which is admissible in the sense that function, which I looking for, in this set of functions. Because I check in training data, it gives the same. Yes, so it always has to be connected to the training data in terms of... Yeah, but property, you can know independent on training data. And this guy prop, so that there is formal property. 31 property, and you can... Fairytale, Russian fairy tale. But Russian fairy tale is not so interesting. More interesting than people apply this to movies, to theater, to different things. The same works, the universal. Well, so I would argue that there's a little bit of a difference between the kind of things that were applied to, which are essentially stories and digit recognition. It is the same story. You're saying digits, there's a story within the digit. Yeah. So, but my point is, why I hope that it's possible to beat a record using not 60,000, but say 100 times less, because instead you will give predicate. And you will select your decision not from wide set of functions, but from set of functions which keeps us predicate. But predicate is not related just to digit recognition. Right, so... Like in Platter's case. Do you think it's possible to automatically discover the predicates? So, you basically said that the essence of intelligence is the discovery of good predickets. Yeah. Now, the natural question is, you know, that's what Einstein was good at doing in physics. Can we make machines do these kinds of discovery of good predickets? Or is this ultimately a human endeavor? Thus, I don't know. I don't think that machine can do. Because, according to theory about weak convergence, any function from Hilbert space can be predicate. So, you have infinite number of predicate and upper, and before you don't know which predicate is good on which. But, whatever prop show and why people call it breaks through, that there is not too many predicate which cover most of situation happened in the world. So, there's a sea of predicates. And most of the only small amount are useful for the kinds of things that happen in the world. But, I think that I would say only a small part of predicate very useful. Useful all of them. Only very few are what we should, let's call them good predickets. Very good predicate. Very good predicate. So, can we linger on it? What's your intuition? Why is it hard for a machine to discover good predickets? Even in my talk described how to do predicate, how to find new predicate. I'm not sure that it is very good. What did you propose in Utah? No. In my talk, I gave example for diabetes, when we achieve some percent. So, then we're looking from area where some sort of predicate, which I formulate, does not keep invariant. So, if it doesn't keep, I retrain my data. I select only function, which keeps it invariant. And when I did it, I improve my performance. I can looking for this predicate. I know technically how to do that. And you can, of course, do it using machine. But I'm not sure that we will construct the smartest predicate. Well, this is the, allow me to linger on it, because that's the essence, that's the challenge, that is artificial. That's the human level intelligence that we seek, is the discovery of these good predickets. You've talked about deep learning as a way to the predickets they use and the functions are mediocre, we can find better ones. Let's talk about deep learning. Sure, let's do it. I know only Jans Le Koon, convolutional network. And what else? I don't know, and it's a very simple convolution. There's not much else to know. It's a left and right. I can do it like that. One, this one predicate. It is, convolution is a single predicate. It's single predicate. Yes, but it is. You know exactly, you take the derivative for translation and predicate. This should be kept. So that's a single predicate, but humans discovered that one, or at least. Not that is a risk, not too many predicate this. And that is big story, because Jans did it 25 years ago, and nothing so clear was added to deep network. And then I don't understand why we should talk about deep network instead of talking about piecewise linear functions, which keeps this predicate. Well, the, you know, a counter argument is that maybe the amount of predicates necessary to solve general intelligence, say in space of images, doing efficient recognition of handwritten digits is very small. And so we shouldn't be so obsessed about finding. We'll find other good predicates like convolution, for example. You know, there has been other advancements like if you look at the work with attention, there's attentional mechanisms in especially used in natural language, focusing the, the net works ability to, to learn at which part of the input to look at. The thing is, there's other things, besides predicates, that are important for the actual engineering mechanism of showing how much you can really do, given such these predicates. I mean, that's essentially the work of deep learning, is constructing architectures that are able to be given the training data to be able to converge towards a function that can approximate, can, can, can generalize well. It's an engineering problem. No, yeah, I understand. But let's talk not on emotional level, but on a mathematical level. You have set of piecewise linear functions. It is all possible neural networks. It's just piecewise linear functions. There's many, many pieces. Large, large number of piecewise linear functions. Okay, exactly. But very large. Very large. Almost, but it's still large. It's still simpler than second-value, then reproducing tier node, Hilbert space, which have a Hilbert set of function. What's Hilbert space? It's space with infinite number of coordinates, function for expansion, something. So it's much richer. So when I talking about closed-form solution, I talking about this set of function, not piecewise linear set, which is particular case. I have it is small part of it. So neural networks is a small part of the space your talk of functions. Small, small, say, small set of functions. Let me take it. But it is fine. It is fine. I don't want to discuss the small or big we take advantage. So you have some set of functions. So now, when you're trying to create architecture, you would like to create admissible set of functions, which all your tricks to use not all functions, but some subset of this set of functions. Say, when you're introducing convolutional net, it is way to make this subset useful for you. But from my point of view, convolutional, it is something you want to keep some invariants, say translation invariants. But now, if you understand this, and you cannot explain on the level of ideas what neural network does, you should agree that it is much better to have a set of functions. And they say, this set of functions should be admissible. It must keep these invariants, these invariants, and that invariant. You know that as soon as you incorporate new invariants, set of function because small and small and smaller. But all the invariants are specified by you, the human. Yeah, but what I hope that there is a standard predicate, like ProP Show, that what I want to find for digital recognition, if we start, it is completely new area of what is intelligence about on the level starting from plot as idea. What is the world of ideas? So, and I believe that it's not too many. But you know, it is amusing that mathematician doing something, neural network in general function, but people from literature, from art, they use this all the time. That's right. In variance, saying, say, it is great how people describe music, we should learn from that. And something on this level, but so why Vladimir ProP, who was just theoretical, who studied theoretical literature, he found that. You know what, let me throw that right back at you, because there's a little bit of less mathematical and more emotional philosophical Vladimir ProP. I mean, he wasn't doing math. No. And you just said another emotional statement, which is you believe that this played a world of ideas is small. I hope. I hope. Do you do what's your intuition, though? If we can linger on it. You know, because not just small or big, I know exactly. Then when I introduce, I think some predicate I decrease set of functions. But my goal to decrease set of function much. I buy as much as possible. Good predicate, which does this. Then I should choose next predicate, which does, which decrease set as much as possible. So set of good predicate, it is such that they decrease this amount of admissible function. So if each good predicate significantly reduces the set of admissible functions, that there naturally should not be that many predicate. No, but if you reduce very well the VC dimension of the function of admissible set of function is small. And you need not too much training data to do well. And VC dimension, by the way, is some major capacity of this set of function. Right. Roughly speaking, how many functions are set? So you're decreasing, decreasing, and it makes it easy for you to find function you're looking for. The most important part to create good admissible set of functions. And it probably there are many ways but the good predicate, it's such that that can do that. So for this duck, you should know a little bit about duck because what are the three fundamental laws of ducks? Looks like a duck, swims like a duck, and quacks like that. You should know something about ducks to be able to do. Not necessarily. Looks like the horse. It's also good. It generalizes from ducks and makes sound like horse. So something and run like horse and moves like horse. It is generally, it is generally predicate that this applied to duck. But for duck, you can say play chess like duck. You cannot say play chess. Why not? So you're saying you can, but that would not be a good. No, you will not reduce a lot of functions. You will not do, you will not reduce the set of functions. So the story is formal story, mathematical story, is that you can use any function you want. Because they predicate. But some of them are good, some of them are not, because some of them reduce a lot of functions. The admissible set of some of them. So the question is, I'll probably keep asking this question, but how do we find such, what's your intuition? Henry, Henry recognition. How do we find the answer to your challenge? Yeah, I understand it like that. I understand what it means. What it means? What it means, I knew predicate. Like guy who understands music can say this word, which he describes when he listens to music. He understands music. He uses not too many different, or you can do like prop, you can make a collection of what he's talking about, music, about this, about that. It's not too many different situations he describes. Because we mentioned Vladimir Prabhabinds, let me just mention, there's a sequence of 31 structural notions, that are common in stories. And I think you call it units. Units. And I think they resonate. I mean, it starts just to give an example, a session, a member of the heroes community, a family leaves the security of the home environment, then it goes to the interdiction, or forbidding edict, or command is passed upon the hero. Don't go there, don't do this. The hero is worn against some action. Then step three, violation of interdiction, brace, you know, break the rules, break out in your own, then reconnaissance, the villain makes an effort to attain knowledge, needing to fulfill their plot. So on, it goes on like this, ends in a wedding, number 31, happily ever after. No, he just gave description of all situations. He understands this world of hotels. Yeah, not for not the focus, but it's a story. And this story is not in just for hotels. The story is in detective cereals as well. And probably in our lives, we probably live with this. And then they roll that this predicate is good for different situation, for movie, for theater. By the way, there's also criticism, right? There's another way to interpret narratives from Claude Levy-Stross. I don't know. I am not in this business. No, I know it's the theoretical literature, but it's looking at paradise. It's always the the the the discussion. Yeah, yeah, but at least there is a unit. It's not too many units that can describe but this guy probably gives another unit. Or another way for exactly another another set of units. Another set of predicate. It doesn't matter. But they exist. Probably. My my question is whether given those units, whether without our human brains to interpret these units, they would still hold as much power as they have. Meaning are those units enough when we give them to the alien species? Let me ask you. Do you understand digital images? No, I don't understand. No, no, no. When you can recognize this digital images, means that you understand. You understand karatias you understand. No, no, no, no. It's the imitation versus understanding question because I don't understand the mechanism by which I am. No, no, I'm not talking about predicate. You understand that it involves symmetry, maybe structure, maybe something. God, I cannot formulate. I just was able to find symmetries. So, I guess that's really good. So this is a good line. I feel like I understand the basic elements of what makes a good hand recognition system my own. Like symmetry connects with me. It seems like that's a very powerful predicate. My question is, is there a lot more going on than we're not able to introspect? Maybe I need to be able to understand a huge amount in the world of ideas. Thousands of predicate, millions of predicate, in order to do hand recognition. I don't think so. So you're both your hope and your intuition and such that. Like explain enough, you're using digits, you're using examples as well. Theori says that if you will use all possible functions from Hilda space, all possible predicate, you don't need training data. You just will have admissible set of function which contain one function. Yes. So the trade off is when you're not using all predicates, you're only using a few good predicates, you need to have some training data. Yes. Exactly. The more the more good predicates you have, the less training data. Exactly. That is intelligent. Still, okay. I'm going to keep asking the same dumb question, handwritten recognition to solve the challenge. You kind of propose a challenge that says we should be able to get state of the art, amnest error rates by using very few 60, maybe fewer examples, predicate. What kind of predicates do you think you'll... That is the challenge. So people who will solve this problem, they will answer. They will answer. Do you think they'll be able to answer it in a human explainable way? They just need to write function, that's it. But so can that function be written, I guess, by an automated reasoning system? Whether we're talking about a neural network learning a particular function or another mechanism? No, I'm not against neural network. I'm against admissible set of functions which create neural network. You're did it by hand. You don't do it by invariance, predicate by reason. But neural networks can then reverse do the reverse step of helping you find a function. The task of a neural network is to find a disentangled representation, for example, what do they call it? It's to find that one predicate function that's really captures some kind of essence. One, not the entire essence, but one very useful essence of this particular visual space. Do you think that's possible? I'm grasping, hoping there's an automated way to find good predicates. So the question is, what are the mechanisms of finding good predicates? Ideas, you think we should pursue? A young grad's listening right now. I gave example. So, find situation where predicate which you suggesting don't create invariant. It's like in physics. Find situation where existing theory cannot explain it. Find situation where the existing theory can't explain it. So you find contradictions. Find contradiction. And then remove this contradiction. But in my case, what means contradiction, you find function, which if you will use this function, you're not keeping invariants. So is really the process of discovering contradictions? Yeah. It is like in physics, find situation where you have contradiction for one of the property, for one of the predicate. Then include this predicate, making invariants. And so again, this problem now you don't have contradiction. But it is not the best way, probably I don't know, to looking for predicate. That's just one way. Okay. That no, no, it is brute force way. The brute force way. What about the ideas of what big umbrella term of symbolic AI, there's what in 80s with expert systems, sort of logic, reasoning based systems? Is there hope there to find some, through sort of deductive reasoning to find good, predicates? I don't think so. I think that just logic is not enough. It's kind of a compelling notion, though, that when smart people sit in a room and reason through things, it seems compelling and making our machines do the same is also compelling. So everything is very simple. When you have infinite number of predicate, you can choose the function you want. You have invariants and you can choose the function you want. But you have to have not too many invariants to solve the problem. So, and how from infinite number function to select finite number and hopefully small function, not a number of functions, which is good enough to extract small set of admissible functions. So they will be admissible, it's for sure, because every function just decreases set of function and leaving it admissible. But it will be small. But why do you think logic-based systems don't, I can't help, intuition, not- Because you should know reality, you should know life. This guy like prop, he knows something and he tried to put in invariant his understanding. So, but that's the human, yeah, to see you're putting too much value into Vladimir prop, knowing something. No, it is my understanding. The story is that what means you know life. What it means? Comments, you know common sense. No, no, no. You know something. Common sense, it is some rules. You think so? Common sense is simply rules. Common sense is, every, it's mortality, it's no, it's fear of death, it's love, it's spirituality, it's happiness and sadness, all of it is tied up into understanding gravity, which is what we think of as common sense. I don't really discuss so quite. I want to discuss, understand, digital recognition. Anytime I bring up love and death, you bring it back to digital recognition. Yeah, no, you know, it is durable because there is a challenge, yeah, which I see how to solve it. If I will have a student, concentratons this work, I will suggest something to solve. You mean handwritten recognition? Yeah, it's a beautifully simple elegant and yet, I think that I know invariants which will solve this. You do. I think so. You do. But it is not universal. It is maybe I want some universal invariants which are good, not only for digital recognition, for image understanding. So let me ask, how hard do you think is 2D image understanding? So if we can kind of intuit handwritten recognition, how big of a step leap journey is it from that? If I gave you good, if I solved your challenge for handwritten recognition, how long would my journey then be from that to understanding more general natural images? Immediately, you will understand this as soon as you will make a record. Because it is not for free. As soon as you will create several invariants which will help you to get the same performance that the best neural net did using 100 times, maybe more than 100 times. Less examples. You have to have something smart to do that. And you're saying that that is invariant. It is predicate. Because you should put some idea how to do that. But okay, let me just pause. Maybe it's a trivial point, maybe not. But handwritten recognition feels like a 2D, two-dimensional problem. And it seems like how much complicated it is the fact that most images are projection of a three-dimensional world onto a 2D plane. It feels like for a three-dimensional world we need to start understanding common sense in order to understand an image. It's no longer visual shape and symmetry. It's having to start to understand concepts of understand life. You're talking that there are different invariants. Different predicate. Yeah. And potentially much larger number. You know, maybe. But let's start from simple. Well, yeah, but you said that it would be easy. No, you know, I cannot think about things which I don't understand. This I understand. But I'm sure that I don't understand everything there. Yeah, it's a different thing. It's a different thing. Do as simple as possible, but not simpler. And that is exact case. With handwritten. With handwritten. Yeah, but nevertheless the difference is in you and I. I welcome and enjoy thinking about things that completely don't understand. Because to me, it's a natural extension without having solved handwritten recognition to wander how difficult is the next step of understanding 2D-3D images. Because ultimately, while the science of intelligence is fascinating, it's also fascinating to see how that maps to the engineering of intelligence. And recognizing handwritten digits is not, doesn't help you. It might it may not help you with the problem of general intelligence. We don't know. It'll help you a little bit. It's unclear. It's unclear. Yeah, it might very much. But I would like to make a remark. I start not from very primitive problem, make a challenge problem. I start with very general problem, with plateau. So you understand and it comes from plateau to digital recognition. So you basically took Plato and the world of forms and ideas and mapped and projected into the clearest, simplest formulation of that big world. You know, I would say that I did not understand Plato until recently. And until I consider weak convergence and then predicate and then know, this is what Plato told. So, how do you think about this world of ideas and world of things in Plato? No, it is metaphor. It is. It's a metaphor for sure. It's a compel, it's a poetic and a beautiful one. Yeah, yeah. But what can you... But it is the way how you should try to understand how a talk ideas in the world. So from my point of view, it is very clear, but it is lying. All the time people looking for that. Say, Plato's and Hedgel, whatever reasonable it exists, whatever exists, it is reasonable. I don't know what you have in mind, reasonable. Right, this philosopher's again. No, no, no, no, no, no, no, it is... Next stop of Vignor, that what you might just understand something, in reality, it is the same plateau line. And then it comes suddenly to Vladimir Prob. Look, 31 ideas, 31 units, and this kind of everything. There's abstractions, ideas that represent our world. And we should always try to reach into that. Yeah, but you should make a projection in reality, but understanding is, it is abstract ideas. You have in your mind several abstract ideas, which you can apply to reality. And reality, in this case, if you look at machine learning as data, it's exactly data. Data. Okay, let me put this on you, because I'm an emotional creature. I'm not a mathematical creature like you. I find compelling the idea, forget the space, the sea of functions. There's also sea of data in the world. And I find compelling that there might be, like you said, teacher, small examples of data that are most useful for discovering good, whether it's predicates or good functions, that the selection of data may be a powerful journey, a useful mechanism. You know, coming up with a mechanism for selecting good data might be useful too. Do you find this idea of finding the right data set? Interesting at all. Or do you kind of take the data set as a given? I think that it is, you know, my scheme is very simple. You have a huge set of functions. If you will apply, and you have not too many data, if you will pick up function which describes this data, you will do not very well. You will randomly pick up? Yeah, you will have a fit, it will be overfeiting. So you should decrease set of function from which you're picking up one. So you should go somehow to admissible set of function. And this is what about weak conversions. So from another point of view, to make admissible set of function, you need just a dig, you just function, which you will take in inner product, which you will measure the property of your function. And that is how it works. No, I get an understanding, but do you, the reality is? But let this, let's think about examples. You have a huge set of function, and you have several examples. If you just trying to keep, but take function, which satisfies these examples, you still will overfit, you need decrease, you need admissible set of function. No, absolutely. But what say you have more data than functions? So consider the, I mean, maybe not more data than functions, because it's impossible. Impossible. But what I was trying to be poetic for a second, I mean, you have a huge amount of data, a huge amount of examples. But amount of function can even be bigger. I understand. Everything. There's always a bigger boat. Full, full, he'll be in space. But okay. But you don't, you don't find the world of data to be an interesting optimization space. Like the, the optimization should be in the space of functions. Creating admissible set of functions. Miscible set of functions. No, you know, even from the classical basis theory, from structure risk minimization, you should, you should organize function in the way that they will be useful for you. Right. And that is, but the way you're thinking about useful is you're given a small set of functions. You're small, small set of functions which contain function by looking. Yeah, but as looking for based on the empirical set of small examples. Yeah, but that is another story. I don't touch it. Because I believe that this small example is not too small. Say, sixty-per-class, that law of large numbers works. I don't need uniform law. The story is that in statistics there are two law. Law of large numbers are uniform law of large numbers. So I want to be in situation where I use law of large numbers, but not uniform law of large numbers. So sixty is law of large numbers. It's not enough. I hope. No, it still needs some evaluation, some bounce. But idea is following that. If you trust that, say, this average gives you something close to expectation. So you can talk about that, about this predict. And that is basis of human intelligence. Good predicates is the discovery of good predicates is the basis of human intelligence. No, no, it is discover of your understanding world, of your methodology of understanding world. Because you have several functions which you will apply to reality. Can you say that again? So you have several functions predicate, but they abstract. Then you will apply them to reality, to your data, and you will create in this way predicate, which is useful for your task. But predicate are not related specifically to your task, to this yet task. It is abstract functions, which being applying applied to many tasks that you might be interested in. It might be many tasks, I don't know. Or different tasks. Well, they should be many tasks, right? Yeah, I did it like in prop case. It was for fairy tales, but it's a pattern to everybody. Okay, so we talked about images a little bit, but can we talk about known chalmsky for a second? No, I don't know him. Yeah, personally, well, not personally, but I don't know his ideas. Well, let me just say, do you think language, human language, is essential to expressing ideas as known chalmsky, believe. So like language is at the core of our formation of predicates. The human language. For me, language and all the story of language is very complicated. I don't understand this, and I'm not, I thought about nobody. I'm not ready to work on that because it's so huge. It is not for me, and I believe not for our century. It's the 21st century. Not for the 21st century. So you should learn something, a lot of stuff from simple tasks, like digital recognition. So you think, you think digital recognition, 2D image, how would you more abstractly define a digital recognition? It's 2D image, symbol recognition, essentially. I mean, I'm trying to get a sense sort of thinking about it now, having worked with MNIST forever, how small of a subset is this of the general vision recognition problem and the general intelligence problem? Yeah, is it a giant subset? Is it not? And how far away is language? You know, let me refer to Einstein. Take the simplest problem as simple as possible, but not simpler. And this is a challenge, it's simple problem. But it's simple by idea, but not simple thought, to get it. When you will do this, you will find some predicate. Each helps you to do it. Well, yeah, I mean, with Einstein, you can, you look at general relativity, but that doesn't help you with quantum mechanics.
