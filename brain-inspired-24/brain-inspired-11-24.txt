 So, so this really sort of gets to the heart of why I'm saying that there needs to be a warning about how philosophers of mind interpret the results of neuroscience. The model that you have of perception is computational in large part because that's a convenient simplifying strategy. It doesn't mean that you have found an inherently computational system within the brain. Nature is, by itself, is unconstrained very often machines, if you like, the stepping stone needed to get from, like, unconstrained nature to model systems in the laboratory that are the starting point for new theoretical developments. This is Brain Inspired. Hey everyone, I'm Paul, and my guest today is Masrita Chiramuta. Masrita has been on a few times before, but today she comes on with a new book that she has written, The Brain Abstracted Simplification in the History and Philosophy of Neuroscience. And the book largely argues that when we try to understand something complex like the brain, something very complicated, and we use models and math and analogies, for example, to do so, that we should keep in mind that these are always of simplifying and abstracting away details to give us something that we actually can understand. And when we do science, every tool that we use, every perspective that we bring, every way that we try to attack a problem to solve it, these are all both necessary to do the science, and they limit the interpretations that we can claim from our results. So she does all of this in more in the book by visiting many topics in neuroscience and in philosophy, many of which we discuss today. And luckily for you, the book, even though, so I have a hard copy, and I think I say in the episode that it's actually a really beautiful looking book, and I have enjoyed the hard copy, but luckily for you, the book is available for free digitally through MIT Press. So I link to that in the show notes and more information and previous episodes of Mazwita's on Brain Inspired, and the show notes at braininspired.co slash podcast slash 186. And of course, we don't discuss everything that's in the book, but we do touch on a few more topics in the full version of this episode, which you can get when you support brain inspired through Patreon. So if you're interested in full versions and joining a discord group, et cetera, go to braininspired.co to learn how to support it on Patreon. Thank you to all my Patreon supporters. Okay, here's Mazwita. Here's the, here's the copy of the book. By the way, I got a copy. Yeah, is it mirrored? No, you can read that, right? Yeah, I can read that. It's a, it's a really a beautiful book. And you had emailed me about, you said, thanks for reading my extremely long book. And I didn't realize it was so long because I was reading a digital copy. But it's not that long. And it didn't feel long to me because I enjoyed it so much. But what I was going to say is it's actually a quite beautiful looking book. Are you happy with the way it turned out? Yeah, yeah, I am. What about the, just the M? What's that about? I guess my name's too long. So my previous book. Is that going to be your moniker going forward? Yeah, so that was how it was for my previous book and my spare journal articles. Okay. Okay. Well, let me start by reading, perhaps my favorite, it's a short quote, but perhaps my favorite quote from the book. Okay. I wonder if you could guess what this is or I'm sure you could guess what it has to do with. Okay. What we make include is that as a matter of research interest, neuroscientists have not given up on trying to understand the brain. I think that comes toward the end of the book. It's so defeatist. It's such a slap in the face of neuroscientists. No, no, not given up. Okay, you've got to take that in context, which is which is going back to that question of prediction versus understanding. So with the power of artificial neural network modeling, applied to brain data, can you just get away with just relying on predictive power and not focusing so much on understanding? And I'm just pointing out that that hasn't happened. There's still neuroscientists that are. Yeah. So it's the yeah, the context is understanding defined as you define it in the book, not our common sense notion of understanding, but read out of context. It's lovely. And actually your whole book out of context could be, I mean, you had mentioned your concern to me that I might find it too pessimistic. Yeah. So anyway, we'll get to all that. It's really an excellent book. And I'm going to, so it's a shame that I could only read it kind of one time through and then kind of revisit some sections, but I'll be revisiting a lot of sections. Sure, I feel I will in the future. And we'll get into everything. Well, lots of stuff in the book, but I thought we might start with, and I know we've spoken about this a little bit before, maybe offline and on the podcast, where you came from and kind of how you got to where you are, like in the book, because you were a neuroscientist. Yeah. And I'm not sure if you can, do you use that word when you, when people say, what do you do now or do you just leave it off the no, no, I mean, since my professional affiliations been in philosophy departments, I haven't described myself as a neuroscientist because that's not how I make living. But no, I started out my academic career in, I would say vision science would maybe be a more accurate description because what I was researching on was the visual system on that intersection between psychophysics and visual neuroscience. So I did my PhD with David Tallhurst at Cambridge in the early 2000s, and he his research had been in classic primary visual cortex neurophysiology, but by the time I joined his group, he didn't have the neurophysiology lab, his experimental work was in psychophysics. But the point of what we were doing was to model the psychophysical data in terms of what was gathered from the neurophysiology about the responses of simple cells to grating contrast. And so he still had a collaboration with some neurophysiologists, and we were reading the V1 literature, but yeah, it wasn't in a wet lab myself. Yeah, okay, okay, and you made the move to philosophy. And I have a personal interest in this, selfish interest because when I was thinking about going back into academia, I considered for the move to philosophy. I ended up back in a, I guess what you would call a computational neuroscience lab. But recently I had coffee with Dan Nicholson, who's been like a processing philosophy person, he's been on the podcast. He came through Pittsburgh, and I had to take a bus to meet him out. You probably know where the philosophical archives are in Pittsburgh. There's like a building that you have, it's off campus anyway. Yeah, the barstice I never made it out. Well, he was really enjoying himself, and he had spent all day, you know, like sifting through, looking for these letters of correspondence between these two scientists, you know, decades ago, trying to suss out, you know, this historical context and the history and philosophy of science. And I thought to myself while chatting with him, and I really enjoyed our chat, I thought, I don't, would I be happy sitting in an archive going through, you know, essentially sitting in a library most days, searching for letters that have something to do with the topic that I'm honing in on, yeah, or what I would be happy doing what I'm doing right now, which is like a lot of data analysis and stuff. And I don't know the answer. I'm assuming that you're glad that you moved to like full, full on philosophy. Yeah, that's right. So my undergraduate degree was in philosophy and psychology, and I did, for most of my degree, prefer the philosophy to the psychology, except into the final year, where I got to do a research project with the late Tom Choshanko, a such an amazingly enthusiastic teacher about everything to do with vision science. It was really a great experience to have an autonomous research project, and I actually go to conferences and present that. And he was at the time collaborating with David Tallhurst, and so that was what brought about the opportunity to go and see the PhD. There, so I was kind of surprised actually by that choice that it made in the end to pursue vision science over philosophy, but then the philosophy bug didn't quite go away when I was doing my PhD. So I had always contemplated going back and actually combining the two because one of my interests in psychology and neuroscience was always to do with philosophy of mind and seeing how the science could be relevant to those old philosophical questions about the nature of perception, how is it that perceiving the world enables us to know anything? And that's what about my previous project in philosophy, which was about the problem of color and the reality of color that we perceive, and trying to use those recent scientific results about the integration between the color visual system and other parts of the visual system to argue for a particular philosophical theory of color, which is broadly speaking, an ecological one, it's also a processual one. And relation is essentially as well, right? Sorry. And relational as well in terms of philosophy of mind. It's arguing that colors are relational properties that are to do with the interaction between the procedure and the environment. So I'm arguing in that book that there is a way to leverage scientific results to draw a philosophical conclusion and actually the new book is to some extent an argument with my form of self because I'm actually now focusing on something that had interested me a long time ago when I was working on primary visual cortex, which is how amazingly simple these models are compared to some of the things that experimentalists find out about the brain. This kind of this mismatch between the war and pericle picture of the brain that we get and the very elegant computational models. And then this leading me around about way to the conclusion that given this given the amount of simplification that is there in the theoretical side of neuroscience, this raises some problems about how philosophers are trying to draw on theoretical neuroscience in their conclusions about in philosophy. Oh, such a mixed up bag because you're drawing on neuroscience to talk about how philosophy shouldn't be drawing necessarily on neuroscience. And in a sense from what you described, you've always had one foot out of the door of like the empirical sciences. But because I was going to ask my guess was that you kind of moved from a more what is now like the common neuroscientific standpoint of computationalism that the brain makes computation that you moved kind of from that perspective to a more organismic holistic perspective. But I guess I'm wrong a little bit. You've always been a little bit hesitant. It sounds like to join the functionalism, computationalism club and neuroscience. Yeah, it's been a mixed bad. I think on the it's probably something to do with on the level of psychology. I was psychology efficient. I was trained by people that read Ma and Gibson and tried to integrate those too. I was supposed to do that. You're supposed to be that. Yeah, no, that was how Tom Toshanku talked his lectures. These are these two very valid approaches to vision. A lot of the work that David Toshanku was doing was on natural scene perception and the whole motivation to doing that goes back to Gibson. So ecological psychology and the visual system is something that interested me for a long time. But at the same time, yeah, it was pretty much a paid up marion in thinking, yeah, just look beginning with the level of computation, going down to algorithm and then seeing how this could be done implementationly. Yeah, that that always made sense to me until recently thinking more about the limitations. Recently in the I mean, this is this book has been a work like all books in the making for you say recently, but it's been a few multiple years, right? So you retouch on a lot of the ideas in the past. Oh, seven decade maybe of papers that you've written that you have been building up to this. Yeah. Yeah. That's right. All right. Well, let's go over the sort of the overarching principles or ideas in the book. And you've already touched on some of these. And I'll say some things and then you can correct me. And because the way that I'm going to say it, I'm sure is wrong. But one overarching overarching theme is that essentially it's like a big mistake to maybe not big. It's a it's a fundamental mistake that neuroscience makes in taking a computation or a model as real when in fact, it's always a simplification. And this is almost so I jotted this down as a note but that neuroscience really should be thought of as aiming to understand and maybe we can talk about the difference between understanding and control aiming to understand the technology that it's dealing with as as a model or as a stand in or an analogy for the real thing. It's actually aiming to understand that technology, not the brain as it is in itself. And there, you know, there multiple other messages broadly in the book. But how did I do? And then what would you change and add? Yeah, yeah. And yeah, I mean, that certainly sort of catches the board themes that I'm pushing for. Yeah, one thing I would say about this point that neuroscientists are making a mistake. I wouldn't put it exactly like that in terms of being a realist about about their models. So being by being a realist, taking the models to be sort of literally and factually descriptive just of how things are going on with the brain. I mean, I think if this question of realism as if you like a meta-scientific issue, it's not. It can be fine within your scientific discourse just to, you know, not not have these so many of these philosophical quills about, though, is this representation literally true of what we're representing. You just take it for granted that if it's empirically adequate, then it's giving you adequate representation of your target. But my point is not to sort of reform how neuroscientists talk, but to say that if you're a philosopher and you have questions about what is perception, what is decision-making, and you're going to the neuroscientists and you're looking at those models and saying, ah, these are literally and factually non-idealized descriptions of what's going on in the brain, then you will be misled because you're ignoring the distance between the brain complexity, which is actually there, and the amount of effort that's gone on amongst the scientists to strip away that complexity and present you with a neat, simplified model. And I think the reason why this issue hasn't been salient to people is I think a quite common view in this review that I used to subscribe to is that when you do have a simplified model in science, what you're actually doing is discovering some simplicity, which is if you're inherent in the thing that you're modeling, but kind of masked by all this surface complexity, which is there in the data. And I think I'm just really raising the question, what justifies us in assuming that, like given that the brain, the more that we probe it experimentally, the more sort of levels of complexity seem to be emerging. I don't think we should be confident that the simplified models are targeting underlying simplicity so much as we are imposing a simplification for our own purposes on this, on the subject. And of course, you talk about how this doesn't just apply to studying things like brains in their infinite complexity that science always does this, but it's particularly salient in the neurosciences. So the book, so I read it as a neuroscientist, I think. And what you're saying is that it's, is it primarily aimed at philosophers because this, what you described as philosophers, which has been a popular thing for the past few decades, I guess, looking to science and to ask like how scientists are doing things and what, you know, and then to use whatever they find there and bring it into philosophy. And so caution should be taken there because to not believe that scientists are on the right track in terms of what is real. Yeah. Yeah. Anyway, there was a bunch of questions I guess in there, but as it, so you're talking to philosophers in this book, is that? I know. I wrote it for sort of both parties, but I would say that okay. I, I do this a paraphrase of, of marks in the introduction. So the point of the book is to interpret neuroscience, not to change it. Right. So I'm not telling neurosciences to change their business, but I'm, to for anyone that wants to interpret neuroscience, which will be both philosophers and neuroscientists themselves when they're speaking to the public or just reflecting on what these results mean for our understanding of the mind in general, people in general, then these are the cautionary tales that need to be taken on board. I mean, as a neuroscientist, when you read this, there are many ways to interpret it. One could be that you're sort of patting neuroscience on the head saying, you guys can keep talking about whatever you want to talk about, but you're actually not, not talking about something real. You're talking about your little models, you know, and keep, and you're saying, and it's fine to, to keep doing that. And you are saying that. And in fact, you justify it and you advocate for a lot of the ways that neuroscientists speak about things like representation of models. But at the same time, you kind of destroy something that seems somewhat precious, perhaps to a lot of neuroscientists, that what they're really doing in studying these models is understanding the real brain. Yeah, so we should say more about this issue of realism. So there's a long standing debate within philosophy of science about the question of realism, which is the question of whether scientific theories, models, other representations are hitting upon some underlying reality, which if you like goes behind the data, so in the way that a theory which posits electron, there's actually going beyond just summarising experimental data that physicists observe in a lab and actually sort of hitting upon this unseen world of particles. So that's how the realism debate is normally figured and anti-realists or empiricists were sort of skeptical about even the existence of electrons. I'm not, yeah, an anti-realist in that old sense of saying, well, what neuroscientists depicting doesn't exist. The view that I'm arguing for, I call it haptic realism because I'm saying that, sure, when we're doing neuroscientists are interacting with an actual object that is the brain neurons, no one denies that they exist, no one denies that they have lots of the properties that could be measured experimentally. But what I'm stepping back from is the standard scientific realism, which says that when science is fully, you know, do it at its best when it's got lots of experimental data and favour of it when it's mature enough theory, we can take that scientific representation to be giving us like the literal truth of how things exactly are in the system of nature. And I'm saying that we shouldn't go as far as that precisely because if you look at all of the process that goes behind science, what you're having to do in order to generate your theories and models is strip away from complexity, how you just, how you go about doing that will be determined by your own prior interests, your own prior theoretical commitments. There will be multiple ways that you can strip away complexity that give you different perspectives on that one same target system. And so what you're left with is not the representation of exactly how things are in the brain independently of your choice of scientist to idealize and abstract in specific ways. And so if one of the, one of the things that your model is telling you is that what perception is is essentially a certain series of computations, I'm saying that shouldn't be right at face value because the model that you have of perception is computational in large part because that's a convenient simplifying strategy. It doesn't mean that you have found an inherently computational system within the brain, something we touched upon in the last podcast that we do with Mark Sprawick. Right. Yeah. Well, so, okay, and I wanted to find haptic for everyone since you use the term haptic realize realism, which well, and maybe you mean it in a certain way, but it means having to do with touch. So it's almost like an epistemic. It alludes to the, to the interact, like the physical kind of interaction that scientists have with their technology in doing these research. Yeah, that's right. So like you can think of the standard scientific realism that I'm opposing is saying that science gives us a window on reality. So when science is at its best, it's like it's it's wiped away all the distortions, it's completely transparent and clear. We look at nature just as is independently of any of our decisions about how to represent it. Haptic realism shifts to this metaphor of touch. Well, when you touch something, you can't deny that you're part of the your part of the thing, that part of the system that is being modeled if you like, you have to acknowledge that the very choice that you have to go out and discover this object through touch makes a difference to what you end up knowing about it. Another thing about the Haptic metaphor is that your hands are not only sensory organs, they're also the means that we have to actually affect changes on the world. And I think we should think of science as having this like double-faced nature. Science is epistemic. It's about knowledge, it's about discovery, but it is also in the biological sciences inherently technological. It's driven by very many technological ambitions of therapeutic, more blue skies things that people are going into their research with the idea that they want to use this knowledge for affecting certain changes, maybe not immediately, but long-term. So I think thinking of scientific knowledge as giving us this haptically real knowledge just makes us remember that double-faced nature of what we're doing. So it's not like we're just clearing the window and reality just sitting back. This is how things are independently of our own interests and choices and long-term ambitions. And along the same lines, I mean, there so then there is no fundamental objectivity because the scientist is always bringing his or her interests and perspective and toolmaking and strategies and these in essence mold their questions into the questions that they can answer because they need to be able to mold them. And so there is no objective window into reality in that case. No scientific realism, I suppose. Yeah, I mean, it depends what you mean by objectivity. If you use a contrasting it with subjectivity, I would sort of hesitate there because I'm not saying that, you know, science is subjective in that, you know, it's like the whims of the scientists, what they feel like discovering in the brain is what they will discover. Objectivity in a more modest sense of being like inter-subjective, corroborated, cross-checked in a rigorous way certainly has that quality. So there are so many, when science is working properly, there are so many layers of verification and evidence that need to be brought to bear. But that doesn't mean that science transcends if you like the human standpoint and we see things with a god's eye for you. If that's what we mean by objective, then I would say no, it's not objective. You always have to be careful with your words with a philosopher, that's independent like you said is what you're more comfortable with. Yeah. Is when you just said when science is being done properly, is that that's never the case, is it? No, I mean, just there are just more and more worries that people have about fraudulent science. Oh yeah. So ideally, everything should be cross corroborated, but it's not possible, practically speaking for that to happen. And so there's stuff in the published record, which is fraudulent. Yeah. Yeah, sure. Okay, well, so maybe we could shift along these same lines to so we have this idea that scientists are always bringing their own interests and perspectives to bear. And you talk about three simplifying strategies. So the whole idea is that we're always as scientists simplifying in order to understand in some in some respect, even when we're using these really complex models, there are lots of simplifications still in these models. So what are the, and you discuss like three different simplifying strategies that scientists use, whether they know it or not. And could you discuss those three simplifying strategies? Yeah, so I begin with the point that quantification itself, so using maths to represent things in nature is inherently a simplifying strategy. So this is an argument that I can't go back to various people. I thought, I thought just early 20th century people like Berksson and Whitehead, but actually I was reading something yesterday by Michaela Masami, who are Edinburgh, and she sees this point in Spinoza, though she's not making the use of it that I will. But the point is that whenever you make the decision to count a series of objects, you're making the decision that the similarities between those objects are what, are what matters and any differences you can ignore. So the very idea of mathematically representing something is, depending on your prior decision to say that, okay, there's a whole bunch of observable variables, see in what we're measuring or counting. And yet we're going to abstract away from that and say, these chickens are all just chickens, right? Or these neurons are all just neurons. Or these spikes are all just spikes. But in biology, we can observe the sort of variation all the time. And so when we, especially in biology, and I don't think this is necessarily an issue that comes about in physics, like the home of quantification sites. But anyway, when we quantify and mathematicize in biology, we are always abstracting away from a lot of the variability, which is there in the system. So I'm saying that by itself is a simplifying strategy. If you think of statistics, so branch of methods that sort of goes back to the state, the word state, there's the root of statistics. So if you think of a society that as a state, you're trying to manage, there's so much going on. You don't have spies everywhere. How do you know what your population is doing? A whole bunch of methods to do with there are certain numerical values that you need to keep track of, like births, deaths, amount of food that your country consumes in a week. Certain things need to be measured and you need to average over them so that you can make sense of those data. But there's obviously way more going on in a society than the statistics that the state can gather are able to capture. So you can think of that as a nice example where it's very clear that there's a mismatch between like the inherent complexity of the system, all of the details and processes that are going on there, and the mathematical representations, which are very effective for certain management purposes, but you can't say that they capture everything that's going on. Management purposes like control, you mean? Yeah, well, just planning the case of saying, I'm not saying. Well, I don't mean control in terms of like government controlling or something like that. I just mean in the way that you use control versus understanding in a scientific agenda, right? So that so you can use these abstractions like counting, right, to talk about the number of chickens that need to be hatched per week in a given population size of X to maintain stability or to throw the stability into chaos or something. And that's all way of like controlling it. So it would happy, right? Yeah. So for prediction and control of the variables that you're talking, yeah, these are these are methods that are indispensable because if you just try and sort of take in all of the raw, non-quantified, perceptual data, you wouldn't you wouldn't be able to work with that. Yeah. Okay, so that's that's mathematics and you talked about stability and states. And so we'll come back to that because that's an interesting topic in itself. So that's a strategy, simplifying strategy. Number one, the next one, another one is just reduction in itself. Reduction? Yeah, I mean, so reduction is obviously really been important, you know, approach and biology in the 20th century. Like the most important almost, maybe besides math. Yeah. Yeah. And I, it's not always thought about as a simplifying strategy, but if you if you sort of reflect a moment about what's going on when people reduce the water, the motivations for it. Oh, so if you're faced with something like a mouse, which is a complex system, there's a whole lot going on with a mouse or mouse brain. And then they will, how can I begin to understand a system of this complexity? If you allow yourself the reductionist assumption that knowing what the parts do, knowing the properties of the parts is the these are the building blocks for knowing the operation of the whole system, then you will, you know, give yourself a workable research project, which is like, okay, we're going to look at the smaller, less complex units. So mouse brain, individual neurons or, you know, in the, sort of, mouth hole mouse, looking at cells of different, different organs. And then seeing from what you can discover about those individual parts in rather subisolation, you might get some targets of intervention. So if we're looking at liver cells, you might sort of find some targets of intervention of how to ameliorate certain conditions with the liver or if you're the bet with neuroscience and reduction, was that by looking at individual cells or small groups of cells, and we would find out, you know, how different, almost cognitive capacities of the brain come about. So assuming that the relevant operations were there, not, you know, as an emergent conglomerate thing out of the systemic interactions of the whole brain, but actually by looking at the parts of wireless isolation, you could, you could make progress towards the relationship between brain and mind. So I'd say it's a simplifying strategy in the sense that it's a way of dealing with a complex system. Yeah, but there's also the reduction in the other sense in terms of the preparation of your experiments, right? So reducing the, for example, in many animal experiments, reducing the mobility of the animal into like, so that you're essentially to control as many variables as possible, and that's been a reductive approach that has been super, quote unquote, successful or a major force in the sciences, and has led to lots of progress using these terms like, lightly, right? Yeah, so, so, yes, so that's another mode of reduction that I talk about as well. So, and it's something that, yeah, I first started thinking about actually my earlier graduate work, because one of the things that we were doing most of my experiments were with sinusoidal grating, so that's reduced stimulus. Insanely reduced. Yeah, you know, it's kind of crazy to think, right? It's like the highest control that you could have. So, so sinusoidal grating is just like this, you could think of it as like kind of blurry light and dark bars that you put in the, in front, somewhere in front of people and you, or animals or organisms, and you, and you try to put it in an area where you know that the neurons respond to best, and, and then you can change the orientation of the gratings and how thick the bars are. So, there's a lot of minutia, and we don't go around at the grocery store reading barcodes and things. In fact, we're kind of bad at it. That's a terrible example, but this is not a natural stimulus. No, so it's not a natural stimulus, but I mean, the theory at the time was that neurons in the areas sort of selectively responsive to these, and if you like, these are the building blocks of responses to complete scenes, but the problem with this that we were confronting in the research at the time was that when you took the models well for the reduced stimulus, the gratings, and then applied them to responses that you got when someone would look at a natural image and these black and white, they didn't even have color, then you would see the limitations of those models. So, I think when you have reduction as a simplifying strategy, it can work well within the confines of the controls situation, but then the question of translation to uncontrolled responses, and yeah, you can't be sure. I mean, since you mentioned the gratings, it's always bothered me because I came up in the visual neurosciences, and these gratings have always bothered me because of what we're talking about, and it has seemed ridiculous, and then there's a trend, and I'm not knocking anyone that's studying gratings, but there is a large trend of people who have studied gratings in the cognitive sciences, right? It started out, well, this is going to say something about how we build up images, but then what you end up doing is studying the neural properties and the neural correlations that have nothing to do necessarily with behavior or the complexity of cognition that you've wanted to study in the first place. So then you end up studying more and more reduced levels, I suppose. Yeah, so this really sort of gets to the heart of why I'm saying that there needs to be a warning about how philosophers of mind interpret the results of neuroscience, because when philosophers of mind, they're interested in something like decision-making, will, perception and action, they care about what goes on outside of the laboratory, they care about what people and animals are doing in their rich social, socially mediated lives. And so if they don't keep in mind that the version of perception and action, or the version of decision-making, which is what is being properly modeled and understood within neuroscience because of the need for use and control and reduced setups in your experiment, if they don't keep in mind that there's a mismatch there, they're just going to think that, oh, well, what decision-making most rigorously is, is what is modeled in this way. And it does look more rigorous because you have all this maths and you can show quite neat results if you use those methods, but it doesn't mean that it really translates to what people do, what they are in all of their richly integrated psychological lives where decision-making, perception and action are not just like one independent sliver, which you can isolate from the rest of what is going on. So you're saying that philosophers and I would add news outlets also should not just read the discussion sections at their face value in neuroscience papers, because it's those discussion sections and abstracts and introductions that talk about decision-making, for example, as if it's the same decision-making in the field and in natural behavior as it is in the lab. So is that the case? Or so what is the answer? Should philosophers then who want to glean something from a science then become super experts in that science or should the science always put asterisks on the terms that they use or somewhere in between? It's tricky. I mean most of the philosophers doing this kind of naturalistic work in philosophy of mind are now quite well adapted to the science and can sort of read the results and... But I haven't really understand so many scientific papers that are like just a adjacent to my field. So how could you expect a philosopher to really see the... Well, yeah, I mean in terms of the terms of the depth and knowledge that you've had as a working scientist using those methods, no, but knowing enough to not only read the discussion at face value and like realize that there's a methodological complexity behind it, I think that's like this standard in the field of philosophy of cognitive science, naturalistic, philosophy of mind now. So I think this issue goes deeper. It's not just a question of ignorance, but it does go back to this assumption, this maybe convenient assumption that people have, is that what the reduced method is tapping into, what the simplifying strategy is allowing you to access is this essential underlying simplicity which was there all along. So if you think that decision-making essentially is this thing that you can discover by stripping away all of the interacting factors that come about when people go to the shops and they're doing all kinds of other distracted things, then you think, ah-ha, we've found the core of decision-making in the lab and now we can be happy with that. But if you drop that assumption, then it becomes... it becomes mood. So I think that's where the discussion really needs to be had. And I think this is probably speaking of philosophical discussion. It goes back when to the history of classical philosophy, questions about essences, questions about the shifting nature of appearances versus the underlying stability of reality. So this notion that reality is more simple than it appears to us is actually quite an old philosophical notion. I mean decision-making, let's be clear here, it's just a stochastic variable that goes to one of two bounds, right? That's the way decision-making works, yeah. So we got off a little off track there because of me of course, but we're still on the three sort of fine strategies. The third of which is analogies. And analogies and metaphors aren't they just how we think that? Aren't they don't we rely on them to think anything? Yeah, so we do. So the question of analogies and the sense that I'm discussing it here, so it goes back to the point that we maybe didn't explain enough your audience about, am I saying that neuroscientists just understand their technologies and not the brain itself? So the relevant analogy here is the analogy that's drawn between biological brains and computers. And I'm saying that analogy is a simplifying strategy. So what you're doing there is you're taking a invented system, a computer, a digital computer, which is relatively well characterized compared to biological brain. And by lining up the similarities between those two systems, you can use that relatively simple machine as if you're like a model or proxy for what you're trying to leverage in your understanding of the brain. And so by drawing on analogies between things that are very, very complex and not very well understood and things which are relatively simpler and better understood, it's a common scientific strategy for just sort of bootstrapping up from where you would be otherwise if you're just starting with something that doesn't make a lot of sense by itself. So if you can think of analogies as giving you a lens through which to highlight certain relationships, which you would would be maybe more murky or hidden in the full complex system, but making you sort of highlight a heart. There's a certain bunch of relationships that we see in the relatively simple system and it's just similar to what we find in the complex system. So let's just focus on those similarities, ignore all that background complexity, then that allows you to make a certain amount of progress. But is there a phrase jumped to mind like the analogy trick or something because you start off, right? You can start off with good intentions and saying, well, we're going to focus on the similarities. But then over time, I don't know if it's because our human, our brains aren't as awesome as we think they are and we're just lazy and we need to simplify. So but then the analogy gets replaced with like a realist of you about the analogy becomes reality force over like time and like slips into a reality. Is that a thing? Yeah. So that's what I think has happened with the computational brain. That's what I'm arguing has happened because I see that there are good reasons for once the digital computer was available as a machine and notions of information processing were being theorized with a machine to use that as a lens through which to try and figure out what's going on with brain physiology. But there's been this tendency to verify the analogy or say that or just ignore the differences between the two. Which I think is becoming is starting to be misleading. So it's interesting that you use the computer as an example here and this is you've written about this plenty. One of the things that you write about in the book is and you just mentioned it that once we had this physical computer machine, we could then use it to analogize to brains and then this trick that happens over some sort of time where you get more and more comfortable with that analogy and then it becomes the real thing. Computers. So you're arguing the book that technology essentially precedes science. Science has to have an object of study and so often like a technology will come about like a computer and then science can look to that and then use their simplification strategies and say, okay, well brain is a computer for example. Although in this case, the computer was invented with some inspiration from science. What we understood quote unquote about neurons and stuff. Yeah, so this computer is an interesting case because it is you think the chewing machine. It's a machine that is supposed to duplicate the work of a human computer. So a person saying the human computer. Doing calculations. Yeah, so it's a model of a particular form of activity that people were doing. But a machine invented to duplicate that. Yeah, that's interesting because in that case, the technology is the human doing the computing, right? Yeah. Well, that's what yeah. So I think it says something important about what machines often are, which is labor saving devices and the labor is originally the labor done by an animal. If you're talking about an ox pulling stuff and you get a steam tractor or it could be a human doing mental calculations. Yeah. But your argument in the book is that understanding always comes after there is some physical simplified physical object to understand. Right. So this sort of yeah, this sort of to say more about this thing about technology preceding science and then why that relates to understanding. So one of the classic examples of this is a 19th century physics. So how steam engines preceded the invention of thermodynamics. Though people so engineers think of them around with machines getting all of these devices working. Scientists coming along often with the aim of theorizing those machines in order to increase efficiency. But thermodynamics was able to make the progress as it did because the machines provided a model system with which to explore thermodynamic relationships. Whereas if you just go out in nature and think of how does energy transfer happen. It's too uncontrolled. You can't just do that. But once you've got a machine, then you can precisely use that as an inspiration, maybe even for laboratories, studies where you can do things like track conservation, also, or white and conservation principles. So the point is that nature is in it by itself is unconstrained very often machines. If you like the stepping stone needed to get from like unconstrained nature to model systems in the laboratory that are the starting point for new theoretical developments. So that's where you see this path often in the history of science, not just with thermodynamics, but with mechanics in the 17th century. And I'm arguing with cognitive science in the 20th century, you had the computers and then you had the more general cognitive science which is both of the biological and machine systems. So then understanding is aided by the study of machines precisely because they are these simpler systems. And generally speaking when you're thinking about, well, what is it that scientists even doing basic research get to understand? Then they're saying then my point would be strictly speaking what they understand is their lab created system. And then there's the expectation or the hope that this knowledge will apply in the unconstrained realm. In physics, it tends to work quite well because physical objects are not particularly context sensitive. So if you get a few relationships figured out in the lab, you'll often be able to find enough similarity with how those things behave outside of the lab. With mice, with people, you can't always make that assumption that what you are discovering in your heavily controlled lab situation or in your completely non-biological machine, set up will transfer in unconstrained situations. And so this question about understanding being tied to having a technology or machine or having a very controlled, almost machine-like set up in your laboratory, that's behind this. So one of the downers in the book to me is that I've frequently mentioned, well, I want to understand. But what you're saying is that I scientists' role is not to understand in that respect. Well, understanding the thing in itself, they're understanding the technology, right? But the role of science is essentially manipulation and control. And then I thought, ah, shouldn't be, and maybe studying this complex thing. Yeah, so what you're saying, though, is that I can't understand the thing itself if I apply the scientific methods of simplification. Yeah, yeah, if you accept that the thing itself will have all of these dimensions and complexity, all of these various properties, which are not revealed in that simplified laboratory preparation. I mean, this points about sort of what is made, what's the technology, and what's not. I think in biology, it's really interesting because it becomes a tricky question. So if a mouse is a knockout mouse, not a well-tight mouse, is it an artifact? So in a certain way, yes. So the reason why biologists deal with, you know, imbred strains knock out mice as well. But if you actually imbred strangers, it's the more revealing example here, is that they're trying to get away from the flukiness that is just out there with wild types. They want their mice to be more and more stereotyped because that is what will help them get the repeatable, predictable results, which will allow for a nice, comprehensible model. Love the values also. Yeah, yeah, of course. And so in a way, just saying, okay, we're working on imbred mice, you are working on a technology. So your understanding is targeted to that technological version of the mouse. And when we're talking about biomedical research, obviously you're hoping that that model system will reveal relevant things which will apply not only to wild type mice, but to humans. But of course, we know it only with a model system, and the model is never identical to the thing that you're ultimately trying to target. I wonder if pharmaceutical research is a good example of this as well. I don't remember if you mentioned that in the book, but a lot of from almost all pharmaceutical medical discoveries are discovered by accident, right? So you bade the system with this particular drug. But then that informs how you think about how the system works. And then all of a sudden you have a quote unquote technology in that respect. Yeah, yeah, so that's another example of a technology not coming about from basic science, but going the other way. So you know, with people finding that certain drugs are anti-psychotics, and then that leading, and then people looking at the mechanism, saying something to do with dopamine, that leading to the dopamine hypothesis about what schizophrenia is. You used the term theoretical a few times when talking about this, you know, technology or some artifact needing to precede an understanding, using it as an analogy to try to understand other systems, but you're really understanding the artifact. But what the way that I read it in your book is more that it's like the scientific approach, the experimentation and perspective is where the technology needs to precede that scientific understanding or control. But I was wondering where theory does come into this. And you mentioned you can't just go out into the world and just sort of theorize about something in nature. But I don't know. There is a ratcheting effect, right, of one and then the other and then the other and the other. So can theory precede technology or just theory itself need to come after some artifact of study? I mean, I don't know if that there's just too much going on in the history of science, for that to be one clear answer for that. But the part, yeah, there were some historians of science that I was drawing on when I was writing these sections so they were looking at the context of the scientific revolution in the 17th century and they were pointing out that there'd been so much going on in industry in the late middle ages and Renaissance of the new methods of mining, all kinds of things which became the impetus for people that were interested in relationships to do with things, you know, in a natural world, to start investigating, investigating, I know, forces and optics and all these other things that you know, with historical questions, we don't know exactly with a cause of the fact relationships et cetera, et cetera. It seems in the light of that a bit implausible that like a theory ever just popped into a scientist head out of nowhere and then they got to apply and invent a whole u-round with technology. But given that there's been, I mean, technology has always existed in human society and people interested in relationships with things in nature has always existed. It seems like they've just been growing up together from a long way, but what I'm really trying to resist is this notion which takes things the other way around which goes, we need to do basic science in order to foster technology. So making it seem as if it always goes from the other way for the basic science to the technology. So it's not that it always has to be the case. It's just that there's a lot there are a lot of examples historically that it's the case. Yeah. This I was going to ask you this sort of later as an extra thing, but one way that this can happen is so it's interesting that a lot of advances in a science are made because someone who is not in that science, someone who's from a different area of science comes in, visits the new area. And I imagine part of the reason is because they bring their own artifacts, their own studying the artifacts and their own science and then make the easy and quick analogy to the new science and then all of a sudden there's a lot of low hanging fruit around that particular artifact. Would you agree with that? Yeah. Yeah. I think that's often the case. I think that's precisely right. Having a different background gives you a different like suite of analogies, which you can then often fruitfully apply to other other new territory. So it's still the same thing. It's almost like cheating because it's not like you came in, you were theorizing in some space and then brought your theory in. You're importing the technological artifacts that you were studying in that other space into another. It just seems like a good strategy, career strategy. Yeah, but we should think of the theory being part of that ecosystem with the technologies as well. So when we're talking about the new technologies and science, even have a very elaborate theoretical overlay with them, it's not just like the gadgets that anyone can use. You need a sophisticated understanding of the principles of operation of the thing in order to employ it. Yeah. You've already mentioned you've made a few illusions to physics and quote unquote simpler systems that are under study and the great advances in physics and successes in physics over the years. And this book is primarily aimed at more complex systems like brains and minds, which you get into especially later in the book. But when I read the book, all of these principles seem to apply to all different levels of science. My reading is that you're really concerned with these more complex sciences because they're affected more by these principles or mistakes. So can you talk about that division between like studying simple quote unquote simpler systems and complex systems and sort of the history of that and how these ideas affect the different types of systems that you're studying in different ways? Yeah. So yeah, there's various things I could say. I mean, so one of the philosophers of science that really got me interested in the field early on and I think sort of left an imprint on my mind, Snancy Cartwright. So she has this book from 1983, How the Laws of Physics Lie, which is one of the first books to really make idealization a central topic in their account of how the science is operating. So she says that the laws of physics lie in the sense that if you look at the most basic fundamental laws of physics, they apply only strictly speaking in a very idealized controlled system. And then to get them to apply beyond that, you have to do kind of tinkering and fudging and altering to get it to apply to the messy non-idealized system. So strictly speaking, they only apply, they only are true of a very controlled system which as close as possible conforms to the actual impossible standards of an idealization like being frictionless. Stereical cows. And I should say like, right, the the vast majority, another reason why this is interesting and timely is because neuroscience has really become more integrated into society and it's just a bigger scientific endeavor. But the vast majority of studies in philosophy regarding like the history and philosophy of science have dealt with physics, right? And it's only kind of more recent times. Although maybe in the past what 150 years, 100 years, it's been applied to like biological systems. But I think that the world of applying the philosophy of science to complex systems is grown and grown. So a lot of the things that you allude to are some of that early biological philosophy of science. But then the vast majority is having to do with these the physics, right? Yeah, yeah. So the amount of attention, philosophers of science paid to science outside physics has sort of definitely been growing. But one of the reasons why the field was so physics centric for so long is that physics is a queen of the sciences. It has the most fundamental theories, the most rigorous methods, the most mathematically sophisticated approaches or at least that's how it was for a long time. Now your science is very maths, as we know. Physics and v. Yeah, yeah. But then it's interesting to us why was physics? Why didn't make such rapid advances? Why did it become so impressive? And often physicists will admit we have the easy objects we study things that are not complex in the way that biology is. And a lot of the complexity of biology is precisely to do with the context sensitivity of biological organisms. So electrons aren't finicuity. They're not going to behave differently whether the blinds are in different color that day. That's what physics says anyway, but we don't know that for sure. Anyway, the gap between the predictions that the physicists make on the basis of the assumption that they're not finicuity and then what actually gets predicted is true, but in psychology, there are as much as you try to control your variables, there's going to be factors that are affecting your object of study, which you might not be aware of. And when you go from one country to an X, electrons don't change their characteristics, what people do. And then so human psychology is at the extreme end of that context sensitivity, but everything in biology is to some extent. So recently, we've been reading into this literature on plant behavior and plant cognition. If you like, this is the controversy. Do plants cognize? Yeah, plants do show a very pronounced amount of behavioral plasticity and ways that are just you'd be surprised by. Behavioral plasticity. I want to emphasize you said behavioral because... Yeah, exactly. This is what's the use of such terms as controversial, but it's precisely because plants show this plasticity, which isn't what you'd expect on the assumption that there are somewhat machine-like in how they operate. And one of the things that I notice in one of the papers is that if you want to see the full amount of plasticity and plants, you have to go to the wild type because if you look at, you know, agriculturally bred species, you'll find less of this because obviously people want their weak crops and they're corn just to do the same thing again and again and you can control, can control the fields so that it doesn't have to rely on its innate plasticity to deal with things like drought and nutrition levels, varying and stuff like that. But the organism in its unconstrained ecology has to have a lot of plasticity in order to deal with the vicitudes of life. So I think that this context sensitivity plasticity is just a very face of biology, but it means that the problem between the mismatch, what you can show in the lab and what will go on outside of that is going to be present in a way that you won't find in physics. Does that, so when you're talking about plants, I immediately thought, if you raise a plant inside with no wind, it's also going to be less adaptable or plastic, right? So you need to like take it outside every once in a while, let it experience weather. That's right. You want it to grow a strong, healthy plant. So there's always, in some sense, it's just hard to control for for anything, right? And these, especially with complex systems. And you said that psychology is kind of at the one end of the height of complexity, but then isn't there sociology? Quoting quote above that is, would that be, I don't know how you think about this? Yeah, so thinking like an extreme example, yeah, a few extreme one subject that you can put in a lab, you can't put a society in a lab. But yeah, so this notion that the sciences get orders by levels of complexity that was put forward by August Compton in the 19th century, he's the father of positivism. He also coined the word sociology. So he said that physics studies the things which are simplest and the laws are most general precisely because the things that they study don't change their behaviour, depending on various things that you do to them, but then you build up from there to chemistry, to biology, psychology, and then sociology at the top. That was his model. And soon galaxies of organisms, right? Well, maybe. I lost my train of thought where I was going to go. In large sense, the modern boom of like dynamical systems theory in neuroscience is imported from physics essentially. So I'm interested in a process, processural perspective in studying these things and I struggle to figure out how to do it. And dynamical systems is an inch toward that, because it treats systems not as stable things, although it kind of does, it still reduces to a state, right? And you can have a trajectory through a state space. And you're still defining a space, which is a mathematical abstracted, stable, static thing. And so it's not exactly the the full kind of holistic process based approach that I want. But I'm not sure if it's as good as we can get. Or if it's just like the latest kind of push, I mean, our scientists bound to study static. So you talked about how just counting, you know, is an abstraction to a static thing, as if it's a thing. I mean, are we bound to that approach? Can we not study things in a different approach? Do we always have to study things as if they're static? Yeah. Yes. So what I'm talking about in the book there is how one of the ways that the brain is extremely complex and challenging to investigate is that it's always changing. It never returns to initial conditions. Like how you treat a mouse one day will affect it a long time in advance in ways that you don't know. That's just the nature of what it means to be a living person, living thing with a brain. At least we see from examples that, you know, all of our memories, what happens from day to day, it means that we're never quite the same person going forward. And I think that's probably true in animal life as well. So there is this inherent changeability. It makes sense if you think about what brains have to do, which is deal with a constantly changing environment. Like I said, with the plant, you know, to survive in an unconstrained ecosystem, they have to have all of this plasticity and they just stuck it in one place. Animals, again, they have to move around and deal with novel situations, all the time. So experience is always affecting us. But in science, so much of the drive is towards inductive knowledge. So actually being able to use past experience in order to predict what happens in the future. So going from, okay, we've found property X causes, causes Y in the past. We want to see how stable that relationship is. So going forward, when X happens, we'll see that why will happen. Maybe most of science has that inductive character. You're looking for stable regularities that you can expect to hold in the future. Hume's problem of induction, just asks the question, how do we know that induction will work? Well, it always worked in the past, but that's just applying induction to say it worked in the past, so it should have applied in the future. And he says that what we're banking on really is the assumption of the unity, formative nature, he calls it. We just assume that nature is stable enough for us to be able to reliably base future expectations on past experience. Now, obviously this works enough, most of the time for us to get by. But the question is when we're wanting to do very precise science of changeable complex systems, maybe we start to see that principle of uniformity of nature not quite worked for us in the ways that we wanted to. And maybe we start to see some limits of how much knowledge that we can acquire through induction and how much prediction we can gain through that. On the other hand, it's impressive in complex systems that you do get reproducibility in many respects and stability. Yeah, so that's right. I mean, if we look at animal behavior, it's not completely unpredictable, chaotic or anything like that. So what I'm talking about with complexity here isn't just stochasticity or chaos, but what I'm talking about is sensitivity to factors which cannot be anticipated and you cannot just base, you cannot do or make almost the amount of characterization that you have to do to be able to make very rigorous inductive predictions as kind of being exhaustible. Yeah. One of the things that I wanted to ask about in this goes back to the very beginning of our conversation is your trend toward, so you argue that we should think of organisms as being embodied and embedded in nature. And there's this ecological psychology kind of bent that you have. Yeah. But and so maybe you can comment on that at the same time, you say that maybe the the 4-E approach the embodied and active embedded. What is it? I can never get the embedded ecological ecological. Thank you. The 4-E approach is is something that philosophy maybe can work with. But it's not something necessarily that neuroscience itself can work with. So that's what I really wanted you to sort of extrapolate and discuss a little bit. Yeah. So the way that I argue for that point is to look at how in order to simplify and come up with workable rigorous models and science, you know, where you have a small number of well-constrained variables and you can show the quantitative relationships between them, you need to impose boundaries around a system. You can't go along with the idea that this system is somehow this I mean this item over here is somehow boundlessly interacting with everything around it. You have to treat things more, you know, as far as possible as closed systems to do that rigorous theoretical work. And I'm saying that the core insight of the 4-E tradition is actually to appreciate that what it is to be a minded being is to be somehow boundless interfacing with your environment. So the brain is sort of boundlessly richly interfacing with the rest of the body and the body is richly interfacing with its environment. And that's what cognition is. It's this very rich interactive process. So I'm saying there's this trade-off between having that insight, acknowledging that and actually wanting to do rigorous science which means you need to start enforcing boundaries from things and treating the brain as if it's more or less an isolation from the rest of the body. So you're ignoring vascular to you, ignoring immunology, you're ignoring the most different neuroscience the rest of the brain and just looking at the circuit in isolation. You need that to do the kind modeling work that sets the standards for rigor and the theorization. But it, yeah, you cannot you cannot then hold on to that insight. Well actually what's really going on when things are cognitively interacting with their environment is that there's just numerous or innumerable channels of interaction and sensitivity. So then first of all, what do 4E scientists, apologists, what do they think about this claim that essentially that the embodied perspective is just that. It's a perspective that almost can't be approached by science. Yeah, well I mean the book isn't out yet so I'm waiting to hear what what responses it elicited. Yeah, I've discussed it actually a bit with my colleague Dave Wardhase that we ran a reading group on the manuscript and he's he's a philosopher he works on 4E cognitive science. So he's he told me he's writing a paper which actually pushes back to some extent. Oh okay cool. Well I said so I'm waiting to read that and hopefully others will tell me. I mean this is this is a thing in philosophy when you start after an argument like that you know well you want to hear a lot of the people saying because I'm sure there are responses that can be made to that. I mean I think the key thing will be to look at examples of work in science which has actually managed to mediate this tension. I mentioned Gibson before someone that was influential on me and the people that mentored me in vision science. I don't think his whole research career was a waste of time so I think there is an inherent tension there and I do think that philosophy probably is the better arena for working out these 4E insights but I don't think that it means that mainstream science should just completely ignore 4E principles. I mean what I say in the book about Gibson is that he had he was an important figure but also to some extent people looked at him and said well that's not really how we should be doing things. And that ecological psychology has sort of struggled to attain the prestige of other branches of psychology and I'm saying well maybe that's why maybe it's because they were trying to mediate this path where there is just an inherent tension or an inherent compromise that can't easily be struck. So this is a theme I regularly felt when reading your book and there's a tension in myself. I'm always wanting to think like how I said this about you know process philosophy and I think about about ecological psychology like how can this inform what I'm doing as a neuroscientist right? So some sort of like what is applicable philosophy or something for neuroscience. Yeah. And then I'm like reading your book I constantly had this I recurrently had this feeling of sort of a letting go and saying okay well it can't really inform what I'm doing but what it can do is serve as a sort of checks and balances in my own mind about what I'm doing. But then how much there's a tension between that and like what I want to be doing is figuring these things out that you're constantly reminding me that using the tools that I have as a scientist I can't approach essentially. So I'm trying to understand like what what good is it to be able you know this letting go and accepting that there are these and we'll get into mind maybe eventually if we have time accepting that there are these things that aren't touchable that they're with the tools that I'm using these days. That's interesting to reflect on that because I wrote this book as someone no longer doing your scientific research. And you don't care anymore you don't care how that side you don't need well no I can. I think you you phrase it as you're not bound to the same epistemic aims or something like that. Yeah exactly. Another way to say that is that you don't care anymore. No but I'm not I'm not in that situation of philosophically speaking having a a view say a four-use empathetic view or a processual view and then also trying to play that out in a research in a research environment in neuroscience. So that's the tension I'm not feeling. Yeah I mean I I had more in in mind as a stereotype neuroscientist here someone who who is a just a hardcore computationalist and just thinks aha that's the philosophy and that is supported by the results that I'm getting and saying no the philosophy that you have is a convenient like simplifying strategy you shouldn't let this success of this modeling strategy the you know the impressiveness of these results convince you that that philosophical position is is wrong that actually we should hold on to those insights of the foree tradition which are points into criticisms with that hardcore computationalism. So it's really just the interpretation of what you're doing instead of the you're saying mm-hmm like is that sorry? You're you're agreeing with me that it's it's more about the interpretation of your scientific result. What I'm wondering is like what the danger is to me because I accept your arguments essentially in this book and in some sense I know I feel like a leaf blowing in the wind so frequently when I read things like this because I'm like oh yeah she's right she's right oh yeah that's right you know however I feel about it but then I thought is there like a a dainn you know what is one of the repercussions for me moving forward if I accept you know the all these views it's just a my own interpretation of what I'm doing isn't it? Yeah I suppose it is though I find this already interesting question and it's a disaster that I mean it's nice to hear that you found it compelling and um it is compelling but part of the reason is because you you're constantly reminding the reader it's it's okay it's fine you know you can let go and it's fine because I because you have no metaphysical claim on things either right so you're metaphysically neutral go ahead sorry yeah I mean I don't I don't see the danger I'm not saying you should give up your day job and not do this kind of research I'm saying that if your long-term goal as a neuroscience test is to discover that the essential features of the brain systems that lead to certain cognitive capacities then this isn't the right way to go about this so yeah it's saying that you have to be more modest about what you think the neuroscience will lead you to for people like me who went into neuroscience precisely because they wanted to learn about things philosophically deep I'm saying you might be dissatisfied and so for neuroscientists who are so actively still trying to tap that yeah maybe that is bad news well but I mean the other bad news for someone like me right is that there is one of the conclusions that you make in the book is that there is a fundamental limit on on what science can say about even brains not even minds right so studying something as complex as the brain in itself yeah so that's you know it's a disheartening conclusion but at the same time you also say but it's okay it's okay you can keep doing what you're doing yeah I mean so what is the one one of the ideas there is that yeah there's limits to what can be discovered through this third person methodology like taking the brain as this external objects and sort of employing the methods of mathematician and so forth but it doesn't mean that there are other methodologies that given that limitation one might want to see as complementary to it I mean if you think of our first person experience of our own mental lives our second person experience of interacting with other people it just seems right to say these also give us insights into what it means to be an embodied person with a brain it's just that it hasn't had the prestige of science so I think one of the targets of my book is scientism this notion that science by itself will have all the answers to the questions that are important to us and by saying well there are limitations to what it can tell us about how the brain gives rise to mental life what it means to be a cognizing person employing their brain then that opens the door to other approaches that you should see as complementary to that and not think that they don't have a place because in confrontation to science they're not using the same methods but those same limits don't apply to control as an as an aim of science right so just on the understanding part yeah exactly so my point about control is that we should realize that it occurs by making the thing that you are aiming to control very very often right so you can I don't know create certain cyborg systems etc etc etc that can instantiate behaviors that you might want them to do tweaking the brain I think if you take control to be translation across the board then that suggests like pessimism about that so if your aims are control of all of the wild type unconstrained phenomena yeah my message there isn't so positive though you might I mean it technology is always unpredictable people just so indefinitely discover hacks for this and that but I think it's somewhat pessimistic about systematic discovery of all of the things that one might want to learn to control through lab experiments then translate it beyond the lab I mean maybe I wonder what you think about brain computer interfaces right so this is an interesting case where you can put some electrodes in someone's brain read out a very very small proportion of their neural and firing activity yeah run it through a quite simple it turns out yeah mathematical transformation like a linear decoder and still get the person being able to or animal being able to control like a cursor on a screen without moving a hand or something like that so it's so that level of control is actually quite my point is that it's interesting that you can use such relatively dumb simple things for a complex system although so my question is like what you think about that I mean I wasn't going to ask you this I didn't prepare to ask you this but because in a sense then you are creating a technology in an an away your understanding what do you understanding then like what is the technology that you're understanding then if you're controlling a very that's a reduced preparation yeah yeah no I think that's a really interesting example and so when I was in Pittsburgh yeah I got to know some of the work of the Schwartz lab and the Schwartz yeah and yeah and they were using these you know quite simple linear models to decode motor cortex and and because I noticed notice the parallel with the modeling that I was doing primary visual cortex and this thing but how can such simple basically linear models actually get you anywhere with this the what was interesting about the BCIs is that there's a certain amount of learning that goes on so right right people and your brain is adapting right is adapting to gets the feedback over what signals needs to be sort of tweaked so that it will get the custom movement that at once so there's an element you plug you plug in and it's not like I can move a robot arm where I want it you have to it takes training yeah you spend a pretty good deal of time in the book talking about using artifice these artificial neural networks and this has been to model brain activity to understand brains and this has been the modern trend it's a hot topic in neuroscience and machine learning it's podcast is a lot yeah or used to be about anyway I don't know if it is anymore so much in fact I'm going to moderate a panel in a couple days about neuro AI yeah you know this this convergence or match between neuroscience and AI but and you say these yes these are very these are complex models they're also way way simpler and abstracted than the things that they're modeling and therefore that they're subject to the exact same limitations essentially yeah that's right I mean so one thing about so artificial neural networks and this sort of the brain inspired confluence that we're talking about here is that I think there were hopes for it being the technology that would lead to theoretical insights in the brain so as we talked about before like having the invention that then reveals some general principles of cognition I think people in hope are still high those are hopes are still yeah yeah it's maybe not in my mind anymore but you've let go yeah yeah yeah but what I'm still pointing out here is the theoretical assumption behind these which everyone's well aware of that it's only this very abstracted level of neural wiring connection strengths that assume to be the cognitively relevant properties of the brain there's so much evidence that there's many layers of biological complexity that are important for biological cognition so even though we can have superficial similarities with what an ANN does and what biological brain does I think we're not going to get much beyond the superficial similarities basically because I think the assumption that cognition just is taking place at that marion very top level independent of implementational details I just don't think that's correct anymore for reasons that I give in the book and elsewhere I mean one of the things that has got me interested in that basal cognition field is precisely the reasons for thinking that the principles of information processing within biology are very pervasive in cellular life so it's like electrical signaling you see in on totany and development all kinds of things to do with just basic biological maintenance that it's turned out to be fruitful to characterize in certain terms that are cognition like it makes it then seem implausible to me that in the brain all of those inherently biological processes are not also somehow relevant to cognition which is what assumes in that ANN approach that there's a hard way the implementation is a rather fun yeah yeah you talk about this in terms of multiple realized ability degeneracy and I've been thinking along these lines for some time now as well you know and you have influenced me over the years in this respect as of others thinking about the importance of life processes in these cognitive terms but you know there's still attention in that you can get a long way with just this computational super abstracted approach but so then what else left is there and there's that space of well biological life processes are important for cognition this also depends on how we define cognition because I think a modern computationalist approach would just define cognition as the functions yeah the output or something I'm just choosing the right thing and so there's a certain amount of redefining right I'd be going on here as well but but this is one reason and well let me step back because all right so we've talked about artificial networks and what you don't write about I think in the book are these the idea of like the blue brain project and these massive simulations where you're essentially trying to emulate as many biological details as you can with in a system and so I'm wondering what you think about that I think what you're going to say is something that you did write about in your book and that's if you if you simulate or emulate or model all of the biological details you no longer have a model you have a a neuron yeah exactly yeah I mean every model has to be an abstraction you've got a model without an abstraction it's not a model anymore it's it's the thing that you were it started out with so I think I'm yeah I'm not saying that a super bioreal realistic models are inherently better I think the notion of the inherently vast model is is a flawed notion because different models are good for different purposes so very simplified models can be great depending on your purposes what I'm sort of backing away from and encouraging people not to subscribe to is this notion that a simplified model can be you know give you all of the essential characteristics of the target because if you think that you're you're forgetting that it's a simplification yeah so for many projects and you've talked about prediction and control simplified models can be superior because they might just hone in on a couple of variables that happen to be relevant to the predictions that you want to make so I think there's always you know balances and compromises and trade-offs between like the level of detail that's workable and relevant and useful to your projects and all of that I mean if you take the blue brain project and the human brain project from what I understand I met a researcher in science technology studies Taram Alfred who actually did some field research with the human brain project and she talks about how for the experimentalists that were collaborating on this project these models were much too simplified there was they weren't biorealistic enough because they were having to make compromises in the models like assuming identity across different organisms and across different labs that if you knew the details you'd see that actually this is very much an idealized representation and so then you have to ask for the purposes for the scientific questions that they were posing themselves was this the right compromise I think other people in the computational neuroscience community said no this is this is needlessly detailed for the questions that they want to pose so yeah but but if if we did and this is just a thought experiment if we did recreate let's say the simulation of a or a robotic full brain in some anemat that's moving in the environment right and could pass the embodied Turing test my question is where is the line between good because I agree that there's something special about the biological processes but where is the line if we can recreate it down to some almost limit right almost a limit of some asymptote where we're really really close to the real thing I mean is there is that is the abstraction just that one last point 0 0 0 1 to get to the real thing is that where the special differences or do we just call that thing that's close enough to we call it life at that point and then we're satisfied and of course then we wouldn't be able to understand according to your analysis but I mean is there something special about life itself or would we call that life we like where do you sit in your thought experiment is this yeah like a biomimetic system that does everything that an organism does like feeding itself has motivations goals embedded I'm just trying to get as close as possible to where to make you uncomfortable okay to know is it constantly fighting against the thermodynamic all of that I mean so so when in this in this sort of life minds continuum field it's the sort of basic biological needs of having to work against entropy they're having to take energy from your environment having to maintain that environment body boundary that are taken to be sort of very basic to what it is to also be a cognizing thing so I think in principle if an artifact is having those same challenges and having to do the same things I don't see why we wouldn't think it as a maximally close to evolved biology but if it is you know something like a current robot that isn't having to do all of those self maintenance things but is in a superficial way copying some cognitive characteristics that's why I think we should hesitate to say that it's really cognizing as opposed to giving like a club a mimicry of cognizing yeah okay I won't push you too hard on that but especially because of time constraints but I do want to just mention briefly in this segues from your focus and appreciation of biological processes and being far away from thermal thermodynamic equilibrium as a fundamental aspect of cognitive organisms you go on to conclude so you talk about the mind and consciousness for I don't know if it's a whole chapter but you go on to conclude that fundamentally something like consciousness is will forever be in the realm for philosophers and not scientists do am I stating that correctly and yeah so so I'd say it's outside the premises of the computationalist tradition okay because what computationalist do is draw in this analogy between computing systems which I think no one has any reason to think are conscious and biological systems which can be conscious and explains things in terms of what's similar between those two but if you're lensed through which you're trying to theorize biological cognition is always through those similarities with a non-conscious machine that's why I think consciousness will resist that traditional fall outside what's expected in that tradition yeah when I these days there's so much of neuroscience as computational neuroscience that it's it's almost by default when I say science I mean computational neuroscience right but the reason why I brought up consciousness here is because you go from this like you have the perspective that that these biological properties are necessary you make an argument and conclude that it's biology that only biology can be conscious and you know I'll leave it to listeners to read that in the book yeah because it's sort of a grand conclusion in some sense yeah um well with the caveat that if you have a very biomimetic artifacts that it could be so but no the point is that to understand what cognition and I think consciousness is made probably more central to cognition than people have tended to assume on the basis of that computational framework which thinks of consciousness as like epiphenomenon and the real work is all of the computational processes but no once you appreciate that there is um the centrality of just biological sort of life maintenance to what we mean or what it is to be a cognizing thing um then it just looks less and less plurable plausible that a fully non-living thing um kid have all of that which cognitive life that is one a self consciousness okay well I will conclude by thanking you again for the book I really I love the book and congratulations on it um this will be out it'll the book will be out when this airs um and it was it am I okay to say it it's like free digitally and if people want a physical copy then they can also get that yeah yeah now well thank you thank you so much for reading it and kind of it's that you said about it oh I'm gonna be revisiting it and I'm I'm of course because of people like you I've been influenced to be interested in things like basal cognition so I'm looking forward to that work coming out as well so thanks much you too that was thanks very much really I still can see bye bye I alone produce brain inspired if you value this podcast consider supporting it through Patreon to access full versions of all the episodes and to join our discord community or if you want to learn more about the intersection of neuroscience and AI consider signing up for my online course neuro AI the quest to explain intelligence go to braininspired.co to learn more to get in touch with me email paul at braininspired.co you're hearing music by the new year find them at the new year.net thank you thank you for your support see you next time